{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fastai.tabular import *\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "from fastai.basic_data import DataBunch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "TYPES              = np.array(['1JHC', '2JHH', '1JHN', '2JHN', '2JHC', '3JHH', '3JHC', '3JHN'])\n",
    "TYPES_MAP          = {t: i for i, t in enumerate(TYPES)}\n",
    "SC_EDGE_FEATS      = ['type_0', 'type_1', 'type_2', 'type_3', 'type_4', 'type_5', 'type_6', 'type_7', 'dist',\n",
    "                      'dist_min_rad', 'dist_electro_neg_adj', 'normed_dist', 'diangle', 'cos_angle', \n",
    "                      'cos_angle0', 'cos_angle1']\n",
    "MOL_FEATS          = ['num_atoms', 'num_C_atoms', 'num_F_atoms', 'num_H_atoms', \n",
    "                      'num_N_atoms', 'num_O_atoms']\n",
    "N_EDGE_FEATURES    = 8\n",
    "N_SC_EDGE_FEATURES = 16\n",
    "N_MOL_FEATURES     = 6\n",
    "N_ATOM_FEATURES    = 20\n",
    "N_TYPES            = len(TYPES)\n",
    "N_MOLS             = 130775\n",
    "SC_MEAN            = 16\n",
    "SC_STD             = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../tmp/'\n",
    "# PATH = '../input/champs-processed-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['atomic_features.csv',\n",
       " 'train_proc_df.csv',\n",
       " 'mask.csv',\n",
       " 'edge_mask.csv',\n",
       " 'atom_df.csv',\n",
       " 'pairs_idx.csv',\n",
       " 'edge_df.csv',\n",
       " 'edge_features.csv',\n",
       " 'test_proc_df.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(PATH)\n",
    "files = [f for f in files if f.find('.csv') != -1]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/python36/lib/python3.6/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(PATH+'train_proc_df.csv', index_col=0)\n",
    "test_df  = pd.read_csv(PATH+'test_proc_df.csv', index_col=0)\n",
    "atom_df  = pd.read_csv(PATH+'atom_df.csv', index_col=0)\n",
    "edge_df  = pd.read_csv(PATH+'edge_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['scalar_coupling_constant'] = (train_df['scalar_coupling_constant'] - SC_MEAN) / SC_STD\n",
    "train_df[['num_atoms', 'num_C_atoms', 'num_F_atoms', 'num_H_atoms', 'num_N_atoms', 'num_O_atoms']] /= 10\n",
    "test_df[['num_atoms', 'num_C_atoms', 'num_F_atoms', 'num_H_atoms', 'num_N_atoms', 'num_O_atoms']] /= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MEGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_init(m): pass\n",
    "#     if type(m) == nn.BatchNorm1d:\n",
    "#         nn.init.ones_(m.weight)\n",
    "#         nn.init.zeros_(m.bias)\n",
    "\n",
    "def selu_weights_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        fan_in = m.weight.size(1)\n",
    "        nn.init.normal_(m.weight, 0.0, 1.0 / math.sqrt(fan_in))\n",
    "        nn.init.zeros_(m.bias)\n",
    "    bn_init(m)\n",
    "\n",
    "def relu_weights_init(m): \n",
    "#     if type(m) == nn.Linear:\n",
    "#         nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "#         nn.init.zeros_(m.bias)\n",
    "    bn_init(m)\n",
    "\n",
    "def hidden_layer(n_in, n_out, batch_norm, dropout, act=None):\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(n_in, n_out))\n",
    "    if act: layers.append(act)\n",
    "    if batch_norm: layers.append(nn.BatchNorm1d(n_out))\n",
    "    if dropout != 0: layers.append(nn.Dropout(dropout))\n",
    "    return layers\n",
    "\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input, n_output=None, layers=[], act=nn.ReLU(True), dropout=[], batch_norm=False, \n",
    "                 out_act=None, final_bn=False):\n",
    "        super().__init__()\n",
    "        sizes = [n_input] + layers\n",
    "        if n_output: \n",
    "            sizes += [n_output]\n",
    "            dropout += [0.0]\n",
    "        layers_ = []\n",
    "        for i, (n_in, n_out, dr) in enumerate(zip(sizes[:-1], sizes[1:], dropout)):\n",
    "            act_ = act if i < len(layers) else out_act\n",
    "            batch_norm_ = batch_norm if i < len(layers) else final_bn\n",
    "            layers_ += hidden_layer(n_in, n_out, batch_norm_, dr, act_)      \n",
    "        self.layers = nn.Sequential(*layers_)\n",
    "        if type(act) == nn.SELU: self.layers.apply(selu_weights_init)\n",
    "        else: self.layers.apply(relu_weights_init)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenLSTMCell(nn.Module):\n",
    "    \"\"\"Implements the LSTM cell update described in the sec 4.2 of https://arxiv.org/pdf/1511.06391.pdf.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_h_out):\n",
    "        \"\"\"This LSTM cell takes no external 'x' inputs, but has a hidden state appended with the \n",
    "        readout from a content based attention mechanism. Therefore the hidden state is of a dimension\n",
    "        that is two times the number of nodes in the set.\"\"\"\n",
    "        super().__init__()\n",
    "        self.n_h_out, self.n_h = n_h_out, n_h_out * 2 \n",
    "        self.w_h = nn.Parameter(torch.Tensor(self.n_h, n_h_out * 4))\n",
    "        self.b = nn.Parameter(torch.Tensor(n_h_out * 4))\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "                # nn.init.orthogonal_(p.data)\n",
    "            else: \n",
    "                nn.init.zeros_(p.data)\n",
    "                # initialize the forget gate bias to 1\n",
    "                p.data[self.n_h_out:self.n_h_out*2] = torch.ones(self.n_h_out)\n",
    "        \n",
    "    def forward(self, h_prev, c_prev):\n",
    "        \"\"\"Takes previuos hidden and cell states as arguments and performs a \n",
    "        single LSTM step using no external input.\n",
    "        \"\"\"\n",
    "        n_h_ = self.n_h_out # number of output hidden states\n",
    "        # batch the computations into a single matrix multiplication\n",
    "        gates = h_prev @ self.w_h + self.b\n",
    "        i_g, f_g, g, o_g = (\n",
    "            torch.sigmoid(gates[:, :n_h_]), # input\n",
    "            torch.sigmoid(gates[:, n_h_:n_h_*2]), # forget\n",
    "            torch.tanh(gates[:, n_h_*2:n_h_*3]),\n",
    "            torch.sigmoid(gates[:, n_h_*3:]), # output\n",
    "        )\n",
    "        c = f_g * c_prev + i_g * g\n",
    "        h = o_g * torch.tanh(c)\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Set2Set(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted from: https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric\\\n",
    "        /nn/glob/set2set.html#Set2Set\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, proc_steps, n_layers=1):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = 2 * in_channels\n",
    "        self.proc_steps = proc_steps\n",
    "        self.lstm = torch.nn.LSTM(self.out_channels, self.in_channels, n_layers)\n",
    "        self.init_q_star = nn.Parameter(torch.Tensor(1, self.out_channels))\n",
    "        self.init_h = nn.Parameter(torch.Tensor(n_layers, 1, self.in_channels))\n",
    "        self.init_c = nn.Parameter(torch.Tensor(n_layers, 1, self.in_channels))\n",
    "        nn.init.zeros_(self.init_q_star)\n",
    "        nn.init.zeros_(self.init_h)\n",
    "        nn.init.zeros_(self.init_c)\n",
    "\n",
    "    def forward(self, x, node_idx):\n",
    "        \"\"\"\n",
    "        x - input tensor of shape (batch_size * n_nodes, in_channels).\n",
    "        - node_idx: tensor of shape (batch_size * n_nodes) mapping each\n",
    "            node to its corresponding index in the batch.\n",
    "        \"\"\"\n",
    "        batch_size = node_idx.max().item() + 1\n",
    "        h = (self.init_h.expand(-1, batch_size, -1).contiguous(),\n",
    "             self.init_c.expand(-1, batch_size, -1).contiguous())\n",
    "        q_star = self.init_q_star.expand(batch_size, -1).contiguous()\n",
    "        for i in range(self.proc_steps):\n",
    "            q, h = self.lstm(q_star.unsqueeze(0), h)\n",
    "            q = q.view(batch_size, self.in_channels)\n",
    "            e = (x * q[node_idx]).sum(dim=-1, keepdim=True)\n",
    "            a = softmax(e, node_idx, num=batch_size)\n",
    "            r = scatter_add(a * x, node_idx, num=batch_size) # sum 'a*x' over nodes \n",
    "            q_star = torch.cat([q, r], dim=-1)\n",
    "            \n",
    "        return q_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomHead(nn.Module):\n",
    "    def __init__(self, n_input, n_output, pre_layers=[], post_layers=[], act=nn.ReLU(True), dropout=[], \n",
    "                 batch_norm=False):\n",
    "        super().__init__()\n",
    "        n_pre_layers = len(pre_layers)\n",
    "        self.preproc = FullyConnectedNet(n_input, None, pre_layers, act, dropout[:n_pre_layers], batch_norm)\n",
    "        self.postproc = nn.ModuleList([\n",
    "            FullyConnectedNet(pre_layers[-1], n_output, post_layers, act, dropout[n_pre_layers:], batch_norm=False)\n",
    "            for _ in range(N_TYPES)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x, sc_types):\n",
    "        x_ = self.preproc(x)\n",
    "        y = torch.zeros(sc_types.size(0), device=x.device)\n",
    "        for i in range(N_TYPES):\n",
    "            if torch.any(sc_types == i): \n",
    "                y[sc_types == i] = self.postproc[i](x_[sc_types == i]).view(-1)\n",
    "        return y        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Set2SetOutput(nn.Module):\n",
    "    def __init__(self, feat_szs, state_szs, proc_steps, net_args):\n",
    "        super().__init__()\n",
    "        self.feat_combiners = []\n",
    "        self.set2sets = []\n",
    "        for n_feat, n_state in zip(feat_szs[:-1], state_szs[:-1]):\n",
    "            self.feat_combiners.append(nn.Linear(n_feat, n_state))\n",
    "            self.set2sets.append(Set2Set(n_state, proc_steps))\n",
    "        self.feat_combiners = nn.ModuleList(self.feat_combiners)\n",
    "        self.set2sets = nn.ModuleList(self.set2sets)\n",
    "        n_in = 2 * (sum(state_szs[:-1]) + state_szs[0] + state_szs[2]) + state_szs[-1] + sum(feat_szs[-2:])\n",
    "        # n_in = 2 * sum(state_szs[:-1]) + state_szs[-1]\n",
    "        self.head = MyCustomHead(n_in, 1, **net_args)\n",
    "        if type(net_args['act']) == nn.SELU: self.feat_combiners.apply(selu_weights_init)\n",
    "        else: self.feat_combiners.apply(relu_weights_init)\n",
    "    \n",
    "    def forward(self, states, feats, idxs, sc_nodes_idx, sc_types):\n",
    "        \"\"\" \n",
    "        Readout node and edge states and make predictions.\n",
    "        \n",
    "        Args:\n",
    "        - states is a list of node (v), edge(e), sclar coupling edge (sc_e) \n",
    "            and global (u) states of shapes:\n",
    "                (batch_size * n_nodes, n_v), \n",
    "                (batch_size * n_edges, n_e), \n",
    "                (batch_size * n_sc_edges, n_sc_e), \n",
    "                (batch_size, n_u).\n",
    "        - feats is a list of node, edge, sclar coupling edge \n",
    "            and global (u) features of shapes:\n",
    "                (batch_size * n_nodes, n_v_feat), \n",
    "                (batch_size * n_edges, n_e_feat), \n",
    "                (batch_size * n_sc_edges, n_sc_e_feat), \n",
    "                (batch_size, n_u_feat).\n",
    "        - idxs is a list of tensors mapping each node, edge and \n",
    "            scalar coupling to its corresponding index in the batch. \n",
    "            The tensors are of shapes:\n",
    "                (batch_size * n_nodes), \n",
    "                (batch_size * n_edges),\n",
    "                (batch_size * n_sc_edges), \n",
    "                (batch_size * n_sc).\n",
    "        - sc_nodes_idx: tensor of shape (batch_size * n_sc, 2) containing \n",
    "            atom indices of the atoms for which the scalar coupling constant\n",
    "            need to be predicted. Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_types: tensor of shape (batch_size * n_sc) containing the scalar \n",
    "            coupling type of each observation. \n",
    "        \"\"\"\n",
    "        qs, n_sc = [], len(idxs[-1])\n",
    "        for i, (state, feat, idx) in enumerate(zip(states[:-1], feats[:-1], idxs[:-1])):\n",
    "            state = state + self.feat_combiners[i](feat)\n",
    "            qs.append(self.set2sets[i](state, idx))\n",
    "        \n",
    "        # introduce skip connection to final states and global features\n",
    "        inp = torch.cat([q.index_select(0, idxs[-1]) for q in qs] + [\n",
    "            states[0].index_select(0, sc_nodes_idx[:,0]), # final node states of sc atom 0\n",
    "            states[0].index_select(0, sc_nodes_idx[:,1]), # final node states of sc atom 1\n",
    "            states[2][:n_sc], # final node states of sc edges in\n",
    "            states[2][n_sc:], # final node states of sc edges out\n",
    "            states[-1].index_select(0, idxs[-1]), # global state\n",
    "            feats[2][:n_sc], # sc edge features\n",
    "            feats[-1].index_select(0, idxs[-1]) # global features\n",
    "        ], dim=-1)\n",
    "        y = self.head(inp, sc_types)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_sum(src, idx):\n",
    "    out_szs = (idx.max().item() + 1, src.size(1))\n",
    "    idx_ = idx.unsqueeze(-1).repeat(1, out_szs[1])\n",
    "    return torch.zeros(out_szs, device=src.device).scatter_add(0, idx_, src)\n",
    "    \n",
    "def scatter_mean(src, idx):\n",
    "    return scatter_sum(src, idx) / scatter_sum(torch.ones_like(src), idx).clamp(1.)\n",
    "\n",
    "def phi_edge_inp(v, e, u, edge_idx, pairs_idx):\n",
    "    return torch.cat([v.index_select(0, pairs_idx[:,0]),\n",
    "                      v.index_select(0, pairs_idx[:,1]),\n",
    "                      e,\n",
    "                      u.index_select(0, edge_idx)], dim=-1)\n",
    "\n",
    "def last_layer_to_n_output_arg(args):\n",
    "    new_args = {k:v for k,v in args.items() if k!='layers'}\n",
    "    new_args['layers'] = args['layers'][:-1]\n",
    "    new_args['n_output'] = args['layers'][-1]\n",
    "    return new_args\n",
    "    \n",
    "class MEGNetLayer(nn.Module):\n",
    "    def __init__(self, state_szs, phi_args=4*[{}]):\n",
    "        super().__init__()\n",
    "        inp_sz_v  = sum(state_szs)\n",
    "        inp_sz_e = 2*state_szs[0] + state_szs[1] + state_szs[3]\n",
    "        inp_sz_sc_e = 2*state_szs[0] + state_szs[2] + state_szs[3]\n",
    "        inp_sz_u  = sum(state_szs)\n",
    "        \n",
    "        self.phi_v = FullyConnectedNet(inp_sz_v, **last_layer_to_n_output_arg(phi_args[0]))\n",
    "        self.phi_e = FullyConnectedNet(inp_sz_e, **last_layer_to_n_output_arg(phi_args[1]))\n",
    "        self.phi_sc_e = FullyConnectedNet(inp_sz_sc_e, **last_layer_to_n_output_arg(phi_args[2]))\n",
    "        self.phi_u = FullyConnectedNet(inp_sz_u, **last_layer_to_n_output_arg(phi_args[3]))\n",
    "        \n",
    "    def forward(self, v, e, sc_e, u, node_idx, edge_idx, sc_edge_idx, pairs_idx, sc_pairs_idx):\n",
    "        \"\"\"\n",
    "        Performs the MEGNet module part of the state updates.\n",
    "        \n",
    "        Args:\n",
    "        - v: a tensor of node states of shape (batch_size * n_nodes, n_v).\n",
    "        - e: a tensor of edge states of shape \n",
    "            (batch_size * n_edges, n_e).\n",
    "        - sc_e: a tensor of scalar coupling edge states of shape \n",
    "            (batch_size * n_sc_edges, n_sc_e).\n",
    "        - u: a tensor of global states of shape (batch_size, n_u_feat).\n",
    "        - node_idx: tensor of shape (batch_size * n_nodes) mapping each\n",
    "            node to its corresponding index in the batch.\n",
    "        - edge_idx: tensor of shape (batch_size * n_edges) mapping each\n",
    "            edge to its corresponding index in the batch.\n",
    "        - sc_idx: tensor of shape (batch_size * n_sc_edges) mapping each\n",
    "            scalar coupling edge to its corresponding index in the batch.\n",
    "        - pairs_idx: tensor of shape (batch_size * n_edges, 2) mapping atom \n",
    "            indexes (first column) to the other atom indexes they form a \n",
    "            bond with (second column). Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_pairs_idx: tensor of shape (batch_size * n_sc_edges, 2) containing \n",
    "            atom indices of the atoms of scalar coupling edges. Atom indices \n",
    "            are unique to the entire batch.\n",
    "        \"\"\"\n",
    "        # update edges\n",
    "        e = self.phi_e(phi_edge_inp(v, e, u, edge_idx, pairs_idx))\n",
    "        sc_e = self.phi_sc_e(phi_edge_inp(v, sc_e, u, sc_edge_idx, sc_pairs_idx))\n",
    "        \n",
    "        # aggregate edges to nodes\n",
    "        e_v = scatter_mean(e, pairs_idx[:,0]) \n",
    "        sc_e_v = scatter_mean(sc_e, sc_pairs_idx[:,0])\n",
    "        \n",
    "        # update nodes\n",
    "        v = self.phi_v(torch.cat([e_v, sc_e_v, v, u.index_select(0, node_idx)], dim=-1))\n",
    "        \n",
    "        # aggregate edges and nodes to global\n",
    "        e_u = scatter_mean(e, edge_idx) \n",
    "        sc_e_u = scatter_mean(sc_e, sc_edge_idx)\n",
    "        v_u = scatter_mean(v, node_idx)\n",
    "        \n",
    "        # update global state\n",
    "        u = self.phi_u(torch.cat([e_u, sc_e_u, v_u, u], dim=-1))\n",
    "        \n",
    "        return [v, e, sc_e, u]\n",
    "\n",
    "class MEGNetBlock(nn.Module):\n",
    "    def __init__(self, inp_szs=None, preproc_net_args=4*[{}], phi_args=4*[{}]):\n",
    "        super().__init__()\n",
    "        if inp_szs:\n",
    "            self.preproc_nets = [FullyConnectedNet(n_in, None, **net_args) \n",
    "                                 for n_in, net_args in zip(inp_szs, preproc_net_args)]\n",
    "            self.preproc_nets = nn.ModuleList(self.preproc_nets)\n",
    "            self.preproc = True\n",
    "        else:\n",
    "            self.preproc = False\n",
    "        state_szs = [args['layers'][-1] for args in preproc_net_args]\n",
    "        self.megnet_layer = MEGNetLayer(state_szs, phi_args)\n",
    "        \n",
    "    def forward(self, states, idxs, pairs_idx, sc_pairs_idx):\n",
    "        \"\"\"\n",
    "        Updates states.\n",
    "        \n",
    "        Args:\n",
    "        - states is a list of node (v), edge(e), sclar coupling edge (sc_e) \n",
    "            and global (u) states of shapes:\n",
    "                (batch_size * n_nodes, n_v_feat), \n",
    "                (batch_size * n_edges, n_e_feat), \n",
    "                (batch_size * n_sc_edges, n_sc_e_feat), \n",
    "                (batch_size, n_u_feat).\n",
    "        - idxs is a list of tensors mapping each node, edge and \n",
    "            scalar coupling to its corresponding index in the batch. \n",
    "            The tensors are of shapes:\n",
    "                (batch_size * n_nodes), \n",
    "                (batch_size * n_edges),\n",
    "                (batch_size * n_sc_edges).\n",
    "        - pairs_idx: tensor of shape (batch_size * n_edges, 2) mapping atom \n",
    "            indexes (first column) to the other atom indexes they form a \n",
    "            bond with (second column). Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_pairs_idx: tensor of shape (batch_size * n_sc_edges, 2) containing \n",
    "            atom indices of the atoms of scalar coupling edges. Atom indices \n",
    "            are unique to the entire batch.\n",
    "        - sc_types: tensor of shape (batch_size * n_sc) containing the scalar \n",
    "            coupling type of each observation. \n",
    "        \"\"\"\n",
    "        if self.preproc: \n",
    "            states = [self.preproc_nets[i](state) for i, state in enumerate(states)]\n",
    "        return self.megnet_layer(*states, *idxs, pairs_idx, sc_pairs_idx)\n",
    "\n",
    "def act_bn_layer(act, batch_norm, n_out):\n",
    "    layers = [act, nn.BatchNorm1d(n_out)] if batch_norm else [act]\n",
    "    return nn.Sequential(*layers)\n",
    "    \n",
    "class MEGNet(nn.Module):\n",
    "    res_scaling = .5 ** .5\n",
    "    \n",
    "    def __init__(self, n_v_feat, n_e_feat, n_sc_e_feat, n_u_feat, n_blocks=3, proc_steps=10, \n",
    "                 preproc_net_args=4*[{}], phi_args=4*[{}], readout_net_args={}):\n",
    "        super().__init__()\n",
    "        self.n_blocks = n_blocks \n",
    "        feat_szs = [n_v_feat, n_e_feat, n_sc_e_feat, n_u_feat]\n",
    "        for pre_a, phi_a in zip(phi_args, preproc_net_args):\n",
    "            assert pre_a['layers'][-1]==phi_a['layers'][-1]\n",
    "        state_szs = [args['layers'][-1] for args in preproc_net_args]\n",
    "        \n",
    "        # Add preproc net for first block\n",
    "        self.preproc_nets = [FullyConnectedNet(n_in, None, **net_args) \n",
    "                             for n_in, net_args in zip(feat_szs, preproc_net_args)]\n",
    "        self.preproc_nets = nn.ModuleList(self.preproc_nets)\n",
    "        \n",
    "        # Add post skip connection activations and batch norm layers\n",
    "        self.acts = nn.ModuleList([act_bn_layer(args['act'], args['batch_norm'], args['layers'][-1])\n",
    "                                   for args in phi_args])\n",
    "        self.acts.apply(bn_init)\n",
    "        \n",
    "        self.blocks = []\n",
    "        for t in range(n_blocks):\n",
    "            inp_szs = None if t==0 else state_szs\n",
    "            self.blocks.append(MEGNetBlock(inp_szs, preproc_net_args, phi_args))\n",
    "        self.blocks = nn.ModuleList(self.blocks)\n",
    "        self.readout = Set2SetOutput(feat_szs, state_szs, proc_steps, readout_net_args)\n",
    "        \n",
    "    def forward(self, v_feat, e_feat, sc_e_feat, u_feat, node_idx, edge_idx, \n",
    "                sc_edge_idx, sc_idx, pairs_idx, sc_pairs_idx, sc_nodes_idx, sc_types):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - feats is a list of node (v), edge(e), sclar coupling edge (sc_e) \n",
    "            and global (u) features of shapes:\n",
    "                (batch_size * n_nodes, n_v_feat), \n",
    "                (batch_size * n_edges, n_e_feat), \n",
    "                (batch_size * n_sc_edges, n_sc_e_feat), \n",
    "                (batch_size, n_u_feat).\n",
    "        - idxs is a list of tensors mapping each node, edge, scalar \n",
    "            coupling edges and scalar coupling values to its corresponding \n",
    "            index in the batch. The tensors are of shapes:\n",
    "                (batch_size * n_nodes), \n",
    "                (batch_size * n_edges), \n",
    "                (batch_size * n_sc_edges), \n",
    "                (batch_size * n_sc).\n",
    "        - pairs_idx: tensor of shape (batch_size * n_edges, 2) mapping atom \n",
    "            indexes (first column) to the other atom indexes they form a \n",
    "            bond with (second column). Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_pairs_idx: tensor of shape (batch_size * n_sc_edges, 2) containing \n",
    "            atom indices of the atoms of scalar coupling edges. Atom indices \n",
    "            are unique to the entire batch.\n",
    "        - sc_nodes_idx: tensor of shape (batch_size * n_sc, 2) containing \n",
    "            atom indices of the atoms for which the scalar coupling constant\n",
    "            need to be predicted. Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_types: tensor of shape (batch_size * n_sc) containing the scalar \n",
    "            coupling type of each observation. \n",
    "        \"\"\"\n",
    "        idxs = [node_idx, edge_idx, sc_edge_idx, sc_idx]\n",
    "        feats = [v_feat, e_feat, sc_e_feat, u_feat]\n",
    "        states = [self.preproc_nets[i](feat) for i, feat in enumerate(feats)]\n",
    "        for t in range(self.n_blocks):\n",
    "            states_ = states\n",
    "            states_ = self.blocks[t](states_, idxs[:-1], pairs_idx, sc_pairs_idx)\n",
    "            for i, state_ in enumerate(states_): \n",
    "                states[i] = self.acts[i](self.res_scaling * (states[i] + state_))\n",
    "        y = self.readout(states, feats, idxs, sc_nodes_idx, sc_types)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softplus2(nn.Module):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.relu(x) + torch.log(0.5 * torch.exp(-x.abs()) + 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MEGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=100):\n",
    "    # python RNG\n",
    "    random.seed(seed)\n",
    "\n",
    "    # pytorch RNGs\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # numpy RNG\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_ids = train_df['molecule_id'].unique()\n",
    "n_obs = len(mol_ids)\n",
    "split = int(n_obs*0.75)\n",
    "set_seed(100)\n",
    "mol_ids_ = np.random.choice(mol_ids, size=n_obs, replace=False)\n",
    "train_mol_ids, val_mol_ids = pd.Series(mol_ids_[:split]), pd.Series(mol_ids_[split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_mol_sc = train_df.groupby('molecule_id')\n",
    "test_gb_mol_sc = test_df.groupby('molecule_id')\n",
    "gb_mol_atom = atom_df.groupby('molecule_id')\n",
    "gb_mol_edge = edge_df.groupby('molecule_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_np(x):\n",
    "    sz = len(x), len(np.unique(x))\n",
    "    x_one_hot = np.zeros(sz, dtype=np.long)\n",
    "    x_one_hot[np.arange(sz[0]), x] = 1\n",
    "    return x_one_hot\n",
    "\n",
    "class MoleculeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, mol_ids, gb_mol_sc, gb_mol_atom, gb_mol_edge):\n",
    "        self.n = len(mol_ids)\n",
    "        self.mol_ids = mol_ids\n",
    "        self.gb_mol_sc = gb_mol_sc\n",
    "        self.gb_mol_atom = gb_mol_atom\n",
    "        self.gb_mol_edge = gb_mol_edge\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.gb_mol_sc.get_group(self.mol_ids[idx]), \n",
    "                self.gb_mol_atom.get_group(self.mol_ids[idx]), \n",
    "                self.gb_mol_edge.get_group(self.mol_ids[idx]))\n",
    "\n",
    "def np_lst_to_torch(arr_lst, dtype=torch.float):\n",
    "    return torch.from_numpy(np.ascontiguousarray(np.concatenate(arr_lst))).type(dtype)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch_size, n_atom_sum = len(batch), 0\n",
    "    v_feat, e_feat, sc_e_feat, u_feat = [], [], [], []\n",
    "    sc_types, sc_vals = [], []\n",
    "    node_idx, edge_idx, sc_idx, = [], [], []\n",
    "    pairs_idx, sc_nodes_idx = [], []\n",
    "    \n",
    "    for b in range(batch_size):\n",
    "        sc_df, atom_df, edge_df = batch[b]\n",
    "        n_atoms, n_edges, n_sc = len(atom_df), len(edge_df), len(sc_df)\n",
    "        \n",
    "        v_feat.append(atom_df.drop(columns='molecule_id').values)\n",
    "        e_feat.append(edge_df.drop(columns=['idx_0', 'idx_1', 'molecule_id']).values)\n",
    "        sc_e_feat.append(sc_df[SC_EDGE_FEATS].values)\n",
    "        u_feat.append(sc_df[MOL_FEATS].values[0,:].reshape(1,-1))\n",
    "        sc_types.append(sc_df['type'].values)\n",
    "        sc_vals.append(sc_df['scalar_coupling_constant'].values)\n",
    "        \n",
    "        node_idx.append(np.repeat(b, n_atoms))\n",
    "        edge_idx.append(np.repeat(b, n_edges))\n",
    "        sc_idx.append(np.repeat(b, n_sc))\n",
    "        pairs_idx.append(edge_df[['idx_0', 'idx_1']].values + n_atom_sum)\n",
    "        sc_nodes_idx.append(sc_df[['atom_index_0', 'atom_index_1']].values + n_atom_sum)\n",
    "        \n",
    "        n_atom_sum += n_atoms\n",
    "    \n",
    "    v_feat    = np_lst_to_torch(v_feat)\n",
    "    e_feat    = np_lst_to_torch(e_feat)\n",
    "    sc_e_feat = np_lst_to_torch(sc_e_feat)\n",
    "    u_feat    = np_lst_to_torch(u_feat)\n",
    "    sc_vals   = np_lst_to_torch(sc_vals)\n",
    "    sc_types  = np_lst_to_torch(sc_types, torch.long)\n",
    "    node_idx  = np_lst_to_torch(node_idx, torch.long)\n",
    "    edge_idx  = np_lst_to_torch(edge_idx, torch.long)\n",
    "    sc_idx    = np_lst_to_torch(sc_idx, torch.long)\n",
    "    pairs_idx = np_lst_to_torch(pairs_idx, torch.long)\n",
    "    sc_nodes_idx = np_lst_to_torch(sc_nodes_idx, torch.long)\n",
    "    \n",
    "    e_feat = torch.cat(2*[e_feat])\n",
    "    sc_e_feat = torch.cat(2*[sc_e_feat])\n",
    "    edge_idx = torch.cat(2*[edge_idx])\n",
    "    sc_edge_idx = torch.cat(2*[sc_idx])\n",
    "    pairs_idx = torch.cat([pairs_idx, pairs_idx[:,[1,0]]])\n",
    "    sc_pairs_idx = torch.cat([sc_nodes_idx, sc_nodes_idx[:,[1,0]]])\n",
    "    \n",
    "    return (v_feat, e_feat, sc_e_feat, u_feat, node_idx, edge_idx, sc_edge_idx, sc_idx, \n",
    "            pairs_idx, sc_pairs_idx, sc_nodes_idx, sc_types), sc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MoleculeDataset(train_mol_ids, gb_mol_sc, gb_mol_atom, gb_mol_edge)\n",
    "val_ds   = MoleculeDataset(val_mol_ids, gb_mol_sc, gb_mol_atom, gb_mol_edge)\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "val_dl   = DataLoader(val_ds, batch_size, num_workers=8, drop_last=True)\n",
    "db = DataBunch(train_dl, val_dl, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([377, 20])\n",
      "torch.Size([776, 8])\n",
      "torch.Size([2376, 16])\n",
      "torch.Size([20, 6])\n",
      "torch.Size([377])\n",
      "torch.Size([776])\n",
      "torch.Size([2376])\n",
      "torch.Size([1188])\n",
      "torch.Size([776, 2])\n",
      "torch.Size([2376, 2])\n",
      "torch.Size([1188, 2])\n",
      "torch.Size([1188])\n",
      "torch.Size([1188])\n"
     ]
    }
   ],
   "source": [
    "for el in batch[0]: print(el.size())\n",
    "print(batch[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_feat:\n",
      " tensor([[0.0000, 1.0000, 0.0000,  ..., 1.2044, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 1.3088, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 1.3795, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 1.0961, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 1.0954, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 1.1141, 0.0000, 0.0000]])\n",
      "e_feat:\n",
      " tensor([[ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  1.5343,  1.4541],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0941, -0.7425],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0954, -0.7359],\n",
      "        ...,\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0954, -0.8267],\n",
      "        [ 0.0000,  1.0000,  0.0000,  ...,  0.0000,  1.2116, -0.2080],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  1.1141, -0.7270]])\n",
      "sc_e_feat:\n",
      " tensor([[ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.3126],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.3506,  0.7505, -0.0889],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.4220, -0.1738],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.4174,  0.7899,  0.8870],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.3096, -0.9130],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.5106]])\n",
      "u_feat:\n",
      " tensor([[2.3000, 0.7000, 0.0000, 1.4000, 0.0000, 0.2000],\n",
      "        [2.0000, 0.6000, 0.0000, 1.1000, 0.1000, 0.2000],\n",
      "        [2.2000, 0.7000, 0.0000, 1.3000, 0.1000, 0.1000],\n",
      "        [1.2000, 0.3000, 0.0000, 0.5000, 0.1000, 0.3000],\n",
      "        [1.8000, 0.7000, 0.0000, 0.9000, 0.1000, 0.1000],\n",
      "        [1.9000, 0.6000, 0.0000, 1.1000, 0.1000, 0.1000],\n",
      "        [2.0000, 0.7000, 0.0000, 1.1000, 0.1000, 0.1000],\n",
      "        [1.8000, 0.6000, 0.0000, 1.0000, 0.0000, 0.2000],\n",
      "        [1.6000, 0.6000, 0.0000, 0.7000, 0.1000, 0.2000],\n",
      "        [1.3000, 0.4000, 0.0000, 0.4000, 0.4000, 0.1000],\n",
      "        [2.1000, 0.7000, 0.0000, 1.2000, 0.0000, 0.2000],\n",
      "        [1.7000, 0.7000, 0.0000, 0.8000, 0.0000, 0.2000],\n",
      "        [2.1000, 0.9000, 0.0000, 1.2000, 0.0000, 0.0000],\n",
      "        [2.1000, 0.7000, 0.0000, 1.2000, 0.0000, 0.2000],\n",
      "        [1.9000, 0.6000, 0.0000, 1.0000, 0.0000, 0.3000],\n",
      "        [2.3000, 0.8000, 0.0000, 1.4000, 0.0000, 0.1000],\n",
      "        [2.2000, 0.7000, 0.0000, 1.3000, 0.1000, 0.1000],\n",
      "        [1.9000, 0.7000, 0.0000, 1.0000, 0.0000, 0.2000],\n",
      "        [1.5000, 0.6000, 0.0000, 0.6000, 0.2000, 0.1000],\n",
      "        [1.8000, 0.6000, 0.0000, 1.0000, 0.0000, 0.2000]])\n",
      "node_idx:\n",
      " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "         9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "        17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19,\n",
      "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])\n",
      "edge_idx:\n",
      " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "        15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17,\n",
      "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18,\n",
      "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "        12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15,\n",
      "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "        17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "        18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "        19, 19])\n",
      "sc_edge_idx:\n",
      " tensor([ 0,  0,  0,  ..., 19, 19, 19])\n",
      "sc_idx:\n",
      " tensor([ 0,  0,  0,  ..., 19, 19, 19])\n",
      "pairs_idx:\n",
      " tensor([[  0,   1],\n",
      "        [  0,   9],\n",
      "        [  0,  10],\n",
      "        ...,\n",
      "        [375, 364],\n",
      "        [366, 365],\n",
      "        [376, 365]])\n",
      "sc_pairs_idx:\n",
      " tensor([[  9,   0],\n",
      "        [  9,   1],\n",
      "        [  9,   2],\n",
      "        ...,\n",
      "        [363, 376],\n",
      "        [364, 376],\n",
      "        [365, 376]])\n",
      "sc_nodes_idx:\n",
      " tensor([[  9,   0],\n",
      "        [  9,   1],\n",
      "        [  9,   2],\n",
      "        ...,\n",
      "        [376, 363],\n",
      "        [376, 364],\n",
      "        [376, 365]])\n",
      "sc_types:\n",
      " tensor([0, 4, 6,  ..., 4, 6, 0])\n",
      "sc_vals:\n",
      " tensor([ 2.0131, -0.5164, -0.3938,  ...,  0.4345, -0.3822,  2.6998])\n"
     ]
    }
   ],
   "source": [
    "b_dict = dict(v_feat=batch[0][0], \n",
    "              e_feat=batch[0][1], \n",
    "              sc_e_feat=batch[0][2], \n",
    "              u_feat=batch[0][3], \n",
    "              node_idx=batch[0][4],  \n",
    "              edge_idx=batch[0][5], \n",
    "              sc_edge_idx=batch[0][6],   \n",
    "              sc_idx=batch[0][7], \n",
    "              pairs_idx=batch[0][8],\n",
    "              sc_pairs_idx=batch[0][9], \n",
    "              sc_nodes_idx=batch[0][10], \n",
    "              sc_types=batch[0][11], \n",
    "              sc_vals=batch[1])\n",
    "for k,v in b_dict.items(): print(f'{k}:\\n {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_mean_log_mae(y_true, y_pred, types):\n",
    "    proc = lambda x: x.cpu().numpy().ravel() \n",
    "    y_true, y_pred, types = proc(y_true), proc(y_pred), proc(types)\n",
    "    y_true = SC_MEAN + y_true * SC_STD\n",
    "    y_pred = SC_MEAN + y_pred * SC_STD\n",
    "    maes = pd.Series(y_true - y_pred).abs().groupby(types).mean()\n",
    "    return np.log(maes).mean()\n",
    "\n",
    "class GroupMeanLogMAE(Callback):\n",
    "    _order = -20 #Needs to run before the recorder\n",
    "\n",
    "    def __init__(self, learn, **kwargs): self.learn = learn\n",
    "    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['group_mean_log_mae'])\n",
    "    def on_epoch_begin(self, **kwargs): self.input, self.output, self.target = [], [], []\n",
    "    \n",
    "    def on_batch_end(self, last_target, last_output, last_input, train, **kwargs):\n",
    "        if not train:\n",
    "            self.input.append(last_input[-1])\n",
    "            self.output.append(last_output)\n",
    "            self.target.append(last_target)\n",
    "                \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        if (len(self.input) > 0) and (len(self.output) > 0):\n",
    "            inputs = torch.cat(self.input)\n",
    "            preds = torch.cat(self.output)\n",
    "            target = torch.cat(self.target)\n",
    "            metric = group_mean_log_mae(preds, target, inputs)\n",
    "            return add_metrics(last_metrics, [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd, batch_norm, act = 0, False, nn.SELU(False) #Softplus2()\n",
    "n_blocks, proc_steps = 5, 10\n",
    "n_v_feat, n_e_feat, n_sc_e_feat, n_u_feat = N_ATOM_FEATURES, N_EDGE_FEATURES, N_SC_EDGE_FEATURES, N_MOL_FEATURES\n",
    "preproc_net_args = 3*[dict(layers=[100, 100], act=act, dropout=2*[0.0], batch_norm=batch_norm)] \\\n",
    "    + [dict(layers=[200, 200], act=act, dropout=2*[0.0], batch_norm=batch_norm)]\n",
    "phi_args = 3*[dict(layers=[300, 200, 100], act=act, dropout=3*[0.0], batch_norm=batch_norm)]\\\n",
    "    + [dict(layers=[400, 300, 200], act=act, dropout=3*[0.0], batch_norm=batch_norm)]\n",
    "readout_net_args = dict(pre_layers=[1000], post_layers=[500], act=act, dropout=[0.0, 0.0], batch_norm=batch_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(100)\n",
    "model = MEGNet(n_v_feat, n_e_feat, n_sc_e_feat, n_u_feat, n_blocks, proc_steps, \n",
    "                 preproc_net_args, phi_args, readout_net_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEGNet(\n",
      "  (preproc_nets): ModuleList(\n",
      "    (0): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=20, out_features=100, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (3): SELU()\n",
      "      )\n",
      "    )\n",
      "    (1): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=8, out_features=100, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (3): SELU()\n",
      "      )\n",
      "    )\n",
      "    (2): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=100, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (3): SELU()\n",
      "      )\n",
      "    )\n",
      "    (3): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=6, out_features=200, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (3): SELU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (acts): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): SELU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): SELU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): SELU()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): SELU()\n",
      "    )\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0): MEGNetBlock(\n",
      "      (megnet_layer): MEGNetLayer(\n",
      "        (phi_v): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=300, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=300, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (phi_e): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=300, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=300, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (phi_sc_e): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=300, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=300, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (phi_u): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=400, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=400, out_features=300, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=300, out_features=200, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): MEGNetBlock(\n",
      "      (preproc_nets): ModuleList(\n",
      "        (0): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (3): SELU()\n",
      "          )\n",
      "        )\n",
      "        (1): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (3): SELU()\n",
      "          )\n",
      "        )\n",
      "        (2): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (3): SELU()\n",
      "          )\n",
      "        )\n",
      "        (3): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (megnet_layer): MEGNetLayer(\n",
      "        (phi_v): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=300, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=300, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (phi_e): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=300, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=300, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (phi_sc_e): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=300, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=300, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (phi_u): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=400, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=400, out_features=300, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=300, out_features=200, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): MEGNetBlock(\n",
      "      (preproc_nets): ModuleList(\n",
      "        (0): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (3): SELU()\n",
      "          )\n",
      "        )\n",
      "        (1): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (3): SELU()\n",
      "          )\n",
      "        )\n",
      "        (2): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (3): SELU()\n",
      "          )\n",
      "        )\n",
      "        (3): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (megnet_layer): MEGNetLayer(\n",
      "        (phi_v): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=300, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=300, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (phi_e): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=300, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=300, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (phi_sc_e): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=300, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=300, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (phi_u): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=400, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=400, out_features=300, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=300, out_features=200, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): MEGNetBlock(\n",
      "      (preproc_nets): ModuleList(\n",
      "        (0): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (3): SELU()\n",
      "          )\n",
      "        )\n",
      "        (1): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (3): SELU()\n",
      "          )\n",
      "        )\n",
      "        (2): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (3): SELU()\n",
      "          )\n",
      "        )\n",
      "        (3): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (megnet_layer): MEGNetLayer(\n",
      "        (phi_v): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=300, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=300, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (phi_e): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=300, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=300, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (phi_sc_e): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=300, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=300, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (phi_u): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=400, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=400, out_features=300, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=300, out_features=200, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): MEGNetBlock(\n",
      "      (preproc_nets): ModuleList(\n",
      "        (0): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (3): SELU()\n",
      "          )\n",
      "        )\n",
      "        (1): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (3): SELU()\n",
      "          )\n",
      "        )\n",
      "        (2): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (3): SELU()\n",
      "          )\n",
      "        )\n",
      "        (3): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (megnet_layer): MEGNetLayer(\n",
      "        (phi_v): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=300, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=300, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (phi_e): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=300, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=300, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (phi_sc_e): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=300, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=300, out_features=200, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (phi_u): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=400, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=400, out_features=300, bias=True)\n",
      "            (3): SELU()\n",
      "            (4): Linear(in_features=300, out_features=200, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (readout): Set2SetOutput(\n",
      "    (feat_combiners): ModuleList(\n",
      "      (0): Linear(in_features=20, out_features=100, bias=True)\n",
      "      (1): Linear(in_features=8, out_features=100, bias=True)\n",
      "      (2): Linear(in_features=16, out_features=100, bias=True)\n",
      "    )\n",
      "    (set2sets): ModuleList(\n",
      "      (0): Set2Set(\n",
      "        (lstm): HiddenLSTMCell()\n",
      "      )\n",
      "      (1): Set2Set(\n",
      "        (lstm): HiddenLSTMCell()\n",
      "      )\n",
      "      (2): Set2Set(\n",
      "        (lstm): HiddenLSTMCell()\n",
      "      )\n",
      "    )\n",
      "    (head): MyCustomHead(\n",
      "      (preproc): FullyConnectedNet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1222, out_features=1000, bias=True)\n",
      "          (1): SELU()\n",
      "        )\n",
      "      )\n",
      "      (postproc): ModuleList(\n",
      "        (0): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (1): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (2): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (3): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (4): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (5): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (6): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (7): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.2267, -0.1170, -1.0779,  ..., -0.1779, -1.3522,  1.3734],\n",
      "       grad_fn=<IndexPutBackward>)\n",
      "torch.Size([1188])\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(model(*batch[0]))\n",
    "print(model(*batch[0]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(db, model, metrics=[mean_absolute_error], callback_fns=GroupMeanLogMAE, \n",
    "                wd=wd, loss_func=root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(start_lr=1e-7, end_lr=1, num_it=100, stop_div=True)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='9' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      90.00% [9/10 1:59:03<13:13]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>group_mean_log_mae</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.068870</td>\n",
       "      <td>0.077403</td>\n",
       "      <td>0.058338</td>\n",
       "      <td>0.615427</td>\n",
       "      <td>12:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.082214</td>\n",
       "      <td>0.098659</td>\n",
       "      <td>0.080283</td>\n",
       "      <td>0.761751</td>\n",
       "      <td>13:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.064965</td>\n",
       "      <td>0.059671</td>\n",
       "      <td>0.046962</td>\n",
       "      <td>0.362164</td>\n",
       "      <td>13:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.052805</td>\n",
       "      <td>0.052565</td>\n",
       "      <td>0.040239</td>\n",
       "      <td>0.266511</td>\n",
       "      <td>13:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.045977</td>\n",
       "      <td>0.064451</td>\n",
       "      <td>0.050190</td>\n",
       "      <td>0.350891</td>\n",
       "      <td>13:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.037898</td>\n",
       "      <td>0.036675</td>\n",
       "      <td>0.026178</td>\n",
       "      <td>-0.136184</td>\n",
       "      <td>13:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.033944</td>\n",
       "      <td>0.036977</td>\n",
       "      <td>0.027067</td>\n",
       "      <td>-0.226302</td>\n",
       "      <td>13:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.030559</td>\n",
       "      <td>0.030446</td>\n",
       "      <td>0.020958</td>\n",
       "      <td>-0.426712</td>\n",
       "      <td>13:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.029049</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.019257</td>\n",
       "      <td>-0.513017</td>\n",
       "      <td>13:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3018' class='' max='3187', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      94.70% [3018/3187 10:35<00:35 0.0282]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with group_mean_log_mae value: 0.615426778793335.\n",
      "Better model found at epoch 2 with group_mean_log_mae value: 0.36216434836387634.\n",
      "Better model found at epoch 3 with group_mean_log_mae value: 0.2665105164051056.\n",
      "Better model found at epoch 5 with group_mean_log_mae value: -0.13618430495262146.\n",
      "Better model found at epoch 6 with group_mean_log_mae value: -0.22630205750465393.\n",
      "Better model found at epoch 7 with group_mean_log_mae value: -0.42671239376068115.\n",
      "Better model found at epoch 8 with group_mean_log_mae value: -0.5130167603492737.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, max_lr=3e-5, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='group_mean_log_mae',  name='mpnn1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses(skip_start=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
