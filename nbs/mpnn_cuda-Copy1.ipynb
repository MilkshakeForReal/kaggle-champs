{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import deepchem as dc\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.spatial.distance import norm\n",
    "\n",
    "from fastai.tabular import *\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "from fastai.basic_data import DataBunch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPES              = np.array(['1JHC', '2JHH', '1JHN', '2JHN', '2JHC', '3JHH', '3JHC', '3JHN'])\n",
    "TYPES_MAP          = {t: i for i, t in enumerate(TYPES)}\n",
    "N_EDGE_FEATURES    = 7\n",
    "N_SC_EDGE_FEATURES = 9\n",
    "N_ATOM_FEATURES    = 27\n",
    "MAX_N_ATOMS        = 29\n",
    "MAX_N_BONDS        = 58\n",
    "N_TYPES            = len(TYPES)\n",
    "N_MOLS             = 130775"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../tmp/'\n",
    "# PATH = '../storage/CHAMPS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['atomic_features.csv',\n",
       " 'train_proc_df.csv',\n",
       " 'mask.csv',\n",
       " 'edge_mask.csv',\n",
       " 'pairs_idx.csv',\n",
       " 'edge_features.csv',\n",
       " 'test_proc_df.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(PATH)\n",
    "files = [f for f in files if f.find('.csv') != -1]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/python36/lib/python3.6/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(PATH+'train_proc_df.csv', index_col=0)\n",
    "test_df  = pd.read_csv(PATH+'test_proc_df.csv', index_col=0)\n",
    "target = train_df.pop('scalar_coupling_constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_features = np.genfromtxt(PATH+'atomic_features.csv', delimiter=',', dtype=np.int16)\n",
    "edge_features   = np.genfromtxt(PATH+'edge_features.csv', delimiter=',', dtype=np.float64)\n",
    "pairs_idx       = np.genfromtxt(PATH+'pairs_idx.csv', delimiter=',', dtype=np.int16)\n",
    "mask            = np.genfromtxt(PATH+'mask.csv', delimiter=',', dtype=np.int16)\n",
    "edge_mask       = np.genfromtxt(PATH+'edge_mask.csv', delimiter=',', dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_features = atomic_features.reshape(N_MOLS, MAX_N_ATOMS, N_ATOM_FEATURES)\n",
    "edge_features   = edge_features.reshape(N_MOLS, MAX_N_BONDS, N_EDGE_FEATURES)\n",
    "pairs_idx       = pairs_idx.reshape(N_MOLS, MAX_N_BONDS, 2)\n",
    "mask            = mask.reshape(N_MOLS, MAX_N_ATOMS)\n",
    "edge_mask       = edge_mask.reshape(N_MOLS, MAX_N_BONDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MPNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "def hidden_layer(n_in, n_out, batch_norm, dropout, act=None):\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(n_in, n_out))\n",
    "    if act: layers.append(act)\n",
    "    if batch_norm: layers.append(nn.BatchNorm1d(n_out))\n",
    "    if dropout != 0: layers.append(nn.Dropout(dropout))\n",
    "    return layers\n",
    "\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input, n_output, layers=[], act=nn.ReLU(True), dropout=[], batch_norm=False):\n",
    "        super().__init__()\n",
    "        sizes = [n_input] + layers + [n_output]\n",
    "        layers_ = []\n",
    "        for i, (n_in, n_out, dr) in enumerate(zip(sizes[:-1], sizes[1:], dropout+[0.0])):\n",
    "            act_ = act if i < len(layers) else None\n",
    "            batch_norm_ = batch_norm if i < len(layers) else False\n",
    "            layers_ += hidden_layer(n_in, n_out, batch_norm_, dr, act_)      \n",
    "        self.layers = nn.Sequential(*layers_)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class HiddenLSTMCell(nn.Module):\n",
    "    \"\"\"Implements the LSTM cell update described in the sec 4.2 of https://arxiv.org/pdf/1511.06391.pdf.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_h_out):\n",
    "        \"\"\"This LSTM cell takes no external 'x' inputs, but has a hidden state appended with the \n",
    "        readout from a content based attention mechanism. Therefore the hidden state is of a dimension\n",
    "        that is two times the number of nodes in the set.\"\"\"\n",
    "        super().__init__()\n",
    "        self.n_h_out, self.n_h = n_h_out, n_h_out * 2 \n",
    "        self.w_h = nn.Parameter(torch.Tensor(self.n_h, n_h_out * 4))\n",
    "        self.b = nn.Parameter(torch.Tensor(n_h_out * 4))\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            else: \n",
    "                nn.init.zeros_(p.data)\n",
    "                # initialize the forget gate bias to 1\n",
    "                p.data[self.n_h_out:self.n_h_out*2] = torch.ones(self.n_h_out)\n",
    "        \n",
    "    def forward(self, h_prev, c_prev):\n",
    "        \"\"\"Takes previuos hidden and cell states as arguments and performs a single LSTM step using \n",
    "        no external input.\n",
    "        \"\"\"\n",
    "        n_h_ = self.n_h_out # number of output hidden states\n",
    "        # batch the computations into a single matrix multiplication\n",
    "        gates = h_prev @ self.w_h + self.b\n",
    "        i_g, f_g, g, o_g = (\n",
    "            torch.sigmoid(gates[:, :n_h_]), # input\n",
    "            torch.sigmoid(gates[:, n_h_:n_h_*2]), # forget\n",
    "            torch.tanh(gates[:, n_h_*2:n_h_*3]),\n",
    "            torch.sigmoid(gates[:, n_h_*3:]), # output\n",
    "        )\n",
    "        c = f_g * c_prev + i_g * g\n",
    "        h = o_g * torch.tanh(c)\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Set2Set(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted from: https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric\\\n",
    "        /nn/glob/set2set.html#Set2Set\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, proc_steps):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = 2 * in_channels\n",
    "        self.proc_steps = proc_steps\n",
    "        self.lstm = HiddenLSTMCell(self.in_channels)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        x - input tensor of shape (batch_size, n_nodes, in_channels)\n",
    "        mask - integer tensor used to zero out nodes missing in a particualr graph \n",
    "            (not all graphs have 'n_nodes'). Is of shape (batch_size, n_nodes)\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = mask.size(0), mask.size(1)\n",
    "        batch_idx = torch.arange(0, batch_size).expand(n_nodes, batch_size).transpose(0, 1)\n",
    "        h = torch.zeros(batch_size, self.in_channels, device=x.device)\n",
    "        q_star = torch.zeros(batch_size, self.out_channels, device=x.device\n",
    "                            )\n",
    "        mask = (mask.float() - 1) * 1e6\n",
    "        for i in range(self.proc_steps):\n",
    "            q, h = self.lstm(q_star, h)\n",
    "            e = (x * q[batch_idx]).sum(dim=-1)\n",
    "            # set masked nodes not to large negative energy (attention mask will convert this to 0)\n",
    "            e += mask \n",
    "            a = F.softmax(e, dim=-1)\n",
    "            # sum a*x over node dimension \n",
    "            r = torch.sum(a.unsqueeze(-1) * x, dim=1)\n",
    "            q_star = torch.cat([q, r], dim=-1)\n",
    "            \n",
    "        return q_star\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels, self.out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def segment_sum(data, segment_ids):\n",
    "    \"\"\"\n",
    "    Computes the sum along segments of a tensor. Analogous to tf.unsorted_segment_sum.\n",
    "\n",
    "    :param data: A tensor whose segments are to be summed.\n",
    "    :param segment_ids: The segment indices tensor.\n",
    "    :return: A tensor of same data type as the data argument.\n",
    "    \"\"\"\n",
    "    assert all([i in data.shape for i in segment_ids.shape]), \"segment_ids.shape should be a prefix of data.shape\"\n",
    "        \n",
    "    # segment_ids is a 1-D tensor repeat it to have the same shape as data\n",
    "    if len(segment_ids.shape) == 1:\n",
    "        s = torch.prod(torch.tensor(data.shape[1:], device=data.device)).long()\n",
    "        segment_ids = segment_ids.repeat_interleave(s).view(segment_ids.shape[0], *data.shape[1:])\n",
    "\n",
    "    assert data.shape == segment_ids.shape, \"data.shape and segment_ids.shape should be equal\"\n",
    "\n",
    "    num_segments = segment_ids.max() + 1#len(torch.unique(segment_ids))\n",
    "    shape = [num_segments] + list(data.shape[1:])\n",
    "    tensor = torch.zeros(*shape, device=data.device).scatter_add(0, segment_ids, data.float())\n",
    "    tensor = tensor.type(data.dtype)\n",
    "    return tensor\n",
    "\n",
    "class EdgeNetwork(nn.Module):\n",
    "    def __init__(self, n_h, n_e, n_sc_e, net_args={}):\n",
    "        super().__init__()\n",
    "        self.n_e, self.n_h = n_e, n_h\n",
    "        self.adj_net = FullyConnectedNet(n_e, n_h ** 2, **net_args)\n",
    "        self.sc_adj_net = FullyConnectedNet(n_sc_e, n_h ** 2, **net_args)\n",
    "        self.b = nn.Parameter(torch.Tensor(n_h)) # bias for the message function\n",
    "        nn.init.zeros_(self.b)\n",
    "    \n",
    "    def forward(self, h, e, sc_e, mask, edge_mask, pairs_idx, sc_pairs_idx, t=0):\n",
    "        \"\"\"\n",
    "        Compute message vector m_t given the previuos hidden state\n",
    "        h_t-1 and edge features e.\n",
    "        - h: tensor of hidden states of shape (batch_size, n_nodes, n_h)\n",
    "        - e: tensor of edge features of shape (batch_size, n_edges, n_e).\n",
    "        - sc_e: tensor of scalar coupling edge features of shape \n",
    "            (batch_size, n_sc_e).\n",
    "        - mask: tensor used to  zero out nodes missing in a particular \n",
    "            graph (not all graphs have 'n_nodes'). Is of shape \n",
    "            (batch_size, n_nodes)\n",
    "        - edge_mask: tensor of shape (batch_size, n_edges) masking non \n",
    "            present edges.\n",
    "        - pairs_idx: tensor of shape (batch_size, n_edges, 2) mapping atom \n",
    "            indexes (first column) to the other atom indexes they form a \n",
    "            bond with (second column).\n",
    "        - sc_pairs_idx: tensor of shape (batch_size, 2) containing atom \n",
    "            indices of the atoms for which the scalar coupling constant\n",
    "            needs to be predicted.\n",
    "        - t: update iteration. \n",
    "        \"\"\"\n",
    "        batch_size, n_nodes, n_edges = h.size(0), h.size(1), e.size(1)\n",
    "        \n",
    "        # compute 'A(e)'\n",
    "        if t==0: self.a_vect = self.adj_net(e.view(-1, self.n_e))\n",
    "        edge_mask_ = edge_mask.type(torch.uint8)==True\n",
    "        edge_mask_flat = edge_mask.view(-1).type(torch.uint8)==True\n",
    "        \n",
    "        # do the matrix multiplication 'Ah'\n",
    "        a_mat = self.a_vect[edge_mask_flat].view(-1, self.n_h, self.n_h)\n",
    "        h_stacked = torch.cat([h[b,ix,:] for b, ix in enumerate(torch.unbind(pairs_idx[:,:,1]))])\n",
    "        h_stacked = h_stacked[edge_mask_flat]\n",
    "        ah = torch.einsum('bij,bjk->bik', h_stacked.unsqueeze(1), a_mat).squeeze(1)\n",
    "        \n",
    "        # Sum up all 'Ah' per node\n",
    "        n_nodes_per_graph = pairs_idx[:,:,0].max(dim=1).values + 1\n",
    "        unique_idx = pairs_idx[:,:,0] + (torch.cat([\n",
    "                                             torch.zeros(1, dtype=torch.long, device=h.device), \n",
    "                                             n_nodes_per_graph[:-1].cumsum(dim=0)\n",
    "                                         ])).unsqueeze(-1).expand(-1, n_edges)\n",
    "        m_stacked = segment_sum(ah, unique_idx[edge_mask_])\n",
    "        \n",
    "        m_per_graph_lst = torch.split(m_stacked, n_nodes_per_graph.tolist())\n",
    "        m = torch.cat([F.pad(m_, pad=(0, 0, 0, n_nodes - n_nodes_)) \n",
    "                       for m_, n_nodes_ in zip(m_per_graph_lst, n_nodes_per_graph)])\n",
    "        m = m.view(batch_size, n_nodes, self.n_h)\n",
    "        \n",
    "        # add virtual edge messages between atoms of the scalar coupling constant\n",
    "        if t==0: self.a_sc_mat = self.sc_adj_net(sc_e).view(-1, self.n_h, self.n_h)\n",
    "        sc_idx = sc_pairs_idx[:, :, None].repeat(1, 1, self.n_h)\n",
    "        ah_sc = torch.einsum('bij,bjk->bik', h.gather(1, sc_idx), self.a_sc_mat).squeeze(1)\n",
    "        m.scatter_add_(1, sc_idx, ah_sc)\n",
    "        \n",
    "        # add message bias\n",
    "        m += self.b\n",
    "        \n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class GRUUpdate(nn.Module):\n",
    "    def __init__(self, n_h):\n",
    "        super().__init__()\n",
    "        self.n_h = n_h\n",
    "        self.gru = nn.GRUCell(n_h, n_h)\n",
    "        \n",
    "    def forward(self, m, h_prev, mask):\n",
    "        \"\"\"\n",
    "        Update hidden state h.\n",
    "        - h_prev is vector of hidden states of shape (batch_size, n_nodes, n_h)\n",
    "        - m is vector of messages of shape (batch_size, n_nodes, n_h)\n",
    "        - mask is used to  zero out nodes missing in a particualr graph (not all graphs \n",
    "            have 'n_nodes'). Is of shape (batch_size, n_nodes)\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = h_prev.size(0), h_prev.size(1)\n",
    "        h = self.gru(m.view(-1, self.n_h), h_prev.view(-1, self.n_h))\n",
    "        return h.view(batch_size, n_nodes, self.n_h) * mask.unsqueeze(-1).expand(batch_size, n_nodes, self.n_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MyCustomHead(nn.Module):\n",
    "    def __init__(self, n_input, n_output, pre_layers=[], post_layers=[], act=nn.ReLU(True), dropout=[], \n",
    "                 batch_norm=False):\n",
    "        super().__init__()\n",
    "        sizes, n_pre_layers = [n_input] + pre_layers, len(pre_layers)\n",
    "        pre_layers_ = []\n",
    "        for i, (n_in, n_out, dr) in enumerate(zip(sizes[:-1], sizes[1:], dropout[:n_pre_layers])):\n",
    "            pre_layers_ += hidden_layer(n_in, n_out, batch_norm, dr, act)      \n",
    "        self.preproc = nn.Sequential(*pre_layers_)\n",
    "        self.postproc = nn.ModuleList([\n",
    "            FullyConnectedNet(pre_layers[-1], n_output, post_layers, act, dropout, batch_norm)\n",
    "            for _ in range(N_TYPES)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x, i=0):\n",
    "        x_ = self.preproc(x)\n",
    "        y = self.postproc[i](x_)\n",
    "        return y        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Set2SetOutput(nn.Module):\n",
    "    def __init__(self, n_x, n_h, proc_steps, net_args):\n",
    "        super().__init__()\n",
    "        self.n_h, self.n_x = n_h, n_x\n",
    "        self.R_proj = nn.Linear(n_h + n_x, n_h)\n",
    "        self.R_proc = Set2Set(n_h, proc_steps)\n",
    "        self.R_write = MyCustomHead(2 * n_h, 1, **net_args)\n",
    "    \n",
    "    def forward(self, h, x, mask, types=None):\n",
    "        \"\"\"\n",
    "        Update hidden state h.\n",
    "        - h is vector of hidden states of shape (batch_size, n_nodes, n_h)\n",
    "        - x is vector of input features of shape (batch_size, n_nodes, n_x)\n",
    "        - mask is used to  zero out nodes missing in a particualr graph (not all graphs \n",
    "            have 'n_nodes'). Is of shape (batch_size, n_nodes)\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = h.size(0), h.size(1)\n",
    "        m = self.R_proj(torch.cat([h.view(-1, self.n_h), x.view(-1, self.n_x)], dim=1))\n",
    "        m_reshaped = m.view(batch_size, n_nodes, self.n_h)\n",
    "        q = self.R_proc(m_reshaped, mask) \n",
    "        if types is not None:\n",
    "            y = torch.zeros(batch_size, 1, device=x.device)\n",
    "            for i in range(N_TYPES):\n",
    "                if torch.any(types == i): y[types == i] = self.R_write(q[types == i], i)\n",
    "        else:\n",
    "            y = self.R_write(q)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MPNN(nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_e, n_sc_e, update_steps=3, proc_steps=10, enn_args={}, R_net_args={}):\n",
    "        super().__init__()\n",
    "        self.n_h, self.n_x = n_h, n_x\n",
    "        self.M = EdgeNetwork(n_h, n_e, n_sc_e, enn_args)\n",
    "        self.U = GRUUpdate(n_h)\n",
    "        self.R = Set2SetOutput(n_x, n_h, proc_steps, R_net_args)\n",
    "        self.update_steps = update_steps\n",
    "        \n",
    "    def forward(self, x, e, sc_e, mask, edge_mask, pairs_idx, sc_pairs_idx, types):\n",
    "        h = F.pad(x, pad=(0, self.n_h - self.n_x))\n",
    "        for t in range(self.update_steps):\n",
    "            m = self.M(h, e, sc_e, mask, edge_mask, pairs_idx, sc_pairs_idx, t)\n",
    "            h = self.U(m, h, mask)\n",
    "        y = self.R(h, x, mask, types)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Fit MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = 10000 # len(train_df)\n",
    "train_idx, val_idx = train_test_split(np.arange(n_obs), test_size=0.25, shuffle=True, random_state=100)\n",
    "y_train, y_val = target[train_idx].values, target[val_idx].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_target = StandardScaler()\n",
    "y_train = ss_target.fit_transform(y_train.reshape(-1,1))\n",
    "y_val = ss_target.transform(y_val.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def one_hot_encode_np(x):\n",
    "    sz = len(x), len(np.unique(x))\n",
    "    x_one_hot = np.zeros(sz, dtype=np.long)\n",
    "    x_one_hot[np.arange(sz[0]), x] = 1\n",
    "    return x_one_hot\n",
    "    \n",
    "class MoleculeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, y, x, e, mask, pairs_idx, edge_mask):\n",
    "        self.n = len(df)\n",
    "        self.training = y is not None\n",
    "        self.y = y.astype(np.float32) if self.training else None\n",
    "        self.x = x.astype(np.float32)\n",
    "        self.e = e.astype(np.float32)\n",
    "        self.mask = mask.astype(np.float32)\n",
    "        self.pairs_idx = pairs_idx.astype(np.long)\n",
    "        self.edge_mask = edge_mask.astype(np.float32)\n",
    "        self.mol_ids = df['molecule_id'].values.astype(np.long)\n",
    "        self.sc_types = df['type'].values.astype(np.long)\n",
    "        self.sc_e = np.concatenate(\n",
    "            (df['dist'].values.reshape(-1,1), \n",
    "             one_hot_encode_np(self.sc_types)), \n",
    "            axis=1\n",
    "        ).astype(np.float32)\n",
    "        self.sc_pairs_idx = df[['atom_index_0', 'atom_index_1']].values.astype(np.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        m_idx = self.mol_ids[idx]\n",
    "        x_ = torch.from_numpy(self.x[m_idx])\n",
    "        sc_pairs_idx_ = torch.from_numpy(self.sc_pairs_idx[idx])\n",
    "        sc_bool = torch.zeros(x_.size()[:-1])\n",
    "        sc_bool.scatter_add_(sc_pairs_idx_.dim()-1, sc_pairs_idx_, torch.ones_like(sc_bool))\n",
    "        xs = (\n",
    "            torch.cat([x_, sc_bool.unsqueeze(-1)], dim=-1), \n",
    "            self.e[m_idx], \n",
    "            self.sc_e[idx], \n",
    "            self.mask[m_idx], \n",
    "            self.edge_mask[m_idx],\n",
    "            self.pairs_idx[m_idx],\n",
    "            sc_pairs_idx_,\n",
    "            self.sc_types[idx]\n",
    "        )\n",
    "        if self.training: return xs, self.y[idx]\n",
    "        else: return xs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_.dim()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_idx = train_ds.mol_ids[idx]\n",
    "x_ = torch.from_numpy(train_ds.x[m_idx])\n",
    "sc_pairs_idx_ = torch.from_numpy(train_ds.sc_pairs_idx[idx])\n",
    "sc_bool = torch.zeros(x_.size()[:-1])\n",
    "print(sc_pairs_idx_.size(), sc_bool.size())\n",
    "sc_bool.scatter_add(sc_pairs_idx_.dim()-1, sc_pairs_idx_, torch.ones_like(sc_bool))\n",
    "torch.cat([x_, sc_bool.unsqueeze(-1)], dim=-1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MoleculeDataset(train_df.iloc[train_idx], y_train, atomic_features, edge_features, \n",
    "                           mask, pairs_idx, edge_mask)\n",
    "val_ds   = MoleculeDataset(train_df.iloc[val_idx], y_val, atomic_features, edge_features, \n",
    "                           mask, pairs_idx, edge_mask)\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=8)\n",
    "val_dl   = DataLoader(val_ds, batch_size, num_workers=8)\n",
    "db = DataBunch(train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 29, 28])\n",
      "torch.Size([20, 58, 7])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([20, 29])\n",
      "torch.Size([20, 58])\n",
      "torch.Size([20, 58, 2])\n",
      "torch.Size([20, 2])\n",
      "torch.Size([20])\n",
      "torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "for el in batch[0]: print(el.size())\n",
    "print(batch[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "code_folding": [
     0,
     7,
     29
    ]
   },
   "outputs": [],
   "source": [
    "def group_mean_log_mae(y_true, y_pred, types):\n",
    "    y_true, y_pred, types = y_true.cpu().numpy().ravel(), y_pred.cpu().numpy().ravel(), types.cpu().numpy().ravel()\n",
    "    y_true = ss_target.mean_ + y_true * ss_target.scale_\n",
    "    y_pred = ss_target.mean_ + y_pred * ss_target.scale_\n",
    "    maes = pd.Series(y_true-y_pred).abs().groupby(types).mean()\n",
    "    return np.log(maes).mean()\n",
    "\n",
    "class GroupMeanLogMAE(Callback):\n",
    "    _order = -20 #Needs to run before the recorder\n",
    "    types_cidx = 2\n",
    "\n",
    "    def __init__(self, learn, **kwargs): self.learn = learn\n",
    "    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['group_mean_log_mae'])\n",
    "    def on_epoch_begin(self, **kwargs): self.input, self.output, self.target = [], [], []\n",
    "    \n",
    "    def on_batch_end(self, last_target, last_output, last_input, train, **kwargs):\n",
    "        if not train:\n",
    "            self.input.append(last_input[-1])\n",
    "            self.output.append(last_output)\n",
    "            self.target.append(last_target)\n",
    "                \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        if (len(self.input) > 0) and (len(self.output) > 0):\n",
    "            inputs = torch.cat(self.input)\n",
    "            preds = torch.cat(self.output)\n",
    "            target = torch.cat(self.target)\n",
    "            metric = group_mean_log_mae(preds, target, inputs)\n",
    "            return add_metrics(last_metrics, [metric])\n",
    "\n",
    "def set_seed(seed=100):\n",
    "    # python RNG\n",
    "    random.seed(seed)\n",
    "\n",
    "    # pytorch RNGs\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # numpy RNG\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd, batch_norm = 0, False\n",
    "update_steps, proc_steps = 5, 10\n",
    "n_x, n_h, n_e, n_sc_e = N_ATOM_FEATURES + 1, 50, N_EDGE_FEATURES, N_SC_EDGE_FEATURES\n",
    "enn_args = dict(layers=[50, 50, 50, 50], act=nn.ReLU(True), dropout=[0.0, 0.0, 0.0, 0.0], \n",
    "                batch_norm=batch_norm)\n",
    "R_net_args = dict(pre_layers=[500, 500], post_layers=[500, 200], act=nn.ReLU(True), dropout=[0.0, 0.0, 0.0, 0.0], \n",
    "                  batch_norm=batch_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(100)\n",
    "model = MPNN(n_x, n_h, n_e, n_sc_e, update_steps, proc_steps, enn_args, R_net_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNN(\n",
      "  (M): EdgeNetwork(\n",
      "    (adj_net): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=7, out_features=50, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (5): ReLU(inplace)\n",
      "        (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): Linear(in_features=50, out_features=2500, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (sc_adj_net): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=9, out_features=50, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (5): ReLU(inplace)\n",
      "        (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): Linear(in_features=50, out_features=2500, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (U): GRUUpdate(\n",
      "    (gru): GRUCell(50, 50)\n",
      "  )\n",
      "  (R): Set2SetOutput(\n",
      "    (R_proj): Linear(in_features=78, out_features=50, bias=True)\n",
      "    (R_proc): Set2Set(50, 100)\n",
      "    (R_write): MyCustomHead(\n",
      "      (preproc): Sequential(\n",
      "        (0): Linear(in_features=100, out_features=500, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Linear(in_features=500, out_features=500, bias=True)\n",
      "        (3): ReLU(inplace)\n",
      "      )\n",
      "      (postproc): ModuleList(\n",
      "        (0): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=200, bias=True)\n",
      "            (3): ReLU(inplace)\n",
      "            (4): Linear(in_features=200, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (1): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=200, bias=True)\n",
      "            (3): ReLU(inplace)\n",
      "            (4): Linear(in_features=200, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (2): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=200, bias=True)\n",
      "            (3): ReLU(inplace)\n",
      "            (4): Linear(in_features=200, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (3): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=200, bias=True)\n",
      "            (3): ReLU(inplace)\n",
      "            (4): Linear(in_features=200, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (4): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=200, bias=True)\n",
      "            (3): ReLU(inplace)\n",
      "            (4): Linear(in_features=200, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (5): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=200, bias=True)\n",
      "            (3): ReLU(inplace)\n",
      "            (4): Linear(in_features=200, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (6): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=200, bias=True)\n",
      "            (3): ReLU(inplace)\n",
      "            (4): Linear(in_features=200, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (7): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=500, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=200, bias=True)\n",
      "            (3): ReLU(inplace)\n",
      "            (4): Linear(in_features=200, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "tensor([[-0.0284],\n",
      "        [-0.0780],\n",
      "        [-0.0289],\n",
      "        [-0.0286],\n",
      "        [ 0.0166],\n",
      "        [-0.0285],\n",
      "        [-0.0098],\n",
      "        [ 0.0165],\n",
      "        [-0.0100],\n",
      "        [-0.0283],\n",
      "        [ 0.0167],\n",
      "        [ 0.0164],\n",
      "        [-0.0284],\n",
      "        [ 0.0170],\n",
      "        [ 0.0623],\n",
      "        [ 0.0626],\n",
      "        [-0.0084],\n",
      "        [-0.0776],\n",
      "        [ 0.0170],\n",
      "        [ 0.0169]], grad_fn=<IndexPutBackward>)\n",
      "torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "model.zero_grad()\n",
    "print(model)\n",
    "pred = model(*batch[0])\n",
    "print(pred)\n",
    "print(pred.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.mse_loss(pred, batch[1])\n",
    "print(loss)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      "gradient:M.b\n",
      "----------\n",
      "tensor([ 5.7171e-04,  4.3661e-04,  1.2466e-03, -1.1703e-04,  5.0940e-05,\n",
      "         4.4239e-05, -2.0561e-04,  2.6477e-05,  8.5388e-04, -7.1126e-06,\n",
      "        -1.9289e-04, -3.2975e-04,  4.4536e-04, -5.0138e-04,  1.5453e-03,\n",
      "         1.0375e-03,  1.1368e-04, -3.4411e-04, -1.0500e-04, -4.5863e-04,\n",
      "        -6.6880e-04,  2.1421e-04,  5.5213e-04, -8.5129e-04, -1.3326e-03,\n",
      "         6.7328e-04, -3.5594e-04,  1.2283e-03, -5.6490e-04,  1.4061e-04,\n",
      "         3.0810e-04,  9.3537e-04,  7.0939e-04,  9.2510e-04,  6.3014e-04,\n",
      "         1.5955e-04,  9.0754e-04,  5.6940e-04, -3.6151e-04,  7.8520e-04,\n",
      "         1.1561e-03,  8.8414e-04,  1.3788e-03, -8.0341e-04, -7.3117e-04,\n",
      "         2.5198e-04, -2.1136e-04, -3.5770e-04, -7.6694e-04,  4.0864e-04])\n",
      "===========\n",
      "gradient:M.adj_net.layers.0.weight\n",
      "----------\n",
      "tensor([[ 0.0000e+00,  5.5788e-07,  0.0000e+00,  0.0000e+00,  1.1086e-06,\n",
      "          3.6478e-06,  1.0485e-06],\n",
      "        [-4.3599e-06, -3.5819e-06,  0.0000e+00,  0.0000e+00, -4.1637e-07,\n",
      "         -8.4515e-06, -1.1302e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.3961e-04,  3.9844e-05,  2.2164e-07,  0.0000e+00,  4.4211e-05,\n",
      "          5.0367e-05,  2.1978e-04],\n",
      "        [ 0.0000e+00, -5.1389e-06,  0.0000e+00,  0.0000e+00, -1.8050e-06,\n",
      "          3.2561e-06, -5.8893e-06],\n",
      "        [ 0.0000e+00, -1.2642e-05,  0.0000e+00,  0.0000e+00, -1.2642e-05,\n",
      "         -2.9487e-06, -1.5786e-05],\n",
      "        [-1.3444e-04, -2.2095e-06,  1.4238e-06,  0.0000e+00, -1.5184e-05,\n",
      "         -5.2471e-05, -1.7459e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 2.5050e-05,  1.9526e-06, -7.0267e-07,  0.0000e+00,  1.2379e-05,\n",
      "         -9.7831e-06,  2.7585e-05],\n",
      "        [-6.0661e-05, -3.1973e-06,  5.6784e-07,  0.0000e+00, -1.8626e-05,\n",
      "         -7.7638e-06, -7.4592e-05],\n",
      "        [ 4.1590e-05,  1.8663e-06,  0.0000e+00,  0.0000e+00, -3.8126e-07,\n",
      "          1.5301e-05,  5.4390e-05],\n",
      "        [-1.4171e-06, -7.4198e-07,  0.0000e+00,  0.0000e+00, -2.1591e-06,\n",
      "          0.0000e+00, -2.8612e-06],\n",
      "        [ 6.0748e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.6933e-06,\n",
      "          0.0000e+00,  7.1810e-05],\n",
      "        [ 5.7711e-05,  1.9090e-05, -7.5910e-07,  0.0000e+00,  1.9823e-05,\n",
      "          2.5523e-05,  9.7371e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-5.7439e-05,  0.0000e+00,  7.7881e-08,  0.0000e+00, -2.6032e-06,\n",
      "          5.4103e-06, -6.9004e-05],\n",
      "        [-1.0745e-05, -5.8351e-07,  0.0000e+00,  0.0000e+00,  5.0806e-07,\n",
      "         -1.1329e-05, -1.7152e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 5.1904e-06,  1.1803e-05, -5.1952e-07,  0.0000e+00,  5.0554e-06,\n",
      "         -1.6393e-05,  1.0682e-05],\n",
      "        [-1.6259e-04, -2.5754e-05,  0.0000e+00,  0.0000e+00, -2.3176e-05,\n",
      "         -8.0043e-05, -2.4410e-04],\n",
      "        [-8.1250e-06, -6.1902e-06,  0.0000e+00,  0.0000e+00, -9.0681e-06,\n",
      "         -9.3570e-07, -1.9950e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 4.7034e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          4.7034e-06,  6.8476e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.5127e-06,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -1.8083e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  5.6900e-07,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  6.8526e-07],\n",
      "        [-6.7217e-05, -3.4546e-06, -2.3664e-07,  0.0000e+00,  2.4107e-06,\n",
      "         -2.2819e-05, -9.0162e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 7.2863e-05,  1.8290e-06,  7.3220e-07,  0.0000e+00,  0.0000e+00,\n",
      "          3.6077e-05,  1.0123e-04],\n",
      "        [ 1.8549e-05, -2.7131e-06,  5.9889e-07,  0.0000e+00,  1.6686e-06,\n",
      "         -4.9318e-06,  1.8840e-05],\n",
      "        [ 7.0444e-06,  4.6717e-06,  5.4477e-07,  0.0000e+00,  3.1748e-06,\n",
      "          8.8169e-07,  1.6596e-05],\n",
      "        [-9.1139e-06, -3.3438e-07,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -1.3997e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -2.3653e-07,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -2.3653e-07, -3.1489e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 5.3989e-05, -4.5383e-07,  0.0000e+00,  0.0000e+00,  1.8430e-05,\n",
      "          2.3736e-05,  7.1360e-05],\n",
      "        [ 1.1779e-06,  1.6999e-05, -1.5338e-07,  0.0000e+00,  1.8513e-05,\n",
      "          1.6517e-06,  2.2620e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  2.2467e-05,  0.0000e+00,  0.0000e+00,  1.7553e-05,\n",
      "         -2.2374e-07,  2.7291e-05],\n",
      "        [ 5.5545e-05, -5.2239e-06, -4.4606e-07,  0.0000e+00,  6.5908e-06,\n",
      "          9.8943e-06,  6.1788e-05],\n",
      "        [ 4.0607e-06, -3.0351e-07,  5.1010e-07,  0.0000e+00,  0.0000e+00,\n",
      "          3.7572e-06,  6.2740e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 2.4140e-05,  0.0000e+00, -6.5549e-07,  0.0000e+00, -3.5275e-06,\n",
      "          1.4180e-05,  3.0615e-05],\n",
      "        [-2.0673e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.5568e-06,\n",
      "         -9.1946e-06, -2.5716e-05],\n",
      "        [-1.9361e-05, -2.6696e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.1167e-06, -2.4345e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "===========\n",
      "gradient:M.adj_net.layers.0.bias\n",
      "----------\n",
      "tensor([ 5.5788e-07, -7.9418e-06,  0.0000e+00,  1.7967e-04, -5.1389e-06,\n",
      "        -1.2642e-05, -1.3523e-04,  0.0000e+00,  2.6300e-05, -6.3291e-05,\n",
      "         4.3456e-05, -2.1591e-06,  6.0748e-05,  7.6042e-05,  0.0000e+00,\n",
      "        -5.7361e-05, -1.1329e-05,  0.0000e+00,  0.0000e+00,  1.6474e-05,\n",
      "        -1.8834e-04, -1.4315e-05,  0.0000e+00,  4.7034e-06, -1.5127e-06,\n",
      "         5.6900e-07, -7.0908e-05,  0.0000e+00,  7.5424e-05,  1.6435e-05,\n",
      "         1.2261e-05, -9.4483e-06,  0.0000e+00, -2.3653e-07,  0.0000e+00,\n",
      "         5.3535e-05,  1.8023e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         2.2467e-05,  4.9875e-05,  4.2673e-06,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  2.3485e-05, -2.0673e-05, -2.2031e-05,  0.0000e+00])\n",
      "===========\n",
      "gradient:M.adj_net.layers.2.weight\n",
      "----------\n",
      "tensor([[-7.4215e-06, -2.3067e-05,  0.0000e+00,  ..., -6.9681e-05,\n",
      "         -2.0475e-05,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.6578e-06,  3.6577e-06,  0.0000e+00,  ...,  7.2953e-07,\n",
      "         -4.6350e-06,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 5.8834e-08, -9.9422e-07,  0.0000e+00,  ..., -3.8611e-07,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-2.5782e-06, -4.7903e-06,  0.0000e+00,  ..., -1.2630e-05,\n",
      "         -5.8143e-06,  0.0000e+00]])\n",
      "===========\n",
      "gradient:M.adj_net.layers.2.bias\n",
      "----------\n",
      "tensor([-5.2665e-04,  0.0000e+00, -3.4787e-05,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  1.0542e-04,  0.0000e+00,  0.0000e+00, -3.5739e-05,\n",
      "        -5.8606e-05, -7.8635e-06, -1.8488e-04,  0.0000e+00,  0.0000e+00,\n",
      "         3.5190e-04,  2.7863e-04,  0.0000e+00, -1.0300e-06,  0.0000e+00,\n",
      "        -1.5442e-04,  0.0000e+00, -5.8911e-07, -5.0203e-04, -1.6270e-05,\n",
      "         1.2956e-04,  0.0000e+00, -1.1565e-07,  0.0000e+00,  9.7582e-05,\n",
      "         2.3358e-04, -1.2317e-04,  3.6476e-05,  5.5831e-05,  2.7961e-04,\n",
      "         4.9209e-05, -2.7768e-05, -2.8102e-04,  6.7931e-06, -6.9707e-07,\n",
      "        -4.2750e-05,  2.3667e-04, -1.3719e-04, -3.3527e-06, -2.9307e-05,\n",
      "         0.0000e+00,  0.0000e+00, -5.5493e-05,  0.0000e+00, -1.0673e-04])\n",
      "===========\n",
      "gradient:M.adj_net.layers.4.weight\n",
      "----------\n",
      "tensor([[-6.9991e-05,  0.0000e+00, -6.8541e-05,  ..., -1.9740e-06,\n",
      "          0.0000e+00, -8.5080e-05],\n",
      "        [ 6.2624e-05,  0.0000e+00,  6.1608e-05,  ...,  4.3820e-06,\n",
      "          0.0000e+00,  8.9909e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [-1.6671e-06,  0.0000e+00, -3.8003e-06,  ..., -4.7618e-07,\n",
      "          0.0000e+00, -8.7712e-06],\n",
      "        [-1.6801e-04,  0.0000e+00, -1.8995e-04,  ..., -9.6297e-06,\n",
      "          0.0000e+00, -2.3713e-04],\n",
      "        [ 1.4390e-05,  0.0000e+00,  3.4220e-06,  ..., -2.7696e-06,\n",
      "          0.0000e+00, -4.1611e-06]])\n",
      "===========\n",
      "gradient:M.adj_net.layers.4.bias\n",
      "----------\n",
      "tensor([-4.1078e-04,  4.1121e-04,  0.0000e+00,  0.0000e+00,  2.1371e-04,\n",
      "         0.0000e+00, -3.6508e-04,  0.0000e+00,  0.0000e+00, -5.5616e-04,\n",
      "         0.0000e+00,  0.0000e+00, -3.8558e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  5.2270e-04,  7.1900e-05, -1.7874e-04,\n",
      "         0.0000e+00, -3.4007e-04,  6.5355e-04,  0.0000e+00,  3.6533e-05,\n",
      "        -1.5688e-04, -3.2181e-04, -2.9313e-05,  1.0209e-03, -4.4131e-04,\n",
      "         0.0000e+00,  1.4884e-03, -1.0597e-04, -1.8816e-04,  1.6608e-03,\n",
      "         0.0000e+00,  4.5018e-05,  0.0000e+00, -8.9112e-05,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -4.5602e-04,  0.0000e+00,  0.0000e+00,\n",
      "         2.3303e-04,  7.2482e-04, -3.2698e-05, -1.1801e-03, -1.7142e-05])\n",
      "===========\n",
      "gradient:M.adj_net.layers.6.weight\n",
      "----------\n",
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-5.4343e-05, -1.7866e-05,  0.0000e+00,  ..., -1.8207e-07,\n",
      "         -1.0241e-04, -7.9191e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 9.0364e-05,  9.3729e-06,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          1.0962e-04,  1.0016e-04],\n",
      "        [-5.8227e-05, -1.8553e-05,  0.0000e+00,  ..., -4.6511e-07,\n",
      "         -9.7499e-05, -8.1956e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "===========\n",
      "gradient:M.adj_net.layers.6.bias\n",
      "----------\n",
      "tensor([ 0.0000e+00, -9.5846e-04,  0.0000e+00, -3.1951e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -2.3751e-04, -2.7383e-03, -2.0337e-03,\n",
      "         2.1199e-03,  4.1053e-04,  2.1230e-03,  6.7764e-04,  0.0000e+00,\n",
      "        -9.3332e-04, -7.7356e-05,  0.0000e+00,  0.0000e+00, -7.1652e-04,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -1.6291e-03, -1.1967e-03,  1.6668e-03, -9.6754e-04,  4.4667e-04,\n",
      "         0.0000e+00,  7.2100e-04,  0.0000e+00,  7.2376e-04,  0.0000e+00,\n",
      "        -1.4868e-04,  1.4299e-03,  0.0000e+00, -3.0326e-03,  0.0000e+00,\n",
      "        -4.2100e-03,  2.9076e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  9.4526e-04, -8.6326e-04,  0.0000e+00])\n",
      "===========\n",
      "gradient:M.adj_net.layers.8.weight\n",
      "----------\n",
      "tensor([[ 0.0000e+00, -3.2401e-05,  0.0000e+00,  ..., -1.4829e-07,\n",
      "         -2.0384e-05,  0.0000e+00],\n",
      "        [ 0.0000e+00, -4.1937e-06,  0.0000e+00,  ..., -9.6801e-08,\n",
      "         -1.8369e-06,  0.0000e+00],\n",
      "        [ 0.0000e+00, -3.6947e-06,  0.0000e+00,  ..., -2.6400e-07,\n",
      "          4.3446e-07,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00, -1.9218e-05,  0.0000e+00,  ...,  2.9525e-08,\n",
      "         -1.2616e-05,  0.0000e+00],\n",
      "        [ 0.0000e+00, -6.3586e-05,  0.0000e+00,  ..., -2.8337e-07,\n",
      "         -3.9213e-05,  0.0000e+00],\n",
      "        [ 0.0000e+00,  2.7702e-05,  0.0000e+00,  ...,  1.9604e-07,\n",
      "          1.6785e-05,  0.0000e+00]])\n",
      "===========\n",
      "gradient:M.adj_net.layers.8.bias\n",
      "----------\n",
      "tensor([-3.2446e-04, -4.0641e-05, -3.4404e-05,  ..., -1.8778e-04,\n",
      "        -6.2783e-04,  2.7556e-04])\n",
      "===========\n",
      "gradient:M.sc_adj_net.layers.0.weight\n",
      "----------\n",
      "tensor([[-6.4028e-07, -4.7025e-06, -9.4514e-07,  0.0000e+00,  0.0000e+00,\n",
      "          5.9725e-07,  6.6926e-07,  1.8323e-06, -6.5627e-07],\n",
      "        [ 7.5371e-06, -5.8834e-07, -7.5250e-08,  0.0000e+00,  0.0000e+00,\n",
      "          7.5738e-07,  5.4206e-07,  9.4561e-07,  6.9212e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2244e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  4.0044e-07,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.7701e-06,  4.0029e-06, -8.1805e-07,  0.0000e+00,  0.0000e+00,\n",
      "         -1.3153e-07, -1.8409e-07,  1.0177e-06, -3.2435e-07],\n",
      "        [ 5.3913e-06,  6.4520e-06,  9.0025e-07,  0.0000e+00,  0.0000e+00,\n",
      "         -2.6624e-07,  2.0589e-07, -1.9610e-06,  6.5327e-07],\n",
      "        [ 2.2346e-06,  1.9362e-06,  7.1529e-07,  0.0000e+00,  0.0000e+00,\n",
      "         -7.6740e-07, -1.5939e-07, -3.4521e-07,  5.3998e-07],\n",
      "        [-4.3007e-06, -1.1366e-06,  4.2476e-07,  0.0000e+00,  0.0000e+00,\n",
      "         -6.3050e-07, -3.5612e-07, -7.9704e-07,  2.7462e-07],\n",
      "        [ 7.8566e-06,  1.0891e-06,  7.8476e-09,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -4.1391e-07,  1.5901e-06,  9.8384e-07],\n",
      "        [-3.8108e-06,  1.9813e-06,  2.7743e-07,  0.0000e+00,  0.0000e+00,\n",
      "         -8.7566e-08, -4.0177e-07, -7.2590e-07, -9.0055e-07],\n",
      "        [ 7.7294e-06,  8.0641e-06,  8.3430e-07,  0.0000e+00,  0.0000e+00,\n",
      "         -8.4570e-08, -3.1260e-07, -9.0089e-07,  3.0093e-07],\n",
      "        [ 5.5160e-06,  1.0965e-06, -6.2433e-07,  0.0000e+00,  0.0000e+00,\n",
      "          4.2631e-07,  1.8187e-07,  1.6144e-06, -1.7131e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.0148e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          3.9370e-08,  1.9735e-08,  1.0222e-06,  5.5658e-07],\n",
      "        [-1.1625e-05, -9.8584e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -2.7932e-07,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.4952e-05, -1.3376e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  1.4882e-07,  0.0000e+00, -2.2558e-07],\n",
      "        [-1.6198e-05, -9.0987e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -2.1964e-06,  0.0000e+00],\n",
      "        [ 1.0733e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -2.2171e-07,  5.7660e-07,  0.0000e+00],\n",
      "        [ 1.4332e-06,  3.7699e-06, -1.6429e-06,  0.0000e+00,  0.0000e+00,\n",
      "         -2.1232e-07,  3.4799e-08,  1.0070e-06, -6.5073e-07],\n",
      "        [-1.2515e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -4.6391e-07,  1.9804e-07,  0.0000e+00, -2.5944e-07],\n",
      "        [-9.7523e-06, -3.2404e-06, -8.2857e-07,  0.0000e+00,  0.0000e+00,\n",
      "         -4.7855e-07,  8.6852e-08, -9.4758e-07, -3.6398e-07],\n",
      "        [-1.7513e-06, -7.3895e-07, -7.8237e-07,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2455e-07],\n",
      "        [-1.4962e-05, -9.2360e-06, -1.2361e-06,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  3.4540e-07, -1.3212e-06,  0.0000e+00],\n",
      "        [ 1.1576e-07,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          5.5497e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.2180e-05, -1.0767e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -4.1527e-07,  8.8601e-08,  3.1025e-07, -1.9263e-07],\n",
      "        [-1.4298e-05, -1.1742e-05, -8.3366e-07,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2330e-05,  7.6718e-06, -3.6609e-07,  0.0000e+00,  0.0000e+00,\n",
      "          5.9771e-07, -3.5646e-07,  7.7027e-07,  6.4189e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.8913e-06,  2.9435e-06,  1.2507e-06,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  1.0944e-07,  5.3932e-08],\n",
      "        [ 1.6263e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -9.2979e-08,  3.6505e-07,  2.7867e-07,  0.0000e+00],\n",
      "        [-1.4428e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.6935e-07, -3.6020e-07,  0.0000e+00,  0.0000e+00],\n",
      "        [ 4.6948e-06,  4.3079e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.1673e-05, -9.2113e-06,  3.2610e-07,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -2.8945e-09,  0.0000e+00, -6.2912e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.0175e-05, -3.5578e-06, -1.0283e-06,  0.0000e+00,  0.0000e+00,\n",
      "          3.8128e-09,  5.9174e-08, -1.4063e-06, -1.7025e-07],\n",
      "        [-1.0085e-05, -2.2336e-06,  9.8756e-07,  0.0000e+00,  0.0000e+00,\n",
      "         -2.5327e-07,  4.2885e-08, -3.0415e-06, -1.1295e-07],\n",
      "        [ 1.0773e-05,  5.4890e-06,  2.2310e-06,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  3.1840e-07,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2825e-05,  5.6602e-06,  4.1891e-08,  0.0000e+00,  0.0000e+00,\n",
      "          9.1669e-07, -3.3408e-07,  2.0026e-06, -3.4571e-08],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.2428e-05, -6.7593e-06, -5.5913e-07,  0.0000e+00,  0.0000e+00,\n",
      "         -2.9480e-07, -4.4002e-07,  3.7248e-07, -9.2504e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.2765e-06,  0.0000e+00,  1.4758e-06,  0.0000e+00,  0.0000e+00,\n",
      "          2.4260e-07,  5.0305e-07,  1.8820e-06, -4.8743e-07],\n",
      "        [ 1.0842e-05,  8.7409e-06,  1.3635e-06,  0.0000e+00,  0.0000e+00,\n",
      "          4.1658e-07, -1.6356e-07, -9.5073e-07,  3.3178e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2411e-05,  1.1832e-05, -5.8825e-07,  0.0000e+00,  0.0000e+00,\n",
      "         -4.0098e-08, -2.1009e-07,  1.3441e-06, -7.6240e-07],\n",
      "        [-1.1033e-05, -8.6943e-06,  7.1533e-07,  0.0000e+00,  0.0000e+00,\n",
      "          2.6248e-07,  5.3076e-07, -1.7750e-06,  0.0000e+00]])\n",
      "===========\n",
      "gradient:M.sc_adj_net.layers.0.bias\n",
      "----------\n",
      "tensor([-3.2050e-06,  2.2736e-06,  0.0000e+00,  4.0044e-07,  3.5626e-06,\n",
      "         5.9841e-06,  1.9195e-06, -2.2209e-06,  3.2570e-06,  1.4292e-07,\n",
      "         7.9013e-06,  2.5234e-06,  0.0000e+00,  0.0000e+00,  1.6379e-06,\n",
      "        -1.0138e-05, -1.3453e-05, -1.1295e-05,  3.5489e-07,  2.3058e-06,\n",
      "        -5.2530e-07, -5.7722e-06, -1.3968e-06, -1.1448e-05,  5.5497e-08,\n",
      "        -1.0976e-05, -1.2575e-05,  0.0000e+00,  8.9591e-06,  0.0000e+00,\n",
      "         4.3575e-06,  5.5074e-07, -5.2955e-07,  4.3079e-06, -9.5173e-06,\n",
      "         0.0000e+00, -6.0997e-06, -4.6109e-06,  8.0385e-06,  0.0000e+00,\n",
      "         8.2528e-06,  0.0000e+00, -8.6058e-06,  0.0000e+00,  0.0000e+00,\n",
      "         3.6161e-06,  9.7384e-06,  0.0000e+00,  1.1575e-05, -8.9607e-06])\n",
      "===========\n",
      "gradient:M.sc_adj_net.layers.2.weight\n",
      "----------\n",
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 6.4882e-07,  3.4601e-07,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          5.1307e-08,  1.8357e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [-3.6237e-06, -6.1064e-07,  0.0000e+00,  ...,  0.0000e+00,\n",
      "         -3.9167e-06, -4.5926e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-7.6354e-06, -1.7269e-06,  0.0000e+00,  ...,  0.0000e+00,\n",
      "         -6.7330e-06, -6.9914e-06]])\n",
      "===========\n",
      "gradient:M.sc_adj_net.layers.2.bias\n",
      "----------\n",
      "tensor([ 0.0000e+00,  7.5121e-07,  0.0000e+00,  3.4163e-07, -3.3537e-05,\n",
      "        -1.1558e-05, -3.9585e-07, -1.7257e-05, -1.0507e-05, -2.6427e-06,\n",
      "        -2.9667e-05,  0.0000e+00,  5.0075e-06,  2.4049e-05,  2.5103e-05,\n",
      "        -2.0679e-05,  2.9258e-06,  0.0000e+00, -1.7454e-06, -2.9351e-05,\n",
      "         1.4226e-05, -4.6320e-06,  3.3668e-06,  3.0995e-05,  5.1761e-06,\n",
      "         1.0478e-05,  2.3961e-05, -7.9158e-07,  0.0000e+00, -2.3296e-05,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.0301e-06,\n",
      "         8.8600e-06,  2.1399e-05,  0.0000e+00,  0.0000e+00, -2.5409e-05,\n",
      "         0.0000e+00,  4.5043e-06,  3.0330e-05, -7.4343e-07,  0.0000e+00,\n",
      "         0.0000e+00, -4.2326e-06, -7.2929e-06,  0.0000e+00, -1.4771e-05])\n",
      "===========\n",
      "gradient:M.sc_adj_net.layers.4.weight\n",
      "----------\n",
      "tensor([[ 0.0000e+00, -1.3321e-07,  0.0000e+00,  ..., -6.1661e-06,\n",
      "          0.0000e+00, -5.5222e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.6919e-07,  0.0000e+00,  ..., -6.7953e-06,\n",
      "          0.0000e+00, -1.7339e-06],\n",
      "        ...,\n",
      "        [ 0.0000e+00, -2.9916e-07,  0.0000e+00,  ..., -2.7854e-06,\n",
      "          0.0000e+00,  5.0905e-07],\n",
      "        [ 0.0000e+00,  1.4430e-07,  0.0000e+00,  ...,  5.9668e-06,\n",
      "          0.0000e+00,  3.3109e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "===========\n",
      "gradient:M.sc_adj_net.layers.4.bias\n",
      "----------\n",
      "tensor([-2.6949e-05,  0.0000e+00, -4.0390e-05, -7.5260e-06,  0.0000e+00,\n",
      "        -6.7449e-05,  2.3703e-06,  0.0000e+00,  0.0000e+00, -7.0465e-06,\n",
      "        -7.0504e-05,  9.7262e-06, -4.6973e-05,  9.7269e-06, -1.7242e-05,\n",
      "         2.5282e-07, -1.0723e-04,  3.1034e-05, -1.2743e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         2.5974e-05,  5.9714e-05,  4.2561e-05, -1.0454e-04,  2.1680e-05,\n",
      "         0.0000e+00,  3.4834e-05,  2.9497e-05,  9.4707e-05,  0.0000e+00,\n",
      "        -1.2317e-06,  8.3423e-05, -5.2715e-05,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  2.8786e-05,  0.0000e+00, -6.3104e-06,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -2.0877e-06,  2.2564e-05,  0.0000e+00])\n",
      "===========\n",
      "gradient:M.sc_adj_net.layers.6.weight\n",
      "----------\n",
      "tensor([[ 1.3290e-05,  0.0000e+00,  2.3409e-05,  ...,  1.2585e-05,\n",
      "          1.7364e-05,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 2.2021e-05,  0.0000e+00,  3.8165e-05,  ...,  2.1213e-05,\n",
      "          2.8196e-05,  0.0000e+00],\n",
      "        [-1.4110e-05,  0.0000e+00, -2.3061e-05,  ..., -1.3488e-05,\n",
      "         -1.7828e-05,  0.0000e+00]])\n",
      "===========\n",
      "gradient:M.sc_adj_net.layers.6.bias\n",
      "----------\n",
      "tensor([ 1.8115e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.7498e-05,\n",
      "        -1.9599e-05, -1.2129e-04,  0.0000e+00,  0.0000e+00,  6.4231e-05,\n",
      "         0.0000e+00,  0.0000e+00,  5.4887e-05,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  1.1707e-05,  0.0000e+00,  1.1950e-04, -3.8508e-05,\n",
      "         7.1772e-05,  7.0502e-05,  9.5024e-05,  1.9492e-06,  4.3557e-05,\n",
      "         4.6660e-05, -1.3492e-04,  0.0000e+00, -2.0244e-04,  0.0000e+00,\n",
      "         0.0000e+00, -5.3666e-05, -2.7350e-05,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  6.2388e-05,  1.2202e-04,  0.0000e+00,  9.4758e-05,\n",
      "         2.0239e-05,  7.0514e-05, -1.8052e-05,  0.0000e+00,  0.0000e+00,\n",
      "         3.9082e-05,  0.0000e+00,  0.0000e+00,  2.9652e-04, -1.9157e-04])\n",
      "===========\n",
      "gradient:M.sc_adj_net.layers.8.weight\n",
      "----------\n",
      "tensor([[-4.2047e-07,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "         -1.5814e-06, -4.1183e-06],\n",
      "        [-1.7694e-07,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "         -7.7958e-07, -1.8798e-06],\n",
      "        [ 3.0113e-08,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          1.3251e-07,  2.6132e-07],\n",
      "        ...,\n",
      "        [-1.5253e-08,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "         -5.5148e-07, -1.4892e-06],\n",
      "        [-6.9695e-07,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "         -2.8993e-06, -7.8264e-06],\n",
      "        [ 2.4169e-07,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          9.7512e-07,  2.3709e-06]])\n",
      "===========\n",
      "gradient:M.sc_adj_net.layers.8.bias\n",
      "----------\n",
      "tensor([-2.2520e-05, -1.0277e-05,  1.4652e-06,  ..., -7.6909e-06,\n",
      "        -4.2651e-05,  1.2961e-05])\n",
      "===========\n",
      "gradient:U.gru.weight_ih\n",
      "----------\n",
      "tensor([[ 5.8595e-05, -6.4363e-06, -9.6144e-06,  ..., -5.2979e-05,\n",
      "          4.3518e-05,  3.8409e-05],\n",
      "        [ 7.6908e-05,  4.8786e-06, -6.2141e-05,  ..., -4.6789e-05,\n",
      "          9.2613e-05,  5.9552e-05],\n",
      "        [-1.2797e-06,  3.2890e-06, -4.7142e-07,  ...,  2.4621e-06,\n",
      "         -2.4791e-06,  2.4639e-06],\n",
      "        ...,\n",
      "        [ 4.1050e-04, -7.5283e-05,  3.1691e-05,  ..., -4.7190e-04,\n",
      "          2.1833e-04,  2.0387e-04],\n",
      "        [ 2.5194e-04, -1.1074e-04,  8.0831e-05,  ..., -2.7597e-04,\n",
      "          1.1833e-04,  1.4841e-04],\n",
      "        [-6.3817e-05,  7.5814e-05, -1.5408e-04,  ...,  8.6336e-05,\n",
      "          3.4903e-05,  2.5720e-05]])\n",
      "===========\n",
      "gradient:U.gru.weight_hh\n",
      "----------\n",
      "tensor([[-1.2883e-05,  2.8188e-05, -1.9204e-05,  ..., -1.4700e-05,\n",
      "          1.1384e-05,  5.0527e-05],\n",
      "        [-2.4696e-06,  4.7719e-05, -2.4390e-05,  ..., -1.8520e-05,\n",
      "          8.7791e-06,  4.5897e-05],\n",
      "        [-5.5766e-06,  4.6193e-06, -2.4978e-07,  ..., -1.8852e-06,\n",
      "         -3.5044e-07, -5.1114e-06],\n",
      "        ...,\n",
      "        [-4.0711e-05,  4.6063e-05, -5.6151e-05,  ..., -3.4890e-05,\n",
      "          3.2624e-05,  1.7623e-04],\n",
      "        [-3.8645e-05,  3.8789e-05, -3.9437e-05,  ..., -1.7321e-05,\n",
      "          3.5953e-05,  1.5144e-04],\n",
      "        [ 4.6477e-05, -4.0420e-06,  1.2386e-05,  ..., -8.8880e-08,\n",
      "         -2.2800e-05, -8.0214e-05]])\n",
      "===========\n",
      "gradient:U.gru.bias_ih\n",
      "----------\n",
      "tensor([ 1.1170e-04,  1.3797e-04, -1.1111e-05, -2.5053e-05,  2.9317e-05,\n",
      "         2.5495e-06,  1.4927e-05,  1.3415e-05,  9.2853e-05,  1.3548e-06,\n",
      "         5.8014e-05, -9.8359e-05,  3.8290e-04,  7.8596e-06,  2.8292e-05,\n",
      "        -1.1328e-05,  1.1982e-05, -2.3570e-05,  2.7320e-05, -1.6454e-05,\n",
      "         3.0242e-05,  1.8495e-05, -4.0448e-06, -9.4948e-06, -5.7235e-05,\n",
      "        -5.0315e-05, -6.4419e-05,  1.8705e-05, -1.9150e-05, -2.6630e-05,\n",
      "         5.7667e-05, -1.8331e-05, -8.2185e-06,  1.8559e-05, -1.7981e-05,\n",
      "         2.2301e-05, -5.1731e-06,  5.7784e-06, -8.4458e-05,  4.3193e-06,\n",
      "        -3.4091e-05,  2.4873e-05,  4.5790e-05, -1.6734e-05, -5.1317e-06,\n",
      "         1.1364e-04, -1.7944e-05,  1.8418e-06, -2.8800e-05, -1.6537e-05,\n",
      "        -8.9733e-05,  1.5070e-05,  2.1011e-05,  5.8694e-05, -9.0098e-06,\n",
      "        -2.9483e-05,  1.0618e-04,  2.2995e-05, -3.1119e-05,  1.8574e-05,\n",
      "        -2.5469e-05,  2.0124e-05,  1.8850e-04,  1.8828e-05,  6.0086e-06,\n",
      "        -5.3355e-05, -1.7050e-05, -2.1703e-05,  8.9976e-05,  3.0155e-05,\n",
      "        -2.5251e-05, -1.8834e-05,  1.0510e-05,  2.2038e-05,  4.4249e-05,\n",
      "         5.5856e-05, -1.4021e-03,  7.9596e-05,  2.0630e-06, -4.8891e-05,\n",
      "        -1.1312e-05,  9.4220e-05, -2.0967e-05, -6.3214e-05, -7.7476e-06,\n",
      "        -4.1979e-05, -3.3902e-05, -7.5095e-05,  2.6014e-05, -7.7516e-05,\n",
      "        -4.8063e-05,  3.1783e-05,  3.8818e-05,  6.1914e-05,  1.6452e-05,\n",
      "        -1.2326e-04,  8.3092e-05, -6.4214e-05, -1.4365e-05, -1.2423e-04,\n",
      "        -1.6170e-03,  1.5889e-03, -7.9750e-04,  7.5638e-04,  1.1020e-03,\n",
      "        -2.2441e-04, -6.9557e-04,  2.2735e-03, -1.5094e-03, -2.8907e-05,\n",
      "         1.6960e-03,  1.5467e-03,  3.1206e-03, -1.2506e-03, -1.0293e-04,\n",
      "        -5.6486e-04,  8.1449e-04, -1.6143e-03,  4.4588e-05,  1.2865e-03,\n",
      "         1.5524e-03, -2.3292e-04, -1.2886e-04, -4.8486e-04,  2.0434e-03,\n",
      "         1.4029e-03, -1.7710e-03,  2.9633e-04, -2.7457e-04, -7.7171e-04,\n",
      "        -8.3951e-04, -1.9142e-04,  1.9625e-04,  8.1719e-05,  1.1401e-04,\n",
      "        -3.6620e-04,  2.9054e-04, -8.1377e-04, -2.4494e-03, -1.5280e-04,\n",
      "        -2.7283e-03,  7.7171e-04,  1.5593e-03,  1.1337e-03, -8.6232e-05,\n",
      "         2.0603e-03, -2.7245e-04,  8.5912e-04,  6.8089e-04, -2.3788e-04])\n",
      "===========\n",
      "gradient:U.gru.bias_hh\n",
      "----------\n",
      "tensor([ 1.1170e-04,  1.3797e-04, -1.1111e-05, -2.5053e-05,  2.9317e-05,\n",
      "         2.5495e-06,  1.4927e-05,  1.3415e-05,  9.2853e-05,  1.3548e-06,\n",
      "         5.8014e-05, -9.8359e-05,  3.8290e-04,  7.8596e-06,  2.8292e-05,\n",
      "        -1.1328e-05,  1.1982e-05, -2.3570e-05,  2.7320e-05, -1.6454e-05,\n",
      "         3.0242e-05,  1.8495e-05, -4.0448e-06, -9.4948e-06, -5.7235e-05,\n",
      "        -5.0315e-05, -6.4419e-05,  1.8705e-05, -1.9150e-05, -2.6630e-05,\n",
      "         5.7667e-05, -1.8331e-05, -8.2185e-06,  1.8559e-05, -1.7981e-05,\n",
      "         2.2301e-05, -5.1731e-06,  5.7784e-06, -8.4458e-05,  4.3193e-06,\n",
      "        -3.4091e-05,  2.4873e-05,  4.5790e-05, -1.6734e-05, -5.1317e-06,\n",
      "         1.1364e-04, -1.7944e-05,  1.8418e-06, -2.8800e-05, -1.6537e-05,\n",
      "        -8.9733e-05,  1.5070e-05,  2.1011e-05,  5.8694e-05, -9.0098e-06,\n",
      "        -2.9483e-05,  1.0618e-04,  2.2995e-05, -3.1119e-05,  1.8574e-05,\n",
      "        -2.5469e-05,  2.0124e-05,  1.8850e-04,  1.8828e-05,  6.0086e-06,\n",
      "        -5.3355e-05, -1.7050e-05, -2.1703e-05,  8.9976e-05,  3.0155e-05,\n",
      "        -2.5251e-05, -1.8834e-05,  1.0510e-05,  2.2038e-05,  4.4249e-05,\n",
      "         5.5856e-05, -1.4021e-03,  7.9596e-05,  2.0630e-06, -4.8891e-05,\n",
      "        -1.1312e-05,  9.4220e-05, -2.0967e-05, -6.3214e-05, -7.7476e-06,\n",
      "        -4.1979e-05, -3.3902e-05, -7.5095e-05,  2.6014e-05, -7.7516e-05,\n",
      "        -4.8063e-05,  3.1783e-05,  3.8818e-05,  6.1914e-05,  1.6452e-05,\n",
      "        -1.2326e-04,  8.3092e-05, -6.4214e-05, -1.4365e-05, -1.2423e-04,\n",
      "        -7.8002e-04,  9.3672e-04, -3.1428e-04,  3.7415e-04,  4.8386e-04,\n",
      "        -8.9077e-05, -4.3939e-04,  1.2355e-03, -6.5786e-04, -1.2695e-05,\n",
      "         7.7198e-04,  8.5393e-04,  1.6776e-03, -4.5713e-04, -4.2692e-05,\n",
      "        -3.2491e-04,  2.6849e-04, -7.9779e-04, -3.7595e-05,  7.8052e-04,\n",
      "         8.0514e-04, -4.2335e-05, -1.5015e-04, -2.0192e-04,  1.1537e-03,\n",
      "         7.3534e-04, -9.0634e-04,  1.4459e-04, -1.1013e-04, -2.8377e-04,\n",
      "        -4.1535e-04, -7.3359e-05,  6.2381e-05,  8.4445e-05,  8.3257e-05,\n",
      "        -1.6151e-04,  1.2009e-04, -4.0350e-04, -9.4010e-04, -8.6695e-05,\n",
      "        -1.4393e-03,  4.1209e-04,  7.7943e-04,  5.2859e-04, -6.1350e-05,\n",
      "         9.7137e-04, -1.6072e-04,  3.6985e-04,  3.2528e-04, -1.5253e-04])\n",
      "===========\n",
      "gradient:R.R_proj.weight\n",
      "----------\n",
      "tensor([[-2.3525e-04,  2.3618e-04, -8.7055e-05,  ...,  0.0000e+00,\n",
      "          6.5611e-03,  3.1997e-04],\n",
      "        [-2.3032e-04,  2.6018e-04, -6.9666e-05,  ...,  0.0000e+00,\n",
      "          6.6363e-03,  3.1429e-04],\n",
      "        [-3.8874e-04,  4.2579e-04, -1.3664e-04,  ...,  0.0000e+00,\n",
      "          1.1160e-02,  5.3671e-04],\n",
      "        ...,\n",
      "        [-6.1790e-05,  6.8684e-05, -1.5477e-05,  ...,  0.0000e+00,\n",
      "          1.9064e-03,  1.0877e-04],\n",
      "        [ 1.8681e-04, -2.0411e-04,  6.6449e-05,  ...,  0.0000e+00,\n",
      "         -5.2277e-03, -2.5915e-04],\n",
      "        [ 2.9175e-04, -3.4437e-04,  8.2708e-05,  ...,  0.0000e+00,\n",
      "         -8.2191e-03, -3.9085e-04]])\n",
      "===========\n",
      "gradient:R.R_proj.bias\n",
      "----------\n",
      "tensor([ 0.0018,  0.0019,  0.0031,  0.0027,  0.0048, -0.0005,  0.0002, -0.0020,\n",
      "         0.0008,  0.0023, -0.0013,  0.0004, -0.0043,  0.0032,  0.0038,  0.0026,\n",
      "        -0.0015, -0.0008,  0.0006,  0.0017, -0.0040,  0.0016,  0.0002,  0.0009,\n",
      "         0.0012,  0.0050,  0.0022, -0.0009,  0.0019, -0.0020,  0.0020,  0.0012,\n",
      "        -0.0004, -0.0006, -0.0017, -0.0036,  0.0043, -0.0016,  0.0009, -0.0021,\n",
      "         0.0011, -0.0022, -0.0012, -0.0002, -0.0036, -0.0025, -0.0046,  0.0005,\n",
      "        -0.0015, -0.0025])\n",
      "===========\n",
      "gradient:R.R_proc.lstm.w_h\n",
      "----------\n",
      "tensor([[-6.5939e-07, -1.1788e-07,  1.7286e-07,  ...,  3.4196e-06,\n",
      "         -6.4072e-06, -5.8045e-07],\n",
      "        [ 1.2562e-07,  2.3923e-08,  1.5171e-10,  ..., -4.3793e-07,\n",
      "          1.0318e-06,  2.5971e-07],\n",
      "        [ 1.7772e-07, -5.1029e-09, -8.2121e-08,  ...,  8.1070e-09,\n",
      "          3.7189e-07,  7.7506e-07],\n",
      "        ...,\n",
      "        [-6.1483e-06, -4.7889e-07,  2.0874e-06,  ...,  2.2627e-05,\n",
      "         -4.2729e-05, -5.4902e-06],\n",
      "        [ 2.7952e-06,  2.6091e-07, -1.0884e-06,  ..., -1.2358e-05,\n",
      "          2.2793e-05,  3.5371e-06],\n",
      "        [ 1.0409e-06,  5.1209e-08, -2.0344e-07,  ..., -2.2976e-06,\n",
      "          4.7224e-06,  1.2185e-06]])\n",
      "===========\n",
      "gradient:R.R_proc.lstm.b\n",
      "----------\n",
      "tensor([-1.7173e-05, -1.2762e-06,  5.5056e-06, -2.6333e-04,  1.0470e-07,\n",
      "         4.6430e-06, -1.2134e-04,  1.1140e-04,  1.0271e-05,  4.6602e-05,\n",
      "        -1.8562e-04,  9.7814e-06, -3.0263e-06,  1.5724e-06, -3.1667e-05,\n",
      "        -9.9139e-05,  2.4291e-04, -2.5871e-05, -1.4841e-05, -1.4304e-05,\n",
      "        -8.2611e-05, -8.2957e-05,  2.9615e-05,  9.6073e-05, -1.2320e-05,\n",
      "        -1.3325e-04,  8.5102e-05, -2.6814e-04,  1.2328e-04,  3.3675e-06,\n",
      "        -6.2885e-06, -7.1912e-06,  1.4326e-04,  6.3362e-06,  4.4677e-05,\n",
      "        -2.2798e-05, -1.4638e-06,  5.9572e-05, -3.0964e-05, -1.7073e-04,\n",
      "         8.5457e-05,  7.7213e-06, -1.4942e-04,  3.0324e-05, -8.3700e-05,\n",
      "        -1.4245e-04, -2.5899e-05,  5.5048e-05, -1.1163e-04, -1.9123e-05,\n",
      "        -7.7583e-06, -8.3354e-06,  7.2801e-06, -3.0691e-04,  1.1774e-05,\n",
      "         5.2685e-06, -9.9166e-05,  1.4874e-04, -2.9914e-06,  4.6425e-05,\n",
      "        -1.8772e-04,  3.1078e-05, -1.0358e-05, -6.4963e-06, -4.0845e-05,\n",
      "        -9.6218e-05,  2.3608e-04, -3.5334e-05,  1.0875e-05, -2.0212e-05,\n",
      "        -1.2571e-04, -9.8707e-05,  2.3497e-05,  8.8045e-05, -1.0599e-05,\n",
      "        -1.4745e-04,  8.1133e-05, -2.4600e-04,  1.6140e-04,  1.5175e-06,\n",
      "        -4.1343e-06, -2.1963e-06,  1.6934e-04,  8.1002e-06,  4.5127e-05,\n",
      "        -1.8748e-05,  2.6863e-06,  7.7317e-05, -3.9171e-05, -1.7651e-04,\n",
      "         1.0475e-04,  1.2437e-05, -1.9055e-04,  3.2320e-05, -5.8811e-05,\n",
      "        -1.4131e-04, -4.6271e-05,  3.9696e-05, -1.2094e-04, -9.2074e-06,\n",
      "        -2.9756e-04,  9.7415e-04, -4.2726e-04,  2.3938e-03, -2.7104e-04,\n",
      "         8.3998e-05,  2.0412e-03, -1.5804e-03, -1.4923e-03,  2.2967e-03,\n",
      "         1.9130e-03,  1.2519e-03, -1.6945e-05, -1.1431e-03,  1.1006e-03,\n",
      "         1.7782e-03,  1.5958e-03, -3.1777e-04,  1.5815e-03, -2.1656e-04,\n",
      "        -1.1641e-03, -1.3797e-03,  8.0800e-04,  2.6533e-03,  1.8607e-04,\n",
      "        -1.6913e-03, -1.8095e-03, -3.4975e-03,  1.3910e-03,  6.1928e-05,\n",
      "        -3.4438e-04, -1.4941e-04, -3.4946e-03,  3.0597e-04, -2.3630e-03,\n",
      "        -3.5837e-04,  6.8130e-04, -2.3790e-03,  1.1303e-03, -2.7945e-03,\n",
      "        -1.6882e-03, -1.0264e-04,  5.4464e-03, -9.1890e-04,  2.0348e-03,\n",
      "         1.4812e-03,  3.2371e-03,  2.0375e-03, -2.7283e-03, -2.4926e-04,\n",
      "        -1.6249e-05, -1.3111e-06,  5.8219e-06, -2.6969e-04,  3.3560e-07,\n",
      "         4.3841e-06, -1.1228e-04,  1.3272e-04,  1.0795e-05,  4.5357e-05,\n",
      "        -1.6279e-04,  1.0098e-05, -3.1660e-06,  1.1677e-06, -3.8098e-05,\n",
      "        -9.6994e-05,  3.1877e-04, -3.9706e-05, -1.7187e-05, -1.8324e-05,\n",
      "        -8.0306e-05, -9.9255e-05,  2.9684e-05,  9.2961e-05, -1.2737e-05,\n",
      "        -1.3400e-04,  1.0344e-04, -2.6901e-04,  1.2523e-04,  3.0337e-06,\n",
      "        -6.1674e-06, -7.2945e-06,  1.1631e-04,  6.0759e-06,  5.6861e-05,\n",
      "        -2.5476e-05, -1.9737e-06,  4.9458e-05, -2.6596e-05, -1.7261e-04,\n",
      "         7.1553e-05,  7.9501e-06, -1.5645e-04,  3.7111e-05, -7.3330e-05,\n",
      "        -1.2390e-04, -2.7942e-05,  5.9620e-05, -1.1257e-04, -1.8508e-05])\n",
      "===========\n",
      "gradient:R.R_write.preproc.0.weight\n",
      "----------\n",
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.3021e-06, -8.3235e-07,  1.2719e-06,  ...,  2.5439e-06,\n",
      "         -2.7661e-06, -1.0130e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-9.1617e-05,  6.1684e-06, -3.5615e-06,  ..., -6.3717e-04,\n",
      "          3.3183e-04,  6.6459e-05],\n",
      "        [-1.3047e-04,  4.9385e-06, -2.9397e-06,  ..., -8.9709e-04,\n",
      "          4.6278e-04,  9.7087e-05]])\n",
      "===========\n",
      "gradient:R.R_write.preproc.0.bias\n",
      "----------\n",
      "tensor([ 0.0000e+00,  1.3179e-05,  0.0000e+00,  0.0000e+00,  1.7770e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.6205e-03,\n",
      "         2.2083e-03, -5.1349e-04,  0.0000e+00,  1.0743e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5418e-03,  3.6589e-04,\n",
      "         3.9064e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.1965e-03,\n",
      "         0.0000e+00,  0.0000e+00,  2.9312e-03, -2.5683e-03,  0.0000e+00,\n",
      "        -2.8894e-03, -1.3832e-03,  0.0000e+00,  0.0000e+00, -3.8598e-04,\n",
      "        -6.1738e-04,  0.0000e+00,  1.0511e-03, -3.4225e-03,  0.0000e+00,\n",
      "         6.0948e-05,  0.0000e+00,  0.0000e+00,  6.4028e-04,  2.3698e-03,\n",
      "         3.0533e-03,  0.0000e+00,  0.0000e+00, -2.4834e-03,  0.0000e+00,\n",
      "         0.0000e+00, -1.5012e-03,  4.7392e-04,  0.0000e+00,  0.0000e+00,\n",
      "         1.2956e-03, -3.5788e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         1.8707e-03,  1.5106e-03,  0.0000e+00,  2.5414e-03,  7.0308e-05,\n",
      "         0.0000e+00,  0.0000e+00, -3.0644e-03,  0.0000e+00, -2.9000e-03,\n",
      "         0.0000e+00, -3.1059e-03,  0.0000e+00, -2.4498e-04, -9.6497e-05,\n",
      "         5.2953e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.3680e-03,\n",
      "         0.0000e+00, -5.3785e-04,  0.0000e+00,  1.2676e-03, -1.1552e-04,\n",
      "         0.0000e+00, -3.5462e-04, -1.3824e-03,  1.4754e-03, -9.2524e-04,\n",
      "        -1.8048e-03,  2.3458e-03,  0.0000e+00, -1.8352e-03,  0.0000e+00,\n",
      "         0.0000e+00, -4.4811e-04,  0.0000e+00,  1.2433e-03, -2.7798e-03,\n",
      "         1.4820e-03, -1.8707e-03,  1.5685e-03,  0.0000e+00,  1.4325e-03,\n",
      "         5.9351e-03,  2.9613e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  2.8991e-04,  0.0000e+00,  0.0000e+00, -7.9749e-04,\n",
      "        -3.5670e-04,  0.0000e+00,  2.5195e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  9.8151e-05,  2.0520e-03,  5.4538e-03, -1.4127e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1193e-03,\n",
      "         5.4901e-04,  0.0000e+00, -7.3591e-05, -2.7464e-03,  5.5902e-05,\n",
      "         6.6637e-04,  0.0000e+00,  0.0000e+00,  1.9861e-04,  0.0000e+00,\n",
      "         0.0000e+00, -2.8741e-03,  0.0000e+00, -2.2001e-03, -9.4930e-04,\n",
      "         2.6783e-03, -1.2491e-03, -6.8840e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  9.3287e-06,  1.7077e-03,  0.0000e+00, -3.8034e-03,\n",
      "         3.4374e-04,  0.0000e+00,  1.5538e-03, -2.0437e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -5.0971e-04, -3.8984e-03,\n",
      "         2.0841e-03,  0.0000e+00,  1.7430e-03,  1.6378e-03,  2.0147e-03,\n",
      "        -5.2458e-03,  5.8358e-04,  0.0000e+00,  4.8476e-03,  0.0000e+00,\n",
      "         2.9424e-04, -2.3696e-03,  1.9288e-03,  1.4358e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.7930e-03,\n",
      "        -8.9357e-04, -1.0514e-03, -1.5080e-03,  3.0230e-06,  0.0000e+00,\n",
      "         0.0000e+00,  3.9984e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -9.2330e-04,  0.0000e+00,  8.3761e-04, -1.6410e-03,\n",
      "         0.0000e+00, -2.6245e-04,  3.4113e-03,  5.2710e-06, -3.9938e-03,\n",
      "         0.0000e+00,  0.0000e+00,  5.4658e-03, -4.3001e-03,  3.1009e-03,\n",
      "        -5.5869e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.0856e-03,\n",
      "        -4.0330e-03,  3.2285e-03,  2.0842e-04,  0.0000e+00,  0.0000e+00,\n",
      "         2.1782e-04,  6.6581e-04,  0.0000e+00, -1.9715e-03,  0.0000e+00,\n",
      "         5.0593e-03,  0.0000e+00,  0.0000e+00,  7.1798e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.7945e-03, -8.4817e-04,  0.0000e+00,\n",
      "         1.9472e-03,  0.0000e+00,  0.0000e+00, -1.0793e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  1.6769e-03,  0.0000e+00, -1.2312e-03,\n",
      "        -1.3960e-03,  1.2774e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         1.3219e-04,  1.2717e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         2.2515e-03,  0.0000e+00,  0.0000e+00,  2.3548e-03,  0.0000e+00,\n",
      "         2.0405e-03,  0.0000e+00, -1.9660e-03,  0.0000e+00,  2.2684e-03,\n",
      "         0.0000e+00,  0.0000e+00,  2.7548e-04, -3.1705e-03,  0.0000e+00,\n",
      "        -2.6825e-03,  0.0000e+00,  6.2459e-04, -9.0719e-04,  0.0000e+00,\n",
      "         6.8984e-04,  0.0000e+00, -5.7440e-04, -1.8918e-03,  2.8768e-03,\n",
      "         2.3700e-03,  3.7450e-03,  3.5784e-03,  0.0000e+00,  3.9345e-04,\n",
      "         2.9093e-03,  2.6792e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  6.7236e-04,  0.0000e+00,  0.0000e+00,\n",
      "         1.1449e-03, -4.6111e-04, -5.2738e-04,  0.0000e+00,  0.0000e+00,\n",
      "         1.3491e-03,  1.8815e-04, -1.4863e-04,  3.0209e-03,  2.6295e-03,\n",
      "         0.0000e+00,  2.8070e-03,  3.3367e-03,  1.0456e-03, -1.0353e-03,\n",
      "         1.6128e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         3.7981e-05, -7.9329e-04,  0.0000e+00,  7.5261e-04,  0.0000e+00,\n",
      "         0.0000e+00,  2.0538e-03,  0.0000e+00, -3.3340e-03, -1.2230e-03,\n",
      "         0.0000e+00,  1.0751e-04,  0.0000e+00,  3.4549e-03, -2.1597e-03,\n",
      "        -2.0451e-03, -2.6420e-03,  0.0000e+00,  0.0000e+00, -1.3376e-03,\n",
      "        -2.3793e-03,  0.0000e+00, -2.4031e-03, -2.1967e-03,  4.6577e-05,\n",
      "        -1.7874e-03,  0.0000e+00, -2.2910e-03,  6.9746e-04,  7.3974e-04,\n",
      "         1.0322e-03, -6.7693e-05, -1.5248e-03,  0.0000e+00,  6.6571e-04,\n",
      "        -1.6638e-03,  2.4307e-03, -4.3734e-03,  1.9008e-03, -6.3534e-04,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.5128e-03,  2.4531e-03,\n",
      "        -5.3173e-03,  0.0000e+00, -2.1388e-03,  0.0000e+00, -3.1769e-03,\n",
      "         0.0000e+00,  2.3354e-03, -2.9091e-04,  0.0000e+00,  7.1461e-04,\n",
      "         0.0000e+00,  0.0000e+00,  1.4747e-04,  0.0000e+00,  0.0000e+00,\n",
      "        -1.5592e-03,  0.0000e+00,  0.0000e+00, -6.9904e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -7.9928e-04, -2.3160e-03,  0.0000e+00,\n",
      "         3.8576e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -6.7064e-04,  1.4881e-03, -7.2515e-04,\n",
      "         0.0000e+00, -1.3964e-03,  0.0000e+00,  1.8538e-03,  0.0000e+00,\n",
      "        -5.1883e-05, -6.6593e-03,  0.0000e+00,  1.3088e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  2.2830e-03, -5.0582e-03,  0.0000e+00,\n",
      "         2.9392e-03,  0.0000e+00,  0.0000e+00,  2.6354e-03,  0.0000e+00,\n",
      "        -3.0061e-03,  0.0000e+00, -2.7089e-05,  7.9135e-05,  2.2019e-03,\n",
      "        -1.8782e-03, -4.8173e-03,  0.0000e+00,  5.5180e-04,  0.0000e+00,\n",
      "         0.0000e+00, -1.4867e-03,  6.6536e-05,  0.0000e+00, -2.2104e-03,\n",
      "         1.5992e-04, -2.9307e-03,  0.0000e+00,  0.0000e+00, -1.0556e-03,\n",
      "         2.9662e-03,  2.3070e-04, -2.5518e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -3.0899e-04,  9.1241e-04,  5.0900e-03,  0.0000e+00, -5.1642e-03,\n",
      "         0.0000e+00, -2.5093e-03,  3.2555e-03, -1.6388e-03,  6.4225e-04,\n",
      "         0.0000e+00,  1.1608e-03,  0.0000e+00,  4.8894e-03, -3.4570e-04,\n",
      "         0.0000e+00,  0.0000e+00,  1.0806e-03, -2.6738e-03,  0.0000e+00,\n",
      "         5.4745e-05,  0.0000e+00, -8.3026e-04,  1.1920e-03, -3.5926e-03,\n",
      "         2.5499e-05, -2.3605e-03,  0.0000e+00,  0.0000e+00, -3.5786e-03,\n",
      "         0.0000e+00,  1.6189e-03, -4.7273e-04, -3.8585e-03, -9.3222e-05,\n",
      "         0.0000e+00,  3.0186e-03,  2.7005e-03, -6.5848e-04, -9.6815e-04,\n",
      "         2.6052e-03, -3.0170e-04,  7.4971e-04,  0.0000e+00, -1.7779e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3403e-03,  1.7537e-03,\n",
      "         0.0000e+00, -2.2043e-03,  2.2260e-03,  1.2208e-03,  0.0000e+00,\n",
      "         1.4076e-03,  2.8897e-03,  0.0000e+00, -1.6469e-03, -2.3065e-03])\n",
      "===========\n",
      "gradient:R.R_write.preproc.2.weight\n",
      "----------\n",
      "tensor([[ 0.0000e+00, -1.3724e-05,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          1.2410e-03,  7.7732e-04],\n",
      "        [ 0.0000e+00, -2.0528e-06,  0.0000e+00,  ...,  0.0000e+00,\n",
      "         -6.2249e-05, -3.9310e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -5.2811e-06,  0.0000e+00,  ...,  0.0000e+00,\n",
      "         -7.4961e-04, -4.8233e-04]])\n",
      "===========\n",
      "gradient:R.R_write.preproc.2.bias\n",
      "----------\n",
      "tensor([ 4.5713e-03, -2.4817e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -2.7099e-03,  2.7689e-03,  0.0000e+00, -3.8746e-03,  0.0000e+00,\n",
      "         0.0000e+00, -5.5274e-03,  0.0000e+00, -6.4839e-04,  0.0000e+00,\n",
      "        -2.7470e-03, -1.2396e-03,  0.0000e+00,  9.0858e-03, -5.1767e-03,\n",
      "         3.5306e-03,  0.0000e+00,  4.9790e-04,  0.0000e+00,  0.0000e+00,\n",
      "         6.6132e-03, -5.1770e-04,  7.9337e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -3.7531e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  6.2094e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -6.5067e-04,  5.8709e-03,  5.8848e-03, -6.1337e-03,\n",
      "         3.7117e-03,  8.2135e-05,  0.0000e+00,  0.0000e+00,  3.7596e-03,\n",
      "         5.2088e-04, -1.3700e-04, -7.0093e-03,  5.7888e-03,  0.0000e+00,\n",
      "         0.0000e+00, -2.5231e-03,  0.0000e+00, -8.7643e-03,  1.6883e-03,\n",
      "         7.6432e-03,  1.1153e-02, -3.6706e-04,  0.0000e+00,  0.0000e+00,\n",
      "         1.9401e-03, -4.7919e-03,  0.0000e+00,  0.0000e+00, -5.1215e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.8418e-03,\n",
      "         7.5964e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -7.2092e-03,  1.9156e-03,  0.0000e+00,  0.0000e+00, -2.6168e-03,\n",
      "        -8.8708e-03,  0.0000e+00,  0.0000e+00, -6.8322e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.8227e-04,\n",
      "         8.5244e-03,  0.0000e+00, -6.1647e-03,  0.0000e+00,  8.2061e-03,\n",
      "        -4.2061e-03,  7.8019e-03, -2.3463e-03, -1.1712e-02,  1.4396e-03,\n",
      "         1.7992e-03,  9.6891e-04,  7.0220e-03, -9.2041e-03,  1.0761e-02,\n",
      "         2.2653e-03,  1.1075e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         2.2956e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  1.7224e-05, -7.3280e-03, -6.3681e-03, -2.3815e-04,\n",
      "         0.0000e+00, -1.0755e-03, -1.4980e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -4.9068e-03, -1.3665e-03,  0.0000e+00, -1.1525e-02,\n",
      "         0.0000e+00, -3.6225e-04,  0.0000e+00,  0.0000e+00,  5.8696e-03,\n",
      "        -1.4394e-03,  0.0000e+00,  6.4925e-04,  0.0000e+00,  0.0000e+00,\n",
      "         4.6963e-03,  0.0000e+00,  1.2207e-02,  4.7997e-03,  0.0000e+00,\n",
      "        -5.9252e-03,  0.0000e+00,  0.0000e+00,  3.2135e-03,  0.0000e+00,\n",
      "        -4.1540e-03,  1.6208e-03,  0.0000e+00,  4.3971e-03,  8.4252e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  8.5764e-03, -6.7093e-03,\n",
      "         1.0824e-03, -7.8952e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.5170e-03,\n",
      "        -2.6725e-03, -2.1165e-03, -7.1107e-04,  7.9945e-03,  0.0000e+00,\n",
      "         1.0606e-02,  0.0000e+00,  0.0000e+00, -1.2369e-02,  0.0000e+00,\n",
      "        -6.1125e-03, -6.4619e-03, -5.1841e-03,  3.8992e-03, -3.3325e-03,\n",
      "         0.0000e+00, -5.6402e-03, -2.7282e-03,  0.0000e+00, -3.1048e-03,\n",
      "        -3.4837e-04,  0.0000e+00,  0.0000e+00, -8.6585e-03,  0.0000e+00,\n",
      "        -4.1767e-03,  0.0000e+00, -8.7487e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -6.4786e-03,  0.0000e+00, -6.1999e-03,  2.5036e-03,  5.7043e-03,\n",
      "         2.9706e-04,  0.0000e+00,  5.6932e-04, -6.1847e-03,  0.0000e+00,\n",
      "         0.0000e+00, -9.9398e-04,  0.0000e+00,  0.0000e+00,  1.0637e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -2.5342e-03,  1.8208e-03,  4.1280e-04, -9.7755e-03, -1.3224e-03,\n",
      "         5.9508e-03,  0.0000e+00, -6.5277e-04, -5.1966e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -5.3003e-03, -5.6624e-03, -1.5052e-03,  1.1869e-02,  0.0000e+00,\n",
      "         1.5062e-03,  0.0000e+00,  2.1911e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -7.5728e-03,  6.0211e-04,\n",
      "         4.6846e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1345e-03,\n",
      "        -2.2091e-03, -6.1020e-03, -4.9498e-03, -9.0408e-03,  0.0000e+00,\n",
      "         0.0000e+00,  1.8682e-03, -1.1309e-02,  2.9525e-04,  4.7680e-03,\n",
      "        -7.9518e-03, -1.1250e-02,  6.3969e-03, -2.3774e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1052e-03,\n",
      "         0.0000e+00, -6.4005e-03,  0.0000e+00, -1.5725e-03, -6.4273e-03,\n",
      "         3.4785e-03,  3.2714e-03,  0.0000e+00, -7.6910e-03, -1.9110e-03,\n",
      "         0.0000e+00,  2.9750e-03, -7.0728e-03,  8.1331e-03,  0.0000e+00,\n",
      "         0.0000e+00, -7.2446e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         8.5344e-04,  9.4843e-04,  0.0000e+00,  0.0000e+00,  1.5994e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -3.0245e-03, -2.7970e-04,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -5.3405e-03,  4.3579e-04,  4.9878e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -1.6752e-03,  4.6209e-03, -1.0575e-02,  0.0000e+00,\n",
      "         7.5265e-03, -1.5734e-03,  4.4387e-03,  5.0251e-03, -2.4954e-05,\n",
      "         7.1360e-03, -3.2461e-03,  0.0000e+00,  5.4007e-03,  6.7264e-03,\n",
      "        -2.1657e-03,  0.0000e+00,  4.9757e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -3.7736e-03, -1.0856e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  6.7304e-03,  0.0000e+00,\n",
      "         9.4072e-03, -9.0002e-04,  0.0000e+00,  8.4384e-03, -4.1181e-03,\n",
      "        -3.3964e-03,  0.0000e+00,  0.0000e+00, -1.2613e-02, -2.3560e-03,\n",
      "         0.0000e+00,  1.7211e-03, -1.4309e-03, -8.9979e-04,  0.0000e+00,\n",
      "         2.3404e-03,  3.7389e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -5.7323e-03,  0.0000e+00,  4.9287e-03,  0.0000e+00, -6.0941e-03,\n",
      "         0.0000e+00,  4.4896e-03,  0.0000e+00,  1.1311e-04,  5.1683e-03,\n",
      "        -1.2642e-02,  0.0000e+00,  3.9346e-05, -4.0001e-03,  2.6383e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -5.2764e-03, -6.8353e-03,\n",
      "        -4.7383e-03,  0.0000e+00,  1.3990e-03,  0.0000e+00, -7.4205e-03,\n",
      "        -3.1367e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4110e-04,  3.4502e-03,\n",
      "        -8.9878e-03,  0.0000e+00, -7.5833e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.7063e-03, -1.4598e-03,\n",
      "        -1.5714e-03,  0.0000e+00, -6.8344e-03,  4.2129e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.3375e-04, -2.2853e-03,\n",
      "        -3.3411e-03,  0.0000e+00,  5.4542e-03,  1.7185e-03,  0.0000e+00,\n",
      "         0.0000e+00, -3.2590e-03,  4.4856e-04, -1.1849e-02,  0.0000e+00,\n",
      "        -7.4272e-04,  0.0000e+00, -1.1846e-03,  3.3710e-04,  0.0000e+00,\n",
      "        -1.9138e-03,  0.0000e+00,  0.0000e+00,  1.6755e-03,  1.1539e-02,\n",
      "         0.0000e+00,  5.5749e-03,  1.0327e-02,  9.1154e-05,  0.0000e+00,\n",
      "        -1.4810e-03,  4.4050e-03, -5.9155e-03, -5.6079e-03, -2.7167e-03,\n",
      "         0.0000e+00,  6.0905e-03, -4.6358e-03,  3.9036e-03, -7.8214e-03,\n",
      "         1.5490e-04, -6.1657e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -3.6029e-03,  0.0000e+00, -2.0880e-03,  0.0000e+00,\n",
      "         6.1533e-03, -9.7960e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         4.8271e-03,  1.1821e-03,  3.7702e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  5.7866e-03, -4.1132e-03,  0.0000e+00,\n",
      "         0.0000e+00, -5.0915e-03,  0.0000e+00,  0.0000e+00,  1.1116e-03,\n",
      "         0.0000e+00, -3.5493e-04,  0.0000e+00,  0.0000e+00, -5.2168e-03,\n",
      "         0.0000e+00, -4.7217e-03,  0.0000e+00,  0.0000e+00, -2.8949e-03])\n",
      "===========\n",
      "gradient:R.R_write.postproc.0.layers.0.weight\n",
      "----------\n",
      "tensor([[-1.6296e-04,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -9.4218e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-3.3568e-04,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -1.7497e-04],\n",
      "        ...,\n",
      "        [-5.0790e-04,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -2.7023e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "===========\n",
      "gradient:R.R_write.postproc.0.layers.0.bias\n",
      "----------\n",
      "tensor([-5.9414e-03,  0.0000e+00, -1.1392e-02,  1.7308e-02,  0.0000e+00,\n",
      "         0.0000e+00, -6.4135e-03,  0.0000e+00,  1.3532e-02, -1.7286e-02,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  2.0858e-02,  4.9765e-04,  8.5596e-03,  0.0000e+00,\n",
      "        -2.2709e-02, -1.3348e-02,  0.0000e+00,  0.0000e+00,  1.5039e-02,\n",
      "        -1.9558e-02, -3.9723e-03,  9.9470e-03,  0.0000e+00,  0.0000e+00,\n",
      "         1.3826e-02,  0.0000e+00, -5.8191e-03, -3.2923e-03, -9.3651e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         3.8670e-04,  3.8830e-03,  0.0000e+00,  0.0000e+00,  8.5017e-04,\n",
      "         1.2872e-02,  0.0000e+00,  9.3026e-03,  0.0000e+00,  5.5968e-03,\n",
      "         0.0000e+00, -9.1374e-03,  2.2980e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -9.4442e-04,  1.2317e-02,  0.0000e+00, -1.9733e-02, -3.2282e-04,\n",
      "        -2.1131e-02, -2.6821e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -2.0562e-02,  0.0000e+00,  1.5000e-02, -8.1197e-03,  6.3691e-03,\n",
      "         0.0000e+00,  1.4970e-02,  0.0000e+00, -4.5445e-03, -1.4304e-02,\n",
      "         5.8068e-03,  0.0000e+00, -6.1149e-03,  0.0000e+00, -4.1542e-03,\n",
      "        -1.7879e-02,  3.1498e-03,  1.6685e-03,  0.0000e+00, -2.3651e-02,\n",
      "        -1.1672e-02, -8.1148e-03,  6.0739e-04,  0.0000e+00,  1.7068e-02,\n",
      "        -9.9261e-03,  2.4132e-03, -2.2472e-02,  0.0000e+00,  2.1417e-03,\n",
      "         9.1547e-04,  2.2234e-02,  0.0000e+00, -4.2273e-03,  1.4967e-02,\n",
      "        -1.8677e-02, -4.4086e-03, -2.0715e-02,  0.0000e+00,  0.0000e+00,\n",
      "         1.5321e-02,  0.0000e+00, -2.3304e-02, -1.4180e-02,  0.0000e+00,\n",
      "        -2.7839e-03,  0.0000e+00,  8.4089e-03,  0.0000e+00,  0.0000e+00,\n",
      "         1.2514e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         2.2569e-02, -1.2816e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -6.2580e-03,  8.7568e-03,  0.0000e+00, -1.2659e-02,\n",
      "        -2.0018e-03, -4.2384e-03,  3.1844e-03,  1.0212e-02, -9.0415e-03,\n",
      "         2.1332e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.0182e-03,\n",
      "         7.5743e-03,  0.0000e+00, -1.6598e-02,  1.3018e-02,  1.0686e-02,\n",
      "         0.0000e+00, -3.0670e-02,  4.9034e-03, -1.1484e-03,  1.3157e-02,\n",
      "         5.7549e-03, -5.7910e-03, -6.3534e-03,  8.0108e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  5.1108e-03,  1.2861e-02,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.8013e-02,  0.0000e+00,\n",
      "         0.0000e+00,  2.2078e-02, -1.1875e-02, -1.6199e-02,  7.2808e-03,\n",
      "         0.0000e+00,  0.0000e+00,  3.4830e-03,  1.4911e-02,  6.7361e-03,\n",
      "         0.0000e+00, -1.8685e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -1.4301e-02,  0.0000e+00, -2.4151e-02,  0.0000e+00,\n",
      "        -5.4265e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  7.1447e-03,  0.0000e+00,\n",
      "         1.5404e-02,  0.0000e+00,  8.9454e-04,  0.0000e+00,  0.0000e+00,\n",
      "         1.3155e-03, -1.4043e-02, -6.8499e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -1.3084e-02,  0.0000e+00,  9.3233e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  3.0349e-02,  0.0000e+00, -2.1194e-02,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -9.0627e-03,  0.0000e+00,  9.4135e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  8.4265e-03,  7.3223e-03,\n",
      "         1.2440e-03, -4.0639e-03,  2.0066e-03,  1.5340e-02,  3.4890e-03,\n",
      "        -1.1232e-02,  0.0000e+00,  3.3959e-02,  5.3155e-03,  0.0000e+00,\n",
      "         3.3551e-02,  3.1684e-02, -8.6053e-04, -7.5852e-03,  0.0000e+00,\n",
      "        -2.1730e-02,  1.7544e-03,  2.7286e-02,  1.5865e-02,  1.0009e-02,\n",
      "         0.0000e+00,  9.3091e-03, -2.0889e-02,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -4.4758e-03,  1.6593e-02,\n",
      "         7.3453e-04, -8.3005e-03, -5.8091e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -2.3820e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  8.1514e-03,\n",
      "         0.0000e+00,  0.0000e+00,  4.6280e-03,  2.5357e-02,  0.0000e+00,\n",
      "        -7.0763e-03,  0.0000e+00,  1.4493e-04,  0.0000e+00,  0.0000e+00,\n",
      "         8.4636e-03, -4.5619e-03,  0.0000e+00,  0.0000e+00,  2.5054e-03,\n",
      "         0.0000e+00, -1.4741e-02,  0.0000e+00,  3.3953e-03,  0.0000e+00,\n",
      "         0.0000e+00, -4.2659e-03,  1.6700e-02, -8.6834e-03, -7.9161e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  2.6472e-04,  0.0000e+00, -4.8809e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -4.7472e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  2.2700e-02,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -7.6809e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -3.0059e-03,  0.0000e+00, -7.1565e-03,  1.8096e-02,  1.5335e-02,\n",
      "        -1.0073e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         1.9169e-02, -1.0524e-02,  1.9688e-02,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  3.1815e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  1.5545e-02,  1.9763e-02,  1.3547e-02,\n",
      "        -2.5353e-02, -1.1146e-02, -8.1507e-03,  0.0000e+00,  1.6481e-03,\n",
      "         8.6318e-05,  1.1425e-02,  6.0263e-03, -5.3856e-03, -1.4314e-02,\n",
      "         0.0000e+00,  7.3482e-04,  0.0000e+00,  1.7265e-02, -2.7164e-03,\n",
      "         0.0000e+00,  0.0000e+00, -8.9619e-03,  0.0000e+00, -7.5059e-03,\n",
      "        -1.4155e-02,  1.1972e-02, -3.0360e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -1.6256e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         6.5815e-03, -1.7744e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  4.4133e-04,  0.0000e+00, -1.6961e-02, -9.2295e-03,\n",
      "        -9.4759e-03,  0.0000e+00,  4.0565e-03,  0.0000e+00,  1.5506e-02,\n",
      "         0.0000e+00, -2.3294e-02, -4.8399e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -6.3221e-03,  0.0000e+00,  0.0000e+00, -1.0360e-04,\n",
      "         0.0000e+00,  1.6137e-03,  0.0000e+00,  0.0000e+00,  2.7570e-03,\n",
      "         0.0000e+00,  1.2725e-02,  0.0000e+00, -1.4753e-02,  0.0000e+00,\n",
      "         0.0000e+00, -1.4985e-02,  0.0000e+00,  1.3644e-02, -3.0858e-03,\n",
      "         9.6619e-04,  0.0000e+00,  0.0000e+00,  1.1235e-02,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.0129e-02, -1.1517e-02, -2.0824e-03,\n",
      "        -6.1825e-04,  0.0000e+00,  8.4064e-03, -1.5941e-03, -1.7690e-02,\n",
      "        -1.3658e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         3.3820e-02,  0.0000e+00,  0.0000e+00,  6.1497e-04, -7.5510e-03,\n",
      "         0.0000e+00,  0.0000e+00,  3.5565e-02,  1.6939e-02, -5.5128e-04,\n",
      "         6.3023e-03,  0.0000e+00,  6.8703e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -1.0737e-02, -6.6257e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         3.5227e-03, -1.7455e-02, -1.8247e-02,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -2.5148e-02,  0.0000e+00,  0.0000e+00, -4.1217e-03,\n",
      "         0.0000e+00,  0.0000e+00, -1.6092e-02,  0.0000e+00,  1.7309e-02,\n",
      "         1.0703e-02, -8.3126e-03,  0.0000e+00, -3.9615e-04,  0.0000e+00,\n",
      "        -3.1928e-04, -9.7249e-03,  1.9901e-02, -5.9841e-03,  3.1124e-03,\n",
      "         1.0082e-02,  0.0000e+00, -2.3811e-02,  0.0000e+00,  7.2458e-03,\n",
      "         1.1197e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7574e-03,\n",
      "         0.0000e+00,  1.7888e-02,  2.4345e-02,  0.0000e+00,  0.0000e+00,\n",
      "        -9.3444e-03,  0.0000e+00,  8.6891e-03,  0.0000e+00, -1.1708e-02,\n",
      "         2.7951e-03, -7.0932e-03, -1.8017e-02,  0.0000e+00,  0.0000e+00])\n",
      "===========\n",
      "gradient:R.R_write.postproc.0.layers.2.weight\n",
      "----------\n",
      "tensor([[-0.0005,  0.0000, -0.0004,  ..., -0.0016,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0018,  0.0000,  0.0014,  ...,  0.0053,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "===========\n",
      "gradient:R.R_write.postproc.0.layers.2.bias\n",
      "----------\n",
      "tensor([-0.0208,  0.0000,  0.0000,  0.0834,  0.0665,  0.0925,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0732, -0.0683, -0.0662,  0.0119,  0.0000,  0.0523,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0596,  0.0000,\n",
      "         0.0000, -0.0777, -0.0082,  0.0718, -0.0809,  0.0470, -0.0139, -0.0863,\n",
      "         0.0000,  0.0000,  0.0000,  0.0099,  0.0000,  0.0073,  0.0162,  0.0000,\n",
      "         0.0740,  0.0000,  0.0507, -0.0761,  0.0000, -0.0730, -0.0319,  0.0000,\n",
      "         0.0000,  0.0000,  0.0675,  0.0000, -0.0804,  0.0000, -0.0243,  0.0353,\n",
      "         0.0367, -0.0079, -0.0966,  0.0088,  0.0000,  0.0897,  0.0000,  0.0000,\n",
      "         0.0000,  0.0612, -0.0721,  0.0000, -0.0681,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0377,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0782,  0.0673,  0.0000,  0.0000,  0.0337,  0.0000, -0.0117,\n",
      "         0.0618, -0.0471,  0.0000,  0.0000,  0.0000,  0.0000,  0.0785,  0.0000,\n",
      "         0.0000, -0.0432,  0.0451,  0.0000, -0.0594,  0.0000, -0.0152,  0.0000,\n",
      "         0.0000, -0.0980,  0.0000, -0.0882, -0.0518, -0.0536, -0.0150,  0.0000,\n",
      "         0.0000,  0.0000,  0.0427, -0.0259, -0.0840, -0.0571,  0.0000,  0.0003,\n",
      "         0.0000,  0.0661,  0.0174, -0.0420,  0.0155,  0.0000,  0.0000, -0.0425,\n",
      "         0.0000,  0.0000, -0.0756,  0.0000,  0.0000, -0.0339,  0.0000,  0.0287,\n",
      "         0.0388,  0.0000,  0.0588,  0.0133,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0345, -0.0665,  0.0000,  0.0000, -0.0856,  0.0000, -0.0321,\n",
      "         0.0000,  0.0000,  0.0000, -0.0474,  0.0000, -0.0774,  0.0000,  0.0000,\n",
      "        -0.0956,  0.0316,  0.0000,  0.0000,  0.0000, -0.0501,  0.0000, -0.0732,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0853,\n",
      "        -0.0287, -0.0226,  0.0000,  0.0000, -0.0507, -0.0178,  0.0180, -0.0952,\n",
      "         0.0636,  0.0379,  0.0000,  0.0000,  0.0000,  0.0000,  0.0587,  0.0000,\n",
      "         0.0017,  0.0272,  0.0000, -0.0621,  0.0431,  0.0000,  0.0697,  0.0000])\n",
      "===========\n",
      "gradient:R.R_write.postproc.0.layers.4.weight\n",
      "----------\n",
      "tensor([[-8.8770e-02,  0.0000e+00,  0.0000e+00, -2.9211e-02, -8.0397e-02,\n",
      "         -3.7208e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.7608e-02, -6.1292e-02, -5.7388e-02, -5.7174e-02,  0.0000e+00,\n",
      "         -6.6746e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -1.7669e-02,  0.0000e+00,  0.0000e+00,\n",
      "         -1.4344e-02, -7.0173e-02, -8.8747e-03, -1.5524e-02, -7.3507e-03,\n",
      "         -5.8775e-02, -5.5729e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -2.9700e-02,  0.0000e+00, -5.8708e-02, -1.5183e-02,  0.0000e+00,\n",
      "         -5.0166e-02,  0.0000e+00, -5.0820e-02, -5.4518e-03,  0.0000e+00,\n",
      "         -4.3626e-03, -7.8563e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -7.1817e-02,  0.0000e+00, -4.4449e-02,  0.0000e+00, -8.8293e-02,\n",
      "         -4.2514e-02, -6.7597e-03, -3.7991e-02, -5.7791e-02, -5.3614e-02,\n",
      "          0.0000e+00, -5.4240e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.1044e-01, -8.9335e-04,  0.0000e+00, -5.2530e-02,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -6.0930e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -2.0556e-02, -4.1849e-02,  0.0000e+00,  0.0000e+00,\n",
      "         -9.2116e-02,  0.0000e+00, -6.7914e-05, -4.6743e-02, -1.2881e-02,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.5802e-02,\n",
      "          0.0000e+00,  0.0000e+00, -1.3810e-03, -3.8754e-02,  0.0000e+00,\n",
      "         -5.4275e-02,  0.0000e+00, -7.2359e-02,  0.0000e+00,  0.0000e+00,\n",
      "         -5.1987e-02,  0.0000e+00, -4.0452e-03, -3.9867e-04, -5.3678e-02,\n",
      "         -1.4238e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4867e-02,\n",
      "         -3.9550e-02, -6.2274e-02, -3.2976e-02,  0.0000e+00, -4.5612e-02,\n",
      "          0.0000e+00, -1.1442e-02, -1.1227e-02, -5.1082e-03, -1.1190e-02,\n",
      "          0.0000e+00,  0.0000e+00, -5.7411e-04,  0.0000e+00,  0.0000e+00,\n",
      "         -1.6889e-02,  0.0000e+00,  0.0000e+00, -1.5396e-02,  0.0000e+00,\n",
      "         -1.3694e-04, -3.0998e-02,  0.0000e+00, -3.2197e-02, -1.7300e-02,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.2959e-03, -1.9894e-02,  0.0000e+00,  0.0000e+00, -3.2851e-02,\n",
      "          0.0000e+00, -2.6925e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -7.0357e-02,  0.0000e+00, -3.3690e-02,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3931e-03, -5.3384e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -9.1470e-02,  0.0000e+00, -4.8763e-02,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.4748e-02, -3.7275e-02, -3.7159e-02,  0.0000e+00,  0.0000e+00,\n",
      "         -1.1687e-02, -5.4026e-02, -2.5131e-04, -2.7798e-02, -7.7085e-02,\n",
      "         -6.2080e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -8.5667e-02,  0.0000e+00, -1.3560e-02, -3.5563e-03,  0.0000e+00,\n",
      "         -1.7065e-02, -2.9779e-02,  0.0000e+00, -1.1100e-01,  0.0000e+00]])\n",
      "===========\n",
      "gradient:R.R_write.postproc.0.layers.4.bias\n",
      "----------\n",
      "tensor([-1.4022])\n",
      "===========\n",
      "gradient:R.R_write.postproc.1.layers.0.weight\n",
      "----------\n",
      "tensor([[7.7080e-06, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         3.5644e-06],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [4.2604e-05, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         2.3770e-05],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]])\n",
      "===========\n",
      "gradient:R.R_write.postproc.1.layers.0.bias\n",
      "----------\n",
      "tensor([ 2.6960e-04,  0.0000e+00,  0.0000e+00,  6.7183e-04, -5.2278e-04,\n",
      "         5.8258e-04,  0.0000e+00,  1.1662e-03,  0.0000e+00,  0.0000e+00,\n",
      "         4.8058e-05,  0.0000e+00,  0.0000e+00,  8.1243e-04,  0.0000e+00,\n",
      "         0.0000e+00,  1.7920e-03,  6.9711e-05,  0.0000e+00,  0.0000e+00,\n",
      "         6.3137e-04, -2.2489e-04,  0.0000e+00,  0.0000e+00, -3.2336e-03,\n",
      "         2.1404e-03,  0.0000e+00,  2.7316e-03, -4.3135e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  9.3696e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  9.3884e-05,  0.0000e+00,  0.0000e+00, -6.3942e-04,\n",
      "         2.6947e-04, -2.1430e-03,  0.0000e+00, -1.2721e-03,  8.7157e-04,\n",
      "        -1.6177e-03,  0.0000e+00, -1.0397e-03,  0.0000e+00, -8.7056e-05,\n",
      "        -2.5752e-03,  2.3193e-03,  3.8052e-03,  0.0000e+00,  1.3578e-03,\n",
      "        -2.1985e-03, -8.1291e-04,  0.0000e+00, -8.8879e-04, -2.9691e-03,\n",
      "         0.0000e+00,  0.0000e+00, -1.8642e-03,  4.0665e-04, -2.7753e-03,\n",
      "        -3.0660e-03,  0.0000e+00,  0.0000e+00, -2.3211e-03,  0.0000e+00,\n",
      "         1.8349e-03,  0.0000e+00, -1.8021e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -6.2048e-05,  2.1988e-03, -2.0023e-03,  1.0315e-03,  0.0000e+00,\n",
      "         0.0000e+00,  1.2242e-03,  1.5799e-03, -2.9629e-04, -5.9779e-04,\n",
      "         0.0000e+00,  0.0000e+00,  6.1421e-04, -5.5059e-04,  1.4715e-03,\n",
      "         0.0000e+00, -3.0748e-03, -1.9283e-03, -1.1728e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -3.6531e-03,  0.0000e+00, -2.8388e-03,\n",
      "         4.3989e-03, -1.3813e-03,  3.2110e-03,  0.0000e+00, -1.5580e-03,\n",
      "         0.0000e+00, -6.9476e-04,  0.0000e+00,  1.8174e-03,  1.6700e-03,\n",
      "         4.4492e-04,  0.0000e+00, -1.3695e-03, -2.4585e-03,  0.0000e+00,\n",
      "        -4.5051e-03, -1.4207e-03, -3.1481e-04,  0.0000e+00,  1.4985e-03,\n",
      "         0.0000e+00,  0.0000e+00, -2.4374e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -1.8737e-03,  0.0000e+00,  9.9291e-04, -2.1163e-03,\n",
      "         1.3834e-03,  0.0000e+00,  3.8011e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -7.8703e-04,  0.0000e+00, -1.5510e-04, -2.2639e-03,\n",
      "         0.0000e+00, -9.9954e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         7.7966e-05, -3.0194e-03,  2.9154e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -1.6533e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -9.5931e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -1.1132e-03,  2.6363e-04,  0.0000e+00, -2.6532e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.3242e-03,\n",
      "        -1.1958e-03, -7.5506e-04,  1.1179e-03,  0.0000e+00,  1.5626e-03,\n",
      "         1.7979e-03,  1.3386e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         8.9314e-04, -1.2044e-03,  0.0000e+00,  1.1579e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -6.7315e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.9913e-03,  2.1464e-03,\n",
      "         4.5774e-04,  3.3019e-04, -1.0184e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -1.7792e-03,  4.1861e-04,  0.0000e+00, -5.5539e-04, -3.2623e-03,\n",
      "         0.0000e+00,  2.4843e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         1.2592e-03, -3.9798e-03,  2.4523e-03, -3.6320e-03,  0.0000e+00,\n",
      "         5.9295e-04,  0.0000e+00,  1.7607e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -2.2663e-03, -1.2505e-03,  1.2258e-03, -8.6944e-04, -2.6113e-03,\n",
      "         0.0000e+00,  0.0000e+00,  4.4308e-03,  0.0000e+00,  8.9874e-04,\n",
      "         0.0000e+00,  0.0000e+00, -5.5506e-04,  9.6508e-06,  0.0000e+00,\n",
      "         1.3343e-03, -3.6613e-03, -1.9369e-03, -7.6266e-04,  0.0000e+00,\n",
      "         0.0000e+00, -3.0819e-03,  0.0000e+00, -1.0359e-03,  1.6875e-03,\n",
      "         0.0000e+00, -1.7938e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -7.3601e-04, -1.7026e-03,  0.0000e+00,  0.0000e+00, -5.6003e-04,\n",
      "         0.0000e+00, -1.0515e-03, -1.2861e-03,  1.4259e-03,  0.0000e+00,\n",
      "         3.5656e-04,  0.0000e+00, -7.7624e-04, -1.7374e-03,  2.8082e-04,\n",
      "        -2.2805e-03, -1.9218e-03,  0.0000e+00,  0.0000e+00,  2.8581e-05,\n",
      "        -7.0948e-04, -1.3732e-03,  0.0000e+00,  1.5399e-03,  0.0000e+00,\n",
      "        -1.2737e-03,  9.6544e-04,  0.0000e+00,  0.0000e+00,  1.7203e-03,\n",
      "         0.0000e+00, -1.4950e-03, -8.4034e-05,  0.0000e+00, -1.6894e-03,\n",
      "        -5.5110e-04, -5.6009e-04,  2.4861e-04,  0.0000e+00,  0.0000e+00,\n",
      "        -1.7638e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.0858e-03,\n",
      "         2.9045e-03, -4.8774e-04, -2.1549e-03,  1.8331e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  1.4268e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -2.7835e-04,  0.0000e+00,  3.8292e-03,  0.0000e+00,\n",
      "         7.8581e-04,  0.0000e+00,  0.0000e+00, -3.0716e-05,  3.8327e-03,\n",
      "         1.7232e-03,  0.0000e+00, -4.6435e-04,  1.3288e-03,  0.0000e+00,\n",
      "         0.0000e+00,  7.3402e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         8.8460e-04,  1.9477e-04,  0.0000e+00,  1.9620e-03,  0.0000e+00,\n",
      "         0.0000e+00,  1.4305e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  1.2438e-03,  0.0000e+00,  0.0000e+00,\n",
      "         4.5195e-03,  3.1114e-03, -2.3951e-04,  0.0000e+00, -3.4498e-04,\n",
      "        -1.0108e-03,  0.0000e+00, -2.1426e-03,  1.1414e-03,  5.2231e-05,\n",
      "         0.0000e+00,  0.0000e+00,  3.5885e-03,  0.0000e+00, -1.5524e-03,\n",
      "        -2.2921e-03,  4.1858e-04,  3.9120e-04,  0.0000e+00, -1.3600e-03,\n",
      "        -2.3928e-03,  9.4614e-06,  0.0000e+00,  1.2658e-03, -9.7315e-04,\n",
      "         0.0000e+00,  0.0000e+00,  3.7684e-03,  0.0000e+00,  5.3810e-04,\n",
      "        -7.0154e-04, -2.6453e-03,  0.0000e+00,  0.0000e+00,  3.0406e-03,\n",
      "         4.3481e-04, -1.3580e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  2.2138e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  5.9978e-04, -2.3864e-03,  0.0000e+00,\n",
      "         0.0000e+00, -4.1895e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.7522e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -6.8642e-04,  0.0000e+00,  2.0991e-04,  0.0000e+00,\n",
      "        -1.8302e-03,  0.0000e+00,  0.0000e+00, -1.0337e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.6553e-04, -2.8469e-03,\n",
      "        -2.0298e-03, -3.7585e-04,  0.0000e+00, -9.8355e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  4.9995e-03,  7.4663e-05,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  2.7485e-03, -1.0859e-04,  0.0000e+00,\n",
      "         0.0000e+00,  4.7983e-03, -3.9440e-04, -2.0666e-03,  0.0000e+00,\n",
      "         0.0000e+00, -1.2404e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  3.4167e-03, -2.0593e-03,  6.0150e-04,\n",
      "         0.0000e+00,  0.0000e+00,  7.7542e-04,  2.0687e-03, -3.1547e-03,\n",
      "        -1.8149e-03, -2.9814e-03,  0.0000e+00,  8.3202e-04,  0.0000e+00,\n",
      "         1.7682e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -5.6244e-04, -2.6106e-04, -7.6920e-04,  0.0000e+00,\n",
      "        -4.8659e-05,  0.0000e+00, -3.7564e-03,  1.8170e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  2.1729e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -7.6914e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7703e-04,\n",
      "        -8.7269e-04,  0.0000e+00,  0.0000e+00, -9.2159e-04,  0.0000e+00,\n",
      "         0.0000e+00, -2.0004e-03,  0.0000e+00,  1.4205e-03,  0.0000e+00])\n",
      "===========\n",
      "gradient:R.R_write.postproc.1.layers.2.weight\n",
      "----------\n",
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-5.3264e-06,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "         -1.5858e-04,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-9.1390e-06,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "         -2.7209e-04,  0.0000e+00],\n",
      "        [-9.0246e-06,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "         -2.6868e-04,  0.0000e+00]])\n",
      "===========\n",
      "gradient:R.R_write.postproc.1.layers.2.bias\n",
      "----------\n",
      "tensor([ 0.0000e+00, -4.8755e-03,  0.0000e+00,  0.0000e+00, -3.7256e-03,\n",
      "         0.0000e+00,  0.0000e+00,  9.4174e-04,  4.3999e-03, -9.2388e-03,\n",
      "        -7.2384e-03, -9.5061e-03, -8.8965e-03,  6.0916e-03,  0.0000e+00,\n",
      "         0.0000e+00, -5.2272e-03, -4.8918e-03,  7.0746e-03, -5.3948e-03,\n",
      "         0.0000e+00, -6.5939e-03, -5.3619e-03,  1.0149e-02,  3.0835e-03,\n",
      "         0.0000e+00, -7.2669e-03, -3.7296e-03, -8.7121e-03,  6.6478e-03,\n",
      "        -9.1974e-03, -6.9225e-03, -4.6371e-03, -3.7818e-03, -6.1403e-03,\n",
      "         0.0000e+00,  0.0000e+00, -5.0179e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -2.7411e-03, -1.0779e-02,  0.0000e+00, -4.5936e-03,  6.0250e-03,\n",
      "         0.0000e+00,  0.0000e+00, -1.1011e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -2.6880e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.2808e-03,\n",
      "         1.0672e-02,  0.0000e+00,  0.0000e+00, -5.8500e-03, -4.6482e-03,\n",
      "         0.0000e+00, -7.0122e-03,  7.4737e-03,  0.0000e+00, -7.1817e-03,\n",
      "         0.0000e+00,  0.0000e+00,  3.7425e-03,  8.2294e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         9.0877e-03,  5.4249e-03,  1.6850e-03,  9.4136e-03,  0.0000e+00,\n",
      "         6.3299e-04,  9.9251e-04,  1.8942e-03,  5.1937e-03,  0.0000e+00,\n",
      "         0.0000e+00, -4.3882e-03,  9.9325e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  8.9769e-03,  5.4326e-03, -4.2685e-03,\n",
      "         3.6679e-03, -7.5939e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  8.8024e-03,  8.6519e-03, -7.1264e-03,  0.0000e+00,\n",
      "         0.0000e+00,  2.1282e-03,  0.0000e+00,  0.0000e+00,  6.7296e-03,\n",
      "         7.4609e-03,  0.0000e+00,  5.1994e-03,  0.0000e+00, -8.0589e-03,\n",
      "         0.0000e+00,  4.8542e-03,  6.1271e-03,  5.0666e-03, -9.3179e-03,\n",
      "        -5.9239e-03, -8.5516e-03,  9.5517e-03, -1.0828e-02,  5.0769e-03,\n",
      "        -8.8624e-03,  1.0597e-02, -5.5973e-03, -2.3113e-03,  7.1246e-03,\n",
      "        -1.0309e-02,  0.0000e+00,  0.0000e+00,  5.1583e-03,  0.0000e+00,\n",
      "         7.1825e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.5381e-03,\n",
      "        -5.5408e-05,  0.0000e+00, -6.2443e-03,  0.0000e+00, -3.5653e-03,\n",
      "         2.7384e-03, -1.5180e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         5.4580e-04,  3.4474e-04,  0.0000e+00,  7.5185e-03, -3.5623e-03,\n",
      "         2.2421e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.1293e-03,\n",
      "         5.8691e-03,  0.0000e+00,  0.0000e+00, -2.5215e-03,  9.6955e-03,\n",
      "        -9.3094e-03,  0.0000e+00,  3.6356e-03,  0.0000e+00, -7.9833e-03,\n",
      "         0.0000e+00,  6.8651e-03,  0.0000e+00, -1.0806e-02, -3.3136e-03,\n",
      "         7.3799e-03, -5.5453e-03,  0.0000e+00,  0.0000e+00,  2.8550e-03,\n",
      "         6.7639e-03, -2.5382e-04, -1.6166e-03,  8.4930e-03, -5.1425e-03,\n",
      "         0.0000e+00,  1.0848e-02,  7.7352e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -1.0850e-02,  0.0000e+00,  0.0000e+00, -3.2714e-04,  6.9712e-03,\n",
      "        -2.9455e-03,  4.7353e-03,  0.0000e+00, -8.3654e-03, -8.2607e-03])\n",
      "===========\n",
      "gradient:R.R_write.postproc.1.layers.4.weight\n",
      "----------\n",
      "tensor([[0.0000e+00, 3.6075e-03, 0.0000e+00, 0.0000e+00, 2.9420e-03, 0.0000e+00,\n",
      "         0.0000e+00, 3.7398e-03, 3.1041e-03, 5.3445e-03, 5.9694e-03, 7.7684e-04,\n",
      "         1.1852e-03, 1.9740e-03, 0.0000e+00, 0.0000e+00, 4.3020e-03, 6.8047e-03,\n",
      "         1.8420e-03, 6.6498e-03, 0.0000e+00, 4.7812e-03, 3.8511e-03, 2.0429e-03,\n",
      "         5.5764e-03, 0.0000e+00, 5.0394e-04, 1.0057e-03, 1.0487e-02, 3.8149e-03,\n",
      "         8.3484e-03, 1.0919e-03, 6.1039e-03, 3.1834e-04, 4.7929e-04, 0.0000e+00,\n",
      "         0.0000e+00, 3.8108e-04, 0.0000e+00, 0.0000e+00, 4.1224e-03, 1.8911e-03,\n",
      "         0.0000e+00, 4.8293e-03, 1.9212e-03, 0.0000e+00, 0.0000e+00, 2.3862e-03,\n",
      "         0.0000e+00, 0.0000e+00, 7.4595e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.9028e-03, 5.2774e-03, 0.0000e+00, 0.0000e+00, 5.4305e-03, 2.7783e-03,\n",
      "         0.0000e+00, 2.5813e-03, 6.4371e-03, 0.0000e+00, 1.5031e-03, 0.0000e+00,\n",
      "         0.0000e+00, 8.1091e-03, 4.3911e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.4643e-04, 1.5548e-03, 3.5217e-03,\n",
      "         1.0479e-04, 0.0000e+00, 2.2687e-03, 4.8237e-03, 7.8396e-03, 4.6394e-03,\n",
      "         0.0000e+00, 0.0000e+00, 4.6967e-03, 6.4284e-03, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0058e-03, 2.4062e-04, 1.5283e-03, 2.5929e-03,\n",
      "         1.9595e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2366e-03,\n",
      "         5.5424e-03, 3.8022e-03, 0.0000e+00, 0.0000e+00, 4.1755e-03, 0.0000e+00,\n",
      "         0.0000e+00, 3.2174e-04, 6.3403e-04, 0.0000e+00, 5.0876e-03, 0.0000e+00,\n",
      "         3.3700e-03, 0.0000e+00, 1.5085e-03, 5.4618e-03, 4.7453e-03, 6.8765e-03,\n",
      "         2.9923e-03, 6.5143e-03, 1.7318e-03, 5.7779e-03, 2.0246e-03, 9.3309e-03,\n",
      "         6.8293e-04, 5.6970e-04, 7.1102e-04, 3.4748e-03, 3.9427e-04, 0.0000e+00,\n",
      "         0.0000e+00, 6.2032e-03, 0.0000e+00, 1.2597e-03, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 9.7167e-03, 6.1125e-03, 0.0000e+00, 2.0751e-03, 0.0000e+00,\n",
      "         6.2650e-03, 4.1976e-03, 4.9246e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.4036e-03, 5.9590e-05, 0.0000e+00, 4.3446e-04, 1.1326e-03, 3.9728e-04,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8959e-03, 1.0873e-03, 0.0000e+00,\n",
      "         0.0000e+00, 7.1475e-04, 4.0469e-05, 7.8859e-03, 0.0000e+00, 1.5046e-03,\n",
      "         0.0000e+00, 2.7055e-03, 0.0000e+00, 4.7388e-03, 0.0000e+00, 7.0296e-03,\n",
      "         2.7267e-03, 2.6482e-03, 4.3950e-03, 0.0000e+00, 0.0000e+00, 2.3823e-03,\n",
      "         2.0523e-03, 4.8172e-03, 4.3498e-03, 2.5404e-03, 2.9042e-04, 0.0000e+00,\n",
      "         5.5817e-04, 1.1805e-03, 0.0000e+00, 0.0000e+00, 5.7976e-03, 0.0000e+00,\n",
      "         0.0000e+00, 4.3140e-03, 4.6345e-03, 4.1130e-03, 6.8629e-08, 0.0000e+00,\n",
      "         2.1063e-03, 2.4676e-03]])\n",
      "===========\n",
      "gradient:R.R_write.postproc.1.layers.4.bias\n",
      "----------\n",
      "tensor([0.1537])\n",
      "===========\n",
      "gradient:R.R_write.postproc.2.layers.0.weight\n",
      "----------\n",
      "None\n",
      "===========\n",
      "gradient:R.R_write.postproc.2.layers.0.bias\n",
      "----------\n",
      "None\n",
      "===========\n",
      "gradient:R.R_write.postproc.2.layers.2.weight\n",
      "----------\n",
      "None\n",
      "===========\n",
      "gradient:R.R_write.postproc.2.layers.2.bias\n",
      "----------\n",
      "None\n",
      "===========\n",
      "gradient:R.R_write.postproc.2.layers.4.weight\n",
      "----------\n",
      "None\n",
      "===========\n",
      "gradient:R.R_write.postproc.2.layers.4.bias\n",
      "----------\n",
      "None\n",
      "===========\n",
      "gradient:R.R_write.postproc.3.layers.0.weight\n",
      "----------\n",
      "None\n",
      "===========\n",
      "gradient:R.R_write.postproc.3.layers.0.bias\n",
      "----------\n",
      "None\n",
      "===========\n",
      "gradient:R.R_write.postproc.3.layers.2.weight\n",
      "----------\n",
      "None\n",
      "===========\n",
      "gradient:R.R_write.postproc.3.layers.2.bias\n",
      "----------\n",
      "None\n",
      "===========\n",
      "gradient:R.R_write.postproc.3.layers.4.weight\n",
      "----------\n",
      "None\n",
      "===========\n",
      "gradient:R.R_write.postproc.3.layers.4.bias\n",
      "----------\n",
      "None\n",
      "===========\n",
      "gradient:R.R_write.postproc.4.layers.0.weight\n",
      "----------\n",
      "tensor([[ 6.6942e-06,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  4.9604e-06],\n",
      "        [ 9.7844e-06,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  7.2502e-06],\n",
      "        [ 1.6178e-05,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  1.1988e-05],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 4.3516e-06,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  3.2245e-06],\n",
      "        [-1.7459e-05,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -1.2937e-05]])\n",
      "===========\n",
      "gradient:R.R_write.postproc.4.layers.0.bias\n",
      "----------\n",
      "tensor([ 4.5114e-04,  6.5940e-04,  1.0903e-03,  2.7662e-04,  2.0174e-03,\n",
      "         0.0000e+00, -6.7402e-04,  1.9176e-04,  0.0000e+00, -5.5600e-04,\n",
      "         0.0000e+00,  6.2450e-04,  1.0318e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.6141e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -5.5812e-04, -1.4631e-04,\n",
      "         6.7796e-05, -7.9409e-04,  4.0301e-04,  2.7777e-04, -5.4125e-04,\n",
      "         0.0000e+00,  0.0000e+00,  6.2300e-04,  0.0000e+00,  1.9661e-04,\n",
      "        -1.4385e-04, -1.2060e-03, -1.4523e-03,  0.0000e+00,  5.1735e-04,\n",
      "         0.0000e+00,  0.0000e+00, -2.9752e-04, -5.4475e-04, -1.0952e-03,\n",
      "        -1.2298e-05, -1.0048e-03,  5.3191e-04,  1.6268e-04,  0.0000e+00,\n",
      "         0.0000e+00, -3.0054e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.3867e-03,  8.6262e-04,  1.3867e-05,\n",
      "         8.1111e-04,  9.6190e-05,  0.0000e+00,  0.0000e+00,  4.8587e-04,\n",
      "        -7.9948e-04, -2.3339e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         4.7421e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -3.5459e-04,  7.0573e-04, -1.1697e-03,  0.0000e+00,\n",
      "         1.8666e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         8.5329e-04, -8.9340e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  6.3954e-04,  7.1300e-04, -1.5809e-04,  2.9050e-04,\n",
      "         5.8973e-04,  0.0000e+00, -1.6563e-04, -2.4124e-04, -5.1109e-04,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.9034e-04,  0.0000e+00,\n",
      "        -9.6754e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         1.4306e-03,  0.0000e+00,  0.0000e+00,  3.4061e-04,  1.1370e-03,\n",
      "        -1.3147e-03,  0.0000e+00,  0.0000e+00, -7.0209e-04,  0.0000e+00,\n",
      "        -1.5068e-04, -9.0322e-04,  2.5910e-04,  0.0000e+00,  2.2663e-04,\n",
      "         3.5410e-04, -2.7151e-04,  0.0000e+00,  0.0000e+00, -5.9055e-04,\n",
      "         1.8113e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.1359e-04,\n",
      "         0.0000e+00, -4.9910e-04,  0.0000e+00,  1.8565e-04, -5.8645e-04,\n",
      "         6.4222e-04, -1.4571e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  7.9924e-05,  1.6903e-04,  0.0000e+00,\n",
      "         0.0000e+00, -7.6342e-04,  0.0000e+00,  4.7729e-04, -1.8160e-03,\n",
      "         0.0000e+00,  0.0000e+00, -1.2693e-03, -1.2567e-03,  0.0000e+00,\n",
      "         0.0000e+00,  4.2940e-04,  0.0000e+00,  0.0000e+00, -2.6001e-04,\n",
      "         1.2235e-03,  0.0000e+00, -1.3106e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -2.0238e-03, -5.9612e-04, -6.7708e-04, -1.1159e-03, -1.7074e-03,\n",
      "         0.0000e+00, -3.5917e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         4.8206e-04,  0.0000e+00,  0.0000e+00,  9.7911e-04,  0.0000e+00,\n",
      "        -6.8716e-05,  1.0172e-03,  0.0000e+00, -5.9318e-04, -4.9966e-04,\n",
      "        -2.7222e-04,  1.1786e-03,  0.0000e+00,  0.0000e+00, -7.5271e-05,\n",
      "         0.0000e+00,  0.0000e+00, -1.2721e-03, -4.1036e-05, -4.5161e-04,\n",
      "        -7.3755e-05, -2.1392e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  7.4167e-05,  0.0000e+00, -5.9573e-04,  1.6059e-04,\n",
      "        -3.8750e-04,  0.0000e+00, -5.0213e-04,  1.5802e-04,  1.1723e-03,\n",
      "         2.1605e-04,  0.0000e+00,  0.0000e+00, -5.3296e-04,  1.0554e-03,\n",
      "         0.0000e+00,  0.0000e+00,  1.1511e-03,  2.1607e-03, -1.6406e-03,\n",
      "        -7.0906e-05,  8.9774e-04,  0.0000e+00, -2.2337e-05, -1.4892e-03,\n",
      "        -2.1064e-04,  0.0000e+00,  9.1566e-04,  0.0000e+00, -1.2538e-03,\n",
      "         0.0000e+00,  1.2613e-04,  1.7765e-04,  9.1336e-04,  4.7309e-04,\n",
      "         7.4893e-05,  2.8536e-04, -2.0389e-04,  3.2739e-04, -1.1451e-03,\n",
      "        -1.3711e-04,  0.0000e+00, -4.3513e-04,  0.0000e+00,  0.0000e+00,\n",
      "        -7.0889e-05,  0.0000e+00, -3.5120e-04, -8.2580e-04,  1.6229e-05,\n",
      "        -1.5356e-05, -1.1623e-03,  0.0000e+00,  0.0000e+00,  1.1465e-03,\n",
      "         1.0793e-04,  0.0000e+00, -3.0782e-04,  0.0000e+00,  8.8736e-04,\n",
      "         0.0000e+00,  0.0000e+00,  2.6905e-04,  1.4481e-04, -1.2913e-03,\n",
      "        -2.1018e-03,  7.6033e-04,  0.0000e+00, -1.0422e-03,  2.5281e-03,\n",
      "         0.0000e+00,  0.0000e+00,  6.3057e-05, -3.6850e-05,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  7.1069e-04,  0.0000e+00,  0.0000e+00,\n",
      "        -1.2265e-03,  0.0000e+00, -1.9401e-05,  0.0000e+00,  2.0260e-04,\n",
      "        -1.8459e-03,  0.0000e+00, -7.5056e-04, -9.6038e-04, -3.5385e-04,\n",
      "         3.4104e-04,  0.0000e+00,  0.0000e+00,  4.5576e-04,  0.0000e+00,\n",
      "         1.5323e-03,  0.0000e+00,  0.0000e+00,  9.2610e-04,  0.0000e+00,\n",
      "         0.0000e+00,  2.1074e-03, -5.4985e-04,  2.8455e-03,  2.4759e-04,\n",
      "        -1.8344e-05,  0.0000e+00, -5.8839e-04, -8.5770e-05,  0.0000e+00,\n",
      "         7.5647e-04,  9.3308e-04,  0.0000e+00,  1.8256e-04,  0.0000e+00,\n",
      "         1.4692e-04, -8.4259e-04, -2.8754e-04, -1.0997e-04,  0.0000e+00,\n",
      "        -6.7328e-04,  3.7820e-04, -4.4484e-04,  0.0000e+00,  0.0000e+00,\n",
      "         5.5391e-04,  0.0000e+00,  0.0000e+00, -5.7611e-04,  0.0000e+00,\n",
      "         4.0471e-04,  0.0000e+00,  0.0000e+00,  1.4319e-03,  6.9455e-05,\n",
      "        -1.6900e-03,  0.0000e+00, -9.2103e-04,  0.0000e+00,  8.2288e-04,\n",
      "         0.0000e+00,  0.0000e+00, -1.9607e-04, -6.2404e-05,  0.0000e+00,\n",
      "         3.1573e-04,  0.0000e+00,  7.1562e-04, -3.9242e-04, -1.2133e-03,\n",
      "         0.0000e+00,  2.8002e-04,  0.0000e+00,  0.0000e+00,  1.4432e-03,\n",
      "         0.0000e+00,  0.0000e+00,  3.0830e-04, -3.3186e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  1.2751e-03, -1.1051e-03,  1.3180e-04,  1.9399e-03,\n",
      "         3.4533e-04,  0.0000e+00, -1.3867e-05,  0.0000e+00,  8.8583e-04,\n",
      "         5.7956e-04, -6.4145e-04,  1.0740e-04, -9.4507e-04, -4.2274e-05,\n",
      "         0.0000e+00, -3.0342e-04,  4.3946e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  1.3471e-03,  5.2451e-04, -4.9691e-04,  0.0000e+00,\n",
      "         0.0000e+00,  1.0192e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.9459e-04,\n",
      "         0.0000e+00, -4.5443e-04,  0.0000e+00,  9.4189e-04, -4.6727e-04,\n",
      "         1.0514e-03,  0.0000e+00,  4.4552e-04,  0.0000e+00,  7.2427e-04,\n",
      "         0.0000e+00, -5.0975e-04, -8.2281e-04,  0.0000e+00,  7.2205e-04,\n",
      "         0.0000e+00, -1.3860e-03,  0.0000e+00, -1.2428e-03, -6.3537e-04,\n",
      "         8.1438e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.4682e-05,\n",
      "         3.3247e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -6.8564e-04, -5.4966e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  2.7519e-04, -2.0522e-03,  0.0000e+00,\n",
      "         0.0000e+00, -1.2286e-03,  6.6496e-04,  0.0000e+00,  1.0675e-03,\n",
      "         0.0000e+00,  7.0489e-04,  0.0000e+00,  0.0000e+00,  2.5492e-04,\n",
      "        -9.0505e-04, -1.0385e-03,  6.9980e-04,  0.0000e+00,  0.0000e+00,\n",
      "         2.5085e-04,  0.0000e+00,  0.0000e+00,  5.4098e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -9.2515e-05,\n",
      "         0.0000e+00,  6.8088e-04, -1.4845e-03, -1.3847e-04,  7.5853e-04,\n",
      "         8.2570e-04,  0.0000e+00, -6.6103e-05,  0.0000e+00,  2.4775e-04,\n",
      "         9.6841e-04,  0.0000e+00, -1.0383e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -6.2075e-04, -2.4121e-04,  0.0000e+00,  0.0000e+00,  1.0101e-03,\n",
      "         0.0000e+00,  0.0000e+00, -1.5520e-03, -1.3536e-04,  0.0000e+00,\n",
      "        -9.9438e-04, -2.0067e-03,  0.0000e+00,  2.9327e-04, -1.1766e-03])\n",
      "===========\n",
      "gradient:R.R_write.postproc.4.layers.2.weight\n",
      "----------\n",
      "tensor([[7.5038e-05, 2.5951e-05, 2.6785e-05,  ..., 0.0000e+00, 2.2932e-05,\n",
      "         7.0579e-05],\n",
      "        [1.4393e-05, 4.9775e-06, 5.1375e-06,  ..., 0.0000e+00, 4.3985e-06,\n",
      "         1.3537e-05],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [3.1481e-05, 1.0887e-05, 1.1237e-05,  ..., 0.0000e+00, 9.6210e-06,\n",
      "         2.9611e-05],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]])\n",
      "===========\n",
      "gradient:R.R_write.postproc.4.layers.2.bias\n",
      "----------\n",
      "tensor([ 2.0518e-03,  3.9354e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  5.8580e-03,  4.8146e-03,  1.4264e-04,  2.7078e-03,\n",
      "        -3.4272e-03,  1.5761e-03,  0.0000e+00,  1.3752e-03,  1.0782e-03,\n",
      "         0.0000e+00,  3.9954e-03, -4.6065e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -2.6814e-03, -6.1322e-03,  1.7360e-03,  2.7146e-05,\n",
      "         6.8679e-04, -1.2471e-04,  3.3973e-03,  0.0000e+00, -2.8681e-03,\n",
      "         0.0000e+00, -9.6856e-04,  0.0000e+00, -1.0851e-03, -7.2235e-04,\n",
      "         6.9995e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.2250e-03,\n",
      "         0.0000e+00, -2.7030e-03,  0.0000e+00,  0.0000e+00,  3.9312e-03,\n",
      "         7.8579e-04,  2.8402e-03, -3.5376e-03,  0.0000e+00, -2.0442e-03,\n",
      "         0.0000e+00, -4.5866e-03, -5.8496e-03,  8.7843e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -4.6880e-03,  0.0000e+00, -3.0277e-03,  6.2290e-04,  0.0000e+00,\n",
      "        -3.1576e-03,  0.0000e+00,  9.5345e-04,  0.0000e+00, -4.5828e-03,\n",
      "         0.0000e+00, -4.3443e-03,  0.0000e+00,  0.0000e+00,  4.5794e-03,\n",
      "         0.0000e+00,  0.0000e+00, -1.3343e-03,  0.0000e+00,  1.0222e-03,\n",
      "         4.2990e-03, -2.8473e-03,  2.5665e-03,  1.9708e-03, -4.6969e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -4.7637e-03,  2.8294e-03,\n",
      "         6.6332e-04,  5.0972e-04,  0.0000e+00, -5.5432e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  1.1021e-03, -4.4028e-04,  0.0000e+00,\n",
      "         3.7321e-03,  0.0000e+00, -5.3208e-03,  4.2076e-03,  0.0000e+00,\n",
      "         0.0000e+00,  1.2872e-03,  4.6325e-04,  0.0000e+00,  1.7760e-03,\n",
      "        -2.6965e-03,  0.0000e+00,  0.0000e+00,  3.2220e-03, -6.8256e-04,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.1019e-03, -1.8618e-03,\n",
      "        -5.1928e-03, -6.8777e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -3.5725e-03,  5.3932e-03,  0.0000e+00,  3.8405e-03,  0.0000e+00,\n",
      "         0.0000e+00,  9.5413e-04,  0.0000e+00, -4.2159e-03,  2.7920e-03,\n",
      "         0.0000e+00,  0.0000e+00,  3.0580e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  5.9646e-03, -5.8101e-03,  0.0000e+00,\n",
      "        -1.0496e-03, -2.3084e-03,  2.3732e-03,  0.0000e+00,  2.1083e-03,\n",
      "        -4.1474e-03,  5.3015e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -5.8210e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.4705e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -3.0990e-03,  6.5966e-04, -2.5468e-03,  0.0000e+00,\n",
      "        -4.0361e-03,  0.0000e+00,  2.0159e-03,  1.2513e-03, -5.4223e-03,\n",
      "        -2.1230e-03, -5.3397e-03,  0.0000e+00, -5.7930e-03, -1.2410e-03,\n",
      "         6.0590e-04,  0.0000e+00, -5.0068e-03, -2.1713e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  8.6080e-04,  0.0000e+00,  0.0000e+00])\n",
      "===========\n",
      "gradient:R.R_write.postproc.4.layers.4.weight\n",
      "----------\n",
      "tensor([[2.0574e-03, 2.0018e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.0232e-03, 1.6640e-03, 3.2657e-03, 4.2638e-03, 3.1012e-03, 3.9168e-03,\n",
      "         0.0000e+00, 1.3178e-04, 1.4418e-03, 0.0000e+00, 1.4412e-03, 1.5541e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6215e-03, 2.0304e-03, 8.1688e-04,\n",
      "         1.6474e-03, 2.3822e-03, 2.6894e-03, 9.5345e-04, 0.0000e+00, 8.5982e-04,\n",
      "         0.0000e+00, 1.8129e-03, 0.0000e+00, 9.5633e-04, 8.8849e-04, 1.3402e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.8082e-03, 0.0000e+00, 2.7957e-03, 0.0000e+00,\n",
      "         0.0000e+00, 1.0228e-03, 1.8270e-03, 1.7035e-03, 2.0648e-03, 0.0000e+00,\n",
      "         8.8708e-04, 0.0000e+00, 9.3335e-04, 3.9631e-04, 8.0578e-04, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4180e-03, 0.0000e+00,\n",
      "         1.1265e-03, 2.5658e-03, 0.0000e+00, 2.8536e-03, 0.0000e+00, 1.5626e-03,\n",
      "         0.0000e+00, 1.5750e-03, 0.0000e+00, 3.5328e-03, 0.0000e+00, 0.0000e+00,\n",
      "         8.7198e-04, 0.0000e+00, 0.0000e+00, 5.4355e-04, 0.0000e+00, 3.9190e-03,\n",
      "         3.0961e-03, 3.8712e-03, 2.9657e-03, 2.9765e-03, 1.4761e-03, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.8141e-03, 1.2084e-03, 3.9571e-03, 2.4059e-03,\n",
      "         0.0000e+00, 1.1447e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0486e-03,\n",
      "         1.7329e-03, 0.0000e+00, 3.2199e-03, 0.0000e+00, 4.1189e-03, 3.3577e-03,\n",
      "         0.0000e+00, 0.0000e+00, 1.7892e-03, 5.0937e-03, 0.0000e+00, 4.7618e-05,\n",
      "         4.0810e-04, 0.0000e+00, 0.0000e+00, 7.1309e-04, 1.2603e-03, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.1422e-03, 4.3618e-03, 3.2650e-03, 1.1822e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1796e-03, 1.7355e-03, 0.0000e+00,\n",
      "         1.9686e-03, 0.0000e+00, 0.0000e+00, 3.2026e-04, 0.0000e+00, 5.6693e-04,\n",
      "         2.6215e-03, 0.0000e+00, 0.0000e+00, 2.5980e-03, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.3777e-03, 2.4169e-03, 0.0000e+00, 2.8695e-03,\n",
      "         4.7535e-03, 3.3431e-04, 0.0000e+00, 2.2203e-03, 3.0570e-03, 3.4573e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3176e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4933e-03, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.0321e-04, 5.2148e-03, 3.8974e-04, 0.0000e+00,\n",
      "         3.5487e-04, 0.0000e+00, 2.0385e-03, 3.6866e-03, 4.9468e-05, 3.4488e-04,\n",
      "         2.6538e-03, 0.0000e+00, 1.3948e-03, 1.2027e-03, 5.3483e-04, 0.0000e+00,\n",
      "         1.3235e-03, 1.4079e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6598e-03,\n",
      "         0.0000e+00, 0.0000e+00]])\n",
      "===========\n",
      "gradient:R.R_write.postproc.4.layers.4.bias\n",
      "----------\n",
      "tensor([0.0871])\n",
      "===========\n",
      "gradient:R.R_write.postproc.5.layers.0.weight\n",
      "----------\n",
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [-9.4467e-06,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -7.9616e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 8.1560e-06,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  6.6659e-06]])\n",
      "===========\n",
      "gradient:R.R_write.postproc.5.layers.0.bias\n",
      "----------\n",
      "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.2075e-05,  0.0000e+00,\n",
      "        -4.9665e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.4565e-04,\n",
      "         0.0000e+00,  0.0000e+00,  9.8468e-04,  0.0000e+00, -1.1337e-03,\n",
      "         1.8331e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         1.7933e-04,  0.0000e+00,  2.5127e-04,  0.0000e+00, -1.3476e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3387e-03,\n",
      "         0.0000e+00,  2.8529e-04, -2.6986e-04,  3.7314e-04,  6.3173e-04,\n",
      "         0.0000e+00,  5.6556e-04,  0.0000e+00,  7.1502e-04,  0.0000e+00,\n",
      "         7.2888e-05,  0.0000e+00,  0.0000e+00,  8.9968e-05,  7.2502e-04,\n",
      "         7.2925e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.7998e-04,\n",
      "         0.0000e+00,  2.1955e-04,  0.0000e+00,  0.0000e+00, -1.1435e-03,\n",
      "         0.0000e+00, -4.2327e-04,  3.4334e-04,  0.0000e+00, -9.6473e-04,\n",
      "         2.6237e-05,  0.0000e+00,  6.6546e-04,  0.0000e+00, -8.4630e-04,\n",
      "         0.0000e+00,  0.0000e+00,  4.4204e-04, -1.8211e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.9199e-04, -7.4628e-04,\n",
      "         0.0000e+00,  0.0000e+00, -1.3363e-03,  4.1280e-04,  6.1406e-04,\n",
      "         1.2486e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.8263e-06,\n",
      "        -2.0771e-04,  0.0000e+00,  0.0000e+00,  2.0067e-04,  9.5714e-04,\n",
      "         0.0000e+00,  8.3937e-05,  3.0350e-04, -5.7877e-04,  0.0000e+00,\n",
      "         2.2008e-04, -3.0039e-04,  7.1902e-04,  0.0000e+00,  5.3945e-04,\n",
      "         3.4307e-04,  0.0000e+00, -2.8017e-04,  0.0000e+00,  0.0000e+00,\n",
      "        -2.6340e-04,  0.0000e+00, -3.1717e-04,  0.0000e+00, -5.0507e-05,\n",
      "        -3.6718e-04,  4.3803e-04,  5.7000e-04,  7.0518e-04,  0.0000e+00,\n",
      "        -1.0017e-03, -3.4815e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         1.2542e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -3.7504e-04,  0.0000e+00,  7.6665e-04, -1.6424e-04, -1.0926e-05,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.8704e-04,\n",
      "        -1.3498e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.0835e-04,\n",
      "         0.0000e+00, -8.4116e-04,  5.3718e-04,  0.0000e+00, -5.6827e-04,\n",
      "        -8.1001e-05, -6.4164e-04,  2.3828e-05, -4.4761e-04,  0.0000e+00,\n",
      "         0.0000e+00,  2.6432e-04,  0.0000e+00, -3.0981e-04, -1.8572e-04,\n",
      "        -4.9943e-04, -5.3871e-04, -6.7559e-04,  5.1410e-06,  0.0000e+00,\n",
      "         0.0000e+00, -2.0070e-04,  0.0000e+00,  0.0000e+00, -6.7735e-04,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -9.7703e-05,  0.0000e+00,  0.0000e+00,\n",
      "         8.6481e-04,  0.0000e+00,  0.0000e+00, -1.1337e-04,  0.0000e+00,\n",
      "        -9.7378e-05,  8.1835e-04,  1.4776e-03, -1.2274e-03,  0.0000e+00,\n",
      "         6.4865e-04,  0.0000e+00,  3.5727e-04,  3.1862e-04,  7.3961e-05,\n",
      "         0.0000e+00,  0.0000e+00,  3.5378e-04, -1.6815e-03, -1.1648e-04,\n",
      "         0.0000e+00, -2.3889e-04,  6.1937e-04,  1.8708e-04,  0.0000e+00,\n",
      "         0.0000e+00,  5.2555e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0989e-03,  1.1225e-03,\n",
      "         0.0000e+00,  2.6965e-04,  0.0000e+00, -6.7030e-04,  0.0000e+00,\n",
      "         0.0000e+00, -8.2875e-05,  0.0000e+00, -6.4458e-04,  6.0360e-04,\n",
      "        -6.9638e-04, -3.1547e-04,  0.0000e+00,  3.1186e-04,  6.8647e-04,\n",
      "        -3.1046e-04,  0.0000e+00,  0.0000e+00, -2.7382e-05, -1.7511e-04,\n",
      "         1.5735e-04, -1.5041e-04,  9.8936e-05,  0.0000e+00, -3.8549e-04,\n",
      "         1.0748e-04,  9.1190e-04,  0.0000e+00,  1.2435e-03, -3.3491e-04,\n",
      "         0.0000e+00,  1.2417e-03,  0.0000e+00,  0.0000e+00, -3.4229e-04,\n",
      "         0.0000e+00,  0.0000e+00, -6.5664e-05, -1.2777e-03,  0.0000e+00,\n",
      "         2.6310e-04,  0.0000e+00,  0.0000e+00, -2.1547e-04, -8.9519e-04,\n",
      "        -5.3910e-04, -2.9902e-05,  7.2247e-04,  0.0000e+00,  4.4615e-04,\n",
      "         0.0000e+00, -4.8536e-04,  5.1103e-04, -1.4157e-04,  0.0000e+00,\n",
      "        -4.7034e-04,  0.0000e+00, -1.5542e-04,  4.2466e-04, -7.5309e-04,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  2.0867e-04, -4.4315e-04,  0.0000e+00,\n",
      "         1.8271e-05, -2.9336e-06,  1.0403e-04, -8.4108e-04,  0.0000e+00,\n",
      "        -4.0034e-06, -4.5687e-05,  1.5299e-04,  2.1086e-04, -3.6707e-04,\n",
      "         0.0000e+00,  0.0000e+00,  7.7215e-04,  0.0000e+00,  0.0000e+00,\n",
      "        -1.1301e-03, -1.0934e-03, -4.6036e-04,  0.0000e+00,  2.0774e-04,\n",
      "         4.6733e-04, -9.6488e-04, -4.9434e-04,  4.7193e-04,  7.1579e-04,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  8.4266e-04, -5.3270e-04,\n",
      "         4.4553e-04,  0.0000e+00,  8.6648e-04,  0.0000e+00,  0.0000e+00,\n",
      "         1.2386e-04,  7.5811e-04,  4.1432e-04,  1.6927e-04, -9.0874e-05,\n",
      "        -7.4632e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.0766e-04,\n",
      "         9.3089e-04, -1.1464e-03,  0.0000e+00,  3.3215e-05,  0.0000e+00,\n",
      "         0.0000e+00,  2.6723e-04,  0.0000e+00,  0.0000e+00, -3.8422e-04,\n",
      "         0.0000e+00,  8.1398e-05,  0.0000e+00,  3.6300e-04,  0.0000e+00,\n",
      "        -7.1496e-04,  0.0000e+00, -9.1549e-04,  0.0000e+00,  1.0238e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.9070e-04, -3.8910e-04,\n",
      "         0.0000e+00, -3.7265e-04,  0.0000e+00,  1.1553e-06,  3.9768e-05,\n",
      "         1.4501e-03, -1.2774e-03, -1.6136e-04,  3.9488e-05,  0.0000e+00,\n",
      "         8.9905e-04,  0.0000e+00, -1.0505e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  2.5117e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -5.3953e-04, -1.2384e-04,\n",
      "         0.0000e+00,  0.0000e+00, -4.7353e-05, -1.5397e-04,  0.0000e+00,\n",
      "        -7.9850e-04, -8.6803e-05, -8.4327e-04,  0.0000e+00,  1.3400e-04,\n",
      "         3.2862e-04,  8.7417e-05,  0.0000e+00,  4.4206e-05,  0.0000e+00,\n",
      "        -7.8808e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.7976e-04,\n",
      "         6.0658e-05, -3.7807e-04,  0.0000e+00, -5.2518e-04,  4.2469e-04,\n",
      "         0.0000e+00,  7.6808e-04,  0.0000e+00,  2.5895e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -4.9012e-04,  0.0000e+00,  0.0000e+00,  1.0856e-03,  0.0000e+00,\n",
      "        -1.0827e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -7.2857e-04,  0.0000e+00,  0.0000e+00,  1.3167e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.6219e-04,\n",
      "         8.5328e-04, -2.2590e-04,  0.0000e+00,  4.9281e-04,  0.0000e+00,\n",
      "        -1.0640e-03,  0.0000e+00, -6.5160e-04,  3.4021e-04,  1.0380e-04,\n",
      "         0.0000e+00, -6.2948e-04,  9.1420e-05, -6.0478e-04, -1.2085e-04,\n",
      "         7.8123e-05,  0.0000e+00,  0.0000e+00, -1.7853e-04, -5.3535e-04,\n",
      "        -1.0699e-03,  0.0000e+00, -2.2779e-04,  0.0000e+00,  0.0000e+00,\n",
      "        -1.0035e-03, -5.2421e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -4.1721e-04, -4.8561e-05, -1.1844e-03,  0.0000e+00,\n",
      "        -7.7163e-04,  1.0408e-05,  0.0000e+00,  0.0000e+00, -3.5376e-04,\n",
      "         8.5347e-05,  0.0000e+00,  2.7524e-04, -4.9311e-04,  6.3477e-04,\n",
      "        -5.2483e-04,  0.0000e+00, -7.2633e-04, -8.4768e-04,  0.0000e+00,\n",
      "        -3.7386e-04,  6.9513e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -1.3730e-04,  0.0000e+00, -1.0066e-03, -6.3919e-04,  0.0000e+00,\n",
      "         1.8693e-04, -9.6160e-04, -5.8197e-04,  0.0000e+00,  5.0608e-04])\n",
      "===========\n",
      "gradient:R.R_write.postproc.5.layers.2.weight\n",
      "----------\n",
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.3697e-05,\n",
      "          0.0000e+00,  1.6109e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -3.3350e-06,\n",
      "          0.0000e+00, -3.9223e-05]])\n",
      "===========\n",
      "gradient:R.R_write.postproc.5.layers.2.bias\n",
      "----------\n",
      "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.6352e-04,  0.0000e+00,\n",
      "         3.3264e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.1500e-03,\n",
      "         0.0000e+00, -3.8782e-03,  0.0000e+00,  3.9813e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.8716e-03,\n",
      "         4.1357e-03,  0.0000e+00,  0.0000e+00, -3.4025e-03,  1.3752e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -4.0369e-03,  0.0000e+00,  3.4438e-03, -1.9626e-03, -5.0807e-04,\n",
      "         0.0000e+00,  1.3436e-03, -2.0208e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -9.3626e-04,  4.8135e-04, -3.4098e-03,\n",
      "         0.0000e+00,  0.0000e+00,  4.4655e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -1.9663e-03,  1.3811e-03,  2.4412e-03, -2.0250e-03,\n",
      "         3.7570e-03,  0.0000e+00,  0.0000e+00, -6.9859e-04,  0.0000e+00,\n",
      "         0.0000e+00, -3.6047e-03, -1.0945e-03,  2.0585e-03, -3.4303e-03,\n",
      "         1.3323e-03,  5.6732e-04,  0.0000e+00, -1.6836e-03, -2.8699e-03,\n",
      "        -1.8230e-03,  0.0000e+00,  0.0000e+00,  2.5630e-03,  0.0000e+00,\n",
      "         2.9808e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5559e-03,\n",
      "         0.0000e+00, -2.3836e-03, -2.7232e-03, -2.8143e-03,  0.0000e+00,\n",
      "        -2.8061e-03,  1.1195e-03,  0.0000e+00, -2.5133e-03,  1.9923e-03,\n",
      "        -3.9063e-03,  0.0000e+00,  0.0000e+00,  7.7930e-05, -2.9059e-03,\n",
      "         3.8199e-03, -3.0687e-03,  0.0000e+00, -3.0339e-03,  1.0170e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4216e-04,\n",
      "         1.9631e-03,  0.0000e+00,  0.0000e+00,  2.3700e-03,  3.0064e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4827e-03, -1.4819e-03,\n",
      "        -2.9639e-03, -2.7132e-04,  4.1058e-03, -5.3596e-05, -1.0782e-03,\n",
      "        -1.3271e-03, -2.4195e-03, -1.2780e-03,  0.0000e+00,  0.0000e+00,\n",
      "         1.2832e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00, -9.0221e-04,\n",
      "         2.7915e-03,  3.6325e-03,  0.0000e+00,  2.8153e-03,  0.0000e+00,\n",
      "         0.0000e+00, -7.4585e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -4.0185e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.7698e-03,\n",
      "         2.7778e-03,  0.0000e+00,  0.0000e+00, -4.1409e-03,  2.3069e-03,\n",
      "        -2.7907e-03, -9.4598e-04,  1.4082e-03,  0.0000e+00, -2.0614e-04,\n",
      "        -7.2951e-04,  1.2158e-03,  0.0000e+00, -3.1247e-05,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3510e-03,\n",
      "         0.0000e+00,  0.0000e+00,  2.8052e-03, -2.5746e-03, -3.4861e-03,\n",
      "        -3.4458e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -8.7046e-04,  1.1296e-03, -3.9851e-03, -6.4627e-04,  2.7182e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  8.6266e-04,  0.0000e+00,  1.9826e-03,\n",
      "         0.0000e+00, -1.2166e-03, -4.0174e-03,  1.2040e-03,  1.6474e-03,\n",
      "         0.0000e+00,  0.0000e+00,  2.2459e-03,  0.0000e+00, -5.4686e-04])\n",
      "===========\n",
      "gradient:R.R_write.postproc.5.layers.4.weight\n",
      "----------\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1942e-04, 0.0000e+00, 2.9355e-04,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 7.9780e-04, 0.0000e+00, 2.5937e-03,\n",
      "         0.0000e+00, 8.8992e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.2527e-04, 1.6177e-03, 0.0000e+00, 0.0000e+00, 2.1173e-03,\n",
      "         5.6363e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1459e-03, 0.0000e+00, 1.9613e-04, 2.9464e-03, 1.0343e-03, 0.0000e+00,\n",
      "         9.9996e-04, 1.9510e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.7173e-04, 1.4686e-04, 2.4480e-03, 0.0000e+00, 0.0000e+00, 1.1254e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8762e-04, 6.2963e-04, 2.4609e-04,\n",
      "         1.9344e-03, 2.0970e-03, 0.0000e+00, 0.0000e+00, 2.2065e-05, 0.0000e+00,\n",
      "         0.0000e+00, 3.4161e-04, 9.6143e-04, 1.4777e-04, 1.9865e-03, 1.4052e-03,\n",
      "         4.4439e-04, 0.0000e+00, 1.6655e-03, 1.8308e-03, 1.2423e-04, 0.0000e+00,\n",
      "         0.0000e+00, 2.4767e-03, 0.0000e+00, 8.6393e-04, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.6716e-04, 0.0000e+00, 5.3486e-04, 1.2674e-03, 1.2613e-03,\n",
      "         0.0000e+00, 1.0154e-03, 3.0331e-03, 0.0000e+00, 7.8839e-04, 1.3016e-03,\n",
      "         1.3452e-03, 0.0000e+00, 0.0000e+00, 5.8316e-04, 2.6897e-03, 2.3328e-04,\n",
      "         8.8754e-04, 0.0000e+00, 8.1492e-05, 4.0562e-04, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.7823e-04, 2.2541e-03, 0.0000e+00, 0.0000e+00,\n",
      "         2.4306e-03, 4.1727e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6641e-05,\n",
      "         1.5358e-03, 1.3639e-03, 1.0131e-03, 4.1283e-03, 2.3087e-04, 9.9287e-05,\n",
      "         3.1749e-04, 7.3758e-04, 3.3759e-03, 0.0000e+00, 0.0000e+00, 9.3354e-04,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3445e-03, 9.4194e-04, 3.6884e-04,\n",
      "         0.0000e+00, 1.9926e-04, 0.0000e+00, 0.0000e+00, 3.2760e-03, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.3989e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         9.0901e-04, 2.5366e-03, 0.0000e+00, 0.0000e+00, 4.2024e-04, 3.0082e-03,\n",
      "         6.0353e-04, 1.9153e-03, 2.3849e-04, 0.0000e+00, 3.4132e-04, 1.3675e-03,\n",
      "         2.2649e-03, 0.0000e+00, 1.8313e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.5173e-03, 0.0000e+00, 0.0000e+00, 1.1706e-03,\n",
      "         1.0796e-04, 1.6168e-03, 3.3635e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.7221e-04, 4.0545e-04, 1.9134e-03, 1.5424e-03, 1.4503e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0272e-03, 0.0000e+00, 1.4581e-03, 0.0000e+00, 7.1916e-04,\n",
      "         1.6261e-04, 1.6416e-03, 1.7374e-03, 0.0000e+00, 0.0000e+00, 2.2162e-04,\n",
      "         0.0000e+00, 2.5675e-03]])\n",
      "===========\n",
      "gradient:R.R_write.postproc.5.layers.4.bias\n",
      "----------\n",
      "tensor([0.0594])\n",
      "===========\n",
      "gradient:R.R_write.postproc.6.layers.0.weight\n",
      "----------\n",
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-6.4477e-05, -8.8788e-07,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -2.6505e-05],\n",
      "        [ 6.6014e-05,  1.0509e-06,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  2.8254e-05],\n",
      "        ...,\n",
      "        [ 4.3615e-05,  7.2178e-07,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  1.8960e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 2.7523e-05,  4.3654e-07,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  1.1155e-05]])\n",
      "===========\n",
      "gradient:R.R_write.postproc.6.layers.0.bias\n",
      "----------\n",
      "tensor([ 0.0000e+00, -3.2808e-03,  3.3429e-03,  2.6164e-03,  0.0000e+00,\n",
      "         2.9763e-03,  7.1244e-04,  1.2605e-03,  0.0000e+00,  0.0000e+00,\n",
      "         3.6242e-03,  0.0000e+00, -2.6453e-03,  0.0000e+00, -1.8591e-03,\n",
      "         0.0000e+00, -5.3727e-03, -1.9175e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -1.4690e-03,  0.0000e+00,  6.0351e-04,  0.0000e+00, -4.9202e-04,\n",
      "         0.0000e+00, -6.3411e-03,  0.0000e+00, -2.2123e-03, -5.9837e-04,\n",
      "         0.0000e+00,  0.0000e+00, -4.2040e-03,  2.1222e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -3.5610e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -2.6528e-04,  0.0000e+00, -3.4661e-03,  0.0000e+00, -5.2842e-03,\n",
      "        -1.8567e-03,  3.5672e-04,  0.0000e+00, -3.9903e-03,  7.0166e-04,\n",
      "         0.0000e+00,  1.8575e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.1572e-05,  1.4452e-03,  6.1474e-05,\n",
      "         0.0000e+00,  1.0916e-03,  2.6359e-03,  0.0000e+00,  1.8272e-03,\n",
      "         0.0000e+00, -3.1035e-03, -1.7109e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -1.2934e-03, -1.6694e-03,  0.0000e+00,  0.0000e+00, -3.3093e-03,\n",
      "        -3.2373e-03, -1.4088e-03, -2.0311e-03,  0.0000e+00, -1.9875e-03,\n",
      "         3.0745e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.2460e-05,\n",
      "         1.2627e-03, -3.2389e-03,  2.3504e-03,  2.4049e-03,  0.0000e+00,\n",
      "         0.0000e+00, -3.2586e-03,  5.9455e-04,  2.5027e-03,  4.3541e-05,\n",
      "        -2.0302e-03,  0.0000e+00,  1.4376e-03,  2.0731e-03,  4.3849e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -3.5282e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  5.3839e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.3067e-03,  2.0670e-03,  4.7190e-03,\n",
      "         0.0000e+00,  0.0000e+00, -4.7410e-03,  0.0000e+00, -1.1795e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  1.7282e-04,  3.9091e-04,  0.0000e+00,\n",
      "         3.3759e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  8.2597e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -2.4232e-03,  1.7543e-04,  0.0000e+00,  0.0000e+00,  2.0117e-03,\n",
      "         0.0000e+00,  3.2233e-03,  0.0000e+00,  4.1896e-03,  0.0000e+00,\n",
      "         0.0000e+00, -4.1670e-03,  0.0000e+00, -3.3038e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  2.2013e-03,  0.0000e+00,  3.4731e-04,\n",
      "        -2.2686e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.0256e-04,\n",
      "        -3.4810e-04, -2.5979e-03, -6.9816e-04,  0.0000e+00,  0.0000e+00,\n",
      "         1.1058e-03,  0.0000e+00,  0.0000e+00,  2.7140e-03, -3.5727e-03,\n",
      "         0.0000e+00,  0.0000e+00, -1.1114e-03, -8.4911e-04,  0.0000e+00,\n",
      "         0.0000e+00, -3.0916e-04,  0.0000e+00, -1.8560e-03, -2.7000e-03,\n",
      "         0.0000e+00, -2.8958e-03,  2.6383e-03, -4.0718e-04,  0.0000e+00,\n",
      "        -2.3952e-03,  2.3417e-03, -2.7867e-03,  0.0000e+00, -1.6848e-03,\n",
      "         0.0000e+00,  0.0000e+00, -2.0500e-05,  0.0000e+00,  0.0000e+00,\n",
      "         1.2757e-03,  0.0000e+00,  0.0000e+00, -1.9094e-04, -1.3550e-03,\n",
      "        -7.9298e-04,  0.0000e+00,  1.8024e-03,  1.0588e-04,  0.0000e+00,\n",
      "        -1.1223e-03, -3.5592e-04, -2.3080e-03,  4.4328e-03,  2.1774e-03,\n",
      "         0.0000e+00,  0.0000e+00,  4.2718e-03,  0.0000e+00,  3.4330e-03,\n",
      "         0.0000e+00, -7.9081e-04,  1.0690e-03, -2.3237e-03, -2.6854e-03,\n",
      "         0.0000e+00,  4.7841e-04,  3.5825e-03, -2.4251e-03,  0.0000e+00,\n",
      "        -4.9886e-03,  0.0000e+00,  0.0000e+00,  1.6947e-03,  0.0000e+00,\n",
      "         0.0000e+00,  2.8437e-03,  1.3540e-03,  3.8798e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.0048e-04, -2.0920e-03,  0.0000e+00,\n",
      "         2.1901e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8314e-03,\n",
      "         4.2250e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  6.7502e-04, -5.5534e-04,  1.5087e-03,  1.6908e-05,\n",
      "         0.0000e+00,  2.8087e-03, -8.0820e-04,  1.2565e-03,  0.0000e+00,\n",
      "         0.0000e+00,  6.4366e-04,  2.5911e-03, -8.8324e-04,  1.7796e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -6.6370e-05, -2.5363e-04,  0.0000e+00,\n",
      "         3.9524e-04, -1.6820e-03,  0.0000e+00,  0.0000e+00,  1.0526e-04,\n",
      "         0.0000e+00, -3.8484e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -1.8817e-03,  2.8849e-04,  0.0000e+00,  3.9446e-03,  0.0000e+00,\n",
      "         0.0000e+00, -2.1068e-03,  0.0000e+00,  1.8215e-03, -6.7923e-04,\n",
      "         0.0000e+00, -1.4239e-04, -1.5436e-03,  0.0000e+00,  5.4439e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.9182e-04,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4241e-03, -1.2143e-03,\n",
      "        -2.8723e-03, -8.2166e-04, -1.5174e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -1.9514e-03, -1.5899e-03,  0.0000e+00,  3.2466e-03,  5.3177e-04,\n",
      "         2.5420e-03,  2.1321e-03,  9.0358e-04,  0.0000e+00,  0.0000e+00,\n",
      "         3.3937e-03, -1.5784e-03,  0.0000e+00,  5.0221e-03, -2.0539e-03,\n",
      "         7.0696e-04,  0.0000e+00,  4.6027e-03,  4.1423e-03,  0.0000e+00,\n",
      "         0.0000e+00, -1.6328e-03,  4.3540e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -3.3082e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  2.2073e-03, -1.4993e-03,  0.0000e+00,\n",
      "         1.0324e-03,  1.5753e-03,  4.4930e-03, -3.8307e-04,  6.7722e-04,\n",
      "         0.0000e+00, -1.3856e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         1.9622e-04,  3.0660e-05,  0.0000e+00, -1.4290e-04, -4.6903e-03,\n",
      "         0.0000e+00,  2.2791e-03,  1.9235e-03,  0.0000e+00,  4.3230e-03,\n",
      "         0.0000e+00,  0.0000e+00,  2.0117e-03,  6.3322e-04,  0.0000e+00,\n",
      "         0.0000e+00, -3.8593e-03,  0.0000e+00,  0.0000e+00, -2.9264e-04,\n",
      "        -2.4583e-04,  0.0000e+00, -3.9541e-04,  1.1171e-03,  7.5129e-04,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -9.4093e-04,\n",
      "         0.0000e+00, -3.6026e-03,  0.0000e+00,  5.5904e-03, -1.6368e-03,\n",
      "        -1.0996e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.4610e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -4.1660e-03, -1.7806e-03, -6.5639e-06,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  2.4171e-03,  0.0000e+00, -3.5139e-03, -3.4549e-04,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.5655e-03,\n",
      "         5.7464e-04,  0.0000e+00, -6.9092e-05, -1.7253e-03,  0.0000e+00,\n",
      "         0.0000e+00, -4.7283e-03,  0.0000e+00, -5.6008e-04,  0.0000e+00,\n",
      "         3.2156e-03, -1.5679e-03,  3.1900e-04, -1.3578e-03,  2.9390e-03,\n",
      "         0.0000e+00,  9.2864e-06,  3.3517e-03, -3.3516e-03, -3.7927e-04,\n",
      "         0.0000e+00, -8.6192e-04, -3.1355e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -2.1259e-03,  0.0000e+00,  7.2067e-05,\n",
      "         0.0000e+00,  4.1446e-03,  1.7414e-03, -2.5237e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  1.2366e-03, -4.3920e-04,  4.0215e-03,\n",
      "        -7.8529e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3986e-04,\n",
      "         1.5310e-03,  0.0000e+00,  1.8613e-03,  0.0000e+00,  0.0000e+00,\n",
      "         2.8515e-04,  2.3140e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -7.6623e-04,  0.0000e+00,  1.8249e-03,  1.5761e-03,  3.3759e-03,\n",
      "         0.0000e+00, -4.5822e-03,  0.0000e+00,  0.0000e+00, -2.3321e-03,\n",
      "        -1.5217e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.2384e-03,\n",
      "        -1.0847e-04, -2.0120e-03,  2.1989e-03,  0.0000e+00,  1.4443e-03])\n",
      "===========\n",
      "gradient:R.R_write.postproc.6.layers.2.weight\n",
      "----------\n",
      "tensor([[ 0.0000e+00,  4.2535e-04,  7.5862e-04,  ...,  4.9020e-05,\n",
      "          0.0000e+00,  2.4609e-04],\n",
      "        [ 0.0000e+00, -2.5421e-04, -4.5339e-04,  ..., -2.9297e-05,\n",
      "          0.0000e+00, -1.4707e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  1.1525e-04,  2.0554e-04,  ...,  1.3281e-05,\n",
      "          0.0000e+00,  6.6674e-05],\n",
      "        [ 0.0000e+00, -1.5282e-04, -2.7256e-04,  ..., -1.7612e-05,\n",
      "          0.0000e+00, -8.8414e-05],\n",
      "        [ 0.0000e+00, -3.2600e-04, -5.8142e-04,  ..., -3.7570e-05,\n",
      "          0.0000e+00, -1.8861e-04]])\n",
      "===========\n",
      "gradient:R.R_write.postproc.6.layers.2.bias\n",
      "----------\n",
      "tensor([ 1.2271e-02, -7.3338e-03,  0.0000e+00,  5.5808e-03,  0.0000e+00,\n",
      "         0.0000e+00, -7.1370e-03,  0.0000e+00,  6.9920e-03,  2.4250e-03,\n",
      "         1.4993e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -1.4736e-02,  0.0000e+00,  8.3756e-03,  0.0000e+00,\n",
      "         1.1376e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         3.9581e-03,  0.0000e+00,  3.5425e-03,  1.0884e-02,  0.0000e+00,\n",
      "         1.1364e-02,  5.5740e-03, -5.1061e-03,  1.5380e-02,  0.0000e+00,\n",
      "         0.0000e+00, -1.3890e-02,  0.0000e+00,  0.0000e+00,  9.9853e-03,\n",
      "         5.5572e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2029e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2627e-02,  0.0000e+00,\n",
      "         1.0784e-02,  1.0374e-02,  0.0000e+00,  0.0000e+00,  2.2955e-03,\n",
      "         0.0000e+00,  1.5544e-02, -1.0423e-02,  6.7272e-04,  0.0000e+00,\n",
      "         1.3643e-02,  1.5128e-02,  0.0000e+00,  4.4532e-03,  0.0000e+00,\n",
      "         0.0000e+00,  1.8061e-03,  9.0481e-03,  0.0000e+00, -8.9300e-03,\n",
      "         0.0000e+00,  3.7974e-03, -4.1677e-03,  8.8131e-03,  0.0000e+00,\n",
      "         0.0000e+00,  1.2652e-02, -6.8655e-03,  5.0620e-03,  0.0000e+00,\n",
      "         9.4955e-03,  0.0000e+00, -1.3906e-02,  0.0000e+00, -1.2999e-02,\n",
      "         1.5006e-02,  8.1663e-03,  1.4295e-02,  0.0000e+00, -1.8029e-03,\n",
      "        -3.0008e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -1.1796e-02,  0.0000e+00,  0.0000e+00, -1.1661e-03,\n",
      "         4.6184e-03,  0.0000e+00, -6.0992e-04, -1.1237e-02,  8.2156e-04,\n",
      "         0.0000e+00,  0.0000e+00, -1.3413e-02,  0.0000e+00,  0.0000e+00,\n",
      "         8.9731e-03,  1.3726e-02,  0.0000e+00,  0.0000e+00,  1.3688e-02,\n",
      "         7.9984e-04,  0.0000e+00,  1.2510e-02, -1.1427e-02,  0.0000e+00,\n",
      "         0.0000e+00,  6.3828e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -9.1812e-03, -3.8752e-03,  8.7532e-03,  0.0000e+00,\n",
      "         0.0000e+00, -8.0990e-03,  0.0000e+00,  0.0000e+00, -3.4123e-03,\n",
      "         9.5799e-03, -9.0762e-03,  1.3598e-02,  0.0000e+00,  9.8981e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  7.5668e-03,\n",
      "         9.9435e-03,  1.4643e-02, -1.7786e-03,  1.5066e-02, -5.1459e-03,\n",
      "         0.0000e+00,  3.3704e-03, -1.0115e-02, -1.3343e-02,  3.7118e-03,\n",
      "         0.0000e+00,  8.9114e-05, -5.0723e-03,  2.2153e-03, -1.2293e-02,\n",
      "         0.0000e+00, -1.4978e-02,  1.1227e-02,  0.0000e+00,  0.0000e+00,\n",
      "         8.8937e-03,  1.6195e-03, -2.2271e-03,  0.0000e+00,  4.2091e-03,\n",
      "        -3.2709e-03,  0.0000e+00,  9.8384e-03,  0.0000e+00,  0.0000e+00,\n",
      "         8.4847e-03,  0.0000e+00,  0.0000e+00, -2.7797e-03, -1.0871e-02,\n",
      "         5.9493e-03,  0.0000e+00, -3.6059e-03,  6.1709e-03,  1.4365e-02,\n",
      "         7.6641e-03, -1.1921e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         6.3289e-03,  0.0000e+00,  3.3247e-03, -4.4088e-03, -9.4048e-03])\n",
      "===========\n",
      "gradient:R.R_write.postproc.6.layers.4.weight\n",
      "----------\n",
      "tensor([[4.7336e-03, 5.3980e-03, 0.0000e+00, 8.0429e-04, 0.0000e+00, 0.0000e+00,\n",
      "         1.4925e-04, 0.0000e+00, 7.0797e-04, 3.7621e-03, 1.7223e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6734e-03, 0.0000e+00,\n",
      "         4.1686e-03, 0.0000e+00, 7.2357e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 9.5907e-03, 0.0000e+00, 1.1503e-02, 5.0887e-03, 0.0000e+00,\n",
      "         1.0139e-03, 6.6290e-04, 6.8232e-03, 5.6577e-03, 0.0000e+00, 0.0000e+00,\n",
      "         6.1697e-04, 0.0000e+00, 0.0000e+00, 5.8790e-03, 8.8205e-05, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.3249e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0408e-03,\n",
      "         0.0000e+00, 3.5922e-04, 2.5092e-03, 0.0000e+00, 0.0000e+00, 1.0190e-02,\n",
      "         0.0000e+00, 2.0227e-03, 1.8912e-04, 2.2172e-03, 0.0000e+00, 2.1053e-03,\n",
      "         5.0571e-03, 0.0000e+00, 2.6813e-03, 0.0000e+00, 0.0000e+00, 2.4565e-03,\n",
      "         3.3007e-03, 0.0000e+00, 3.8364e-03, 0.0000e+00, 1.1130e-02, 8.2582e-03,\n",
      "         6.9175e-04, 0.0000e+00, 0.0000e+00, 6.1813e-03, 9.5082e-03, 2.9220e-03,\n",
      "         0.0000e+00, 4.1953e-03, 0.0000e+00, 4.0942e-04, 0.0000e+00, 5.5568e-03,\n",
      "         4.5784e-03, 2.3190e-03, 3.0706e-03, 0.0000e+00, 6.6578e-03, 1.2355e-02,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0177e-03,\n",
      "         0.0000e+00, 0.0000e+00, 3.2297e-03, 2.0170e-03, 0.0000e+00, 8.1728e-03,\n",
      "         1.7203e-03, 6.2035e-04, 0.0000e+00, 0.0000e+00, 1.3784e-02, 0.0000e+00,\n",
      "         0.0000e+00, 9.6702e-03, 2.8158e-03, 0.0000e+00, 0.0000e+00, 5.6068e-03,\n",
      "         8.3043e-03, 0.0000e+00, 3.7067e-04, 7.0254e-03, 0.0000e+00, 0.0000e+00,\n",
      "         5.5753e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7369e-03,\n",
      "         2.7094e-03, 1.0919e-02, 0.0000e+00, 0.0000e+00, 1.2920e-03, 0.0000e+00,\n",
      "         0.0000e+00, 2.5455e-03, 9.2310e-04, 6.5402e-03, 5.7524e-03, 0.0000e+00,\n",
      "         1.3946e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4205e-02,\n",
      "         1.1494e-02, 9.3560e-03, 6.3066e-03, 2.5808e-03, 6.9192e-03, 0.0000e+00,\n",
      "         1.5301e-03, 1.0035e-03, 5.2844e-03, 4.9245e-03, 0.0000e+00, 1.2999e-02,\n",
      "         6.0475e-03, 3.2036e-03, 1.0839e-02, 0.0000e+00, 2.1258e-03, 1.0839e-02,\n",
      "         0.0000e+00, 0.0000e+00, 1.2077e-02, 6.3893e-03, 5.6506e-03, 0.0000e+00,\n",
      "         3.2321e-03, 3.8390e-03, 0.0000e+00, 7.7917e-03, 0.0000e+00, 0.0000e+00,\n",
      "         8.8050e-03, 0.0000e+00, 0.0000e+00, 1.6411e-02, 5.7587e-03, 9.1166e-06,\n",
      "         0.0000e+00, 1.1635e-02, 2.3345e-03, 9.6649e-03, 9.2500e-03, 5.5617e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0335e-02, 0.0000e+00, 2.8611e-03,\n",
      "         9.0790e-03, 5.4922e-03]])\n",
      "===========\n",
      "gradient:R.R_write.postproc.6.layers.4.bias\n",
      "----------\n",
      "tensor([0.2200])\n",
      "===========\n",
      "gradient:R.R_write.postproc.7.layers.0.weight\n",
      "----------\n",
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.3530e-05,  1.2731e-06,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  5.9834e-06],\n",
      "        ...,\n",
      "        [-7.6885e-06, -7.2348e-07,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -3.4001e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "===========\n",
      "gradient:R.R_write.postproc.7.layers.0.bias\n",
      "----------\n",
      "tensor([ 0.0000e+00,  0.0000e+00,  1.0538e-03,  4.8318e-04,  0.0000e+00,\n",
      "         0.0000e+00,  2.7878e-04,  1.4358e-04,  0.0000e+00,  5.2320e-05,\n",
      "         0.0000e+00,  6.4655e-04,  7.6724e-04,  4.5531e-04,  4.1811e-04,\n",
      "         0.0000e+00,  0.0000e+00, -6.5546e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -5.4470e-04, -4.5212e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  4.3068e-04,  9.1480e-04,  2.9055e-04,\n",
      "         3.5329e-04, -2.4914e-04,  0.0000e+00,  0.0000e+00, -2.2255e-04,\n",
      "         0.0000e+00,  1.0371e-04,  0.0000e+00,  1.1834e-03,  4.0171e-04,\n",
      "         0.0000e+00,  1.7600e-04,  0.0000e+00,  6.2571e-04,  0.0000e+00,\n",
      "         2.4911e-04, -2.6399e-04, -2.2916e-04, -9.1085e-04,  0.0000e+00,\n",
      "        -2.8601e-04,  0.0000e+00,  0.0000e+00, -5.2927e-04, -4.0859e-04,\n",
      "        -2.6968e-04,  0.0000e+00, -1.5468e-04,  9.3866e-07,  4.6319e-04,\n",
      "         0.0000e+00, -4.2324e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -8.1968e-04,  5.0099e-04,  0.0000e+00, -1.8357e-05,  1.1999e-04,\n",
      "         1.5876e-04,  1.1031e-05,  0.0000e+00,  0.0000e+00,  2.9935e-04,\n",
      "        -3.5370e-04,  9.1546e-04,  0.0000e+00, -8.4123e-05,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -3.5677e-04, -3.0913e-04,  0.0000e+00,\n",
      "         2.3957e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  7.5092e-04,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         8.2313e-04,  0.0000e+00,  2.3047e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -2.9110e-04, -1.2193e-04,  0.0000e+00, -8.1246e-04,\n",
      "         0.0000e+00, -8.9252e-05,  0.0000e+00,  6.4864e-05,  1.7231e-04,\n",
      "         0.0000e+00,  2.2433e-04, -4.6916e-05,  1.5258e-04,  3.7786e-04,\n",
      "         0.0000e+00, -2.1550e-04,  9.4556e-05, -8.5371e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  4.2057e-04,  0.0000e+00,  6.7017e-06,\n",
      "         7.6514e-05,  0.0000e+00, -1.8095e-04, -5.1501e-04,  0.0000e+00,\n",
      "         7.7177e-04,  0.0000e+00,  4.6846e-04,  0.0000e+00, -6.6072e-04,\n",
      "         0.0000e+00,  0.0000e+00,  3.2749e-04,  0.0000e+00,  0.0000e+00,\n",
      "         5.3287e-04,  0.0000e+00,  3.4719e-04,  0.0000e+00,  2.5526e-04,\n",
      "         0.0000e+00, -7.6248e-05,  0.0000e+00,  9.9524e-04,  0.0000e+00,\n",
      "         0.0000e+00, -3.1831e-04,  0.0000e+00,  0.0000e+00,  5.0294e-04,\n",
      "        -2.0578e-04,  0.0000e+00,  2.8106e-04, -4.3984e-04, -1.7112e-04,\n",
      "         0.0000e+00, -1.6675e-04,  2.4820e-04, -2.2766e-04,  0.0000e+00,\n",
      "         0.0000e+00, -8.6193e-04,  4.1568e-04,  0.0000e+00,  6.4332e-04,\n",
      "         0.0000e+00,  8.8375e-05,  1.5970e-04,  0.0000e+00, -2.1542e-05,\n",
      "         4.0242e-04,  2.4219e-04,  0.0000e+00,  0.0000e+00,  2.1143e-04,\n",
      "         0.0000e+00,  3.3181e-04, -2.8442e-05,  0.0000e+00,  1.9196e-04,\n",
      "        -4.0602e-04,  0.0000e+00,  2.0275e-04, -9.9762e-04,  4.5272e-04,\n",
      "         0.0000e+00,  0.0000e+00,  2.7526e-07,  2.2750e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.0676e-04,  0.0000e+00,\n",
      "         1.9360e-04,  7.4405e-05,  2.9509e-04,  2.2144e-04, -4.0191e-04,\n",
      "         0.0000e+00,  5.2504e-04,  0.0000e+00, -3.0106e-05, -3.0160e-04,\n",
      "         0.0000e+00, -3.1944e-04,  0.0000e+00,  1.2292e-04,  3.0332e-04,\n",
      "         1.6359e-04, -5.4289e-04,  0.0000e+00,  0.0000e+00, -1.1312e-03,\n",
      "        -2.5171e-04,  0.0000e+00, -1.6674e-04,  2.4648e-04,  0.0000e+00,\n",
      "         2.1663e-04, -1.4519e-04,  1.0130e-03,  0.0000e+00,  4.5068e-04,\n",
      "         0.0000e+00,  2.8422e-04,  6.5936e-05,  0.0000e+00, -9.4466e-04,\n",
      "         4.7781e-04,  0.0000e+00,  6.8352e-04,  0.0000e+00,  9.8900e-05,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         1.8572e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.2828e-04,\n",
      "         0.0000e+00,  1.3616e-04,  0.0000e+00,  3.0322e-04,  5.8223e-04,\n",
      "         0.0000e+00, -6.6831e-04,  2.1353e-04, -1.3384e-03,  0.0000e+00,\n",
      "         0.0000e+00, -3.1341e-04,  0.0000e+00,  0.0000e+00, -6.8106e-04,\n",
      "         0.0000e+00,  9.5620e-05,  0.0000e+00, -1.0930e-04,  0.0000e+00,\n",
      "        -3.3724e-04, -4.1885e-04,  0.0000e+00,  1.8276e-04,  0.0000e+00,\n",
      "        -7.2820e-04,  0.0000e+00,  0.0000e+00, -5.6543e-04,  0.0000e+00,\n",
      "        -3.3235e-04,  0.0000e+00, -5.9557e-04,  0.0000e+00, -2.5462e-04,\n",
      "        -3.4700e-04, -7.0459e-05, -8.0856e-05,  0.0000e+00, -1.3362e-04,\n",
      "         6.8559e-06,  4.1696e-04, -6.3740e-04,  0.0000e+00,  2.7050e-04,\n",
      "         0.0000e+00,  7.0472e-04,  2.7918e-04,  0.0000e+00,  0.0000e+00,\n",
      "         1.0189e-03,  1.0073e-03,  4.0766e-04,  0.0000e+00,  0.0000e+00,\n",
      "         2.6438e-04, -7.4279e-04,  0.0000e+00,  0.0000e+00,  4.8608e-04,\n",
      "         0.0000e+00, -5.9552e-04,  4.3376e-04,  0.0000e+00,  6.0538e-04,\n",
      "        -3.2302e-04, -1.1971e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         4.4155e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         6.5538e-04, -6.0404e-04,  0.0000e+00,  1.1327e-05,  2.3071e-04,\n",
      "         0.0000e+00, -1.7141e-04, -6.1106e-04,  0.0000e+00,  2.3625e-04,\n",
      "         0.0000e+00, -2.6186e-05,  5.4133e-05,  5.3057e-04,  0.0000e+00,\n",
      "         0.0000e+00, -1.1269e-04,  0.0000e+00,  4.7452e-04,  0.0000e+00,\n",
      "         4.5615e-04, -4.1796e-05,  0.0000e+00,  3.9840e-05,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -1.5208e-04,  1.7970e-04,  1.1934e-03,  0.0000e+00,  5.2788e-04,\n",
      "        -4.4804e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.5626e-04,\n",
      "         0.0000e+00, -4.3396e-05,  4.5127e-04,  0.0000e+00, -5.1828e-04,\n",
      "        -1.6415e-04,  3.5127e-04, -2.7591e-04, -7.8571e-05,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.5692e-04,  0.0000e+00,\n",
      "         2.1957e-04,  0.0000e+00,  0.0000e+00, -2.4163e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  3.2734e-04,  0.0000e+00, -2.4933e-04,\n",
      "         0.0000e+00,  0.0000e+00,  4.0526e-04,  7.2058e-04,  2.4603e-04,\n",
      "         5.4511e-04, -1.1083e-03,  0.0000e+00,  5.8818e-04, -3.4136e-04,\n",
      "         0.0000e+00, -2.2154e-05,  6.1002e-05,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -9.2559e-05, -4.0711e-04, -1.4726e-05,  0.0000e+00,\n",
      "        -1.3306e-04,  0.0000e+00, -4.2517e-04,  0.0000e+00,  1.0807e-03,\n",
      "         0.0000e+00, -3.2184e-04,  0.0000e+00, -7.6422e-04, -2.7701e-04,\n",
      "         0.0000e+00, -4.6890e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  5.7434e-05,  1.9046e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  2.5561e-04,  1.3790e-04,  0.0000e+00,  0.0000e+00,\n",
      "         6.9197e-04,  0.0000e+00,  2.2517e-05,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  5.5127e-04, -9.7141e-05,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -5.9228e-04, -4.7890e-04,  0.0000e+00,\n",
      "        -4.2142e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         8.9881e-04, -6.0950e-04,  0.0000e+00,  0.0000e+00,  1.9919e-04,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  3.8296e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -4.5198e-04,  0.0000e+00,  2.6406e-04, -1.5145e-04,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0136e-03,  1.4781e-03,\n",
      "        -4.6485e-04,  0.0000e+00,  4.8941e-04,  4.4129e-04, -5.5863e-04,\n",
      "         2.8473e-04,  0.0000e+00,  8.7186e-04,  0.0000e+00, -6.3249e-04,\n",
      "         2.6761e-05, -2.3378e-05, -5.7129e-04, -8.1717e-04, -3.6692e-04,\n",
      "         0.0000e+00,  0.0000e+00, -5.9884e-04,  0.0000e+00,  0.0000e+00])\n",
      "===========\n",
      "gradient:R.R_write.postproc.7.layers.2.weight\n",
      "----------\n",
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  3.8533e-05,  ...,  4.5682e-06,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  2.4172e-06,  ...,  2.8657e-07,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00, -7.4231e-05,  ..., -8.8004e-06,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "===========\n",
      "gradient:R.R_write.postproc.7.layers.2.bias\n",
      "----------\n",
      "tensor([ 0.0000e+00,  7.2742e-04,  0.0000e+00, -2.8914e-03,  0.0000e+00,\n",
      "         0.0000e+00, -1.3570e-03,  2.1436e-03, -2.9441e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.4335e-04,  0.0000e+00, -2.9865e-03,\n",
      "         0.0000e+00, -2.4352e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         2.5970e-03,  0.0000e+00, -1.8375e-03, -1.6584e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  9.9978e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  1.3648e-03,  1.3841e-03,  1.9224e-03,  0.0000e+00,\n",
      "         0.0000e+00, -2.3647e-03,  6.0749e-04,  2.5563e-03, -2.1606e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7666e-03,  2.6596e-04,\n",
      "         0.0000e+00, -2.4313e-03,  6.8186e-04,  0.0000e+00,  0.0000e+00,\n",
      "        -2.0188e-03,  1.3571e-03, -5.3161e-04, -2.2364e-03,  0.0000e+00,\n",
      "         6.0105e-04, -4.3570e-04,  0.0000e+00,  5.3704e-04,  0.0000e+00,\n",
      "         1.1309e-03,  0.0000e+00,  0.0000e+00,  2.6941e-03,  0.0000e+00,\n",
      "         5.4858e-04,  0.0000e+00, -1.0171e-03,  0.0000e+00,  1.1016e-03,\n",
      "         0.0000e+00, -1.9869e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         2.9941e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0377e-03,\n",
      "         2.0447e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.3089e-03,\n",
      "         2.0936e-05,  0.0000e+00,  2.6181e-03,  0.0000e+00, -1.6882e-03,\n",
      "         0.0000e+00,  0.0000e+00,  4.7092e-04,  1.1362e-03,  0.0000e+00,\n",
      "         0.0000e+00,  1.0990e-03,  0.0000e+00,  0.0000e+00, -6.8297e-04,\n",
      "         0.0000e+00, -1.8926e-03,  1.7402e-03,  0.0000e+00, -2.1658e-03,\n",
      "         0.0000e+00,  7.1521e-04, -3.0491e-03, -1.2878e-03,  1.1391e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3317e-03, -3.0288e-03,\n",
      "         0.0000e+00,  0.0000e+00,  2.1381e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.1336e-04,\n",
      "         0.0000e+00,  0.0000e+00,  6.2998e-04, -7.3739e-04, -7.4249e-04,\n",
      "         1.5587e-03, -1.2325e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         2.7768e-03, -1.0683e-03,  0.0000e+00,  0.0000e+00, -2.8155e-03,\n",
      "        -3.0873e-04,  0.0000e+00, -2.9975e-03,  6.7815e-04, -2.6016e-04,\n",
      "         0.0000e+00,  0.0000e+00, -4.8716e-04,  0.0000e+00, -2.9854e-03,\n",
      "        -1.7963e-03,  0.0000e+00,  0.0000e+00, -1.7886e-03,  1.8032e-03,\n",
      "        -1.3797e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7168e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.9314e-03, -1.9398e-04,\n",
      "         0.0000e+00,  0.0000e+00, -1.0907e-03,  0.0000e+00, -1.5344e-04,\n",
      "        -1.6676e-03, -2.9891e-03,  0.0000e+00,  2.9011e-03,  2.2477e-03,\n",
      "        -2.1119e-03,  0.0000e+00,  1.1425e-03,  0.0000e+00,  0.0000e+00,\n",
      "         1.7238e-03, -5.2393e-05,  0.0000e+00, -2.4458e-03,  0.0000e+00,\n",
      "        -2.7530e-03, -1.9232e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.4960e-03,  0.0000e+00,\n",
      "         0.0000e+00,  1.0787e-03,  4.5631e-05,  0.0000e+00, -1.4013e-03])\n",
      "===========\n",
      "gradient:R.R_write.postproc.7.layers.4.weight\n",
      "----------\n",
      "tensor([[0.0000e+00, 8.7353e-04, 0.0000e+00, 1.0335e-03, 0.0000e+00, 0.0000e+00,\n",
      "         2.5625e-03, 6.9076e-04, 1.6828e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.6835e-04, 0.0000e+00, 3.2053e-05, 0.0000e+00, 7.4932e-04, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.8274e-03, 0.0000e+00, 4.0321e-04, 6.2867e-04,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4181e-04, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.5669e-04, 1.1384e-03, 1.5599e-04, 0.0000e+00, 0.0000e+00,\n",
      "         9.6689e-05, 4.6307e-04, 3.1690e-04, 1.4072e-03, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.4665e-04, 3.4216e-04, 0.0000e+00, 2.4883e-04, 1.1921e-03,\n",
      "         0.0000e+00, 0.0000e+00, 1.0234e-03, 1.0112e-03, 4.9605e-04, 1.7387e-04,\n",
      "         0.0000e+00, 1.3005e-03, 2.5557e-03, 0.0000e+00, 8.0977e-04, 0.0000e+00,\n",
      "         2.1502e-03, 0.0000e+00, 0.0000e+00, 2.6945e-03, 0.0000e+00, 1.5370e-03,\n",
      "         0.0000e+00, 1.6185e-04, 0.0000e+00, 1.4996e-03, 0.0000e+00, 8.4467e-04,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7108e-05, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.3241e-03, 1.2368e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1980e-03, 1.7512e-03, 0.0000e+00, 1.3719e-03, 0.0000e+00, 6.6662e-04,\n",
      "         0.0000e+00, 0.0000e+00, 7.4026e-04, 1.5963e-03, 0.0000e+00, 0.0000e+00,\n",
      "         1.4977e-03, 0.0000e+00, 0.0000e+00, 1.1118e-03, 0.0000e+00, 1.7766e-03,\n",
      "         5.7620e-04, 0.0000e+00, 8.5275e-04, 0.0000e+00, 1.4550e-03, 7.8332e-04,\n",
      "         2.1754e-03, 1.5267e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.3055e-04,\n",
      "         1.1368e-03, 0.0000e+00, 0.0000e+00, 1.1748e-03, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5270e-04, 0.0000e+00,\n",
      "         0.0000e+00, 2.2144e-04, 4.6659e-04, 3.8598e-04, 1.7246e-03, 6.0026e-04,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4936e-05, 1.0676e-03, 0.0000e+00,\n",
      "         0.0000e+00, 1.1655e-03, 1.4826e-03, 0.0000e+00, 1.6101e-03, 1.3558e-03,\n",
      "         2.3949e-03, 0.0000e+00, 0.0000e+00, 1.6313e-03, 0.0000e+00, 1.4379e-03,\n",
      "         8.1868e-04, 0.0000e+00, 0.0000e+00, 1.8063e-04, 1.1459e-03, 1.0586e-04,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0739e-03, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.0909e-04, 2.3682e-03, 0.0000e+00, 0.0000e+00, 2.4594e-03,\n",
      "         0.0000e+00, 3.0486e-04, 1.3606e-03, 1.2256e-03, 0.0000e+00, 1.1825e-03,\n",
      "         1.7636e-03, 1.4911e-04, 0.0000e+00, 2.7431e-04, 0.0000e+00, 0.0000e+00,\n",
      "         1.7743e-03, 7.3898e-04, 0.0000e+00, 1.1775e-03, 0.0000e+00, 2.8524e-03,\n",
      "         2.3278e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.7669e-04, 0.0000e+00, 0.0000e+00, 5.3105e-04, 7.6339e-04,\n",
      "         0.0000e+00, 1.2359e-03]])\n",
      "===========\n",
      "gradient:R.R_write.postproc.7.layers.4.bias\n",
      "----------\n",
      "tensor([0.0441])\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    if p.requires_grad:\n",
    "        print(f'===========\\ngradient:{n}\\n----------\\n{p.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(db, model, metrics=[mean_absolute_error], callback_fns=GroupMeanLogMAE, \n",
    "                wd=wd, loss_func=root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(start_lr=1e-6, end_lr=1.0, num_it=1, stop_div=True)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>group_mean_log_mae</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='375', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MPNN:\n\tsize mismatch for R.R_proj.weight: copying a param with shape torch.Size([50, 77]) from checkpoint, the shape in current model is torch.Size([50, 78]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;34m\"Clear optimizer gradients.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-8c901a435075>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m learn.fit_one_cycle(10, max_lr=1e-3, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n\u001b[0;32m----> 2\u001b[0;31m                                                                  monitor='group_mean_log_mae',  name='mpnn1')])\n\u001b[0m",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m loss_func_name2activ = {'cross_entropy_loss': F.softmax, 'nll_loss': torch.exp, 'poisson_nll_loss': torch.exp,\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36mon_train_end\u001b[0;34m(self, exception)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;34m\"Handle end of training, `exception` is an `Exception` or False if no exceptions during training.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mAverageMetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, cb_name, call_mets, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcall_mets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_and_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_and_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_dl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36m_call_and_update\u001b[0;34m(self, cb, cb_name, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_and_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;34m\"Call `cb_name` on `cb` and update the inner state.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'on_{cb_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/callbacks/tracker.py\u001b[0m in \u001b[0;36mon_train_end\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;34m\"Load the best model.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevery\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"improvement\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf'{self.learn.model_dir}/{self.name}.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{self.name}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpurge\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mReduceLROnPlateauCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrackerCallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, file, device, strict, with_opt, purge, remove_module)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mmodel_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremove_module\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_module_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 777\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    778\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MPNN:\n\tsize mismatch for R.R_proj.weight: copying a param with shape torch.Size([50, 77]) from checkpoint, the shape in current model is torch.Size([50, 78])."
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, max_lr=1e-3, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                 monitor='group_mean_log_mae',  name='mpnn1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5, max_lr=2e-4, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='group_mean_log_mae',  name='mpnn2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=1e-5, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='group_mean_log_mae',  name='mpnn3')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=1e-6, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='group_mean_log_mae',  name='mpnn4')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, _ = learn.get_preds()\n",
    "pred_test, _ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
