{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import deepchem as dc\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.spatial.distance import norm\n",
    "\n",
    "from fastai.tabular import *\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "from fastai.basic_data import DataBunch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPES              = np.array(['1JHC', '2JHH', '1JHN', '2JHN', '2JHC', '3JHH', '3JHC', '3JHN'])\n",
    "TYPES_MAP          = {t: i for i, t in enumerate(TYPES)}\n",
    "SC_EDGE_FEATS      = ['type_0', 'type_1', 'type_2', 'type_3', 'type_4', 'type_5', 'type_6', 'type_7', 'dist']\n",
    "N_EDGE_FEATURES    = 8\n",
    "N_SC_EDGE_FEATURES = 9\n",
    "N_ATOM_FEATURES    = 21\n",
    "N_TYPES            = len(TYPES)\n",
    "N_MOLS             = 130775\n",
    "SC_MEAN            = 16\n",
    "SC_STD             = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../tmp/'\n",
    "# PATH = '../storage/CHAMPS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['atomic_features.csv',\n",
       " 'train_proc_df.csv',\n",
       " 'mask.csv',\n",
       " 'edge_mask.csv',\n",
       " 'atom_df.csv',\n",
       " 'pairs_idx.csv',\n",
       " 'edge_df.csv',\n",
       " 'edge_features.csv',\n",
       " 'test_proc_df.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(PATH)\n",
    "files = [f for f in files if f.find('.csv') != -1]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/python36/lib/python3.6/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(PATH+'train_proc_df.csv', index_col=0)\n",
    "test_df  = pd.read_csv(PATH+'test_proc_df.csv', index_col=0)\n",
    "atom_df  = pd.read_csv(PATH+'atom_df.csv', index_col=0)\n",
    "edge_df  = pd.read_csv(PATH+'edge_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MPNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "code_folding": [
     0,
     5,
     13
    ]
   },
   "outputs": [],
   "source": [
    "def selu_weights_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        fan_in = m.weight.size(1)\n",
    "        m.weight.data.normal_(0.0, 1.0 / math.sqrt(fan_in))\n",
    "\n",
    "def hidden_layer(n_in, n_out, batch_norm, dropout, act=None):\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(n_in, n_out))\n",
    "    if act: layers.append(act)\n",
    "    if batch_norm: layers.append(nn.BatchNorm1d(n_out))\n",
    "    if dropout != 0: layers.append(nn.Dropout(dropout))\n",
    "    return layers\n",
    "\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input, n_output, layers=[], act=nn.ReLU(True), dropout=[], batch_norm=False, \n",
    "                 out_act=None):\n",
    "        super().__init__()\n",
    "        sizes = [n_input] + layers + [n_output]\n",
    "        layers_ = []\n",
    "        for i, (n_in, n_out, dr) in enumerate(zip(sizes[:-1], sizes[1:], dropout+[0.0])):\n",
    "            act_ = act if i < len(layers) else out_act\n",
    "            batch_norm_ = batch_norm if i < len(layers) else False\n",
    "            layers_ += hidden_layer(n_in, n_out, batch_norm_, dr, act_)      \n",
    "        self.layers = nn.Sequential(*layers_)\n",
    "        if type(act) == nn.SELU: self.layers.apply(selu_weights_init)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class HiddenLSTMCell(nn.Module):\n",
    "    \"\"\"Implements the LSTM cell update described in the sec 4.2 of https://arxiv.org/pdf/1511.06391.pdf.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_h_out):\n",
    "        \"\"\"This LSTM cell takes no external 'x' inputs, but has a hidden state appended with the \n",
    "        readout from a content based attention mechanism. Therefore the hidden state is of a dimension\n",
    "        that is two times the number of nodes in the set.\"\"\"\n",
    "        super().__init__()\n",
    "        self.n_h_out, self.n_h = n_h_out, n_h_out * 2 \n",
    "        self.w_h = nn.Parameter(torch.Tensor(self.n_h, n_h_out * 4))\n",
    "        self.b = nn.Parameter(torch.Tensor(n_h_out * 4))\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            else: \n",
    "                nn.init.zeros_(p.data)\n",
    "                # initialize the forget gate bias to 1\n",
    "                p.data[self.n_h_out:self.n_h_out*2] = torch.ones(self.n_h_out)\n",
    "        \n",
    "    def forward(self, h_prev, c_prev):\n",
    "        \"\"\"Takes previuos hidden and cell states as arguments and performs a \n",
    "        single LSTM step using no external input.\n",
    "        \"\"\"\n",
    "        n_h_ = self.n_h_out # number of output hidden states\n",
    "        # batch the computations into a single matrix multiplication\n",
    "        gates = h_prev @ self.w_h + self.b\n",
    "        i_g, f_g, g, o_g = (\n",
    "            torch.sigmoid(gates[:, :n_h_]), # input\n",
    "            torch.sigmoid(gates[:, n_h_:n_h_*2]), # forget\n",
    "            torch.tanh(gates[:, n_h_*2:n_h_*3]),\n",
    "            torch.sigmoid(gates[:, n_h_*3:]), # output\n",
    "        )\n",
    "        c = f_g * c_prev + i_g * g\n",
    "        h = o_g * torch.tanh(c)\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "code_folding": [
     0,
     6,
     11
    ]
   },
   "outputs": [],
   "source": [
    "def scatter_add(src, idx, num):\n",
    "    sz = num, src.size(1)\n",
    "    exp_idx = idx[:,None].repeat(1, sz[1])\n",
    "    out = torch.zeros(sz, dtype=src.dtype, device=src.device)\n",
    "    return out.scatter_add(0, exp_idx, src)\n",
    "\n",
    "def softmax(x, idx, num=None):\n",
    "    x = x.exp()\n",
    "    x = x / (scatter_add(x, idx, num=num)[idx] + 1e-16)\n",
    "    return x\n",
    " \n",
    "class Set2Set(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted from: https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric\\\n",
    "        /nn/glob/set2set.html#Set2Set\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, proc_steps):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = 2 * in_channels\n",
    "        self.proc_steps = proc_steps\n",
    "        self.lstm = HiddenLSTMCell(self.in_channels)\n",
    "\n",
    "    def forward(self, x, node_idx):\n",
    "        \"\"\"\n",
    "        x - input tensor of shape (batch_size * n_nodes, in_channels).\n",
    "        - node_idx: tensor of shape (batch_size * n_nodes) mapping each\n",
    "            node to its corresponding index in the batch.\n",
    "        \"\"\"\n",
    "        batch_size = node_idx.max().item() + 1\n",
    "        h = torch.zeros(batch_size, self.in_channels, device=x.device)\n",
    "        q_star = torch.zeros(batch_size, self.out_channels, device=x.device)\n",
    "        for i in range(self.proc_steps):\n",
    "            q, h = self.lstm(q_star, h)\n",
    "            e = (x * q[node_idx]).sum(dim=-1, keepdim=True)\n",
    "            a = softmax(e, node_idx, num=batch_size)\n",
    "            r = scatter_add(a * x, node_idx, num=batch_size) # sum 'a*x' over nodes \n",
    "            q_star = torch.cat([q, r], dim=-1)\n",
    "            \n",
    "        return q_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class EdgeNetwork(nn.Module):\n",
    "    def __init__(self, n_h, n_e, n_sc_e, stride=5, net_args={}):\n",
    "        super().__init__()\n",
    "        self.n_h, self.stride = n_h, stride\n",
    "        self.adj_net = FullyConnectedNet(n_e, n_h*stride, **net_args)\n",
    "        self.sc_adj_net = FullyConnectedNet(n_sc_e, n_h*stride, **net_args)\n",
    "        self.b = nn.Parameter(torch.Tensor(n_h)) # bias for the message function\n",
    "        nn.init.zeros_(self.b)\n",
    "    \n",
    "    def forward(self, h, e, sc_e, pairs_idx, sc_pairs_idx, t=0):\n",
    "        \"\"\"\n",
    "        Compute message vector m_t given the previuos hidden state\n",
    "        h_t-1 and edge features e.\n",
    "        - h: tensor of hidden states of shape (batch_size * n_nodes, n_h)\n",
    "        - e: tensor of edge features of shape (batch_size * n_edges, n_e).\n",
    "        - sc_e: tensor of scalar coupling edge features of shape \n",
    "            (batch_size * n_sc, n_sc_e).\n",
    "        - pairs_idx: tensor of shape (batch_size * n_edges, 2) mapping atom \n",
    "            indexes (first column) to the other atom indexes they form a \n",
    "            bond with (second column). Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_pairs_idx: tensor of shape (batch_size * n_sc, 2) containing atom \n",
    "            indices of the atoms for which the scalar coupling constant\n",
    "            need to be predicted. Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - t: update iteration. \n",
    "        \"\"\"\n",
    "        # compute 'A(e)'\n",
    "        if t==0: \n",
    "            self.a_mat = self.get_a_mat(self.adj_net(e))\n",
    "            self.a_sc_mat = self.get_a_mat(self.sc_adj_net(sc_e))\n",
    "            \n",
    "        # compute 'm_{i} = sum_{j in N(i)}(A_{ij}h_{j})' for all nodes 'i'\n",
    "        m = self.add_message(torch.zeros_like(h), self.a_mat, h, pairs_idx)\n",
    "        m = self.add_message(m, self.a_sc_mat, h, sc_pairs_idx)\n",
    "        return m + self.b # add message bias\n",
    "    \n",
    "    def get_a_mat(self, a_vect):\n",
    "        return a_vect.view(-1, self.n_h, self.stride) / (self.stride ** .5)\n",
    "    \n",
    "    def add_message(self, m, a, h, pairs_idx):\n",
    "        # transform 'pairs_idx' and 'a' to make messages go both in to and out of all nodes\n",
    "        in_out_idx = torch.cat((pairs_idx, pairs_idx[:, [1, 0]]))\n",
    "        a_ = torch.cat((a, a)) \n",
    "        \n",
    "        # select the 'h_{j}' feeding into the 'm_{i}'\n",
    "        h_in = h.index_select(0, in_out_idx[:,1])\n",
    "        \n",
    "        # do the matrix multiplication 'A_{ij}h_{j}'\n",
    "        h_unfolded = F.pad(h_in, 2*(self.stride//2, )).unfold(1, self.stride, 1)\n",
    "        ah = (h_unfolded * a_).sum(-1) # ah = (h_in.unsqueeze(1) @ a_).squeeze(1)\n",
    "        \n",
    "        # Sum up all 'A_{ij}h_{j}' per node 'i'\n",
    "        return m.scatter_add(0, in_out_idx[:,0,None].repeat(1, self.n_h), ah)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class GRUUpdate(nn.Module):\n",
    "    def __init__(self, n_h):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRUCell(n_h, n_h)\n",
    "        \n",
    "    def forward(self, m, h_prev):\n",
    "        \"\"\"\n",
    "        Update hidden state h.\n",
    "        - h_prev is vector of hidden states of shape (batch_size * n_nodes, n_h)\n",
    "        - m is vector of messages of shape (batch_size * n_nodes, n_h)\n",
    "        \"\"\"\n",
    "        return self.gru(m, h_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MyCustomHead(nn.Module):\n",
    "    def __init__(self, n_input, n_output, pre_layers=[], post_layers=[], act=nn.ReLU(True), dropout=[], \n",
    "                 batch_norm=False):\n",
    "        super().__init__()\n",
    "        sizes, n_pre_layers = [n_input] + pre_layers, len(pre_layers)\n",
    "        pre_layers_ = []\n",
    "        for i, (n_in, n_out, dr) in enumerate(zip(sizes[:-1], sizes[1:], dropout[:n_pre_layers])):\n",
    "            pre_layers_ += hidden_layer(n_in, n_out, batch_norm, dr, act)      \n",
    "        self.preproc = nn.Sequential(*pre_layers_)\n",
    "        self.postproc = nn.ModuleList([\n",
    "            FullyConnectedNet(pre_layers[-1], n_output, post_layers, act, dropout, batch_norm)\n",
    "            for _ in range(N_TYPES)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x, i=0):\n",
    "        x_ = self.preproc(x)\n",
    "        y = self.postproc[i](x_)\n",
    "        return y        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Set2SetOutput(nn.Module):\n",
    "    def __init__(self, n_x, n_h, proc_steps, net_args):\n",
    "        super().__init__()\n",
    "        self.R_proj = nn.Linear(n_h + n_x, n_h)\n",
    "        self.R_proc = Set2Set(n_h, proc_steps)\n",
    "        self.R_write = MyCustomHead(4 * n_h, 1, **net_args)\n",
    "    \n",
    "    def forward(self, h, x, node_idx, sc_idx, sc_pairs_idx, sc_types):\n",
    "        \"\"\"\n",
    "        Make prediction.\n",
    "        - h is vector of hidden states of shape (batch_size * n_nodes, n_h).\n",
    "        - x is vector of input features of shape (batch_size * n_nodes, n_x).\n",
    "        - node_idx: tensor of shape (batch_size * n_nodes) mapping each\n",
    "            node to its corresponding index in the batch.\n",
    "        - sc_idx: tensor of shape (batch_size * n_sc) mapping each\n",
    "            scalar coupling constant to its corresponding index in the batch.\n",
    "        - sc_pairs_idx: tensor of shape (batch_size * n_sc, 2) containing atom \n",
    "            indices of the atoms for which the scalar coupling constant\n",
    "            need to be predicted. Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_types: tensor of shape (batch_size * n_sc) containing the scalar \n",
    "            coupling type of each observation. \n",
    "        \"\"\"\n",
    "        m = self.R_proj(torch.cat([h, x], dim=1))\n",
    "        q = self.R_proc(m, node_idx)\n",
    "        \n",
    "        # introduce skip connection to final node states of scalar coupling atoms\n",
    "        inp = torch.cat([\n",
    "            q.index_select(0, sc_idx),\n",
    "            h.index_select(0, sc_pairs_idx[:,0]),\n",
    "            h.index_select(0, sc_pairs_idx[:,1])\n",
    "        ], dim=-1)\n",
    "        y = torch.zeros(sc_idx.size(0), device=x.device)\n",
    "        for i in range(N_TYPES):\n",
    "            if torch.any(sc_types == i): \n",
    "                y[sc_types == i] = self.R_write(inp[sc_types == i], i).view(-1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MPNN(nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_e, n_sc_e, stride=5, update_steps=3, proc_steps=10, preproc_net_args={}, \n",
    "                 enn_args={}, R_net_args={}):\n",
    "        super().__init__()\n",
    "        self.preproc_net = FullyConnectedNet(n_x, n_h, **preproc_net_args)\n",
    "        self.M = EdgeNetwork(n_h, n_e, n_sc_e, stride, enn_args)\n",
    "        self.U = GRUUpdate(n_h)\n",
    "        self.R = Set2SetOutput(n_x, n_h, proc_steps, R_net_args)\n",
    "        self.update_steps = update_steps\n",
    "        \n",
    "    def forward(self, x, e, sc_e, node_idx, pairs_idx, sc_idx, sc_pairs_idx, sc_types):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: tensor of node features of shape (batch_size * n_nodes, n_x).\n",
    "        - e: tensor of edge features of shape (batch_size * n_edges, n_e).\n",
    "        - sc_e: tensor of scalar coupling edge features of shape \n",
    "            (batch_size * n_sc, n_sc_e).\n",
    "        - node_idx: tensor of shape (batch_size * n_nodes) mapping each\n",
    "            node to its corresponding index in the batch.\n",
    "        - pairs_idx: tensor of shape (batch_size * n_edges, 2) mapping atom \n",
    "            indexes (first column) to the other atom indexes they form a \n",
    "            bond with (second column). Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_idx: tensor of shape (batch_size * n_sc) mapping each\n",
    "            scalar coupling constant to its corresponding index in the batch.\n",
    "        - sc_pairs_idx: tensor of shape (batch_size * n_sc, 2) containing atom \n",
    "            indices of the atoms for which the scalar coupling constant\n",
    "            need to be predicted. Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_types: tensor of shape (batch_size * n_sc) containing the scalar \n",
    "            coupling type of each observation. \n",
    "        \"\"\"\n",
    "        h = self.preproc_net(x)\n",
    "        for t in range(self.update_steps):\n",
    "            m = self.M(h, e, sc_e, pairs_idx, sc_pairs_idx, t)\n",
    "            h = self.U(m, h)\n",
    "        y = self.R(h, x, node_idx, sc_idx, sc_pairs_idx, sc_types)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Fit MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=100):\n",
    "    # python RNG\n",
    "    random.seed(seed)\n",
    "\n",
    "    # pytorch RNGs\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # numpy RNG\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = 2100 # N_MOLS\n",
    "mol_ids = train_df['molecule_id'].unique()\n",
    "set_seed(100)\n",
    "mol_ids_ = np.random.choice(mol_ids, size=n_obs, replace=False)\n",
    "train_mol_ids, val_mol_ids = pd.Series(mol_ids_[:1500]), pd.Series(mol_ids_[1500:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['scalar_coupling_constant'] = (train_df['scalar_coupling_constant'] - SC_MEAN) / SC_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_mol_sc = train_df.groupby('molecule_id')\n",
    "test_gb_mol_sc = test_df.groupby('molecule_id')\n",
    "gb_mol_atom = atom_df.groupby('molecule_id')\n",
    "gb_mol_edge = edge_df.groupby('molecule_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "code_folding": [
     0,
     6,
     23,
     26
    ]
   },
   "outputs": [],
   "source": [
    "def one_hot_encode_np(x):\n",
    "    sz = len(x), len(np.unique(x))\n",
    "    x_one_hot = np.zeros(sz, dtype=np.long)\n",
    "    x_one_hot[np.arange(sz[0]), x] = 1\n",
    "    return x_one_hot\n",
    "\n",
    "class MoleculeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, mol_ids, gb_mol_sc, gb_mol_atom, gb_mol_edge):\n",
    "        self.n = len(mol_ids)\n",
    "        self.mol_ids = mol_ids\n",
    "        self.gb_mol_sc = gb_mol_sc\n",
    "        self.gb_mol_atom = gb_mol_atom\n",
    "        self.gb_mol_edge = gb_mol_edge\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.gb_mol_sc.get_group(self.mol_ids[idx]), \n",
    "                self.gb_mol_atom.get_group(self.mol_ids[idx]), \n",
    "                self.gb_mol_edge.get_group(self.mol_ids[idx]))\n",
    "\n",
    "def np_lst_to_torch(arr_lst, dtype=torch.float):\n",
    "    return torch.from_numpy(np.concatenate(arr_lst)).type(dtype)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch_size, n_atom_sum = len(batch), 0\n",
    "    x, e, sc_e, sc_types, sc_vals = [], [], [], [], []\n",
    "    node_idx, pairs_idx, sc_pairs_idx, sc_idx = [], [], [], []\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        sc_df, atom_df, edge_df = batch[b]\n",
    "        n_atoms, n_sc = len(atom_df), len(sc_df)\n",
    "        \n",
    "        x.append(atom_df.drop(columns='molecule_id').values)\n",
    "        e.append(edge_df.drop(columns=['idx_0', 'idx_1', 'molecule_id']).values)\n",
    "        sc_e.append(sc_df[SC_EDGE_FEATS].values)\n",
    "        sc_types.append(sc_df['type'].values)\n",
    "        sc_vals.append(sc_df['scalar_coupling_constant'].values)\n",
    "        \n",
    "        node_idx.append(np.repeat(b, n_atoms))\n",
    "        sc_idx.append(np.repeat(b, n_sc))\n",
    "        pairs_idx.append(edge_df[['idx_0', 'idx_1']].values + n_atom_sum)\n",
    "        sc_pairs_idx.append(sc_df[['atom_index_0', 'atom_index_1']].values + n_atom_sum)\n",
    "        \n",
    "        n_atom_sum += n_atoms\n",
    "    \n",
    "    x, e, sc_e = np_lst_to_torch(x), np_lst_to_torch(e), np_lst_to_torch(sc_e)\n",
    "    sc_vals, sc_types = np_lst_to_torch(sc_vals), np_lst_to_torch(sc_types, torch.long)\n",
    "    node_idx = np_lst_to_torch(node_idx, torch.long)\n",
    "    sc_idx = np_lst_to_torch(sc_idx, torch.long)\n",
    "    pairs_idx = np_lst_to_torch(pairs_idx, torch.long)\n",
    "    sc_pairs_idx = np_lst_to_torch(sc_pairs_idx, torch.long)\n",
    "    \n",
    "    return (x, e, sc_e, node_idx, pairs_idx, sc_idx, sc_pairs_idx, sc_types), sc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MoleculeDataset(train_mol_ids, gb_mol_sc, gb_mol_atom, gb_mol_edge)\n",
    "val_ds   = MoleculeDataset(val_mol_ids, gb_mol_sc, gb_mol_atom, gb_mol_edge)\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=8)\n",
    "val_dl   = DataLoader(val_ds, batch_size, num_workers=8)\n",
    "db = DataBunch(train_dl, val_dl, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([384, 21])\n",
      "torch.Size([396, 8])\n",
      "torch.Size([1208, 9])\n",
      "torch.Size([384])\n",
      "torch.Size([396, 2])\n",
      "torch.Size([1208])\n",
      "torch.Size([1208, 2])\n",
      "torch.Size([1208])\n",
      "torch.Size([1208])\n"
     ]
    }
   ],
   "source": [
    "for el in batch[0]: print(el.size())\n",
    "print(batch[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " tensor([[0.0000, 0.0000, 1.0000,  ..., 3.0400, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 2.5500, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 2.5500, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 2.2000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 2.2000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 2.2000, 0.0000, 0.0000]])\n",
      "e:\n",
      " tensor([[ 0.0000,  0.0000,  1.0000,  ...,  0.0000,  1.1549, -0.4825],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  1.4657,  1.1800],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  1.4571,  1.1338],\n",
      "        ...,\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0885, -0.9615],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  1.4488,  1.0769],\n",
      "        [ 0.0000,  0.0000,  1.0000,  ...,  0.0000,  1.1558, -0.5805]])\n",
      "sc_e:\n",
      " tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 3.1502],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 2.0891],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0973],\n",
      "        ...,\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0885],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 2.1361],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 3.1952]])\n",
      "node_idx:\n",
      " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15,\n",
      "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "        17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "        18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "        19, 19, 19, 19, 19, 19])\n",
      "pairs_idx:\n",
      " tensor([[  0,   1],\n",
      "        [  1,   2],\n",
      "        [  2,   3],\n",
      "        [  2,   9],\n",
      "        [  2,  10],\n",
      "        [  3,   4],\n",
      "        [  3,  11],\n",
      "        [  4,  12],\n",
      "        [  4,  13],\n",
      "        [  4,   5],\n",
      "        [  5,   6],\n",
      "        [  5,  14],\n",
      "        [  5,  15],\n",
      "        [  6,   7],\n",
      "        [  6,   8],\n",
      "        [  7,   8],\n",
      "        [  7,  16],\n",
      "        [  7,  17],\n",
      "        [  8,  18],\n",
      "        [  8,  19],\n",
      "        [ 20,  21],\n",
      "        [ 20,  29],\n",
      "        [ 20,  30],\n",
      "        [ 20,  31],\n",
      "        [ 21,  22],\n",
      "        [ 21,  28],\n",
      "        [ 21,  32],\n",
      "        [ 22,  23],\n",
      "        [ 23,  34],\n",
      "        [ 23,  24],\n",
      "        [ 23,  33],\n",
      "        [ 24,  25],\n",
      "        [ 24,  26],\n",
      "        [ 26,  27],\n",
      "        [ 26,  28],\n",
      "        [ 26,  35],\n",
      "        [ 27,  28],\n",
      "        [ 28,  36],\n",
      "        [ 37,  38],\n",
      "        [ 37,  46],\n",
      "        [ 37,  47],\n",
      "        [ 37,  48],\n",
      "        [ 38,  39],\n",
      "        [ 38,  42],\n",
      "        [ 38,  49],\n",
      "        [ 39,  40],\n",
      "        [ 40,  41],\n",
      "        [ 40,  45],\n",
      "        [ 40,  50],\n",
      "        [ 41,  52],\n",
      "        [ 41,  42],\n",
      "        [ 41,  51],\n",
      "        [ 42,  43],\n",
      "        [ 42,  53],\n",
      "        [ 43,  44],\n",
      "        [ 43,  54],\n",
      "        [ 43,  55],\n",
      "        [ 44,  45],\n",
      "        [ 44,  56],\n",
      "        [ 44,  57],\n",
      "        [ 45,  58],\n",
      "        [ 45,  59],\n",
      "        [ 60,  61],\n",
      "        [ 60,  69],\n",
      "        [ 60,  70],\n",
      "        [ 60,  71],\n",
      "        [ 61,  62],\n",
      "        [ 61,  63],\n",
      "        [ 61,  67],\n",
      "        [ 62,  72],\n",
      "        [ 62,  73],\n",
      "        [ 62,  74],\n",
      "        [ 63,  65],\n",
      "        [ 63,  64],\n",
      "        [ 64,  65],\n",
      "        [ 64,  75],\n",
      "        [ 64,  76],\n",
      "        [ 65,  66],\n",
      "        [ 65,  77],\n",
      "        [ 66,  67],\n",
      "        [ 66,  78],\n",
      "        [ 66,  79],\n",
      "        [ 67,  68],\n",
      "        [ 80,  81],\n",
      "        [ 80,  89],\n",
      "        [ 80,  90],\n",
      "        [ 80,  91],\n",
      "        [ 81,  82],\n",
      "        [ 81,  85],\n",
      "        [ 81,  87],\n",
      "        [ 82,  92],\n",
      "        [ 82,  93],\n",
      "        [ 82,  83],\n",
      "        [ 83,  84],\n",
      "        [ 84,  85],\n",
      "        [ 84,  87],\n",
      "        [ 84,  94],\n",
      "        [ 85,  86],\n",
      "        [ 85,  95],\n",
      "        [ 86,  96],\n",
      "        [ 87,  97],\n",
      "        [ 87,  88],\n",
      "        [ 88,  98],\n",
      "        [ 99, 100],\n",
      "        [ 99, 108],\n",
      "        [ 99, 109],\n",
      "        [ 99, 110],\n",
      "        [100, 101],\n",
      "        [101, 102],\n",
      "        [102, 103],\n",
      "        [102, 104],\n",
      "        [102, 107],\n",
      "        [103, 112],\n",
      "        [103, 104],\n",
      "        [103, 111],\n",
      "        [104, 105],\n",
      "        [104, 113],\n",
      "        [105, 106],\n",
      "        [105, 107],\n",
      "        [105, 114],\n",
      "        [106, 116],\n",
      "        [106, 115],\n",
      "        [106, 117],\n",
      "        [118, 119],\n",
      "        [118, 126],\n",
      "        [119, 120],\n",
      "        [119, 127],\n",
      "        [119, 128],\n",
      "        [120, 121],\n",
      "        [120, 129],\n",
      "        [120, 130],\n",
      "        [121, 132],\n",
      "        [121, 131],\n",
      "        [121, 122],\n",
      "        [122, 123],\n",
      "        [122, 125],\n",
      "        [122, 133],\n",
      "        [123, 124],\n",
      "        [123, 134],\n",
      "        [123, 135],\n",
      "        [124, 125],\n",
      "        [124, 136],\n",
      "        [124, 137],\n",
      "        [138, 139],\n",
      "        [138, 147],\n",
      "        [138, 148],\n",
      "        [138, 149],\n",
      "        [139, 140],\n",
      "        [139, 145],\n",
      "        [139, 150],\n",
      "        [140, 141],\n",
      "        [140, 145],\n",
      "        [141, 152],\n",
      "        [141, 151],\n",
      "        [141, 142],\n",
      "        [142, 143],\n",
      "        [142, 145],\n",
      "        [142, 153],\n",
      "        [143, 144],\n",
      "        [143, 154],\n",
      "        [145, 146],\n",
      "        [146, 155],\n",
      "        [146, 156],\n",
      "        [146, 157],\n",
      "        [158, 159],\n",
      "        [158, 166],\n",
      "        [158, 167],\n",
      "        [158, 168],\n",
      "        [159, 160],\n",
      "        [159, 169],\n",
      "        [160, 161],\n",
      "        [160, 164],\n",
      "        [161, 170],\n",
      "        [161, 162],\n",
      "        [162, 163],\n",
      "        [162, 171],\n",
      "        [163, 164],\n",
      "        [163, 172],\n",
      "        [164, 165],\n",
      "        [165, 173],\n",
      "        [165, 174],\n",
      "        [165, 175],\n",
      "        [176, 177],\n",
      "        [176, 185],\n",
      "        [176, 186],\n",
      "        [176, 187],\n",
      "        [177, 178],\n",
      "        [178, 179],\n",
      "        [178, 181],\n",
      "        [178, 184],\n",
      "        [179, 188],\n",
      "        [179, 189],\n",
      "        [179, 180],\n",
      "        [180, 190],\n",
      "        [181, 182],\n",
      "        [181, 191],\n",
      "        [181, 192],\n",
      "        [182, 183],\n",
      "        [182, 184],\n",
      "        [182, 193],\n",
      "        [183, 195],\n",
      "        [183, 184],\n",
      "        [183, 194],\n",
      "        [184, 196],\n",
      "        [197, 198],\n",
      "        [197, 206],\n",
      "        [197, 207],\n",
      "        [198, 199],\n",
      "        [198, 200],\n",
      "        [200, 201],\n",
      "        [200, 204],\n",
      "        [200, 208],\n",
      "        [201, 202],\n",
      "        [202, 203],\n",
      "        [202, 204],\n",
      "        [204, 205],\n",
      "        [204, 209],\n",
      "        [205, 210],\n",
      "        [211, 212],\n",
      "        [211, 219],\n",
      "        [211, 220],\n",
      "        [211, 221],\n",
      "        [212, 213],\n",
      "        [212, 222],\n",
      "        [212, 223],\n",
      "        [213, 214],\n",
      "        [214, 224],\n",
      "        [214, 215],\n",
      "        [215, 216],\n",
      "        [215, 225],\n",
      "        [216, 217],\n",
      "        [216, 218],\n",
      "        [217, 226],\n",
      "        [217, 227],\n",
      "        [217, 228],\n",
      "        [229, 230],\n",
      "        [229, 238],\n",
      "        [230, 231],\n",
      "        [230, 236],\n",
      "        [231, 232],\n",
      "        [232, 233],\n",
      "        [232, 239],\n",
      "        [232, 240],\n",
      "        [233, 241],\n",
      "        [233, 234],\n",
      "        [233, 237],\n",
      "        [234, 235],\n",
      "        [235, 236],\n",
      "        [235, 242],\n",
      "        [235, 243],\n",
      "        [236, 237],\n",
      "        [236, 244],\n",
      "        [245, 246],\n",
      "        [245, 254],\n",
      "        [245, 255],\n",
      "        [245, 256],\n",
      "        [246, 247],\n",
      "        [246, 248],\n",
      "        [246, 257],\n",
      "        [247, 258],\n",
      "        [248, 252],\n",
      "        [248, 251],\n",
      "        [248, 249],\n",
      "        [249, 250],\n",
      "        [249, 259],\n",
      "        [249, 260],\n",
      "        [250, 251],\n",
      "        [250, 252],\n",
      "        [250, 261],\n",
      "        [251, 262],\n",
      "        [251, 263],\n",
      "        [252, 253],\n",
      "        [264, 265],\n",
      "        [264, 273],\n",
      "        [264, 274],\n",
      "        [264, 275],\n",
      "        [265, 266],\n",
      "        [265, 268],\n",
      "        [265, 276],\n",
      "        [266, 267],\n",
      "        [268, 270],\n",
      "        [268, 269],\n",
      "        [269, 277],\n",
      "        [269, 278],\n",
      "        [269, 279],\n",
      "        [270, 271],\n",
      "        [270, 280],\n",
      "        [270, 281],\n",
      "        [271, 272],\n",
      "        [282, 283],\n",
      "        [282, 291],\n",
      "        [282, 292],\n",
      "        [282, 293],\n",
      "        [283, 284],\n",
      "        [283, 285],\n",
      "        [284, 285],\n",
      "        [284, 294],\n",
      "        [284, 295],\n",
      "        [285, 296],\n",
      "        [285, 286],\n",
      "        [286, 287],\n",
      "        [286, 288],\n",
      "        [286, 297],\n",
      "        [287, 288],\n",
      "        [287, 298],\n",
      "        [287, 299],\n",
      "        [288, 289],\n",
      "        [288, 300],\n",
      "        [289, 290],\n",
      "        [290, 301],\n",
      "        [302, 303],\n",
      "        [302, 311],\n",
      "        [302, 312],\n",
      "        [302, 313],\n",
      "        [303, 304],\n",
      "        [303, 314],\n",
      "        [303, 315],\n",
      "        [304, 305],\n",
      "        [304, 310],\n",
      "        [305, 306],\n",
      "        [305, 307],\n",
      "        [306, 318],\n",
      "        [306, 316],\n",
      "        [306, 317],\n",
      "        [307, 308],\n",
      "        [307, 309],\n",
      "        [307, 319],\n",
      "        [308, 309],\n",
      "        [308, 320],\n",
      "        [309, 310],\n",
      "        [309, 321],\n",
      "        [310, 322],\n",
      "        [310, 323],\n",
      "        [324, 325],\n",
      "        [324, 333],\n",
      "        [324, 334],\n",
      "        [324, 335],\n",
      "        [325, 326],\n",
      "        [325, 327],\n",
      "        [325, 332],\n",
      "        [326, 336],\n",
      "        [327, 337],\n",
      "        [327, 338],\n",
      "        [327, 328],\n",
      "        [328, 329],\n",
      "        [328, 331],\n",
      "        [328, 332],\n",
      "        [329, 330],\n",
      "        [329, 339],\n",
      "        [329, 340],\n",
      "        [330, 341],\n",
      "        [331, 343],\n",
      "        [331, 332],\n",
      "        [331, 342],\n",
      "        [332, 344],\n",
      "        [345, 346],\n",
      "        [345, 354],\n",
      "        [345, 355],\n",
      "        [345, 356],\n",
      "        [346, 347],\n",
      "        [346, 357],\n",
      "        [346, 358],\n",
      "        [347, 348],\n",
      "        [347, 351],\n",
      "        [347, 353],\n",
      "        [348, 360],\n",
      "        [348, 359],\n",
      "        [348, 349],\n",
      "        [349, 350],\n",
      "        [349, 353],\n",
      "        [349, 361],\n",
      "        [350, 351],\n",
      "        [351, 352],\n",
      "        [351, 362],\n",
      "        [352, 353],\n",
      "        [352, 363],\n",
      "        [352, 364],\n",
      "        [353, 365],\n",
      "        [366, 367],\n",
      "        [366, 375],\n",
      "        [366, 376],\n",
      "        [366, 377],\n",
      "        [367, 368],\n",
      "        [367, 378],\n",
      "        [367, 379],\n",
      "        [368, 369],\n",
      "        [369, 381],\n",
      "        [369, 370],\n",
      "        [369, 380],\n",
      "        [370, 371],\n",
      "        [370, 372],\n",
      "        [370, 382],\n",
      "        [371, 372],\n",
      "        [372, 383],\n",
      "        [372, 373],\n",
      "        [373, 374]])\n",
      "sc_idx:\n",
      " tensor([ 0,  0,  0,  ..., 19, 19, 19])\n",
      "sc_pairs_idx:\n",
      " tensor([[  9,   0],\n",
      "        [  9,   1],\n",
      "        [  9,   2],\n",
      "        ...,\n",
      "        [383, 372],\n",
      "        [383, 373],\n",
      "        [383, 374]])\n",
      "sc_types:\n",
      " tensor([7, 4, 0,  ..., 0, 4, 7])\n",
      "sc_vals:\n",
      " tensor([-0.4326, -0.6912,  2.2966,  ...,  3.2058, -0.2964, -0.4349])\n"
     ]
    }
   ],
   "source": [
    "b_dict = dict(x=batch[0][0], \n",
    "              e=batch[0][1], \n",
    "              sc_e=batch[0][2], \n",
    "              node_idx=batch[0][3], \n",
    "              pairs_idx=batch[0][4], \n",
    "              sc_idx=batch[0][5], \n",
    "              sc_pairs_idx=batch[0][6], \n",
    "              sc_types=batch[0][7], \n",
    "              sc_vals=batch[1])\n",
    "for k,v in b_dict.items(): print(f'{k}:\\n {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "def group_mean_log_mae(y_true, y_pred, types):\n",
    "    proc = lambda x: x.cpu().numpy().ravel() \n",
    "    y_true, y_pred, types = proc(y_true), proc(y_pred), proc(types)\n",
    "    y_true = SC_MEAN + y_true * SC_STD\n",
    "    y_pred = SC_MEAN + y_pred * SC_STD\n",
    "    maes = pd.Series(y_true - y_pred).abs().groupby(types).mean()\n",
    "    return np.log(maes).mean()\n",
    "\n",
    "class GroupMeanLogMAE(Callback):\n",
    "    _order = -20 #Needs to run before the recorder\n",
    "\n",
    "    def __init__(self, learn, **kwargs): self.learn = learn\n",
    "    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['group_mean_log_mae'])\n",
    "    def on_epoch_begin(self, **kwargs): self.input, self.output, self.target = [], [], []\n",
    "    \n",
    "    def on_batch_end(self, last_target, last_output, last_input, train, **kwargs):\n",
    "        if not train:\n",
    "            self.input.append(last_input[-1])\n",
    "            self.output.append(last_output)\n",
    "            self.target.append(last_target)\n",
    "                \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        if (len(self.input) > 0) and (len(self.output) > 0):\n",
    "            inputs = torch.cat(self.input)\n",
    "            preds = torch.cat(self.output)\n",
    "            target = torch.cat(self.target)\n",
    "            metric = group_mean_log_mae(preds, target, inputs)\n",
    "            return add_metrics(last_metrics, [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd, batch_norm, act = 0, False, nn.ReLU(True)\n",
    "stride, update_steps, proc_steps = 5, 5, 10\n",
    "n_x, n_h, n_e, n_sc_e = N_ATOM_FEATURES, 100, N_EDGE_FEATURES, N_SC_EDGE_FEATURES\n",
    "preproc_net_args = dict(layers=[], act=act, dropout=[], batch_norm=batch_norm, out_act=nn.Tanh())\n",
    "enn_args = dict(layers=3*[n_h], act=act, dropout=3*[0.0], batch_norm=batch_norm)\n",
    "R_net_args = dict(pre_layers=[1000], post_layers=[500], act=act, dropout=[0.0, 0.0], \n",
    "                  batch_norm=batch_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(100)\n",
    "model = MPNN(n_x, n_h, n_e, n_sc_e, stride, update_steps, proc_steps, preproc_net_args, enn_args, R_net_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNN(\n",
      "  (preproc_net): FullyConnectedNet(\n",
      "    (layers): Sequential(\n",
      "      (0): Linear(in_features=21, out_features=100, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (M): EdgeNetwork(\n",
      "    (adj_net): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=8, out_features=100, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (5): ReLU(inplace)\n",
      "        (6): Linear(in_features=100, out_features=500, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (sc_adj_net): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=9, out_features=100, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (5): ReLU(inplace)\n",
      "        (6): Linear(in_features=100, out_features=500, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (U): GRUUpdate(\n",
      "    (gru): GRUCell(100, 100)\n",
      "  )\n",
      "  (R): Set2SetOutput(\n",
      "    (R_proj): Linear(in_features=121, out_features=100, bias=True)\n",
      "    (R_proc): Set2Set(\n",
      "      (lstm): HiddenLSTMCell()\n",
      "    )\n",
      "    (R_write): MyCustomHead(\n",
      "      (preproc): Sequential(\n",
      "        (0): Linear(in_features=400, out_features=1000, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "      )\n",
      "      (postproc): ModuleList(\n",
      "        (0): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (1): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (2): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (3): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (4): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (5): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (6): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (7): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "tensor([-0.0355, -0.0532, -0.0294,  ..., -0.0295, -0.0521, -0.0361],\n",
      "       grad_fn=<IndexPutBackward>)\n",
      "torch.Size([1208])\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(model(*batch[0]))\n",
    "print(model(*batch[0]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(db, model, metrics=[mean_absolute_error], callback_fns=GroupMeanLogMAE, \n",
    "                wd=wd, loss_func=root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(start_lr=1e-6, end_lr=1.0, num_it=100, stop_div=True)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='9' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      90.00% [9/10 23:20<02:35]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>group_mean_log_mae</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.153276</td>\n",
       "      <td>0.098758</td>\n",
       "      <td>1.182019</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.167456</td>\n",
       "      <td>0.131212</td>\n",
       "      <td>0.090276</td>\n",
       "      <td>1.132800</td>\n",
       "      <td>02:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.160850</td>\n",
       "      <td>0.120327</td>\n",
       "      <td>0.084899</td>\n",
       "      <td>1.047128</td>\n",
       "      <td>02:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.141461</td>\n",
       "      <td>0.125835</td>\n",
       "      <td>0.088069</td>\n",
       "      <td>1.089043</td>\n",
       "      <td>02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.119847</td>\n",
       "      <td>0.100860</td>\n",
       "      <td>0.072855</td>\n",
       "      <td>0.906559</td>\n",
       "      <td>02:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.094632</td>\n",
       "      <td>0.083763</td>\n",
       "      <td>0.061483</td>\n",
       "      <td>0.640364</td>\n",
       "      <td>02:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.084769</td>\n",
       "      <td>0.078897</td>\n",
       "      <td>0.056891</td>\n",
       "      <td>0.585148</td>\n",
       "      <td>02:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.077723</td>\n",
       "      <td>0.075499</td>\n",
       "      <td>0.054267</td>\n",
       "      <td>0.499932</td>\n",
       "      <td>02:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071749</td>\n",
       "      <td>0.071299</td>\n",
       "      <td>0.051175</td>\n",
       "      <td>0.445865</td>\n",
       "      <td>02:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='75', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with group_mean_log_mae value: 1.182018518447876.\n",
      "Better model found at epoch 1 with group_mean_log_mae value: 1.1327996253967285.\n",
      "Better model found at epoch 2 with group_mean_log_mae value: 1.047128438949585.\n",
      "Better model found at epoch 4 with group_mean_log_mae value: 0.9065585136413574.\n",
      "Better model found at epoch 5 with group_mean_log_mae value: 0.6403637528419495.\n",
      "Better model found at epoch 6 with group_mean_log_mae value: 0.5851481556892395.\n",
      "Better model found at epoch 7 with group_mean_log_mae value: 0.499932199716568.\n",
      "Better model found at epoch 8 with group_mean_log_mae value: 0.4458645284175873.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-318-4e4e517de71b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m learn.fit_one_cycle(10, max_lr=1e-2, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n\u001b[0;32m----> 2\u001b[0;31m                                                                   monitor='group_mean_log_mae',  name='mpnn1')])\n\u001b[0m",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(50, max_lr=3e-3, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='group_mean_log_mae',  name='mpnn1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=3e-4, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='group_mean_log_mae',  name='mpnn2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=1e-4, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='group_mean_log_mae',  name='mpnn3')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=1e-5, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='group_mean_log_mae',  name='mpnn4')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, _ = learn.get_preds()\n",
    "pred_test, _ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
