{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "\n",
    "from fastai.tabular import *\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "from fastai.basic_data import DataBunch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __print__ = print\n",
    "# def print(*strings):\n",
    "#     for string in strings:\n",
    "#         os.system(f'echo \\\"{string}\\\"')\n",
    "#         __print__(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_ID = 2\n",
    "VERSION = 2\n",
    "\n",
    "TYPES              = np.array(['1JHC', '2JHH', '1JHN', '2JHN', '2JHC', '3JHH', '3JHC', '3JHN'])\n",
    "TYPES_MAP          = {t: i for i, t in enumerate(TYPES)}\n",
    "SC_EDGE_FEATS      = ['type_0', 'type_1', 'type_2', 'type_3', 'type_4', 'type_5', 'type_6', 'type_7', \n",
    "                      'dist', 'dist_min_rad', 'dist_electro_neg_adj', 'normed_dist', \n",
    "                      'diangle', 'cos_angle', 'cos_angle0', 'cos_angle1', \n",
    "                      #'inv_dist', 'normed_inv_dist'\n",
    "                     ]\n",
    "SC_MOL_FEATS       = ['type_0', 'type_1', 'type_2', 'type_3', 'type_4', 'type_5', 'type_6', 'type_7', \n",
    "                      'dist', 'dist_min_rad', 'dist_electro_neg_adj', 'normed_dist', \n",
    "                      'diangle', 'cos_angle', 'cos_angle0', 'cos_angle1', \n",
    "                      'num_atoms', 'num_C_atoms', 'num_F_atoms', 'num_H_atoms', 'num_N_atoms', 'num_O_atoms', \n",
    "                      #'inv_dist', 'normed_inv_dist', \n",
    "                      'std_bond_length', 'ave_bond_length', #'total_bond_length',  \n",
    "                      #'ave_inv_bond_length', 'total_inv_bond_length', \n",
    "                      'ave_atom_weight'#, 'total_atom_weight'\n",
    "                     ]\n",
    "ATOM_FEATS         = ['type_H', 'type_C', 'type_N', 'type_O', 'type_F', \n",
    "                      'degree_1', 'degree_2', 'degree_3', 'degree_4', 'degree_5', \n",
    "                      'SP', 'SP2', 'SP3', 'hybridization_unspecified', \n",
    "                      'aromatic', 'formal_charge', 'atomic_num',\n",
    "                      'donor', 'acceptor', \n",
    "                      'ave_bond_length', \n",
    "                      #'ave_inv_bond_length',\n",
    "                      'ave_neighbor_weight']\n",
    "EDGE_FEATS         = ['single', 'double', 'triple', 'aromatic', \n",
    "                      'conjugated', 'in_ring',\n",
    "                      'dist', 'normed_dist', \n",
    "                      #'inv_dist', 'normed_inv_dist'\n",
    "                     ]\n",
    "TARGET_COL         = 'scalar_coupling_constant'\n",
    "CONTRIB_COLS       = ['fc', 'sd', 'pso', 'dso']\n",
    "N_EDGE_FEATURES    = len(EDGE_FEATS)\n",
    "N_SC_EDGE_FEATURES = len(SC_EDGE_FEATS)\n",
    "N_SC_MOL_FEATURES  = len(SC_MOL_FEATS)\n",
    "N_ATOM_FEATURES    = len(ATOM_FEATS)\n",
    "N_TYPES            = len(TYPES)\n",
    "N_MOLS             = 130775\n",
    "SC_MEAN            = 16\n",
    "SC_STD             = 35\n",
    "\n",
    "SC_FEATS_TO_SCALE   = ['dist', 'dist_min_rad', 'dist_electro_neg_adj', 'num_atoms', 'num_C_atoms', \n",
    "                       'num_F_atoms', 'num_H_atoms', 'num_N_atoms', 'num_O_atoms', 'inv_dist', \n",
    "                       'ave_bond_length', 'std_bond_length', 'total_bond_length',  'ave_inv_bond_length', \n",
    "                       'total_inv_bond_length', 'ave_atom_weight', 'total_atom_weight']\n",
    "ATOM_FEATS_TO_SCALE = ['atomic_num', 'ave_bond_length', 'ave_inv_bond_length', 'ave_neighbor_weight']\n",
    "EDGE_FEATS_TO_SCALE = ['dist', 'inv_dist']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "PATH = '../tmp/'\n",
    "CV_IDXS_PATH = PATH\n",
    "# DATA_PATH = '../input/champs-scalar-coupling/'\n",
    "# PATH = '../input/champs-processed-data-3/'\n",
    "# CV_IDXS_PATH = '../input/champs-cv-4-fold-idxs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../tmp/: ['atomic_features.csv', 'angle_out_df.csv', 'train_proc_df.csv', 'mask.csv', 'train_idxs_8_fold_cv.csv', 'edge_mask.csv', 'atom_df.csv', 'pairs_idx.csv', 'edge_df.csv', 'train_idxs_4_fold_cv.csv', 'edge_features.csv', 'dist_df.csv', 'angle_in_df.csv', 'angle_df.csv', 'val_idxs_8_fold_cv.csv', 'val_idxs_4_fold_cv.csv', 'test_proc_df.csv']\n",
      "../data/: ['scalar_coupling_contributions.csv', 'mulliken_charges.csv', 'structures.csv', 'test.csv', 'train.csv', 'magnetic_shielding_tensors.csv', 'dipole_moments.csv', 'sample_submission.csv', 'potential_energy.csv']\n"
     ]
    }
   ],
   "source": [
    "def show_csv_files(path):\n",
    "    files = os.listdir(path)\n",
    "    files = [f for f in files if f.find('.csv') != -1]\n",
    "    print(f'{path}:', files)\n",
    "show_csv_files(PATH)\n",
    "show_csv_files(DATA_PATH)\n",
    "# show_csv_files(CV_IDXS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/python36/lib/python3.6/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(PATH+'train_proc_df.csv', index_col=0)\n",
    "test_df  = pd.read_csv(PATH+'test_proc_df.csv', index_col=0)\n",
    "atom_df  = pd.read_csv(PATH+'atom_df.csv', index_col=0)\n",
    "edge_df  = pd.read_csv(PATH+'edge_df.csv', index_col=0)\n",
    "dist_df  = pd.read_csv(PATH+'dist_df.csv', index_col=0, dtype=np.float32)\n",
    "angle_in_df  = pd.read_csv(PATH+'angle_in_df.csv', index_col=0)\n",
    "angle_out_df = pd.read_csv(PATH+'angle_out_df.csv', index_col=0)\n",
    "\n",
    "train_mol_ids = pd.read_csv(CV_IDXS_PATH+'train_idxs_8_fold_cv.csv', usecols=[0, FOLD_ID], index_col=0).dropna().astype(int).iloc[:,0]\n",
    "val_mol_ids   = pd.read_csv(CV_IDXS_PATH+'val_idxs_8_fold_cv.csv', usecols=[0, FOLD_ID], index_col=0).dropna().astype(int).iloc[:,0]\n",
    "test_mol_ids  = pd.Series(test_df['molecule_id'].unique())\n",
    "\n",
    "contribs_df = pd.read_csv(DATA_PATH+'scalar_coupling_contributions.csv')\n",
    "train_df = pd.concat((train_df, contribs_df[CONTRIB_COLS]), axis=1)\n",
    "del contribs_df\n",
    "gc.collect()\n",
    "\n",
    "train_df[[TARGET_COL, 'fc']] = (train_df[[TARGET_COL, 'fc']] - SC_MEAN) / SC_STD\n",
    "train_df[CONTRIB_COLS[1:]] = train_df[CONTRIB_COLS[1:]] / SC_STD\n",
    "\n",
    "train_df['num_atoms'] = train_df[['num_C_atoms', 'num_F_atoms', 'num_H_atoms', \n",
    "                                  'num_N_atoms', 'num_O_atoms']].sum(axis=1)\n",
    "test_df['num_atoms'] = test_df[['num_C_atoms', 'num_F_atoms', 'num_H_atoms', \n",
    "                                'num_N_atoms', 'num_O_atoms']].sum(axis=1)\n",
    "train_df[['num_atoms', 'num_C_atoms', 'num_F_atoms', 'num_H_atoms', 'num_N_atoms', 'num_O_atoms']] /= 10\n",
    "test_df[['num_atoms', 'num_C_atoms', 'num_F_atoms', 'num_H_atoms', 'num_N_atoms', 'num_O_atoms']] /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atom_0</th>\n",
       "      <th>atom_1</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>cos_angle</th>\n",
       "      <th>cos_angle0</th>\n",
       "      <th>cos_angle1</th>\n",
       "      <th>diangle</th>\n",
       "      <th>dist</th>\n",
       "      <th>dist_electro_neg_adj</th>\n",
       "      <th>...</th>\n",
       "      <th>std_bond_length</th>\n",
       "      <th>total_bond_length</th>\n",
       "      <th>ave_inv_bond_length</th>\n",
       "      <th>total_inv_bond_length</th>\n",
       "      <th>ave_atom_weight</th>\n",
       "      <th>total_atom_weight</th>\n",
       "      <th>fc</th>\n",
       "      <th>sd</th>\n",
       "      <th>pso</th>\n",
       "      <th>dso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.333335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>2.593389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>4.367799</td>\n",
       "      <td>0.915793</td>\n",
       "      <td>3.663173</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.914926</td>\n",
       "      <td>0.007274</td>\n",
       "      <td>0.035961</td>\n",
       "      <td>0.007772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.333287</td>\n",
       "      <td>0.816483</td>\n",
       "      <td>0.816482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>3.922863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>4.367799</td>\n",
       "      <td>0.915793</td>\n",
       "      <td>3.663173</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.772420</td>\n",
       "      <td>0.010085</td>\n",
       "      <td>0.081668</td>\n",
       "      <td>-0.098103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.333335</td>\n",
       "      <td>0.816498</td>\n",
       "      <td>0.816496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.783147</td>\n",
       "      <td>3.922924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>4.367799</td>\n",
       "      <td>0.915793</td>\n",
       "      <td>3.663173</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.772357</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>0.081672</td>\n",
       "      <td>-0.098111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.333347</td>\n",
       "      <td>0.816502</td>\n",
       "      <td>0.816500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>3.922945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>4.367799</td>\n",
       "      <td>0.915793</td>\n",
       "      <td>3.663173</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.772340</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>0.081673</td>\n",
       "      <td>-0.098112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.333352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.091952</td>\n",
       "      <td>2.593385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>4.367799</td>\n",
       "      <td>0.915793</td>\n",
       "      <td>3.663173</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.914920</td>\n",
       "      <td>0.007274</td>\n",
       "      <td>0.035960</td>\n",
       "      <td>0.007772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  atom_0 atom_1  atom_index_0  atom_index_1  cos_angle  cos_angle0  \\\n",
       "0      H      C             1             0   0.000000    0.000000   \n",
       "1      H      H             1             2  -0.333287    0.816483   \n",
       "2      H      H             1             3  -0.333335    0.816498   \n",
       "3      H      H             1             4  -0.333347    0.816502   \n",
       "4      H      C             2             0   0.000000    0.000000   \n",
       "\n",
       "   cos_angle1  diangle      dist  dist_electro_neg_adj    ...     \\\n",
       "0   -0.333335      0.0  1.091953              2.593389    ...      \n",
       "1    0.816482      0.0  1.783120              3.922863    ...      \n",
       "2    0.816496      0.0  1.783147              3.922924    ...      \n",
       "3    0.816500      0.0  1.783157              3.922945    ...      \n",
       "4   -0.333352      0.0  1.091952              2.593385    ...      \n",
       "\n",
       "   std_bond_length  total_bond_length  ave_inv_bond_length  \\\n",
       "0         0.000003           4.367799             0.915793   \n",
       "1         0.000003           4.367799             0.915793   \n",
       "2         0.000003           4.367799             0.915793   \n",
       "3         0.000003           4.367799             0.915793   \n",
       "4         0.000003           4.367799             0.915793   \n",
       "\n",
       "   total_inv_bond_length  ave_atom_weight  total_atom_weight        fc  \\\n",
       "0               3.663173              0.2                1.0  1.914926   \n",
       "1               3.663173              0.2                1.0 -0.772420   \n",
       "2               3.663173              0.2                1.0 -0.772357   \n",
       "3               3.663173              0.2                1.0 -0.772340   \n",
       "4               3.663173              0.2                1.0  1.914920   \n",
       "\n",
       "         sd       pso       dso  \n",
       "0  0.007274  0.035961  0.007772  \n",
       "1  0.010085  0.081668 -0.098103  \n",
       "2  0.010084  0.081672 -0.098111  \n",
       "3  0.010084  0.081673 -0.098112  \n",
       "4  0.007274  0.035960  0.007772  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atom_0</th>\n",
       "      <th>atom_1</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>cos_angle</th>\n",
       "      <th>cos_angle0</th>\n",
       "      <th>cos_angle1</th>\n",
       "      <th>diangle</th>\n",
       "      <th>dist</th>\n",
       "      <th>dist_electro_neg_adj</th>\n",
       "      <th>...</th>\n",
       "      <th>type_7</th>\n",
       "      <th>inv_dist</th>\n",
       "      <th>normed_inv_dist</th>\n",
       "      <th>ave_bond_length</th>\n",
       "      <th>std_bond_length</th>\n",
       "      <th>total_bond_length</th>\n",
       "      <th>ave_inv_bond_length</th>\n",
       "      <th>total_inv_bond_length</th>\n",
       "      <th>ave_atom_weight</th>\n",
       "      <th>total_atom_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4658147</th>\n",
       "      <td>H</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.261178</td>\n",
       "      <td>5.370298</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.442247</td>\n",
       "      <td>-0.815269</td>\n",
       "      <td>1.107759</td>\n",
       "      <td>0.064573</td>\n",
       "      <td>3.323277</td>\n",
       "      <td>0.905679</td>\n",
       "      <td>2.717037</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658148</th>\n",
       "      <td>H</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.062099</td>\n",
       "      <td>2.522485</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941532</td>\n",
       "      <td>4.621731</td>\n",
       "      <td>1.107759</td>\n",
       "      <td>0.064573</td>\n",
       "      <td>3.323277</td>\n",
       "      <td>0.905679</td>\n",
       "      <td>2.717037</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658149</th>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.323277</td>\n",
       "      <td>7.311210</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300908</td>\n",
       "      <td>-2.038452</td>\n",
       "      <td>1.107759</td>\n",
       "      <td>0.064573</td>\n",
       "      <td>3.323277</td>\n",
       "      <td>0.905679</td>\n",
       "      <td>2.717037</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658150</th>\n",
       "      <td>H</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.062099</td>\n",
       "      <td>2.522485</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941532</td>\n",
       "      <td>4.621731</td>\n",
       "      <td>1.107759</td>\n",
       "      <td>0.064573</td>\n",
       "      <td>3.323277</td>\n",
       "      <td>0.905679</td>\n",
       "      <td>2.717037</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658151</th>\n",
       "      <td>H</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.261178</td>\n",
       "      <td>5.370298</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.442247</td>\n",
       "      <td>-0.815269</td>\n",
       "      <td>1.107759</td>\n",
       "      <td>0.064573</td>\n",
       "      <td>3.323277</td>\n",
       "      <td>0.905679</td>\n",
       "      <td>2.717037</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        atom_0 atom_1  atom_index_0  atom_index_1  cos_angle  cos_angle0  \\\n",
       "4658147      H      C             2             0       -1.0         1.0   \n",
       "4658148      H      C             2             1        0.0         0.0   \n",
       "4658149      H      H             2             3        0.0         1.0   \n",
       "4658150      H      C             3             0        0.0         0.0   \n",
       "4658151      H      C             3             1       -1.0         1.0   \n",
       "\n",
       "         cos_angle1  diangle      dist  dist_electro_neg_adj  \\\n",
       "4658147        -1.0      0.0  2.261178              5.370298   \n",
       "4658148        -1.0      0.0  1.062099              2.522485   \n",
       "4658149         1.0      0.0  3.323277              7.311210   \n",
       "4658150        -1.0      0.0  1.062099              2.522485   \n",
       "4658151        -1.0      0.0  2.261178              5.370298   \n",
       "\n",
       "               ...          type_7  inv_dist  normed_inv_dist  \\\n",
       "4658147        ...               0  0.442247        -0.815269   \n",
       "4658148        ...               0  0.941532         4.621731   \n",
       "4658149        ...               0  0.300908        -2.038452   \n",
       "4658150        ...               0  0.941532         4.621731   \n",
       "4658151        ...               0  0.442247        -0.815269   \n",
       "\n",
       "         ave_bond_length  std_bond_length  total_bond_length  \\\n",
       "4658147         1.107759         0.064573           3.323277   \n",
       "4658148         1.107759         0.064573           3.323277   \n",
       "4658149         1.107759         0.064573           3.323277   \n",
       "4658150         1.107759         0.064573           3.323277   \n",
       "4658151         1.107759         0.064573           3.323277   \n",
       "\n",
       "         ave_inv_bond_length  total_inv_bond_length  ave_atom_weight  \\\n",
       "4658147             0.905679               2.717037             0.35   \n",
       "4658148             0.905679               2.717037             0.35   \n",
       "4658149             0.905679               2.717037             0.35   \n",
       "4658150             0.905679               2.717037             0.35   \n",
       "4658151             0.905679               2.717037             0.35   \n",
       "\n",
       "         total_atom_weight  \n",
       "4658147                1.4  \n",
       "4658148                1.4  \n",
       "4658149                1.4  \n",
       "4658150                1.4  \n",
       "4658151                1.4  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MPNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General dense feedforward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": [
     5,
     12,
     18,
     27
    ]
   },
   "outputs": [],
   "source": [
    "def bn_init(m): pass\n",
    "#     if type(m) == nn.BatchNorm1d: \n",
    "#         nn.init.ones_(m.weight)\n",
    "#         nn.init.zeros_(m.bias)\n",
    "\n",
    "def selu_weights_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        fan_in = m.weight.size(1)\n",
    "        m.weight.data.normal_(0.0, 1.0 / math.sqrt(fan_in))\n",
    "        m.bias.fill_(0.0)\n",
    "    bn_init(m)\n",
    "\n",
    "def relu_weights_init(m): \n",
    "#     if type(m) == nn.Linear:\n",
    "#         nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "#         m.bias.data.fill_(0.0)\n",
    "    bn_init(m)\n",
    "\n",
    "def hidden_layer(n_in, n_out, batch_norm, dropout, layer_norm=False, act=None):\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(n_in, n_out))\n",
    "    if act: layers.append(act)\n",
    "    if batch_norm: layers.append(nn.BatchNorm1d(n_out))\n",
    "    if layer_norm: layers.append(nn.LayerNorm(n_out))\n",
    "    if dropout != 0: layers.append(nn.Dropout(dropout))\n",
    "    return layers\n",
    "\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input, n_output=None, layers=[], act=nn.ReLU(True), dropout=[], \n",
    "                 batch_norm=False, out_act=None, final_bn=False, layer_norm=False, \n",
    "                 final_ln=False):\n",
    "        super().__init__()\n",
    "        sizes = [n_input] + layers\n",
    "        if n_output: \n",
    "            sizes += [n_output]\n",
    "            dropout += [0.0]\n",
    "        layers_ = []\n",
    "        for i, (n_in, n_out, dr) in enumerate(zip(sizes[:-1], sizes[1:], dropout)):\n",
    "            act_ = act if i < len(layers) else out_act\n",
    "            batch_norm_ = batch_norm if i < len(layers) else final_bn\n",
    "            layer_norm_ = layer_norm if i < len(layers) else final_ln\n",
    "            layers_ += hidden_layer(n_in, n_out, batch_norm_, dr, layer_norm_, act_)      \n",
    "        self.layers = nn.Sequential(*layers_)\n",
    "        if type(act) == nn.SELU: self.layers.apply(selu_weights_init)\n",
    "        else: self.layers.apply(relu_weights_init)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "class ResFullyConnectedNet(nn.Module):\n",
    "    def __init__(self, n_input, n_output=None, layers=[], act=nn.ReLU(True), dropout=[], \n",
    "                 batch_norm=False, out_act=None, final_bn=False, layer_norm=False, \n",
    "                 final_ln=False):\n",
    "        super().__init__()\n",
    "        n_layers, sizes = len(layers), [n_input] + layers\n",
    "        if n_output: \n",
    "            sizes += [n_output]\n",
    "            dropout += [0.0]\n",
    "        assert ((n_layers - 1) % 2) == 0\n",
    "        self.n_blocks, blocks =(n_layers - 1) // 2, [], \n",
    "        self.fc1 = nn.Sequential(*hidden_layer(n_input, layers[0], batch_norm, \n",
    "                                               dropout.pop(0), layer_norm, act))\n",
    "        for i in range(self.n_blocks):\n",
    "            blocks.append(FullyConnectedNet(layers[2*i], layers[2*(i+1)], [layers[(2*i)+1]], act, \n",
    "                                            dropout[2*i:2*(i+1)], batch_norm, act, \n",
    "                                            batch_norm, layer_norm, layer_norm))\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "        self.fc_out = nn.Sequential(*hidden_layer(layers[-1], n_output, final_bn, \n",
    "                                                  0.0, final_ln, out_act))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        for i in range(self.n_blocks):\n",
    "            x_ = self.blocks[i](x)\n",
    "            x = x + x_\n",
    "        y = self.fc_out(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LSTM cell as describedi in the set2set paper (https://arxiv.org/pdf/1511.06391.pdf). Doesn't take any inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class HiddenLSTMCell(nn.Module):\n",
    "    \"\"\"Implements the LSTM cell update described in the sec 4.2 of https://arxiv.org/pdf/1511.06391.pdf.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_h_out):\n",
    "        \"\"\"This LSTM cell takes no external 'x' inputs, but has a hidden state appended with the \n",
    "        readout from a content based attention mechanism. Therefore the hidden state is of a dimension\n",
    "        that is two times the number of nodes in the set.\"\"\"\n",
    "        super().__init__()\n",
    "        self.n_h_out, self.n_h = n_h_out, n_h_out * 2 \n",
    "        self.w_h = nn.Parameter(torch.Tensor(self.n_h, n_h_out * 4))\n",
    "        self.b = nn.Parameter(torch.Tensor(n_h_out * 4))\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "                # nn.init.orthogonal_(p.data)\n",
    "            else: \n",
    "                nn.init.zeros_(p.data)\n",
    "                # initialize the forget gate bias to 1\n",
    "                p.data[self.n_h_out:self.n_h_out*2] = torch.ones(self.n_h_out)\n",
    "        \n",
    "    def forward(self, h_prev, c_prev):\n",
    "        \"\"\"Takes previuos hidden and cell states as arguments and performs a \n",
    "        single LSTM step using no external input.\n",
    "        \"\"\"\n",
    "        n_h_ = self.n_h_out # number of output hidden states\n",
    "        # batch the computations into a single matrix multiplication\n",
    "        gates = h_prev @ self.w_h + self.b\n",
    "        i_g, f_g, g, o_g = (\n",
    "            torch.sigmoid(gates[:, :n_h_]), # input\n",
    "            torch.sigmoid(gates[:, n_h_:n_h_*2]), # forget\n",
    "            torch.tanh(gates[:, n_h_*2:n_h_*3]),\n",
    "            torch.sigmoid(gates[:, n_h_*3:]), # output\n",
    "        )\n",
    "        c = f_g * c_prev + i_g * g\n",
    "        h = o_g * torch.tanh(c)\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndRNNCell(nn.Module):\n",
    "    def __init__(self, n_in, n_h, act=nn.ReLU(True), layer_norm=True, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(n_in, n_h)\n",
    "        act_ln_dr = [act]\n",
    "        if layer_norm: act_ln_dr.append(nn.LayerNorm(n_h))\n",
    "        if dropout!=0.0: act_ln_dr.append(nn.Dropout(dropout))\n",
    "        self.act_ln_dr = nn.Sequential(*act_ln_dr)\n",
    "        self.w_h = nn.Parameter(torch.Tensor(n_h))\n",
    "        nn.init.uniform_(self.w_h, a=0, b=1)\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        h = self.act_ln_dr(self.lin(x) + self.w_h * h_prev)\n",
    "        return h\n",
    "        \n",
    "class IndRNN(nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_layers, layer_norm=True, dropout=[]):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        if len(dropout)==0: dropout = n_layers * [0.0]\n",
    "        assert len(dropout) == n_layers\n",
    "        layers = []\n",
    "        for i, dr in enumerate(dropout):\n",
    "            n_in = n_x if 1==0 else n_h\n",
    "            layers.append(IndRNNCell(n_in, n_h, layer_norm=layer_norm, dropout=dr))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "            \n",
    "    def forward(self, x, h_prev):\n",
    "        h, hs = x, []\n",
    "        for i in range(self.n_layers):\n",
    "            h = self.layers[i](h, h_prev[i])\n",
    "            hs.append(h)\n",
    "        return h, torch.cat(hs, dim=0)\n",
    "        \n",
    "class ResIndRNN(nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_blocks, layer_norm=True, dropout=[]):\n",
    "        super().__init__()\n",
    "        self.n_blocks = n_blocks\n",
    "        if len(dropout)==0: dropout = n_blocks * [0.0]\n",
    "        assert len(dropout) == n_blocks\n",
    "        blocks = []\n",
    "        for i, dr in enumerate(dropout):\n",
    "            n_in = n_x if 1==0 else n_h\n",
    "            blocks.append(IndRNN(n_in, n_h, n_layers=2, layer_norm=layer_norm, dropout=2*[dr]))\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "            \n",
    "    def forward(self, x, h_prev):\n",
    "        hs = []\n",
    "        for i in range(self.n_blocks):\n",
    "            h, hs_ = self.blocks[i](x, h_prev[(i*2):((i+1)*2)])\n",
    "            x = h + x\n",
    "            hs.append(hs_)\n",
    "        return x, torch.cat(hs, dim=0)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set2set module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "code_folding": [
     0,
     6,
     11,
     41
    ]
   },
   "outputs": [],
   "source": [
    "def scatter_sum(src, idx, num):\n",
    "    sz = num, src.size(1)\n",
    "    exp_idx = idx[:,None].repeat(1, sz[1])\n",
    "    out = torch.zeros(sz, dtype=src.dtype, device=src.device)\n",
    "    return out.scatter_add(0, exp_idx, src)\n",
    "\n",
    "def scatter_mean(src, idx, num):\n",
    "    return scatter_sum(src, idx, num) / scatter_sum(torch.ones_like(src), idx, num).clamp(1.0)\n",
    "\n",
    "def softmax(x, idx, num=None):\n",
    "    x = x.exp()\n",
    "    x = x / (scatter_sum(x, idx, num=num)[idx] + 1e-16)\n",
    "    return x\n",
    "\n",
    "class SumReadout(nn.Module):\n",
    "    def __init__(self): super().__init__()\n",
    "    def forward(self, x, node_idx): return scatter_sum(x, node_idx, num=node_idx.max().item()+1)\n",
    "    \n",
    "class MeanReadout(nn.Module):\n",
    "    def __init__(self): super().__init__()\n",
    "    def forward(self, x, node_idx): return scatter_mean(x, node_idx, num=node_idx.max().item()+1)\n",
    "\n",
    "class Set2SetIndRNN(nn.Module):\n",
    "    def __init__(self, n_set_in, proc_steps, n_blocks=3):\n",
    "        super().__init__()\n",
    "        self.proc_steps = proc_steps\n",
    "        self.gru = ResIndRNN(n_set_in, n_set_in, n_blocks, layer_norm=True, dropout=[])\n",
    "        self.init_q = nn.Parameter(torch.zeros(2 * n_blocks, 1, n_set_in))\n",
    "        self.init_r = nn.Parameter(torch.zeros(1, n_set_in))\n",
    "\n",
    "    def forward(self, x, node_idx):\n",
    "        \"\"\"\n",
    "        x - input tensor of shape (batch_size * n_nodes, in_channels).\n",
    "        - node_idx: tensor of shape (batch_size * n_nodes) mapping each\n",
    "            node to its corresponding index in the batch.\n",
    "        \"\"\"\n",
    "        batch_size = node_idx.max().item() + 1\n",
    "        qs = self.init_q.expand(-1, batch_size, -1).contiguous()\n",
    "        r = self.init_r.expand(batch_size, -1).contiguous()\n",
    "        for i in range(self.proc_steps):\n",
    "            q, qs = self.gru(r, qs)\n",
    "            e = (x * q[node_idx]).sum(dim=-1, keepdim=True)\n",
    "            a = softmax(e, node_idx, num=batch_size)\n",
    "            r = scatter_sum(a * x, node_idx, num=batch_size) # sum 'a*x' over nodes \n",
    "        return torch.cat([q, r], dim=-1) #q_star\n",
    "    \n",
    "    \n",
    "class Set2SetGRU(nn.Module):\n",
    "    def __init__(self, n_set_in, proc_steps):\n",
    "        super().__init__()\n",
    "        self.proc_steps = proc_steps\n",
    "        self.gru = nn.GRUCell(n_set_in, n_set_in)\n",
    "        self.init_q = nn.Parameter(torch.zeros(1, n_set_in))\n",
    "        self.init_r = nn.Parameter(torch.zeros(1, n_set_in))\n",
    "\n",
    "    def forward(self, x, node_idx):\n",
    "        \"\"\"\n",
    "        x - input tensor of shape (batch_size * n_nodes, in_channels).\n",
    "        - node_idx: tensor of shape (batch_size * n_nodes) mapping each\n",
    "            node to its corresponding index in the batch.\n",
    "        \"\"\"\n",
    "        batch_size = node_idx.max().item() + 1\n",
    "        q = self.init_q.expand(batch_size, -1).contiguous()\n",
    "        r = self.init_r.expand(batch_size, -1).contiguous()\n",
    "        for i in range(self.proc_steps):\n",
    "            q = self.gru(r, q)\n",
    "            e = (x * q[node_idx]).sum(dim=-1, keepdim=True)\n",
    "            a = softmax(e, node_idx, num=batch_size)\n",
    "            r = scatter_sum(a * x, node_idx, num=batch_size) # sum 'a*x' over nodes \n",
    "        return torch.cat([q, r], dim=-1) #q_star\n",
    "\n",
    "class Set2SetLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted from: https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric\\\n",
    "        /nn/glob/set2set.html#Set2Set\n",
    "    \"\"\"\n",
    "    def __init__(self, n_set_in, proc_steps):\n",
    "        super().__init__()\n",
    "        self.n_set_in, n_set_out = n_set_in, 2 * n_set_in\n",
    "        self.proc_steps = proc_steps\n",
    "        self.lstm = HiddenLSTMCell(n_set_in)\n",
    "        self.init_q_star = nn.Parameter(torch.zeros(1, n_set_out))\n",
    "        self.init_h = nn.Parameter(torch.zeros(1, n_set_in))\n",
    "\n",
    "    def forward(self, x, node_idx):\n",
    "        \"\"\"\n",
    "        x - input tensor of shape (batch_size * n_nodes, in_channels).\n",
    "        - node_idx: tensor of shape (batch_size * n_nodes) mapping each\n",
    "            node to its corresponding index in the batch.\n",
    "        \"\"\"\n",
    "        batch_size = node_idx.max().item() + 1\n",
    "        h = self.init_h.expand(batch_size, -1).contiguous()\n",
    "        q_star = self.init_q_star.expand(batch_size, -1).contiguous()\n",
    "        for i in range(self.proc_steps):\n",
    "            q, h = self.lstm(q_star, h)\n",
    "            e = (x * q[node_idx]).sum(dim=-1, keepdim=True)\n",
    "            a = softmax(e, node_idx, num=batch_size)\n",
    "            r = scatter_sum(a * x, node_idx, num=batch_size) # sum 'a*x' over nodes \n",
    "            q_star = torch.cat([q, r], dim=-1)\n",
    "        return q_star\n",
    "    \n",
    "class GaussAtt(nn.Module):\n",
    "    N_TYPES = 8\n",
    "    PAD_VAL = 999\n",
    "    \n",
    "    def __init__(self, dim=1, type_specific=True): \n",
    "        super().__init__()\n",
    "        self.dim, self.type_specific = dim, type_specific\n",
    "        if type_specific: self.log_prec = nn.Parameter(torch.zeros(self.N_TYPES, dim))\n",
    "        else: self.log_prec = nn.Parameter(torch.zeros(dim))\n",
    "    \n",
    "    def forward(self, x, sc_pairs_idx, sc_types, dists, sc_node_idx, sc_idx2):\n",
    "        q0 = self.apply_gauss_att(x, sc_pairs_idx[:int(sc_pairs_idx.size(0)/2),0], dists, sc_node_idx, sc_idx2, sc_types)\n",
    "        q1 = self.apply_gauss_att(x, sc_pairs_idx[:int(sc_pairs_idx.size(0)/2),1], dists, sc_node_idx, sc_idx2, sc_types)\n",
    "        return torch.cat([q0, q1], dim=-1)\n",
    "        \n",
    "    def apply_gauss_att(self, x, sc_pairs_idx, dists, sc_node_idx, sc_idx2, sc_types):\n",
    "        if self.type_specific: log_prec = self.log_prec[sc_types].unsqueeze(1)\n",
    "        else: log_prec = self.log_prec\n",
    "        dists_ = dists.index_select(0, sc_pairs_idx).unsqueeze(-1).expand(-1, -1, self.dim)\n",
    "        pdf = torch.exp(-0.5 * (torch.exp(log_prec) * dists_ ** 2))\n",
    "        att_mask = pdf / pdf.sum(dim=1, keepdim=True)\n",
    "        att_x =  x.index_select(0, sc_node_idx) * att_mask[dists_!=self.PAD_VAL].view(-1, self.dim)\n",
    "        return scatter_sum(att_x, sc_idx2, num=sc_idx2.max().item()+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge network message function as described in the MPNN paper (https://arxiv.org/pdf/1704.01212.pdf). Adds in seperate edge network to allow messages to flow along scalar coupling edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ENNMessage(nn.Module):\n",
    "    def __init__(self, n_h, n_e, n_sc_h, enn_args={}, ann_args={}):\n",
    "        super().__init__()\n",
    "        self.n_h = n_h\n",
    "        self.enn = FullyConnectedNet(n_e, n_h**2, **enn_args)\n",
    "        self.sc_enn = FullyConnectedNet(n_sc_h, n_h**2, **enn_args)\n",
    "        self.ann = FullyConnectedNet(1, n_h, **ann_args)\n",
    "        self.m_bias = nn.Parameter(torch.Tensor(n_h)) # bias for the message function\n",
    "        self.weight_inits()\n",
    "        \n",
    "    def weight_inits(self):\n",
    "        nn.init.zeros_(self.m_bias)\n",
    "    \n",
    "    def forward(self, h, e, sc_h, pairs_idx, sc_pairs_idx, angles, angles_idx, t=0):\n",
    "        \"\"\"\n",
    "        Compute message vector m_t given the previuos hidden state\n",
    "        h_t-1 and edge features e.\n",
    "        - h: tensor of hidden states of shape (batch_size * n_nodes, n_h)\n",
    "        - e: tensor of edge features of shape (batch_size * n_edges, n_e).\n",
    "        - sc_h: tensor of scalar coupling edge hidden states of shape \n",
    "            (batch_size * n_sc, n_sc_e).\n",
    "        - pairs_idx: tensor of shape (batch_size * n_edges, 2) mapping atom \n",
    "            indexes (first column) to the other atom indexes they form a \n",
    "            bond with (second column). Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_pairs_idx: tensor of shape (batch_size * n_sc, 2) containing atom \n",
    "            indices of the atoms for which the scalar coupling constant\n",
    "            need to be predicted. Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - t: update iteration. \n",
    "        \"\"\"\n",
    "        # compute 'A(e)' and angle attention masks\n",
    "        if t==0: \n",
    "            self.a_mat = self.get_a_mat(self.enn(e))\n",
    "            self.a_mat = torch.cat((self.a_mat, self.a_mat))\n",
    "            self.a_sc_mat = self.get_a_mat(self.sc_enn(sc_h))\n",
    "            self.att = self.ann(angles.view(-1,1))\n",
    "            \n",
    "        # compute 'm_{i} = sum_{j in N(i)}(A_{ij}h_{j})' for all nodes 'i'\n",
    "        m = self.add_message(torch.zeros_like(h), self.a_mat, h, pairs_idx, True, angles_idx)\n",
    "        m = self.add_message(m, self.a_sc_mat, h, sc_pairs_idx)\n",
    "        \n",
    "        # add message bias\n",
    "        m = m + self.m_bias\n",
    "        return m # apply optional batch norm\n",
    "    \n",
    "    def get_a_mat(self, a_vect):\n",
    "        return a_vect.view(-1, self.n_h, self.n_h) / (self.n_h ** .5)\n",
    "    \n",
    "    def add_message(self, m, a, h, pairs_idx, use_att=False, angles_idx=None):\n",
    "        # transform 'pairs_idx' and 'a' to make messages go both in to and out of all nodes\n",
    "        # in_out_idx = torch.cat((pairs_idx, pairs_idx[:, [1, 0]]))\n",
    "        # a_ = torch.cat((a, a)) \n",
    "        \n",
    "        # select the 'h_{j}' feeding into the 'm_{i}'\n",
    "        h_in = h.index_select(0, pairs_idx[:,1])\n",
    "        \n",
    "        # do the matrix multiplication 'A_{ij}h_{j}'\n",
    "        ah = (h_in.unsqueeze(1) @ a).squeeze(1)\n",
    "        \n",
    "        # apply atttention\n",
    "        if use_att:\n",
    "            ave_att = scatter_mean(self.att, angles_idx, num=pairs_idx.size(0))\n",
    "            ah = ave_att * ah\n",
    "        \n",
    "        # Sum up all 'A_{ij}h_{j}' per node 'i'\n",
    "        return m.scatter_add(0, pairs_idx[:,0,None].repeat(1, self.n_h), ah)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GRU update function as described in the MPNN paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class GRUUpdate(nn.Module):\n",
    "    def __init__(self, n_x, n_h):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRUCell(n_x, n_h)\n",
    "        \n",
    "    def forward(self, m, h_prev):\n",
    "        \"\"\"\n",
    "        Update hidden state h.\n",
    "        - h_prev is vector of hidden states of shape (batch_size * n_nodes, n_h)\n",
    "        - m is vector of messages of shape (batch_size * n_nodes, n_h)\n",
    "        \"\"\"\n",
    "        return self.gru(m, h_prev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom readout network following th set2set processing stage. Allows some final specialization/fine-tuning for each scalar coupling type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contrib_net(n_in, n_h, act, dropout=0.0, layer_norm=True):\n",
    "    layers = hidden_layer(n_in, n_h, False, dropout, layer_norm, act)\n",
    "    layers += hidden_layer(n_h, 1, False, 0.0) # output layer\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ContribsNet(nn.Module):\n",
    "    N_CONTRIBS = 5\n",
    "    CONTIB_SCALES = [1, 250, 45, 35, 500]\n",
    "    \n",
    "    def __init__(self, n_in, n_h, act, dropout=0.0, layer_norm=True):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            create_contrib_net(n_in, n_h, act, dropout, layer_norm) \n",
    "            for _ in range(self.N_CONTRIBS)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ys = torch.cat([b(x) / s for b, s in zip(self.blocks, self.CONTIB_SCALES)], dim=-1)\n",
    "        return torch.cat([ys[:,:-1], ys.sum(dim=-1, keepdim=True)], dim=-1)\n",
    "\n",
    "class MyCustomHead(nn.Module):\n",
    "    N_TYPES = 8\n",
    "    \n",
    "    def __init__(self, n_input, n_h_contribs, pre_layers=[], post_layers=[], \n",
    "                 act=nn.ReLU(True), dropout=[], norm=False):\n",
    "        super().__init__()\n",
    "        n_pre_layers = len(pre_layers)\n",
    "        self.preproc = FullyConnectedNet(n_input, None, pre_layers, act, \n",
    "                                         dropout[:n_pre_layers], batch_norm=norm)\n",
    "        self.types_net = nn.ModuleList([\n",
    "            FullyConnectedNet(pre_layers[-1], None, post_layers, act, dropout[n_pre_layers:-1], layer_norm=norm)\n",
    "            for _ in range(self.N_TYPES)\n",
    "        ])\n",
    "        self.contribs_net = ContribsNet(post_layers[-1], n_h_contribs, act, dropout[-1], layer_norm=norm)\n",
    "        \n",
    "    def forward(self, x, sc_types):\n",
    "        x_ = self.preproc(x)\n",
    "        x_types = torch.zeros_like(x)\n",
    "        for i in range(self.N_TYPES):\n",
    "            if torch.any(sc_types==i): \n",
    "                x_types[sc_types==i] = self.types_net[i](x_[sc_types==i])\n",
    "        x = x + x_types \n",
    "        y = self.contribs_net(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines all the the components of the readout function described in the MPNN network using set2set processing and the scalar coupling type customized head. Also adds in some skip connections to final node states and scalar coupling input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Readout(nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_sc_m, proc_steps=10, readout_type='Set2SetGRU', net_args={}):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(n_h + n_x, n_h)\n",
    "        if readout_type=='Sum': self.proc = SumReadout()\n",
    "        if readout_type=='Mean': self.proc = MeanReadout()\n",
    "        if readout_type=='Set2SetGRU': self.proc = Set2SetGRU(n_h, proc_steps)\n",
    "        if readout_type=='Set2SetLSTM': self.proc = Set2SetLSTM(n_h, proc_steps)\n",
    "        if readout_type=='Set2SetIndRNN': self.proc = Set2SetIndRNN(n_h, proc_steps)\n",
    "        if readout_type=='GaussAtt': self.proc = GaussAtt(dim=1, type_specific=True)\n",
    "        n_readout = n_h if ((readout_type=='Sum') or (readout_type=='Mean')) else 2 * n_h \n",
    "        self.write_head = MyCustomHead(n_readout + (4 * n_h) + n_sc_m, **net_args)\n",
    "    \n",
    "    def forward(self, h, x, sc_h, sc_m, node_idx, sc_idx, sc_pairs_idx, sc_types, dists, \n",
    "                sc_node_idx, sc_idx2):\n",
    "        \"\"\"\n",
    "        Make prediction.\n",
    "        - h is vector of hidden states of shape (batch_size * n_nodes, n_h).\n",
    "        - x is vector of input features of shape (batch_size * n_nodes, n_x).\n",
    "        - sc_m: tensor of scalar coupling molecule level features of shape \n",
    "            (batch_size * n_sc, n_sc_m).\n",
    "        - node_idx: tensor of shape (batch_size * n_nodes) mapping each\n",
    "            node to its corresponding index in the batch.\n",
    "        - sc_idx: tensor of shape (batch_size * n_sc) mapping each\n",
    "            scalar coupling constant to its corresponding index in the batch.\n",
    "        - sc_pairs_idx: tensor of shape (batch_size * n_sc, 2) containing atom \n",
    "            indices of the atoms for which the scalar coupling constant\n",
    "            need to be predicted. Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_types: tensor of shape (batch_size * n_sc) containing the scalar \n",
    "            coupling type of each observation. \n",
    "        \"\"\"\n",
    "        m = self.proj(torch.cat([h, x], dim=1))\n",
    "        if isinstance(self.proc, GaussAtt): \n",
    "            q = self.proc(m, sc_pairs_idx, sc_types, dists, sc_node_idx, sc_idx2)\n",
    "        else: \n",
    "            q = self.proc(m, node_idx).index_select(0, sc_idx)\n",
    "        \n",
    "        # introduce skip connection to final node states of scalar coupling atoms\n",
    "        inp = torch.cat([\n",
    "            q,\n",
    "            h.index_select(0, sc_pairs_idx[:int(sc_pairs_idx.size(0)/2),0]),\n",
    "            h.index_select(0, sc_pairs_idx[:int(sc_pairs_idx.size(0)/2),1]),\n",
    "            sc_h[:int(sc_pairs_idx.size(0)/2)],\n",
    "            sc_h[int(sc_pairs_idx.size(0)/2):],\n",
    "            sc_m\n",
    "        ], dim=-1)\n",
    "        y = self.write_head(inp, sc_types)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines the edge-network message (M), GRU update (U) and set2set readout (R) functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNN(nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_e, n_sc_e, n_sc_m, update_steps=3, proc_steps=10, \n",
    "                 readout_type='Set2SetGRU', preproc_net_args={}, enn_args={}, ann_args={}, \n",
    "                 R_net_args={}):\n",
    "        super().__init__()\n",
    "        self.preproc_net = FullyConnectedNet(n_x, n_h, **preproc_net_args)\n",
    "        self.sc_preproc_net = FullyConnectedNet(n_sc_e, n_h, **preproc_net_args)\n",
    "        self.M = ENNMessage(n_h, n_e, n_h, enn_args, ann_args)\n",
    "        self.U = GRUUpdate(n_h, n_h)\n",
    "        self.sc_U = GRUUpdate(2*n_h, n_h)\n",
    "        self.R = Readout(n_x, n_h, n_sc_m, proc_steps, readout_type, R_net_args)\n",
    "        self.update_steps = update_steps\n",
    "        \n",
    "    def forward(self, x, e, sc_e, sc_m, node_idx, pairs_idx, sc_idx, sc_pairs_idx, \n",
    "                dists, sc_node_idx, sc_idx2, angles, angles_idx, sc_types):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: tensor of node features of shape (batch_size * n_nodes, n_x).\n",
    "        - e: tensor of edge features of shape (batch_size * n_edges, n_e).\n",
    "        - sc_e: tensor of scalar coupling edge features of shape \n",
    "            (batch_size * n_sc, n_sc_e).\n",
    "        - sc_m: tensor of scalar coupling molecule level features of shape \n",
    "            (batch_size * n_sc, n_sc_m).\n",
    "        - node_idx: tensor of shape (batch_size * n_nodes) mapping each\n",
    "            node to its corresponding index in the batch.\n",
    "        - pairs_idx: tensor of shape (batch_size * n_edges, 2) mapping atom \n",
    "            indexes (first column) to the other atom indexes they form a \n",
    "            bond with (second column). Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_idx: tensor of shape (batch_size * n_sc) mapping each\n",
    "            scalar coupling constant to its corresponding index in the batch.\n",
    "        - sc_pairs_idx: tensor of shape (batch_size * n_sc, 2) containing atom \n",
    "            indices of the atoms for which the scalar coupling constant\n",
    "            need to be predicted. Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_types: tensor of shape (batch_size * n_sc) containing the scalar \n",
    "            coupling type of each observation. \n",
    "        \"\"\"\n",
    "        h = self.preproc_net(x)\n",
    "        sc_h = self.sc_preproc_net(sc_e)\n",
    "        for t in range(self.update_steps):\n",
    "            m = self.M(h, e, sc_h, pairs_idx, sc_pairs_idx, angles, angles_idx, t)\n",
    "            h = self.U(m, h)\n",
    "            sc_x = torch.cat([h.index_select(0, sc_pairs_idx[:,0]), \n",
    "                              h.index_select(0, sc_pairs_idx[:,1])], dim=-1)\n",
    "            sc_h = self.sc_U(sc_x, sc_h)\n",
    "        y = self.R(h, x, sc_h, sc_m, node_idx, sc_idx, sc_pairs_idx, sc_types, dists,\n",
    "                   sc_node_idx, sc_idx2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=100):\n",
    "    # python RNG\n",
    "    random.seed(seed)\n",
    "\n",
    "    # pytorch RNGs\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # numpy RNG\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(100)\n",
    "# mol_ids = train_df['molecule_id'].unique()\n",
    "# n_obs = len(mol_ids)\n",
    "# split = int(n_obs*0.75)\n",
    "# mol_ids_ = np.random.choice(mol_ids, size=n_obs, replace=False)\n",
    "# train_mol_ids, val_mol_ids = pd.Series(mol_ids_[:split]), pd.Series(mol_ids_[split:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def scale_features(df, features, train_mol_ids):\n",
    "    idx = df['molecule_id'].isin(train_mol_ids)\n",
    "    return df.loc[idx, features].mean(), df.loc[idx, features].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "code_folding": [
     0,
     4,
     7
    ]
   },
   "outputs": [],
   "source": [
    "if any(train_df[SC_FEATS_TO_SCALE].mean().abs()>0.1) or any((train_df[SC_FEATS_TO_SCALE].std()-1.0).abs()>0.1):\n",
    "    sc_feat_means, sc_feat_stds = scale_features(train_df, SC_FEATS_TO_SCALE, train_mol_ids)\n",
    "    train_df[SC_FEATS_TO_SCALE] = (train_df[SC_FEATS_TO_SCALE] - sc_feat_means) / sc_feat_stds\n",
    "    test_df[SC_FEATS_TO_SCALE] = (test_df[SC_FEATS_TO_SCALE] - sc_feat_means) / sc_feat_stds\n",
    "if any(atom_df[ATOM_FEATS_TO_SCALE].mean().abs()>0.1) or any((atom_df[ATOM_FEATS_TO_SCALE].std()-1.0).abs()>0.1):\n",
    "    atom_feat_means, atom_feat_stds = scale_features(atom_df, ATOM_FEATS_TO_SCALE, train_mol_ids)\n",
    "    atom_df[ATOM_FEATS_TO_SCALE] = (atom_df[ATOM_FEATS_TO_SCALE] - atom_feat_means) / atom_feat_stds\n",
    "if any(edge_df[EDGE_FEATS_TO_SCALE].mean().abs()>0.1) or any((edge_df[EDGE_FEATS_TO_SCALE].std()-1.0).abs()>0.1):\n",
    "    edge_feat_means, edge_feat_stds = scale_features(edge_df, EDGE_FEATS_TO_SCALE, train_mol_ids)\n",
    "    edge_df[EDGE_FEATS_TO_SCALE] = (edge_df[EDGE_FEATS_TO_SCALE] - edge_feat_means) / edge_feat_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_mol_sc = train_df.groupby('molecule_id')\n",
    "test_gb_mol_sc = test_df.groupby('molecule_id')\n",
    "gb_mol_atom = atom_df.groupby('molecule_id')\n",
    "gb_mol_edge = edge_df.groupby('molecule_id')\n",
    "gb_mol_dist = dist_df.groupby('molecule_id')\n",
    "gb_mol_angle_in = angle_in_df.groupby('molecule_id')\n",
    "gb_mol_angle_out = angle_out_df.groupby('molecule_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the pytorch dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "code_folding": [
     20
    ]
   },
   "outputs": [],
   "source": [
    "def get_existing_group(gb, i):\n",
    "    try: group_df = gb.get_group(i)\n",
    "    except KeyError: group_df = None\n",
    "    return group_df\n",
    "\n",
    "class MoleculeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, mol_ids, gb_mol_sc, gb_mol_atom, gb_mol_edge, gb_mol_dist, \n",
    "                 gb_mol_angle_in, gb_mol_angle_out):\n",
    "        self.n = len(mol_ids)\n",
    "        self.mol_ids = mol_ids\n",
    "        self.gb_mol_sc = gb_mol_sc\n",
    "        self.gb_mol_atom = gb_mol_atom\n",
    "        self.gb_mol_edge = gb_mol_edge\n",
    "        self.gb_mol_dist = gb_mol_dist\n",
    "        self.gb_mol_angle_in = gb_mol_angle_in\n",
    "        self.gb_mol_angle_out = gb_mol_angle_out\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.gb_mol_sc.get_group(self.mol_ids[idx]),\n",
    "                self.gb_mol_atom.get_group(self.mol_ids[idx]), \n",
    "                self.gb_mol_edge.get_group(self.mol_ids[idx]), \n",
    "                self.gb_mol_dist.get_group(self.mol_ids[idx]), \n",
    "                self.gb_mol_angle_in.get_group(self.mol_ids[idx]), \n",
    "                get_existing_group(self.gb_mol_angle_out, self.mol_ids[idx]))\n",
    "\n",
    "def np_lst_to_torch(arr_lst, dtype=torch.float):\n",
    "    return torch.from_numpy(np.ascontiguousarray(np.concatenate(arr_lst))).type(dtype)\n",
    "\n",
    "def collate_fn(batch, test=False):\n",
    "    batch_size, n_atom_sum, n_sc_sum, n_pairs_sum = len(batch), 0, 0, 0\n",
    "    x, e, sc_e, sc_m, dists, angles_in, angles_out = [], [], [], [], [], [], []\n",
    "    sc_types, sc_vals = [], []\n",
    "    node_idx, pairs_idx, sc_pairs_idx, sc_idx = [], [], [], []\n",
    "    sc_node_idx, sc_idx2, angles_in_idx, angles_out_idx = [], [], [], []\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        sc_df, atom_df, edge_df, dist_df, angle_in_df, angle_out_df = batch[b]\n",
    "        n_atoms, n_sc, n_pairs = len(atom_df), len(sc_df), len(edge_df)\n",
    "        dists_ = dist_df.iloc[:,:-1].values\n",
    "        dists_[:,n_atoms:] = 999\n",
    "        \n",
    "        x.append(atom_df[ATOM_FEATS].values)\n",
    "        e.append(edge_df[EDGE_FEATS].values)\n",
    "        sc_e.append(sc_df[SC_EDGE_FEATS].values)\n",
    "        sc_m.append(sc_df[SC_MOL_FEATS].values)\n",
    "        sc_types.append(sc_df['type'].values)\n",
    "        if not test: sc_vals.append(sc_df[CONTRIB_COLS+[TARGET_COL]].values)\n",
    "        dists.append(dists_)\n",
    "        angles_in.append(angle_in_df['cos_angle'].values)\n",
    "        if angle_out_df is not None: angles_out.append(angle_out_df['cos_angle'].values)\n",
    "        \n",
    "        node_idx.append(np.repeat(b, n_atoms))\n",
    "        sc_idx.append(np.repeat(b, n_sc))\n",
    "        pairs_idx.append(edge_df[['idx_0', 'idx_1']].values + n_atom_sum)\n",
    "        sc_pairs_idx.append(sc_df[['atom_index_0', 'atom_index_1']].values + n_atom_sum)\n",
    "        angles_in_idx.append(angle_in_df['p_idx'].values + n_pairs_sum)\n",
    "        if angle_out_df is not None: angles_out_idx.append(angle_out_df['p_idx'].values + n_pairs_sum)\n",
    "        sc_node_idx.append(n_sc * list(range(n_atom_sum, n_atom_sum + n_atoms)))\n",
    "        for i in range(n_sc): sc_idx2.append(n_atoms*[i+n_sc_sum])\n",
    "        \n",
    "        n_atom_sum += n_atoms\n",
    "        n_sc_sum += n_sc\n",
    "        n_pairs_sum += n_pairs\n",
    "        \n",
    "    x, e = np_lst_to_torch(x), np_lst_to_torch(e), \n",
    "    sc_e, sc_m = np_lst_to_torch(sc_e), np_lst_to_torch(sc_m)\n",
    "    sc_e = torch.cat((sc_e, sc_e))\n",
    "    if not test: sc_vals = np_lst_to_torch(sc_vals)\n",
    "    else: sc_vals = torch.tensor([0] * len(sc_types))\n",
    "    sc_types = np_lst_to_torch(sc_types, torch.long)\n",
    "    node_idx = np_lst_to_torch(node_idx, torch.long)\n",
    "    sc_idx = np_lst_to_torch(sc_idx, torch.long)\n",
    "    pairs_idx = np_lst_to_torch(pairs_idx, torch.long)\n",
    "    pairs_idx = torch.cat((pairs_idx, pairs_idx[:, [1, 0]]))\n",
    "    sc_pairs_idx = np_lst_to_torch(sc_pairs_idx, torch.long)\n",
    "    sc_pairs_idx = torch.cat((sc_pairs_idx, sc_pairs_idx[:, [1, 0]]))\n",
    "    angles_in_idx = np_lst_to_torch(angles_in_idx, torch.long)\n",
    "    angles_out_idx = np_lst_to_torch(angles_out_idx, torch.long) + n_pairs_sum\n",
    "    angles_idx = torch.cat((angles_in_idx, angles_out_idx))\n",
    "    sc_node_idx = np_lst_to_torch(sc_node_idx, torch.long)\n",
    "    sc_idx2 = np_lst_to_torch(sc_idx2, torch.long)\n",
    "    dists = np_lst_to_torch(dists)\n",
    "    angles = np_lst_to_torch(angles_in + angles_out)\n",
    "    \n",
    "    return (x, e, sc_e, sc_m, node_idx, pairs_idx, sc_idx, sc_pairs_idx, \n",
    "            dists, sc_node_idx, sc_idx2, angles, angles_idx, sc_types), sc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(100)\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MoleculeDataset(train_mol_ids, gb_mol_sc, gb_mol_atom, gb_mol_edge, gb_mol_dist, gb_mol_angle_in, gb_mol_angle_out)\n",
    "val_ds   = MoleculeDataset(val_mol_ids, gb_mol_sc, gb_mol_atom, gb_mol_edge, gb_mol_dist, gb_mol_angle_in, gb_mol_angle_out)\n",
    "test_ds  = MoleculeDataset(test_mol_ids, test_gb_mol_sc, gb_mol_atom, gb_mol_edge, gb_mol_dist, gb_mol_angle_in, gb_mol_angle_out)\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=8)\n",
    "val_dl   = DataLoader(val_ds, batch_size, num_workers=8)\n",
    "test_dl  = DeviceDataLoader.create(test_ds, batch_size, num_workers=8, collate_fn=partial(collate_fn, test=True))\n",
    "db = DataBunch(train_dl, val_dl, collate_fn=collate_fn)\n",
    "db.test_dl = test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([382, 21])\n",
      "torch.Size([394, 8])\n",
      "torch.Size([2420, 16])\n",
      "torch.Size([1210, 25])\n",
      "torch.Size([382])\n",
      "torch.Size([788, 2])\n",
      "torch.Size([1210])\n",
      "torch.Size([2420, 2])\n",
      "torch.Size([382, 29])\n",
      "torch.Size([24194])\n",
      "torch.Size([24194])\n",
      "torch.Size([1496])\n",
      "torch.Size([1496])\n",
      "torch.Size([1210])\n",
      "torch.Size([1210, 5])\n"
     ]
    }
   ],
   "source": [
    "for el in batch[0]: print(el.size())\n",
    "print(batch[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " tensor([[ 0.0000,  1.0000,  0.0000,  ...,  0.8505, -2.6217, -0.3045],\n",
      "        [ 0.0000,  1.0000,  0.0000,  ...,  0.7247, -0.1754, -0.3045],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.6925,  0.4362,  3.2838],\n",
      "        ...,\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.9125,  0.4362, -0.3045],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.9126,  0.4362, -0.3045],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.9170,  0.4362, -0.3045]])\n",
      "e:\n",
      " tensor([[ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  1.2334,  1.1838],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000, -0.8915, -0.9193],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000, -0.8735, -0.9015],\n",
      "        ...,\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000, -0.8706, -0.8137],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000, -0.8699, -0.8130],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000, -0.8964, -0.8407]])\n",
      "sc_e:\n",
      " tensor([[ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.3350],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.3590,  0.7562, -0.7372],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.3811, -0.8274],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.8904, -0.1125],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.3403,  0.7475, -0.0595],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.3374]])\n",
      "sc_m:\n",
      " tensor([[ 1.0000,  0.0000,  0.0000,  ...,  0.1355,  0.2689, -0.5096],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.1355,  0.2689, -0.5096],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.1355,  0.2689, -0.5096],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.4986, -0.6563, -0.5096],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.4986, -0.6563, -0.5096],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ..., -0.4986, -0.6563, -0.5096]])\n",
      "node_idx:\n",
      " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,\n",
      "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "        15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "        17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "        18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "        19, 19, 19, 19])\n",
      "pairs_idx:\n",
      " tensor([[  0,   1],\n",
      "        [  0,   9],\n",
      "        [  0,  10],\n",
      "        ...,\n",
      "        [380, 368],\n",
      "        [379, 368],\n",
      "        [381, 368]])\n",
      "sc_idx:\n",
      " tensor([ 0,  0,  0,  ..., 19, 19, 19])\n",
      "sc_pairs_idx:\n",
      " tensor([[  9,   0],\n",
      "        [  9,   1],\n",
      "        [  9,   8],\n",
      "        ...,\n",
      "        [366, 381],\n",
      "        [367, 381],\n",
      "        [368, 381]])\n",
      "dists:\n",
      " tensor([[  0.0000,   1.5166,   2.4504,  ..., 999.0000, 999.0000, 999.0000],\n",
      "        [  1.5166,   0.0000,   1.4511,  ..., 999.0000, 999.0000, 999.0000],\n",
      "        [  2.4504,   1.4511,   0.0000,  ..., 999.0000, 999.0000, 999.0000],\n",
      "        ...,\n",
      "        [  7.3542,   6.6395,   5.8141,  ..., 999.0000, 999.0000, 999.0000],\n",
      "        [  6.9260,   6.4147,   5.4238,  ..., 999.0000, 999.0000, 999.0000],\n",
      "        [  7.5899,   7.2147,   6.4965,  ..., 999.0000, 999.0000, 999.0000]])\n",
      "sc_node_idx:\n",
      " tensor([  0,   1,   2,  ..., 379, 380, 381])\n",
      "sc_idx2:\n",
      " tensor([   0,    0,    0,  ..., 1209, 1209, 1209])\n",
      "angles:\n",
      " tensor([-0.3590, -0.3203, -0.3624,  ..., -0.3486, -0.3481, -0.3403])\n",
      "angles_idx:\n",
      " tensor([  0,   0,   0,  ..., 783, 783, 783])\n",
      "sc_types:\n",
      " tensor([0, 4, 6,  ..., 6, 4, 0])\n",
      "y:\n",
      " tensor([[ 2.0939e+00,  5.7855e-03,  1.8053e-02,  2.4014e-02,  2.1417e+00],\n",
      "        [-5.8224e-01,  2.7488e-03, -5.1135e-03,  2.4645e-03, -5.8214e-01],\n",
      "        [-4.0959e-01, -6.2886e-04, -2.5231e-03,  3.8351e-03, -4.0890e-01],\n",
      "        ...,\n",
      "        [-3.2269e-01,  1.3919e-03,  7.2254e-03, -1.1281e-02, -3.2535e-01],\n",
      "        [-6.0649e-01,  1.8663e-04, -9.2220e-03, -1.1164e-03, -6.1664e-01],\n",
      "        [ 2.0211e+00,  5.7765e-03,  2.2478e-02,  1.8577e-02,  2.0679e+00]])\n"
     ]
    }
   ],
   "source": [
    "b_dict = dict(x=batch[0][0], \n",
    "              e=batch[0][1], \n",
    "              sc_e=batch[0][2], \n",
    "              sc_m=batch[0][3], \n",
    "              node_idx=batch[0][4], \n",
    "              pairs_idx=batch[0][5], \n",
    "              sc_idx=batch[0][6], \n",
    "              sc_pairs_idx=batch[0][7], \n",
    "              dists=batch[0][8], \n",
    "              sc_node_idx=batch[0][9], \n",
    "              sc_idx2=batch[0][10], \n",
    "              angles=batch[0][11],\n",
    "              angles_idx=batch[0][12],\n",
    "              sc_types=batch[0][13], \n",
    "              y=batch[1])\n",
    "for k,v in b_dict.items(): print(f'{k}:\\n {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the metric used for this competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "code_folding": [
     0,
     31,
     43,
     46
    ]
   },
   "outputs": [],
   "source": [
    "def group_mean_log_mae(y_true, y_pred, types, epoch):\n",
    "    proc = lambda x: x.cpu().numpy().ravel() \n",
    "    y_true, y_pred, types = proc(y_true), proc(y_pred), proc(types)\n",
    "    y_true = SC_MEAN + y_true * SC_STD\n",
    "    y_pred = SC_MEAN + y_pred * SC_STD\n",
    "    maes = pd.Series(y_true - y_pred).abs().groupby(types).mean()\n",
    "    gmlmae = np.log(maes).mean()\n",
    "    # print(f'Epoch: {epoch} - Group Mean Log Mae: {gmlmae}')\n",
    "    return gmlmae\n",
    "\n",
    "class GroupMeanLogMAE(Callback):\n",
    "    _order = -10 #Needs to run before the save model callback\n",
    "\n",
    "    def __init__(self, learn, **kwargs): self.learn = learn\n",
    "    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['group_mean_log_mae'])\n",
    "    def on_epoch_begin(self, **kwargs): self.input, self.output, self.target = [], [], []\n",
    "    \n",
    "    def on_batch_end(self, last_target, last_output, last_input, train, **kwargs):\n",
    "        if not train:\n",
    "            self.input.append(last_input[-1])\n",
    "            self.output.append(last_output[:,-1])\n",
    "            self.target.append(last_target[:,-1])\n",
    "                \n",
    "    def on_epoch_end(self, epoch, last_metrics, **kwargs):\n",
    "        if (len(self.input) > 0) and (len(self.output) > 0):\n",
    "            inputs = torch.cat(self.input)\n",
    "            preds = torch.cat(self.output)\n",
    "            target = torch.cat(self.target)\n",
    "            metric = group_mean_log_mae(preds, target, inputs, epoch)\n",
    "            return add_metrics(last_metrics, [metric])\n",
    "\n",
    "def contribs_rmse_loss(preds, targs):\n",
    "    \"\"\"\n",
    "    Returns the sum of RMSEs for each sc contribution and total sc value.\n",
    "    \n",
    "    Args:\n",
    "        - preds: tensor of shape (batch_size * n_sc, 5) containing \n",
    "            predictions. Last column is the total scalar coupling value.\n",
    "        - targs: tensor of shape (batch_size * n_sc, 5) containing \n",
    "            true values. Last column is the total scalar coupling value.\n",
    "    \"\"\"\n",
    "    return torch.mean((preds - targs) ** 2, dim=0).sqrt().sum()\n",
    "\n",
    "def rmse(preds, targs):\n",
    "    return torch.sqrt(F.mse_loss(preds[:,-1], targs[:,-1]))\n",
    "\n",
    "def mae(preds, targs):\n",
    "    return torch.abs(preds[:,-1] - targs[:,-1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd, norm, act = 0, True, nn.ReLU(True)\n",
    "update_steps, proc_steps, readout_type = 5, 6, 'GaussAtt'\n",
    "n_x, n_h, n_e, n_sc_e, n_sc_m = N_ATOM_FEATURES, 300, N_EDGE_FEATURES, N_SC_EDGE_FEATURES, N_SC_MOL_FEATURES\n",
    "preproc_net_args = dict(layers=[], act=act, dropout=[], out_act=nn.Tanh())\n",
    "enn_args = dict(layers=3*[n_h], act=act, dropout=3*[0.0], batch_norm=norm)\n",
    "ann_args = dict(layers=1*[n_h], act=act, dropout=1*[0.0], batch_norm=norm, out_act=nn.Tanh())\n",
    "R_net_args = dict(pre_layers=[n_sc_m+6*n_h], post_layers=[n_sc_m+6*n_h], n_h_contribs=200, act=act, dropout=[0.0, 0.0, 0.0], \n",
    "                  norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(100)\n",
    "model = MPNN(n_x, n_h, n_e, n_sc_e, n_sc_m, update_steps, proc_steps, readout_type, \n",
    "             preproc_net_args, enn_args, ann_args, R_net_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNN(\n",
      "  (preproc_net): FullyConnectedNet(\n",
      "    (layers): Sequential(\n",
      "      (0): Linear(in_features=21, out_features=300, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (sc_preproc_net): FullyConnectedNet(\n",
      "    (layers): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=300, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (M): ENNMessage(\n",
      "    (enn): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=8, out_features=300, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): Linear(in_features=300, out_features=300, bias=True)\n",
      "        (4): ReLU(inplace)\n",
      "        (5): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): Linear(in_features=300, out_features=300, bias=True)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (9): Linear(in_features=300, out_features=90000, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (sc_enn): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=300, out_features=300, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): Linear(in_features=300, out_features=300, bias=True)\n",
      "        (4): ReLU(inplace)\n",
      "        (5): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): Linear(in_features=300, out_features=300, bias=True)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (9): Linear(in_features=300, out_features=90000, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (ann): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=300, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): Linear(in_features=300, out_features=300, bias=True)\n",
      "        (4): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (U): GRUUpdate(\n",
      "    (gru): GRUCell(300, 300)\n",
      "  )\n",
      "  (sc_U): GRUUpdate(\n",
      "    (gru): GRUCell(600, 300)\n",
      "  )\n",
      "  (R): Readout(\n",
      "    (proj): Linear(in_features=321, out_features=300, bias=True)\n",
      "    (proc): GaussAtt()\n",
      "    (write_head): MyCustomHead(\n",
      "      (preproc): FullyConnectedNet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1825, out_features=1825, bias=True)\n",
      "          (1): ReLU(inplace)\n",
      "          (2): BatchNorm1d(1825, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (types_net): ModuleList(\n",
      "        (0): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1825, out_features=1825, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (1): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1825, out_features=1825, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (2): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1825, out_features=1825, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (3): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1825, out_features=1825, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (4): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1825, out_features=1825, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (5): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1825, out_features=1825, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (6): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1825, out_features=1825, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (7): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1825, out_features=1825, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (contribs_net): ContribsNet(\n",
      "        (blocks): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Linear(in_features=1825, out_features=200, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): LayerNorm(torch.Size([200]), eps=1e-05, elementwise_affine=True)\n",
      "            (3): Linear(in_features=200, out_features=1, bias=True)\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Linear(in_features=1825, out_features=200, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): LayerNorm(torch.Size([200]), eps=1e-05, elementwise_affine=True)\n",
      "            (3): Linear(in_features=200, out_features=1, bias=True)\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Linear(in_features=1825, out_features=200, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): LayerNorm(torch.Size([200]), eps=1e-05, elementwise_affine=True)\n",
      "            (3): Linear(in_features=200, out_features=1, bias=True)\n",
      "          )\n",
      "          (3): Sequential(\n",
      "            (0): Linear(in_features=1825, out_features=200, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): LayerNorm(torch.Size([200]), eps=1e-05, elementwise_affine=True)\n",
      "            (3): Linear(in_features=200, out_features=1, bias=True)\n",
      "          )\n",
      "          (4): Sequential(\n",
      "            (0): Linear(in_features=1825, out_features=200, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): LayerNorm(torch.Size([200]), eps=1e-05, elementwise_affine=True)\n",
      "            (3): Linear(in_features=200, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "tensor([[-6.2098e-01,  2.4012e-03,  1.0733e-02, -2.7955e-02, -6.3651e-01],\n",
      "        [-1.0031e-01,  4.5088e-03,  5.6625e-03, -1.1181e-02, -1.0118e-01],\n",
      "        [ 4.4674e-01,  3.4065e-04,  8.0591e-03, -6.1860e-03,  4.4910e-01],\n",
      "        ...,\n",
      "        [-4.4966e-01, -6.1768e-04,  2.5193e-03,  4.7339e-02, -4.0111e-01],\n",
      "        [-1.8475e-01,  5.4551e-03,  4.4445e-03, -3.9219e-03, -1.7920e-01],\n",
      "        [-1.2094e+00,  7.0289e-03, -6.6059e-03, -1.5389e-03, -1.2117e+00]],\n",
      "       grad_fn=<CatBackward>)\n",
      "torch.Size([1210, 5])\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(model(*batch[0]))\n",
    "print(model(*batch[0]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientClipping(LearnerCallback):\n",
    "    \"Gradient clipping during training.\"\n",
    "    def __init__(self, learn:Learner, clip:float = 0., start_it:int = 100):\n",
    "        super().__init__(learn)\n",
    "        self.clip, self.start_it = clip, start_it\n",
    "\n",
    "    def on_backward_end(self, iteration, **kwargs):\n",
    "        \"Clip the gradient before the optimizer step.\"\n",
    "        if self.clip and (iteration > self.start_it): nn.utils.clip_grad_norm_(self.learn.model.parameters(), self.clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(db, model, metrics=[rmse, mae], \n",
    "                callback_fns=[partial(GradientClipping, clip=10), GroupMeanLogMAE], \n",
    "                wd=wd, loss_func=contribs_rmse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/python36/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GaussAtt. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/anaconda2/envs/python36/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type MPNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/anaconda2/envs/python36/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type FullyConnectedNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/anaconda2/envs/python36/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type ENNMessage. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/anaconda2/envs/python36/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GRUUpdate. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/anaconda2/envs/python36/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Readout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/anaconda2/envs/python36/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type MyCustomHead. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/anaconda2/envs/python36/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type ContribsNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=DataBunch;\n",
       "\n",
       "Train: <__main__.MoleculeDataset object at 0x1a833336d8>;\n",
       "\n",
       "Valid: <__main__.MoleculeDataset object at 0x1a83333710>;\n",
       "\n",
       "Test: <__main__.MoleculeDataset object at 0x1a83333f98>, model=MPNN(\n",
       "  (preproc_net): FullyConnectedNet(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=21, out_features=300, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (sc_preproc_net): FullyConnectedNet(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=300, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (M): ENNMessage(\n",
       "    (enn): FullyConnectedNet(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=8, out_features=300, bias=True)\n",
       "        (1): ReLU(inplace)\n",
       "        (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (4): ReLU(inplace)\n",
       "        (5): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (7): ReLU(inplace)\n",
       "        (8): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (9): Linear(in_features=300, out_features=90000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (sc_enn): FullyConnectedNet(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (1): ReLU(inplace)\n",
       "        (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (4): ReLU(inplace)\n",
       "        (5): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (7): ReLU(inplace)\n",
       "        (8): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (9): Linear(in_features=300, out_features=90000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (ann): FullyConnectedNet(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=300, bias=True)\n",
       "        (1): ReLU(inplace)\n",
       "        (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (4): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (U): GRUUpdate(\n",
       "    (gru): GRUCell(300, 300)\n",
       "  )\n",
       "  (sc_U): GRUUpdate(\n",
       "    (gru): GRUCell(600, 300)\n",
       "  )\n",
       "  (R): Readout(\n",
       "    (proj): Linear(in_features=321, out_features=300, bias=True)\n",
       "    (proc): GaussAtt()\n",
       "    (write_head): MyCustomHead(\n",
       "      (preproc): FullyConnectedNet(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1825, out_features=1825, bias=True)\n",
       "          (1): ReLU(inplace)\n",
       "          (2): BatchNorm1d(1825, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (types_net): ModuleList(\n",
       "        (0): FullyConnectedNet(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=1825, out_features=1825, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): FullyConnectedNet(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=1825, out_features=1825, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (2): FullyConnectedNet(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=1825, out_features=1825, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (3): FullyConnectedNet(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=1825, out_features=1825, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (4): FullyConnectedNet(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=1825, out_features=1825, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (5): FullyConnectedNet(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=1825, out_features=1825, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (6): FullyConnectedNet(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=1825, out_features=1825, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (7): FullyConnectedNet(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=1825, out_features=1825, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (contribs_net): ContribsNet(\n",
       "        (blocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=1825, out_features=200, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): LayerNorm(torch.Size([200]), eps=1e-05, elementwise_affine=True)\n",
       "            (3): Linear(in_features=200, out_features=1, bias=True)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=1825, out_features=200, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): LayerNorm(torch.Size([200]), eps=1e-05, elementwise_affine=True)\n",
       "            (3): Linear(in_features=200, out_features=1, bias=True)\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=1825, out_features=200, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): LayerNorm(torch.Size([200]), eps=1e-05, elementwise_affine=True)\n",
       "            (3): Linear(in_features=200, out_features=1, bias=True)\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Linear(in_features=1825, out_features=200, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): LayerNorm(torch.Size([200]), eps=1e-05, elementwise_affine=True)\n",
       "            (3): Linear(in_features=200, out_features=1, bias=True)\n",
       "          )\n",
       "          (4): Sequential(\n",
       "            (0): Linear(in_features=1825, out_features=200, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): LayerNorm(torch.Size([200]), eps=1e-05, elementwise_affine=True)\n",
       "            (3): Linear(in_features=200, out_features=1, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<function contribs_rmse_loss at 0x1a5d375a60>, metrics=[<function rmse at 0x10d5bdb70>, <function mae at 0x10d5bdd08>], true_wd=True, bn_wd=True, wd=0, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True), functools.partial(<class '__main__.GradientClipping'>, clip=10), <class '__main__.GroupMeanLogMAE'>], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Linear(in_features=21, out_features=300, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=16, out_features=300, bias=True)\n",
       "  (3): Tanh()\n",
       "  (4): Linear(in_features=8, out_features=300, bias=True)\n",
       "  (5): ReLU(inplace)\n",
       "  (6): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (8): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (10): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): Linear(in_features=300, out_features=90000, bias=True)\n",
       "  (12): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (13): ReLU(inplace)\n",
       "  (14): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (15): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (16): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (17): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (18): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (19): Linear(in_features=300, out_features=90000, bias=True)\n",
       "  (20): Linear(in_features=1, out_features=300, bias=True)\n",
       "  (21): ReLU(inplace)\n",
       "  (22): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (23): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (24): Tanh()\n",
       "  (25): ParameterModule()\n",
       "  (26): GRUCell(300, 300)\n",
       "  (27): GRUCell(600, 300)\n",
       "  (28): Linear(in_features=321, out_features=300, bias=True)\n",
       "  (29): GaussAtt()\n",
       "  (30): Linear(in_features=1825, out_features=1825, bias=True)\n",
       "  (31): ReLU(inplace)\n",
       "  (32): BatchNorm1d(1825, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (33): Linear(in_features=1825, out_features=1825, bias=True)\n",
       "  (34): ReLU(inplace)\n",
       "  (35): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
       "  (36): Linear(in_features=1825, out_features=1825, bias=True)\n",
       "  (37): ReLU(inplace)\n",
       "  (38): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
       "  (39): Linear(in_features=1825, out_features=1825, bias=True)\n",
       "  (40): ReLU(inplace)\n",
       "  (41): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
       "  (42): Linear(in_features=1825, out_features=1825, bias=True)\n",
       "  (43): ReLU(inplace)\n",
       "  (44): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
       "  (45): Linear(in_features=1825, out_features=1825, bias=True)\n",
       "  (46): ReLU(inplace)\n",
       "  (47): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
       "  (48): Linear(in_features=1825, out_features=1825, bias=True)\n",
       "  (49): ReLU(inplace)\n",
       "  (50): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
       "  (51): Linear(in_features=1825, out_features=1825, bias=True)\n",
       "  (52): ReLU(inplace)\n",
       "  (53): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
       "  (54): Linear(in_features=1825, out_features=1825, bias=True)\n",
       "  (55): ReLU(inplace)\n",
       "  (56): LayerNorm(torch.Size([1825]), eps=1e-05, elementwise_affine=True)\n",
       "  (57): Linear(in_features=1825, out_features=200, bias=True)\n",
       "  (58): ReLU(inplace)\n",
       "  (59): LayerNorm(torch.Size([200]), eps=1e-05, elementwise_affine=True)\n",
       "  (60): Linear(in_features=200, out_features=1, bias=True)\n",
       "  (61): Linear(in_features=1825, out_features=200, bias=True)\n",
       "  (62): ReLU(inplace)\n",
       "  (63): LayerNorm(torch.Size([200]), eps=1e-05, elementwise_affine=True)\n",
       "  (64): Linear(in_features=200, out_features=1, bias=True)\n",
       "  (65): Linear(in_features=1825, out_features=200, bias=True)\n",
       "  (66): ReLU(inplace)\n",
       "  (67): LayerNorm(torch.Size([200]), eps=1e-05, elementwise_affine=True)\n",
       "  (68): Linear(in_features=200, out_features=1, bias=True)\n",
       "  (69): Linear(in_features=1825, out_features=200, bias=True)\n",
       "  (70): ReLU(inplace)\n",
       "  (71): LayerNorm(torch.Size([200]), eps=1e-05, elementwise_affine=True)\n",
       "  (72): Linear(in_features=200, out_features=1, bias=True)\n",
       "  (73): Linear(in_features=1825, out_features=200, bias=True)\n",
       "  (74): ReLU(inplace)\n",
       "  (75): LayerNorm(torch.Size([200]), eps=1e-05, elementwise_affine=True)\n",
       "  (76): Linear(in_features=200, out_features=1, bias=True)\n",
       ")], add_time=True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load(f'mpnn_v{VERSION}_fold{FOLD_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchcontrib.optim import SWA\n",
    "learn.opt.opt = SWA(learn.opt.opt, swa_start=10, swa_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>group_mean_log_mae</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='3719', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-0aa4e8ad6aad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m learn.fit(epochs=10, lr=5e-5, callbacks=[SaveModelCallback(learn, every='improvement', mode='min', \n\u001b[1;32m      2\u001b[0m                                                            \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'group_mean_log_mae'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                                            name=f'mpnn_swa_v{VERSION}_fold{FOLD_ID}')])\n\u001b[0m",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit(epochs=10, lr=5e-5, callbacks=[SaveModelCallback(learn, every='improvement', mode='min', \n",
    "                                                           monitor='group_mean_log_mae',  \n",
    "                                                           name=f'mpnn_swa_v{VERSION}_fold{FOLD_ID}')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-631604a2e07b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, dl, callbacks, metrics)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mcb_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCallbackHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_metrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dl, loss_func, cb_handler, pbar, average, n_batch)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-91495e0ab5bf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, e, sc_e, sc_m, node_idx, pairs_idx, sc_idx, sc_pairs_idx, dists, sc_node_idx, sc_idx2, angles, angles_idx, sc_types)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0msc_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc_U\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         y = self.R(h, x, sc_h, sc_m, node_idx, sc_idx, sc_pairs_idx, sc_types, dists,\n\u001b[0;32m---> 48\u001b[0;31m                    sc_node_idx, sc_idx2)\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-5088f85efd7c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, h, x, sc_h, sc_m, node_idx, sc_idx, sc_pairs_idx, sc_types, dists, sc_node_idx, sc_idx2)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGaussAtt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_pairs_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_node_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_idx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-daa26f8284e4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, sc_pairs_idx, sc_types, dists, sc_node_idx, sc_idx2)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_pairs_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_node_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_idx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mq0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gauss_att\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_pairs_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc_pairs_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_node_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_idx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mq1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gauss_att\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_pairs_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc_pairs_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_node_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_idx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-daa26f8284e4>\u001b[0m in \u001b[0;36mapply_gauss_att\u001b[0;34m(self, x, sc_pairs_idx, dists, sc_node_idx, sc_idx2, sc_types)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0matt_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdf\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0matt_x\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_node_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0matt_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdists_\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPAD_VAL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_idx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msc_idx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-daa26f8284e4>\u001b[0m in \u001b[0;36mscatter_sum\u001b[0;34m(src, idx, num)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscatter_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mexp_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.validate()\n",
    "from torchcontrib.optim import _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.validate??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.opt.opt.swap_swa_sgd()\n",
    "learn.opt.opt.bn_update(learn.data.train_dl.dl, learn.model, learn.device)\n",
    "swa_res = learn.validate()\n",
    "learn.opt.opt.swap_swa_sgd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SWA(Callback):\n",
    "    def __init__(self, model, swa_model, swa_start, swa_freq):\n",
    "        super().__init__()\n",
    "        self.model, self.swa_model = model, swa_model \n",
    "        self.swa_start, self.swa_freq = swa_start, swa_freq\n",
    "        \n",
    "    def on_train_begin(self): \n",
    "        self.iter, self.swa_n = 0, 0\n",
    "\n",
    "    def on_step_end(self, metrics):\n",
    "        if (self.iter > self.swa_start) & ((self.iter % self.swa_freq) == 0):\n",
    "            self.update_average_model()\n",
    "            self.swa_n += 1\n",
    "        self.iter += 1\n",
    "        \n",
    "    def on_epoch_end(self, )\n",
    "            \n",
    "    def update_average_model(self):\n",
    "        # update running average of parameters\n",
    "        model_params = self.model.parameters()\n",
    "        swa_params = self.swa_model.parameters()\n",
    "        for model_param, swa_param in zip(model_params, swa_params):\n",
    "            swa_param.data *= self.swa_n\n",
    "            swa_param.data += model_param.data\n",
    "            swa_param.data /= (self.swa_n + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-81eb468a6812>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(learn, start_lr, end_lr, num_it, stop_div, wd)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m def to_fp16(learn:Learner, loss_scale:float=None, max_noskip:int=1000, dynamic:bool=True, clip:float=None,\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.lr_find(start_lr=1e-6, end_lr=1.0, num_it=100, stop_div=True)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>group_mean_log_mae</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='3719', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-e5e7afefb18a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m learn.fit_one_cycle(1, max_lr=5e-4, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n\u001b[1;32m      2\u001b[0m                                                                   \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'group_mean_log_mae'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                                                   name=f'mpnn_swa_v{VERSION}_fold{FOLD_ID}')])\n\u001b[0m",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-91495e0ab5bf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, e, sc_e, sc_m, node_idx, pairs_idx, sc_idx, sc_pairs_idx, dists, sc_node_idx, sc_idx2, angles, angles_idx, sc_types)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0msc_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc_preproc_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc_e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_pairs_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangles_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             sc_x = torch.cat([h.index_select(0, sc_pairs_idx[:,0]), \n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-59497935a5d1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, h, e, sc_h, pairs_idx, sc_pairs_idx, angles, angles_idx, t)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# compute 'm_{i} = sum_{j in N(i)}(A_{ij}h_{j})' for all nodes 'i'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangles_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_sc_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_pairs_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-59497935a5d1>\u001b[0m in \u001b[0;36madd_message\u001b[0;34m(self, m, a, h, pairs_idx, use_att, angles_idx)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# do the matrix multiplication 'A_{ij}h_{j}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mah\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# apply atttention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, max_lr=5e-4, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='group_mean_log_mae',  \n",
    "                                                                  name=f'mpnn_swa_v{VERSION}_fold{FOLD_ID}')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_lr(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses(skip_start=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_contrib_preds = learn.get_preds(DatasetType.Valid)\n",
    "test_contrib_preds = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = val_contrib_preds[0][:,-1].detach().numpy() * SC_STD + SC_MEAN\n",
    "test_preds = test_contrib_preds[0][:,-1].detach().numpy() * SC_STD + SC_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_submit(predictions):\n",
    "    submit = pd.read_csv(DATA_PATH + 'sample_submission.csv')\n",
    "    print(len(submit), len(predictions))   \n",
    "    submit['scalar_coupling_constant'] = predictions\n",
    "    submit.to_csv(f'mpnn-swa-v{VERSION}-idx{FOLD_ID}-submission.csv', index=False)\n",
    "\n",
    "def store_oof(predictions, val_ids):\n",
    "    oof = pd.DataFrame(predictions, columns=['scalar_coupling_constants'])\n",
    "    print(oof.head())\n",
    "    oof.to_csv(f'mpnn-swa-v{VERSION}-idx{FOLD_ID}-oof.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_submit(test_preds)\n",
    "store_oof(val_preds, val_mol_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
