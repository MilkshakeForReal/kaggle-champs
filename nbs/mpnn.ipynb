{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import deepchem as dc\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.spatial.distance import norm\n",
    "\n",
    "from fastai.tabular import *\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "from fastai.basic_data import DataBunch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPES              = np.array(['1JHC', '2JHH', '1JHN', '2JHN', '2JHC', '3JHH', '3JHC', '3JHN'])\n",
    "TYPES_MAP          = {t: i for i, t in enumerate(TYPES)}\n",
    "SC_EDGE_FEATS      = ['type_0', 'type_1', 'type_2', 'type_3', 'type_4', 'type_5', 'type_6', 'type_7', 'dist',\n",
    "                      'dist_min_rad', 'dist_electro_neg_adj', 'normed_dist', 'diangle', 'cos_angle', \n",
    "                      'cos_angle0', 'cos_angle1']\n",
    "SC_MOL_FEATS       = ['type_0', 'type_1', 'type_2', 'type_3', 'type_4', 'type_5', 'type_6', 'type_7', 'dist',\n",
    "                      'dist_min_rad', 'dist_electro_neg_adj', 'normed_dist', 'diangle', 'cos_angle', \n",
    "                      'cos_angle0', 'cos_angle1', 'num_atoms', 'num_C_atoms', 'num_F_atoms', 'num_H_atoms', \n",
    "                      'num_N_atoms', 'num_O_atoms']\n",
    "N_EDGE_FEATURES    = 8\n",
    "N_SC_EDGE_FEATURES = 16\n",
    "N_SC_MOL_FEATURES  = 22\n",
    "N_ATOM_FEATURES    = 20\n",
    "N_TYPES            = len(TYPES)\n",
    "N_MOLS             = 130775\n",
    "SC_MEAN            = 16\n",
    "SC_STD             = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = '../tmp/'\n",
    "PATH = '../storage/CHAMPS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['structures.csv',\n",
       " 'train.csv',\n",
       " 'atom_df.csv',\n",
       " 'test_proc_df.csv',\n",
       " 'mask.csv',\n",
       " 'pairs_idx.csv',\n",
       " 'edge_features.csv',\n",
       " 'test.csv',\n",
       " 'train_proc_df.csv',\n",
       " 'sample_submission.csv',\n",
       " 'atomic_features.csv',\n",
       " 'edge_df.csv',\n",
       " 'edge_mask.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(PATH)\n",
    "files = [f for f in files if f.find('.csv') != -1]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(PATH+'train_proc_df.csv', index_col=0)\n",
    "test_df  = pd.read_csv(PATH+'test_proc_df.csv', index_col=0)\n",
    "atom_df  = pd.read_csv(PATH+'atom_df.csv', index_col=0)\n",
    "edge_df  = pd.read_csv(PATH+'edge_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['scalar_coupling_constant'] = (train_df['scalar_coupling_constant'] - SC_MEAN) / SC_STD\n",
    "train_df[['num_atoms', 'num_C_atoms', 'num_F_atoms', 'num_H_atoms', 'num_N_atoms', 'num_O_atoms']] /= 10\n",
    "test_df[['num_atoms', 'num_C_atoms', 'num_F_atoms', 'num_H_atoms', 'num_N_atoms', 'num_O_atoms']] /= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MPNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0,
     5,
     13
    ]
   },
   "outputs": [],
   "source": [
    "def selu_weights_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        fan_in = m.weight.size(1)\n",
    "        m.weight.data.normal_(0.0, 1.0 / math.sqrt(fan_in))\n",
    "\n",
    "def hidden_layer(n_in, n_out, batch_norm, dropout, act=None):\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(n_in, n_out))\n",
    "    if act: layers.append(act)\n",
    "    if batch_norm: layers.append(nn.BatchNorm1d(n_out))\n",
    "    if dropout != 0: layers.append(nn.Dropout(dropout))\n",
    "    return layers\n",
    "\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input, n_output, layers=[], act=nn.ReLU(True), dropout=[], batch_norm=False, \n",
    "                 out_act=None):\n",
    "        super().__init__()\n",
    "        sizes = [n_input] + layers + [n_output]\n",
    "        layers_ = []\n",
    "        for i, (n_in, n_out, dr) in enumerate(zip(sizes[:-1], sizes[1:], dropout+[0.0])):\n",
    "            act_ = act if i < len(layers) else out_act\n",
    "            batch_norm_ = batch_norm if i < len(layers) else False\n",
    "            layers_ += hidden_layer(n_in, n_out, batch_norm_, dr, act_)      \n",
    "        self.layers = nn.Sequential(*layers_)\n",
    "        if type(act) == nn.SELU: self.layers.apply(selu_weights_init)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class HiddenLSTMCell(nn.Module):\n",
    "    \"\"\"Implements the LSTM cell update described in the sec 4.2 of https://arxiv.org/pdf/1511.06391.pdf.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_h_out):\n",
    "        \"\"\"This LSTM cell takes no external 'x' inputs, but has a hidden state appended with the \n",
    "        readout from a content based attention mechanism. Therefore the hidden state is of a dimension\n",
    "        that is two times the number of nodes in the set.\"\"\"\n",
    "        super().__init__()\n",
    "        self.n_h_out, self.n_h = n_h_out, n_h_out * 2 \n",
    "        self.w_h = nn.Parameter(torch.Tensor(self.n_h, n_h_out * 4))\n",
    "        self.b = nn.Parameter(torch.Tensor(n_h_out * 4))\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            else: \n",
    "                nn.init.zeros_(p.data)\n",
    "                # initialize the forget gate bias to 1\n",
    "                p.data[self.n_h_out:self.n_h_out*2] = torch.ones(self.n_h_out)\n",
    "        \n",
    "    def forward(self, h_prev, c_prev):\n",
    "        \"\"\"Takes previuos hidden and cell states as arguments and performs a \n",
    "        single LSTM step using no external input.\n",
    "        \"\"\"\n",
    "        n_h_ = self.n_h_out # number of output hidden states\n",
    "        # batch the computations into a single matrix multiplication\n",
    "        gates = h_prev @ self.w_h + self.b\n",
    "        i_g, f_g, g, o_g = (\n",
    "            torch.sigmoid(gates[:, :n_h_]), # input\n",
    "            torch.sigmoid(gates[:, n_h_:n_h_*2]), # forget\n",
    "            torch.tanh(gates[:, n_h_*2:n_h_*3]),\n",
    "            torch.sigmoid(gates[:, n_h_*3:]), # output\n",
    "        )\n",
    "        c = f_g * c_prev + i_g * g\n",
    "        h = o_g * torch.tanh(c)\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0,
     6,
     11
    ]
   },
   "outputs": [],
   "source": [
    "def scatter_add(src, idx, num):\n",
    "    sz = num, src.size(1)\n",
    "    exp_idx = idx[:,None].repeat(1, sz[1])\n",
    "    out = torch.zeros(sz, dtype=src.dtype, device=src.device)\n",
    "    return out.scatter_add(0, exp_idx, src)\n",
    "\n",
    "def softmax(x, idx, num=None):\n",
    "    x = x.exp()\n",
    "    x = x / (scatter_add(x, idx, num=num)[idx] + 1e-16)\n",
    "    return x\n",
    " \n",
    "class Set2Set(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted from: https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric\\\n",
    "        /nn/glob/set2set.html#Set2Set\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, proc_steps):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = 2 * in_channels\n",
    "        self.proc_steps = proc_steps\n",
    "        self.lstm = HiddenLSTMCell(self.in_channels)\n",
    "\n",
    "    def forward(self, x, node_idx):\n",
    "        \"\"\"\n",
    "        x - input tensor of shape (batch_size * n_nodes, in_channels).\n",
    "        - node_idx: tensor of shape (batch_size * n_nodes) mapping each\n",
    "            node to its corresponding index in the batch.\n",
    "        \"\"\"\n",
    "        batch_size = node_idx.max().item() + 1\n",
    "        h = torch.zeros(batch_size, self.in_channels, device=x.device)\n",
    "        q_star = torch.zeros(batch_size, self.out_channels, device=x.device)\n",
    "        for i in range(self.proc_steps):\n",
    "            q, h = self.lstm(q_star, h)\n",
    "            e = (x * q[node_idx]).sum(dim=-1, keepdim=True)\n",
    "            a = softmax(e, node_idx, num=batch_size)\n",
    "            r = scatter_add(a * x, node_idx, num=batch_size) # sum 'a*x' over nodes \n",
    "            q_star = torch.cat([q, r], dim=-1)\n",
    "            \n",
    "        return q_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class EdgeNetwork(nn.Module):\n",
    "    def __init__(self, n_h, n_e, n_sc_e, stride=5, net_args={}):\n",
    "        super().__init__()\n",
    "        self.n_h, self.stride = n_h, stride\n",
    "        self.adj_net = FullyConnectedNet(n_e, n_h*stride, **net_args)\n",
    "        self.sc_adj_net = FullyConnectedNet(n_sc_e, n_h*stride, **net_args)\n",
    "        self.b = nn.Parameter(torch.Tensor(n_h)) # bias for the message function\n",
    "        nn.init.zeros_(self.b)\n",
    "    \n",
    "    def forward(self, h, e, sc_e, pairs_idx, sc_pairs_idx, t=0):\n",
    "        \"\"\"\n",
    "        Compute message vector m_t given the previuos hidden state\n",
    "        h_t-1 and edge features e.\n",
    "        - h: tensor of hidden states of shape (batch_size * n_nodes, n_h)\n",
    "        - e: tensor of edge features of shape (batch_size * n_edges, n_e).\n",
    "        - sc_e: tensor of scalar coupling edge features of shape \n",
    "            (batch_size * n_sc, n_sc_e).\n",
    "        - pairs_idx: tensor of shape (batch_size * n_edges, 2) mapping atom \n",
    "            indexes (first column) to the other atom indexes they form a \n",
    "            bond with (second column). Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_pairs_idx: tensor of shape (batch_size * n_sc, 2) containing atom \n",
    "            indices of the atoms for which the scalar coupling constant\n",
    "            need to be predicted. Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - t: update iteration. \n",
    "        \"\"\"\n",
    "        # compute 'A(e)'\n",
    "        if t==0: \n",
    "            self.a_mat = self.get_a_mat(self.adj_net(e))\n",
    "            self.a_sc_mat = self.get_a_mat(self.sc_adj_net(sc_e))\n",
    "            \n",
    "        # compute 'm_{i} = sum_{j in N(i)}(A_{ij}h_{j})' for all nodes 'i'\n",
    "        m = self.add_message(torch.zeros_like(h), self.a_mat, h, pairs_idx)\n",
    "        m = self.add_message(m, self.a_sc_mat, h, sc_pairs_idx)\n",
    "        return m + self.b # add message bias\n",
    "    \n",
    "    def get_a_mat(self, a_vect):\n",
    "        return a_vect.view(-1, self.n_h, self.stride) / (self.stride ** .5)\n",
    "    \n",
    "    def add_message(self, m, a, h, pairs_idx):\n",
    "        # transform 'pairs_idx' and 'a' to make messages go both in to and out of all nodes\n",
    "        in_out_idx = torch.cat((pairs_idx, pairs_idx[:, [1, 0]]))\n",
    "        a_ = torch.cat((a, a)) \n",
    "        \n",
    "        # select the 'h_{j}' feeding into the 'm_{i}'\n",
    "        h_in = h.index_select(0, in_out_idx[:,1])\n",
    "        \n",
    "        # do the matrix multiplication 'A_{ij}h_{j}'\n",
    "        h_unfolded = F.pad(h_in, 2*(self.stride//2, )).unfold(1, self.stride, 1)\n",
    "        ah = (h_unfolded * a_).sum(-1) # ah = (h_in.unsqueeze(1) @ a_).squeeze(1)\n",
    "        \n",
    "        # Sum up all 'A_{ij}h_{j}' per node 'i'\n",
    "        return m.scatter_add(0, in_out_idx[:,0,None].repeat(1, self.n_h), ah)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class GRUUpdate(nn.Module):\n",
    "    def __init__(self, n_h):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRUCell(n_h, n_h)\n",
    "        \n",
    "    def forward(self, m, h_prev):\n",
    "        \"\"\"\n",
    "        Update hidden state h.\n",
    "        - h_prev is vector of hidden states of shape (batch_size * n_nodes, n_h)\n",
    "        - m is vector of messages of shape (batch_size * n_nodes, n_h)\n",
    "        \"\"\"\n",
    "        return self.gru(m, h_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MyCustomHead(nn.Module):\n",
    "    def __init__(self, n_input, n_output, pre_layers=[], post_layers=[], act=nn.ReLU(True), dropout=[], \n",
    "                 batch_norm=False):\n",
    "        super().__init__()\n",
    "        sizes, n_pre_layers = [n_input] + pre_layers, len(pre_layers)\n",
    "        pre_layers_ = []\n",
    "        for i, (n_in, n_out, dr) in enumerate(zip(sizes[:-1], sizes[1:], dropout[:n_pre_layers])):\n",
    "            pre_layers_ += hidden_layer(n_in, n_out, batch_norm, dr, act)      \n",
    "        self.preproc = nn.Sequential(*pre_layers_)\n",
    "        self.postproc = nn.ModuleList([\n",
    "            FullyConnectedNet(pre_layers[-1], n_output, post_layers, act, dropout[n_pre_layers:], batch_norm=False)\n",
    "            for _ in range(N_TYPES)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x, sc_types):\n",
    "        x_ = self.preproc(x)\n",
    "        y = torch.zeros(sc_types.size(0), device=x.device)\n",
    "        for i in range(N_TYPES):\n",
    "            if torch.any(sc_types == i): \n",
    "                y[sc_types == i] = self.postproc[i](x_[sc_types == i]).view(-1)\n",
    "        return y        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Set2SetOutput(nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_sc_m, proc_steps, net_args):\n",
    "        super().__init__()\n",
    "        self.R_proj = nn.Linear(n_h + n_x, n_h)\n",
    "        self.R_proc = Set2Set(n_h, proc_steps)\n",
    "        self.R_write = MyCustomHead((4 * n_h) + n_sc_m, 1, **net_args)\n",
    "    \n",
    "    def forward(self, h, x, sc_m, node_idx, sc_idx, sc_pairs_idx, sc_types):\n",
    "        \"\"\"\n",
    "        Make prediction.\n",
    "        - h is vector of hidden states of shape (batch_size * n_nodes, n_h).\n",
    "        - x is vector of input features of shape (batch_size * n_nodes, n_x).\n",
    "        - sc_m: tensor of scalar coupling molecule level features of shape \n",
    "            (batch_size * n_sc, n_sc_m).\n",
    "        - node_idx: tensor of shape (batch_size * n_nodes) mapping each\n",
    "            node to its corresponding index in the batch.\n",
    "        - sc_idx: tensor of shape (batch_size * n_sc) mapping each\n",
    "            scalar coupling constant to its corresponding index in the batch.\n",
    "        - sc_pairs_idx: tensor of shape (batch_size * n_sc, 2) containing atom \n",
    "            indices of the atoms for which the scalar coupling constant\n",
    "            need to be predicted. Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_types: tensor of shape (batch_size * n_sc) containing the scalar \n",
    "            coupling type of each observation. \n",
    "        \"\"\"\n",
    "        m = self.R_proj(torch.cat([h, x], dim=1))\n",
    "        q = self.R_proc(m, node_idx)\n",
    "        \n",
    "        # introduce skip connection to final node states of scalar coupling atoms\n",
    "        inp = torch.cat([\n",
    "            q.index_select(0, sc_idx),\n",
    "            h.index_select(0, sc_pairs_idx[:,0]),\n",
    "            h.index_select(0, sc_pairs_idx[:,1]),\n",
    "            sc_m\n",
    "        ], dim=-1)\n",
    "        y = self.R_write(inp, sc_types)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MPNN(nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_e, n_sc_e, n_sc_m, stride=5, update_steps=3, proc_steps=10, \n",
    "                 preproc_net_args={}, enn_args={}, R_net_args={}):\n",
    "        super().__init__()\n",
    "        self.preproc_net = FullyConnectedNet(n_x, n_h, **preproc_net_args)\n",
    "        self.M = EdgeNetwork(n_h, n_e, n_sc_e, stride, enn_args)\n",
    "        self.U = GRUUpdate(n_h)\n",
    "        self.R = Set2SetOutput(n_x, n_h, n_sc_m, proc_steps, R_net_args)\n",
    "        self.update_steps = update_steps\n",
    "        \n",
    "    def forward(self, x, e, sc_e, sc_m, node_idx, pairs_idx, sc_idx, sc_pairs_idx, sc_types):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: tensor of node features of shape (batch_size * n_nodes, n_x).\n",
    "        - e: tensor of edge features of shape (batch_size * n_edges, n_e).\n",
    "        - sc_e: tensor of scalar coupling edge features of shape \n",
    "            (batch_size * n_sc, n_sc_e).\n",
    "        - sc_m: tensor of scalar coupling molecule level features of shape \n",
    "            (batch_size * n_sc, n_sc_m).\n",
    "        - node_idx: tensor of shape (batch_size * n_nodes) mapping each\n",
    "            node to its corresponding index in the batch.\n",
    "        - pairs_idx: tensor of shape (batch_size * n_edges, 2) mapping atom \n",
    "            indexes (first column) to the other atom indexes they form a \n",
    "            bond with (second column). Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_idx: tensor of shape (batch_size * n_sc) mapping each\n",
    "            scalar coupling constant to its corresponding index in the batch.\n",
    "        - sc_pairs_idx: tensor of shape (batch_size * n_sc, 2) containing atom \n",
    "            indices of the atoms for which the scalar coupling constant\n",
    "            need to be predicted. Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_types: tensor of shape (batch_size * n_sc) containing the scalar \n",
    "            coupling type of each observation. \n",
    "        \"\"\"\n",
    "        h = self.preproc_net(x)\n",
    "        for t in range(self.update_steps):\n",
    "            m = self.M(h, e, sc_e, pairs_idx, sc_pairs_idx, t)\n",
    "            h = self.U(m, h)\n",
    "        y = self.R(h, x, sc_m, node_idx, sc_idx, sc_pairs_idx, sc_types)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Fit MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=100):\n",
    "    # python RNG\n",
    "    random.seed(seed)\n",
    "\n",
    "    # pytorch RNGs\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # numpy RNG\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_ids = train_df['molecule_id'].unique()\n",
    "n_obs = len(mol_ids)\n",
    "split = int(n_obs*0.75)\n",
    "set_seed(100)\n",
    "mol_ids_ = np.random.choice(mol_ids, size=n_obs, replace=False)\n",
    "train_mol_ids, val_mol_ids = pd.Series(mol_ids_[:split]), pd.Series(mol_ids_[split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_mol_sc = train_df.groupby('molecule_id')\n",
    "test_gb_mol_sc = test_df.groupby('molecule_id')\n",
    "gb_mol_atom = atom_df.groupby('molecule_id')\n",
    "gb_mol_edge = edge_df.groupby('molecule_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": [
     0,
     6,
     23,
     26
    ]
   },
   "outputs": [],
   "source": [
    "def one_hot_encode_np(x):\n",
    "    sz = len(x), len(np.unique(x))\n",
    "    x_one_hot = np.zeros(sz, dtype=np.long)\n",
    "    x_one_hot[np.arange(sz[0]), x] = 1\n",
    "    return x_one_hot\n",
    "\n",
    "class MoleculeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, mol_ids, gb_mol_sc, gb_mol_atom, gb_mol_edge):\n",
    "        self.n = len(mol_ids)\n",
    "        self.mol_ids = mol_ids\n",
    "        self.gb_mol_sc = gb_mol_sc\n",
    "        self.gb_mol_atom = gb_mol_atom\n",
    "        self.gb_mol_edge = gb_mol_edge\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.gb_mol_sc.get_group(self.mol_ids[idx]), \n",
    "                self.gb_mol_atom.get_group(self.mol_ids[idx]), \n",
    "                self.gb_mol_edge.get_group(self.mol_ids[idx]))\n",
    "\n",
    "def np_lst_to_torch(arr_lst, dtype=torch.float):\n",
    "    return torch.from_numpy(np.ascontiguousarray(np.concatenate(arr_lst))).type(dtype)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch_size, n_atom_sum = len(batch), 0\n",
    "    x, e, sc_e, sc_m, sc_types, sc_vals = [], [], [], [], [], []\n",
    "    node_idx, pairs_idx, sc_pairs_idx, sc_idx = [], [], [], []\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        sc_df, atom_df, edge_df = batch[b]\n",
    "        n_atoms, n_sc = len(atom_df), len(sc_df)\n",
    "        \n",
    "        x.append(atom_df.drop(columns='molecule_id').values)\n",
    "        e.append(edge_df.drop(columns=['idx_0', 'idx_1', 'molecule_id']).values)\n",
    "        sc_e.append(sc_df[SC_EDGE_FEATS].values)\n",
    "        sc_m.append(sc_df[SC_MOL_FEATS].values)\n",
    "        sc_types.append(sc_df['type'].values)\n",
    "        sc_vals.append(sc_df['scalar_coupling_constant'].values)\n",
    "        \n",
    "        node_idx.append(np.repeat(b, n_atoms))\n",
    "        sc_idx.append(np.repeat(b, n_sc))\n",
    "        pairs_idx.append(edge_df[['idx_0', 'idx_1']].values + n_atom_sum)\n",
    "        sc_pairs_idx.append(sc_df[['atom_index_0', 'atom_index_1']].values + n_atom_sum)\n",
    "        \n",
    "        n_atom_sum += n_atoms\n",
    "    \n",
    "    x, e = np_lst_to_torch(x), np_lst_to_torch(e), \n",
    "    sc_e, sc_m = np_lst_to_torch(sc_e), np_lst_to_torch(sc_m)\n",
    "    sc_vals, sc_types = np_lst_to_torch(sc_vals), np_lst_to_torch(sc_types, torch.long)\n",
    "    node_idx = np_lst_to_torch(node_idx, torch.long)\n",
    "    sc_idx = np_lst_to_torch(sc_idx, torch.long)\n",
    "    pairs_idx = np_lst_to_torch(pairs_idx, torch.long)\n",
    "    sc_pairs_idx = np_lst_to_torch(sc_pairs_idx, torch.long)\n",
    "    \n",
    "    return (x, e, sc_e, sc_m, node_idx, pairs_idx, sc_idx, sc_pairs_idx, sc_types), sc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MoleculeDataset(train_mol_ids, gb_mol_sc, gb_mol_atom, gb_mol_edge)\n",
    "val_ds   = MoleculeDataset(val_mol_ids, gb_mol_sc, gb_mol_atom, gb_mol_edge)\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "val_dl   = DataLoader(val_ds, batch_size, num_workers=8, drop_last=True)\n",
    "db = DataBunch(train_dl, val_dl, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([375, 20])\n",
      "torch.Size([387, 8])\n",
      "torch.Size([1144, 16])\n",
      "torch.Size([1144, 22])\n",
      "torch.Size([375])\n",
      "torch.Size([387, 2])\n",
      "torch.Size([1144])\n",
      "torch.Size([1144, 2])\n",
      "torch.Size([1144])\n",
      "torch.Size([1144])\n"
     ]
    }
   ],
   "source": [
    "for el in batch[0]: print(el.size())\n",
    "print(batch[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " tensor([[0.0000, 1.0000, 0.0000,  ..., 1.2037, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 1.3965, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 1.2018, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 1.0617, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 1.0785, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 1.0802, 0.0000, 0.0000]])\n",
      "e:\n",
      " tensor([[ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  1.5316,  1.3957],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0947, -0.7402],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0948, -0.7397],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.3961,  0.9587],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.3049,  0.2646],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0802, -1.4458]])\n",
      "sc_e:\n",
      " tensor([[ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.3127],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.3438,  0.7481, -0.7354],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.4088, -0.8878],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.9860, -0.9776],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.4963,  0.8363,  0.8911],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.4963]])\n",
      "sc_m:\n",
      " tensor([[1.0000, 0.0000, 0.0000,  ..., 1.6000, 0.0000, 0.1000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.6000, 0.0000, 0.1000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.6000, 0.0000, 0.1000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3000, 0.1000, 0.1000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3000, 0.1000, 0.1000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 0.3000, 0.1000, 0.1000]])\n",
      "node_idx:\n",
      " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "        12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "        15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "        17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "        18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])\n",
      "pairs_idx:\n",
      " tensor([[  0,   1],\n",
      "        [  0,   9],\n",
      "        [  0,  10],\n",
      "        [  0,  11],\n",
      "        [  1,   2],\n",
      "        [  1,   3],\n",
      "        [  1,  12],\n",
      "        [  2,  13],\n",
      "        [  2,  14],\n",
      "        [  2,  15],\n",
      "        [  3,   4],\n",
      "        [  4,  16],\n",
      "        [  4,   7],\n",
      "        [  4,   5],\n",
      "        [  5,   6],\n",
      "        [  5,  17],\n",
      "        [  5,  18],\n",
      "        [  6,   7],\n",
      "        [  6,  19],\n",
      "        [  6,  20],\n",
      "        [  7,   8],\n",
      "        [  7,  21],\n",
      "        [  8,  22],\n",
      "        [  8,  23],\n",
      "        [  8,  24],\n",
      "        [ 25,  26],\n",
      "        [ 25,  34],\n",
      "        [ 25,  35],\n",
      "        [ 25,  36],\n",
      "        [ 26,  27],\n",
      "        [ 26,  31],\n",
      "        [ 27,  28],\n",
      "        [ 28,  29],\n",
      "        [ 28,  32],\n",
      "        [ 29,  30],\n",
      "        [ 29,  37],\n",
      "        [ 30,  31],\n",
      "        [ 30,  38],\n",
      "        [ 32,  33],\n",
      "        [ 39,  40],\n",
      "        [ 39,  47],\n",
      "        [ 39,  48],\n",
      "        [ 39,  49],\n",
      "        [ 40,  41],\n",
      "        [ 40,  42],\n",
      "        [ 41,  42],\n",
      "        [ 41,  50],\n",
      "        [ 41,  51],\n",
      "        [ 42,  46],\n",
      "        [ 42,  43],\n",
      "        [ 43,  44],\n",
      "        [ 43,  52],\n",
      "        [ 43,  53],\n",
      "        [ 44,  45],\n",
      "        [ 44,  54],\n",
      "        [ 44,  55],\n",
      "        [ 45,  46],\n",
      "        [ 46,  56],\n",
      "        [ 46,  57],\n",
      "        [ 58,  59],\n",
      "        [ 58,  67],\n",
      "        [ 58,  68],\n",
      "        [ 58,  69],\n",
      "        [ 59,  60],\n",
      "        [ 59,  65],\n",
      "        [ 60,  61],\n",
      "        [ 61,  62],\n",
      "        [ 61,  63],\n",
      "        [ 62,  70],\n",
      "        [ 63,  64],\n",
      "        [ 63,  71],\n",
      "        [ 64,  65],\n",
      "        [ 64,  72],\n",
      "        [ 65,  66],\n",
      "        [ 73,  74],\n",
      "        [ 73,  82],\n",
      "        [ 73,  83],\n",
      "        [ 73,  84],\n",
      "        [ 74,  75],\n",
      "        [ 74,  85],\n",
      "        [ 74,  86],\n",
      "        [ 75,  76],\n",
      "        [ 75,  78],\n",
      "        [ 75,  81],\n",
      "        [ 76,  87],\n",
      "        [ 76,  88],\n",
      "        [ 76,  77],\n",
      "        [ 77,  89],\n",
      "        [ 77,  90],\n",
      "        [ 77,  91],\n",
      "        [ 78,  79],\n",
      "        [ 78,  92],\n",
      "        [ 78,  93],\n",
      "        [ 79,  80],\n",
      "        [ 79,  81],\n",
      "        [ 79,  94],\n",
      "        [ 80,  96],\n",
      "        [ 80,  81],\n",
      "        [ 80,  95],\n",
      "        [ 81,  97],\n",
      "        [ 98,  99],\n",
      "        [ 98, 107],\n",
      "        [ 98, 108],\n",
      "        [ 98, 109],\n",
      "        [ 99, 100],\n",
      "        [ 99, 102],\n",
      "        [ 99, 110],\n",
      "        [100, 101],\n",
      "        [100, 102],\n",
      "        [100, 111],\n",
      "        [101, 112],\n",
      "        [102, 103],\n",
      "        [102, 106],\n",
      "        [103, 104],\n",
      "        [103, 113],\n",
      "        [103, 114],\n",
      "        [104, 105],\n",
      "        [104, 106],\n",
      "        [104, 115],\n",
      "        [105, 106],\n",
      "        [106, 116],\n",
      "        [117, 118],\n",
      "        [117, 126],\n",
      "        [117, 127],\n",
      "        [117, 128],\n",
      "        [118, 119],\n",
      "        [118, 124],\n",
      "        [119, 120],\n",
      "        [119, 129],\n",
      "        [120, 121],\n",
      "        [120, 123],\n",
      "        [121, 122],\n",
      "        [121, 130],\n",
      "        [121, 131],\n",
      "        [122, 132],\n",
      "        [123, 124],\n",
      "        [124, 125],\n",
      "        [133, 134],\n",
      "        [133, 142],\n",
      "        [133, 143],\n",
      "        [133, 144],\n",
      "        [134, 135],\n",
      "        [134, 145],\n",
      "        [134, 146],\n",
      "        [135, 136],\n",
      "        [135, 147],\n",
      "        [135, 148],\n",
      "        [136, 137],\n",
      "        [137, 141],\n",
      "        [137, 140],\n",
      "        [137, 138],\n",
      "        [138, 139],\n",
      "        [138, 149],\n",
      "        [138, 150],\n",
      "        [139, 151],\n",
      "        [139, 152],\n",
      "        [139, 153],\n",
      "        [140, 141],\n",
      "        [140, 154],\n",
      "        [140, 155],\n",
      "        [141, 156],\n",
      "        [141, 157],\n",
      "        [158, 159],\n",
      "        [158, 167],\n",
      "        [158, 168],\n",
      "        [158, 169],\n",
      "        [159, 160],\n",
      "        [159, 161],\n",
      "        [159, 170],\n",
      "        [160, 171],\n",
      "        [160, 161],\n",
      "        [161, 162],\n",
      "        [161, 165],\n",
      "        [162, 163],\n",
      "        [162, 172],\n",
      "        [162, 173],\n",
      "        [163, 164],\n",
      "        [164, 174],\n",
      "        [165, 166],\n",
      "        [165, 175],\n",
      "        [176, 177],\n",
      "        [176, 184],\n",
      "        [176, 185],\n",
      "        [176, 186],\n",
      "        [177, 178],\n",
      "        [177, 187],\n",
      "        [177, 188],\n",
      "        [178, 189],\n",
      "        [178, 182],\n",
      "        [178, 179],\n",
      "        [179, 180],\n",
      "        [179, 190],\n",
      "        [179, 191],\n",
      "        [180, 181],\n",
      "        [181, 192],\n",
      "        [181, 193],\n",
      "        [181, 194],\n",
      "        [182, 183],\n",
      "        [195, 196],\n",
      "        [195, 204],\n",
      "        [195, 205],\n",
      "        [195, 206],\n",
      "        [196, 197],\n",
      "        [196, 203],\n",
      "        [197, 198],\n",
      "        [197, 203],\n",
      "        [197, 207],\n",
      "        [198, 208],\n",
      "        [198, 199],\n",
      "        [198, 200],\n",
      "        [199, 200],\n",
      "        [199, 209],\n",
      "        [200, 201],\n",
      "        [200, 203],\n",
      "        [201, 210],\n",
      "        [201, 202],\n",
      "        [203, 211],\n",
      "        [212, 213],\n",
      "        [212, 221],\n",
      "        [212, 222],\n",
      "        [212, 223],\n",
      "        [213, 214],\n",
      "        [213, 215],\n",
      "        [213, 224],\n",
      "        [214, 225],\n",
      "        [214, 226],\n",
      "        [214, 227],\n",
      "        [215, 228],\n",
      "        [215, 219],\n",
      "        [215, 216],\n",
      "        [216, 217],\n",
      "        [216, 229],\n",
      "        [216, 230],\n",
      "        [217, 218],\n",
      "        [217, 219],\n",
      "        [217, 231],\n",
      "        [218, 219],\n",
      "        [219, 220],\n",
      "        [220, 232],\n",
      "        [220, 233],\n",
      "        [220, 234],\n",
      "        [235, 236],\n",
      "        [235, 244],\n",
      "        [235, 245],\n",
      "        [235, 246],\n",
      "        [236, 237],\n",
      "        [236, 240],\n",
      "        [236, 242],\n",
      "        [237, 248],\n",
      "        [237, 247],\n",
      "        [237, 238],\n",
      "        [238, 239],\n",
      "        [238, 249],\n",
      "        [238, 250],\n",
      "        [239, 240],\n",
      "        [240, 241],\n",
      "        [241, 251],\n",
      "        [242, 243],\n",
      "        [243, 252],\n",
      "        [253, 254],\n",
      "        [253, 262],\n",
      "        [254, 255],\n",
      "        [254, 263],\n",
      "        [255, 256],\n",
      "        [256, 257],\n",
      "        [256, 260],\n",
      "        [256, 261],\n",
      "        [257, 264],\n",
      "        [257, 259],\n",
      "        [257, 258],\n",
      "        [258, 259],\n",
      "        [258, 261],\n",
      "        [258, 265],\n",
      "        [259, 260],\n",
      "        [259, 266],\n",
      "        [260, 261],\n",
      "        [260, 267],\n",
      "        [261, 268],\n",
      "        [269, 270],\n",
      "        [269, 278],\n",
      "        [269, 279],\n",
      "        [269, 280],\n",
      "        [270, 271],\n",
      "        [270, 276],\n",
      "        [270, 281],\n",
      "        [271, 272],\n",
      "        [272, 282],\n",
      "        [272, 283],\n",
      "        [272, 273],\n",
      "        [273, 274],\n",
      "        [274, 275],\n",
      "        [274, 277],\n",
      "        [274, 284],\n",
      "        [275, 276],\n",
      "        [275, 285],\n",
      "        [275, 286],\n",
      "        [276, 277],\n",
      "        [276, 287],\n",
      "        [277, 288],\n",
      "        [277, 289],\n",
      "        [290, 291],\n",
      "        [290, 299],\n",
      "        [291, 292],\n",
      "        [291, 295],\n",
      "        [292, 293],\n",
      "        [292, 300],\n",
      "        [292, 301],\n",
      "        [293, 296],\n",
      "        [293, 302],\n",
      "        [293, 294],\n",
      "        [294, 295],\n",
      "        [294, 303],\n",
      "        [294, 304],\n",
      "        [296, 297],\n",
      "        [296, 298],\n",
      "        [296, 305],\n",
      "        [297, 307],\n",
      "        [297, 298],\n",
      "        [297, 306],\n",
      "        [298, 308],\n",
      "        [309, 310],\n",
      "        [309, 318],\n",
      "        [309, 319],\n",
      "        [309, 320],\n",
      "        [310, 311],\n",
      "        [310, 313],\n",
      "        [310, 321],\n",
      "        [311, 315],\n",
      "        [311, 322],\n",
      "        [311, 312],\n",
      "        [312, 313],\n",
      "        [312, 323],\n",
      "        [313, 314],\n",
      "        [315, 316],\n",
      "        [315, 317],\n",
      "        [315, 324],\n",
      "        [316, 326],\n",
      "        [316, 317],\n",
      "        [316, 325],\n",
      "        [317, 327],\n",
      "        [328, 329],\n",
      "        [329, 330],\n",
      "        [329, 337],\n",
      "        [330, 331],\n",
      "        [330, 338],\n",
      "        [331, 332],\n",
      "        [331, 339],\n",
      "        [331, 340],\n",
      "        [332, 333],\n",
      "        [332, 334],\n",
      "        [334, 335],\n",
      "        [334, 341],\n",
      "        [334, 342],\n",
      "        [335, 336],\n",
      "        [336, 343],\n",
      "        [344, 345],\n",
      "        [344, 353],\n",
      "        [345, 346],\n",
      "        [345, 354],\n",
      "        [345, 355],\n",
      "        [346, 347],\n",
      "        [346, 352],\n",
      "        [347, 348],\n",
      "        [347, 356],\n",
      "        [348, 351],\n",
      "        [348, 349],\n",
      "        [348, 350],\n",
      "        [349, 350],\n",
      "        [349, 357],\n",
      "        [349, 358],\n",
      "        [350, 359],\n",
      "        [350, 360],\n",
      "        [351, 352],\n",
      "        [352, 361],\n",
      "        [352, 362],\n",
      "        [363, 364],\n",
      "        [363, 372],\n",
      "        [364, 365],\n",
      "        [365, 366],\n",
      "        [366, 367],\n",
      "        [367, 368],\n",
      "        [367, 371],\n",
      "        [368, 369],\n",
      "        [368, 373],\n",
      "        [369, 370],\n",
      "        [370, 371],\n",
      "        [371, 374]])\n",
      "sc_idx:\n",
      " tensor([ 0,  0,  0,  ..., 19, 19, 19])\n",
      "sc_pairs_idx:\n",
      " tensor([[  9,   0],\n",
      "        [  9,   1],\n",
      "        [  9,   2],\n",
      "        ...,\n",
      "        [374, 368],\n",
      "        [374, 370],\n",
      "        [374, 371]])\n",
      "sc_types:\n",
      " tensor([0, 4, 6,  ..., 6, 3, 0])\n",
      "sc_vals:\n",
      " tensor([ 1.9866, -0.5538, -0.3553,  ..., -0.3705, -0.1089,  3.4257])\n"
     ]
    }
   ],
   "source": [
    "b_dict = dict(x=batch[0][0], \n",
    "              e=batch[0][1], \n",
    "              sc_e=batch[0][2], \n",
    "              sc_m=batch[0][3], \n",
    "              node_idx=batch[0][4], \n",
    "              pairs_idx=batch[0][5], \n",
    "              sc_idx=batch[0][6], \n",
    "              sc_pairs_idx=batch[0][7], \n",
    "              sc_types=batch[0][8], \n",
    "              sc_vals=batch[1])\n",
    "for k,v in b_dict.items(): print(f'{k}:\\n {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "def group_mean_log_mae(y_true, y_pred, types):\n",
    "    proc = lambda x: x.cpu().numpy().ravel() \n",
    "    y_true, y_pred, types = proc(y_true), proc(y_pred), proc(types)\n",
    "    y_true = SC_MEAN + y_true * SC_STD\n",
    "    y_pred = SC_MEAN + y_pred * SC_STD\n",
    "    maes = pd.Series(y_true - y_pred).abs().groupby(types).mean()\n",
    "    return np.log(maes).mean()\n",
    "\n",
    "class GroupMeanLogMAE(Callback):\n",
    "    _order = -20 #Needs to run before the recorder\n",
    "\n",
    "    def __init__(self, learn, **kwargs): self.learn = learn\n",
    "    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['group_mean_log_mae'])\n",
    "    def on_epoch_begin(self, **kwargs): self.input, self.output, self.target = [], [], []\n",
    "    \n",
    "    def on_batch_end(self, last_target, last_output, last_input, train, **kwargs):\n",
    "        if not train:\n",
    "            self.input.append(last_input[-1])\n",
    "            self.output.append(last_output)\n",
    "            self.target.append(last_target)\n",
    "                \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        if (len(self.input) > 0) and (len(self.output) > 0):\n",
    "            inputs = torch.cat(self.input)\n",
    "            preds = torch.cat(self.output)\n",
    "            target = torch.cat(self.target)\n",
    "            metric = group_mean_log_mae(preds, target, inputs)\n",
    "            return add_metrics(last_metrics, [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd, batch_norm, act = 0, True, nn.ReLU(True)\n",
    "stride, update_steps, proc_steps = 5, 5, 10\n",
    "n_x, n_h, n_e, n_sc_e, n_sc_m = N_ATOM_FEATURES, 150, N_EDGE_FEATURES, N_SC_EDGE_FEATURES, N_SC_MOL_FEATURES\n",
    "preproc_net_args = dict(layers=[], act=act, dropout=[], batch_norm=batch_norm, out_act=nn.Tanh())\n",
    "enn_args = dict(layers=3*[n_h], act=act, dropout=3*[0.0], batch_norm=batch_norm)\n",
    "R_net_args = dict(pre_layers=[1000], post_layers=[500], act=act, dropout=[0.0, 0.0], batch_norm=batch_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(100)\n",
    "model = MPNN(n_x, n_h, n_e, n_sc_e, n_sc_m, stride, update_steps, proc_steps, preproc_net_args, enn_args, R_net_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNN(\n",
      "  (preproc_net): FullyConnectedNet(\n",
      "    (layers): Sequential(\n",
      "      (0): Linear(in_features=20, out_features=150, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (M): EdgeNetwork(\n",
      "    (adj_net): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=8, out_features=150, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): Linear(in_features=150, out_features=150, bias=True)\n",
      "        (4): ReLU(inplace)\n",
      "        (5): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): Linear(in_features=150, out_features=150, bias=True)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (9): Linear(in_features=150, out_features=750, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (sc_adj_net): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=150, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): Linear(in_features=150, out_features=150, bias=True)\n",
      "        (4): ReLU(inplace)\n",
      "        (5): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): Linear(in_features=150, out_features=150, bias=True)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (9): Linear(in_features=150, out_features=750, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (U): GRUUpdate(\n",
      "    (gru): GRUCell(150, 150)\n",
      "  )\n",
      "  (R): Set2SetOutput(\n",
      "    (R_proj): Linear(in_features=170, out_features=150, bias=True)\n",
      "    (R_proc): Set2Set(\n",
      "      (lstm): HiddenLSTMCell()\n",
      "    )\n",
      "    (R_write): MyCustomHead(\n",
      "      (preproc): Sequential(\n",
      "        (0): Linear(in_features=622, out_features=1000, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): Dropout(p=0.04)\n",
      "        (4): Linear(in_features=1000, out_features=750, bias=True)\n",
      "        (5): ReLU(inplace)\n",
      "        (6): BatchNorm1d(750, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): Dropout(p=0.03)\n",
      "      )\n",
      "      (postproc): ModuleList(\n",
      "        (0): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=750, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Dropout(p=0.02)\n",
      "            (3): Linear(in_features=500, out_features=250, bias=True)\n",
      "            (4): ReLU(inplace)\n",
      "            (5): Dropout(p=0.01)\n",
      "            (6): Linear(in_features=250, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (1): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=750, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Dropout(p=0.02)\n",
      "            (3): Linear(in_features=500, out_features=250, bias=True)\n",
      "            (4): ReLU(inplace)\n",
      "            (5): Dropout(p=0.01)\n",
      "            (6): Linear(in_features=250, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (2): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=750, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Dropout(p=0.02)\n",
      "            (3): Linear(in_features=500, out_features=250, bias=True)\n",
      "            (4): ReLU(inplace)\n",
      "            (5): Dropout(p=0.01)\n",
      "            (6): Linear(in_features=250, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (3): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=750, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Dropout(p=0.02)\n",
      "            (3): Linear(in_features=500, out_features=250, bias=True)\n",
      "            (4): ReLU(inplace)\n",
      "            (5): Dropout(p=0.01)\n",
      "            (6): Linear(in_features=250, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (4): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=750, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Dropout(p=0.02)\n",
      "            (3): Linear(in_features=500, out_features=250, bias=True)\n",
      "            (4): ReLU(inplace)\n",
      "            (5): Dropout(p=0.01)\n",
      "            (6): Linear(in_features=250, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (5): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=750, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Dropout(p=0.02)\n",
      "            (3): Linear(in_features=500, out_features=250, bias=True)\n",
      "            (4): ReLU(inplace)\n",
      "            (5): Dropout(p=0.01)\n",
      "            (6): Linear(in_features=250, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (6): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=750, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Dropout(p=0.02)\n",
      "            (3): Linear(in_features=500, out_features=250, bias=True)\n",
      "            (4): ReLU(inplace)\n",
      "            (5): Dropout(p=0.01)\n",
      "            (6): Linear(in_features=250, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (7): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=750, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Dropout(p=0.02)\n",
      "            (3): Linear(in_features=500, out_features=250, bias=True)\n",
      "            (4): ReLU(inplace)\n",
      "            (5): Dropout(p=0.01)\n",
      "            (6): Linear(in_features=250, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "tensor([-0.0357,  0.0161,  0.0008,  ...,  0.0117, -0.1415,  0.1484],\n",
      "       grad_fn=<IndexPutBackward>)\n",
      "torch.Size([1144])\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(model(*batch[0]))\n",
    "print(model(*batch[0]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(db, model, metrics=[mean_absolute_error], callback_fns=GroupMeanLogMAE, \n",
    "                wd=wd, loss_func=root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(start_lr=1e-6, end_lr=1.0, num_it=100, stop_div=True)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='19' class='' max='20', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      95.00% [19/20 1:26:38<04:33]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>group_mean_log_mae</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.040078</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.022797</td>\n",
       "      <td>-0.317368</td>\n",
       "      <td>04:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.039981</td>\n",
       "      <td>0.036785</td>\n",
       "      <td>0.023633</td>\n",
       "      <td>-0.403641</td>\n",
       "      <td>04:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.036716</td>\n",
       "      <td>0.031744</td>\n",
       "      <td>0.022062</td>\n",
       "      <td>-0.339929</td>\n",
       "      <td>04:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.034747</td>\n",
       "      <td>0.026544</td>\n",
       "      <td>0.018242</td>\n",
       "      <td>-0.602482</td>\n",
       "      <td>04:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.031141</td>\n",
       "      <td>0.024579</td>\n",
       "      <td>0.015550</td>\n",
       "      <td>-0.685172</td>\n",
       "      <td>04:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.025579</td>\n",
       "      <td>0.023645</td>\n",
       "      <td>0.015542</td>\n",
       "      <td>-0.704422</td>\n",
       "      <td>04:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.024146</td>\n",
       "      <td>0.023972</td>\n",
       "      <td>0.014393</td>\n",
       "      <td>-0.793374</td>\n",
       "      <td>04:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021563</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.012977</td>\n",
       "      <td>-0.875626</td>\n",
       "      <td>04:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.019448</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>0.011329</td>\n",
       "      <td>-1.044839</td>\n",
       "      <td>04:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.018570</td>\n",
       "      <td>0.017831</td>\n",
       "      <td>0.010775</td>\n",
       "      <td>-1.034339</td>\n",
       "      <td>04:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.017304</td>\n",
       "      <td>0.017644</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>-1.048918</td>\n",
       "      <td>04:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.017031</td>\n",
       "      <td>0.015757</td>\n",
       "      <td>0.010140</td>\n",
       "      <td>-1.209002</td>\n",
       "      <td>04:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.015835</td>\n",
       "      <td>0.015178</td>\n",
       "      <td>0.009318</td>\n",
       "      <td>-1.288652</td>\n",
       "      <td>04:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.015054</td>\n",
       "      <td>0.013771</td>\n",
       "      <td>0.008788</td>\n",
       "      <td>-1.312725</td>\n",
       "      <td>04:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.014081</td>\n",
       "      <td>0.013076</td>\n",
       "      <td>0.008025</td>\n",
       "      <td>-1.421852</td>\n",
       "      <td>04:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.013457</td>\n",
       "      <td>0.012009</td>\n",
       "      <td>0.007568</td>\n",
       "      <td>-1.453608</td>\n",
       "      <td>04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.012033</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>-1.449153</td>\n",
       "      <td>04:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.012684</td>\n",
       "      <td>0.011237</td>\n",
       "      <td>0.007087</td>\n",
       "      <td>-1.535122</td>\n",
       "      <td>04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.012477</td>\n",
       "      <td>0.011658</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>-1.526248</td>\n",
       "      <td>04:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='3187', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with group_mean_log_mae value: -0.31736767292022705.\n",
      "Better model found at epoch 1 with group_mean_log_mae value: -0.40364134311676025.\n",
      "Better model found at epoch 3 with group_mean_log_mae value: -0.6024815440177917.\n",
      "Better model found at epoch 4 with group_mean_log_mae value: -0.6851716041564941.\n",
      "Better model found at epoch 5 with group_mean_log_mae value: -0.7044216394424438.\n",
      "Better model found at epoch 6 with group_mean_log_mae value: -0.7933740019798279.\n",
      "Better model found at epoch 7 with group_mean_log_mae value: -0.8756258487701416.\n",
      "Better model found at epoch 8 with group_mean_log_mae value: -1.0448390245437622.\n",
      "Better model found at epoch 10 with group_mean_log_mae value: -1.0489181280136108.\n",
      "Better model found at epoch 11 with group_mean_log_mae value: -1.2090023756027222.\n",
      "Better model found at epoch 12 with group_mean_log_mae value: -1.2886521816253662.\n",
      "Better model found at epoch 13 with group_mean_log_mae value: -1.3127251863479614.\n",
      "Better model found at epoch 14 with group_mean_log_mae value: -1.4218523502349854.\n",
      "Better model found at epoch 15 with group_mean_log_mae value: -1.4536082744598389.\n",
      "Better model found at epoch 17 with group_mean_log_mae value: -1.5351216793060303.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-aa680bc2a0a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m learn.fit_one_cycle(20, max_lr=1e-3, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n\u001b[0;32m----> 2\u001b[0;31m                                                                   monitor='group_mean_log_mae',  name='mpnn1')])\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\n\u001b[0;32m--> 191\u001b[0;31m             callbacks=self.callbacks+callbacks)\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, data, callbacks, metrics)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpg2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(20, max_lr=1e-3, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='group_mean_log_mae',  name='mpnn1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_losses(skip_start=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 40:18 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>group_mean_log_mae</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.015523</td>\n",
       "      <td>0.016465</td>\n",
       "      <td>0.010963</td>\n",
       "      <td>-1.053521</td>\n",
       "      <td>03:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.016273</td>\n",
       "      <td>0.015719</td>\n",
       "      <td>0.010522</td>\n",
       "      <td>-1.095065</td>\n",
       "      <td>03:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.015880</td>\n",
       "      <td>0.016411</td>\n",
       "      <td>0.011262</td>\n",
       "      <td>-0.995226</td>\n",
       "      <td>03:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.014817</td>\n",
       "      <td>0.015940</td>\n",
       "      <td>0.010395</td>\n",
       "      <td>-1.136401</td>\n",
       "      <td>03:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.013509</td>\n",
       "      <td>0.013581</td>\n",
       "      <td>0.008907</td>\n",
       "      <td>-1.268452</td>\n",
       "      <td>04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.012550</td>\n",
       "      <td>0.012496</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>-1.350428</td>\n",
       "      <td>04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>0.012394</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>-1.407910</td>\n",
       "      <td>04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010631</td>\n",
       "      <td>0.013680</td>\n",
       "      <td>0.007637</td>\n",
       "      <td>-1.391376</td>\n",
       "      <td>04:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>0.006933</td>\n",
       "      <td>-1.536116</td>\n",
       "      <td>04:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009683</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.006870</td>\n",
       "      <td>-1.549529</td>\n",
       "      <td>04:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with group_mean_log_mae value: -1.0535207986831665.\n",
      "Better model found at epoch 1 with group_mean_log_mae value: -1.095064640045166.\n",
      "Better model found at epoch 3 with group_mean_log_mae value: -1.1364011764526367.\n",
      "Better model found at epoch 4 with group_mean_log_mae value: -1.2684519290924072.\n",
      "Better model found at epoch 5 with group_mean_log_mae value: -1.3504276275634766.\n",
      "Better model found at epoch 6 with group_mean_log_mae value: -1.4079095125198364.\n",
      "Better model found at epoch 8 with group_mean_log_mae value: -1.536116123199463.\n",
      "Better model found at epoch 9 with group_mean_log_mae value: -1.54952871799469.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, max_lr=6e-4, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='group_mean_log_mae',  name='mpnn2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_losses(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=1e-4, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='group_mean_log_mae',  name='mpnn3')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=1e-5, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='group_mean_log_mae',  name='mpnn4')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, _ = learn.get_preds()\n",
    "pred_test, _ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
