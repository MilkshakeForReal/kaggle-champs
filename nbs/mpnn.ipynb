{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fastai.tabular import *\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "from fastai.basic_data import DataBunch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "TYPES              = np.array(['1JHC', '2JHH', '1JHN', '2JHN', '2JHC', '3JHH', '3JHC', '3JHN'])\n",
    "TYPES_MAP          = {t: i for i, t in enumerate(TYPES)}\n",
    "SC_EDGE_FEATS      = ['type_0', 'type_1', 'type_2', 'type_3', 'type_4', 'type_5', 'type_6', 'type_7', 'dist',\n",
    "                      'dist_min_rad', 'dist_electro_neg_adj', 'normed_dist', 'diangle', 'cos_angle', \n",
    "                      'cos_angle0', 'cos_angle1']\n",
    "SC_MOL_FEATS       = ['type_0', 'type_1', 'type_2', 'type_3', 'type_4', 'type_5', 'type_6', 'type_7', 'dist',\n",
    "                      'dist_min_rad', 'dist_electro_neg_adj', 'normed_dist', 'diangle', 'cos_angle', \n",
    "                      'cos_angle0', 'cos_angle1', 'num_atoms', 'num_C_atoms', 'num_F_atoms', 'num_H_atoms', \n",
    "                      'num_N_atoms', 'num_O_atoms']\n",
    "N_EDGE_FEATURES    = 8\n",
    "N_SC_EDGE_FEATURES = 16\n",
    "N_SC_MOL_FEATURES  = 22\n",
    "N_ATOM_FEATURES    = 20\n",
    "N_TYPES            = len(TYPES)\n",
    "N_MOLS             = 130775\n",
    "SC_MEAN            = 16\n",
    "SC_STD             = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = '../tmp/'\n",
    "PATH = '../input/champs-processed-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_proc_df.csv', 'test_proc_df.csv', 'atom_df.csv', 'edge_df.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(PATH)\n",
    "files = [f for f in files if f.find('.csv') != -1]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(PATH+'train_proc_df.csv', index_col=0)\n",
    "test_df  = pd.read_csv(PATH+'test_proc_df.csv', index_col=0)\n",
    "atom_df  = pd.read_csv(PATH+'atom_df.csv', index_col=0)\n",
    "edge_df  = pd.read_csv(PATH+'edge_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['scalar_coupling_constant'] = (train_df['scalar_coupling_constant'] - SC_MEAN) / SC_STD\n",
    "train_df[['num_atoms', 'num_C_atoms', 'num_F_atoms', 'num_H_atoms', 'num_N_atoms', 'num_O_atoms']] /= 10\n",
    "test_df[['num_atoms', 'num_C_atoms', 'num_F_atoms', 'num_H_atoms', 'num_N_atoms', 'num_O_atoms']] /= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MPNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General dense feedforward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_init(m): pass\n",
    "#     if type(m) == nn.BatchNorm1d: \n",
    "#         nn.init.ones_(m.weight)\n",
    "#         nn.init.zeros_(m.bias)\n",
    "\n",
    "def selu_weights_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        fan_in = m.weight.size(1)\n",
    "        m.weight.data.normal_(0.0, 1.0 / math.sqrt(fan_in))\n",
    "        m.bias.fill_(0.0)\n",
    "    bn_init(m)\n",
    "\n",
    "def relu_weights_init(m): pass\n",
    "#     if type(m) == nn.Linear:\n",
    "#         nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "#         m.bias.data.fill_(0.0)\n",
    "    bn_init(m)\n",
    "\n",
    "def hidden_layer(n_in, n_out, batch_norm, dropout, act=None):\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(n_in, n_out))\n",
    "    if act: layers.append(act)\n",
    "    if batch_norm: layers.append(nn.BatchNorm1d(n_out))\n",
    "    if dropout != 0: layers.append(nn.Dropout(dropout))\n",
    "    return layers\n",
    "\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input, n_output=None, layers=[], act=nn.ReLU(True), dropout=[], batch_norm=False, \n",
    "                 out_act=None, final_bn=False):\n",
    "        super().__init__()\n",
    "        sizes = [n_input] + layers\n",
    "        if n_output: \n",
    "            sizes += [n_output]\n",
    "            dropout += [0.0]\n",
    "        layers_ = []\n",
    "        for i, (n_in, n_out, dr) in enumerate(zip(sizes[:-1], sizes[1:], dropout)):\n",
    "            act_ = act if i < len(layers) else out_act\n",
    "            batch_norm_ = batch_norm if i < len(layers) else final_bn\n",
    "            layers_ += hidden_layer(n_in, n_out, batch_norm_, dr, act_)      \n",
    "        self.layers = nn.Sequential(*layers_)\n",
    "        if type(act) == nn.SELU: self.layers.apply(selu_weights_init)\n",
    "        else: self.layers.apply(relu_weights_init)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LSTM cell as describedi in the set2set paper (https://arxiv.org/pdf/1511.06391.pdf). Doesn't take any inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenLSTMCell(nn.Module):\n",
    "    \"\"\"Implements the LSTM cell update described in the sec 4.2 of https://arxiv.org/pdf/1511.06391.pdf.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_h_out):\n",
    "        \"\"\"This LSTM cell takes no external 'x' inputs, but has a hidden state appended with the \n",
    "        readout from a content based attention mechanism. Therefore the hidden state is of a dimension\n",
    "        that is two times the number of nodes in the set.\"\"\"\n",
    "        super().__init__()\n",
    "        self.n_h_out, self.n_h = n_h_out, n_h_out * 2 \n",
    "        self.w_h = nn.Parameter(torch.Tensor(self.n_h, n_h_out * 4))\n",
    "        self.b = nn.Parameter(torch.Tensor(n_h_out * 4))\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "                # nn.init.orthogonal_(p.data)\n",
    "            else: \n",
    "                nn.init.zeros_(p.data)\n",
    "                # initialize the forget gate bias to 1\n",
    "                p.data[self.n_h_out:self.n_h_out*2] = torch.ones(self.n_h_out)\n",
    "        \n",
    "    def forward(self, h_prev, c_prev):\n",
    "        \"\"\"Takes previuos hidden and cell states as arguments and performs a \n",
    "        single LSTM step using no external input.\n",
    "        \"\"\"\n",
    "        n_h_ = self.n_h_out # number of output hidden states\n",
    "        # batch the computations into a single matrix multiplication\n",
    "        gates = h_prev @ self.w_h + self.b\n",
    "        i_g, f_g, g, o_g = (\n",
    "            torch.sigmoid(gates[:, :n_h_]), # input\n",
    "            torch.sigmoid(gates[:, n_h_:n_h_*2]), # forget\n",
    "            torch.tanh(gates[:, n_h_*2:n_h_*3]),\n",
    "            torch.sigmoid(gates[:, n_h_*3:]), # output\n",
    "        )\n",
    "        c = f_g * c_prev + i_g * g\n",
    "        h = o_g * torch.tanh(c)\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set2set module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Set2Set(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted from: https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric\\\n",
    "        /nn/glob/set2set.html#Set2Set\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, proc_steps, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = 2 * in_channels\n",
    "        self.proc_steps = proc_steps\n",
    "        self.lstm = torch.nn.LSTM(self.out_channels, self.in_channels, n_layers)\n",
    "        self.init_q_star = nn.Parameter(torch.Tensor(1, self.out_channels))\n",
    "        self.init_h = nn.Parameter(torch.Tensor(n_layers, 1, self.in_channels))\n",
    "        self.init_c = nn.Parameter(torch.Tensor(n_layers, 1, self.in_channels))\n",
    "        nn.init.zeros_(self.init_q_star)\n",
    "        nn.init.zeros_(self.init_h)\n",
    "        nn.init.zeros_(self.init_c)\n",
    "\n",
    "    def forward(self, x, node_idx):\n",
    "        \"\"\"\n",
    "        x - input tensor of shape (batch_size * n_nodes, in_channels).\n",
    "        - node_idx: tensor of shape (batch_size * n_nodes) mapping each\n",
    "            node to its corresponding index in the batch.\n",
    "        \"\"\"\n",
    "        batch_size = node_idx.max().item() + 1\n",
    "        h = (self.init_h.expand(-1, batch_size, -1).contiguous(),\n",
    "             self.init_c.expand(-1, batch_size, -1).contiguous())\n",
    "        q_star = self.init_q_star.expand(batch_size, -1).contiguous()\n",
    "        for i in range(self.proc_steps):\n",
    "            q, h = self.lstm(q_star.unsqueeze(0), h)\n",
    "            q = q.view(batch_size, self.in_channels)\n",
    "            e = (x * q[node_idx]).sum(dim=-1, keepdim=True)\n",
    "            a = softmax(e, node_idx, num=batch_size)\n",
    "            r = scatter_add(a * x, node_idx, num=batch_size) # sum 'a*x' over nodes \n",
    "            q_star = torch.cat([q, r], dim=-1)\n",
    "            \n",
    "        return q_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge network message function as described in the MPNN paper (https://arxiv.org/pdf/1704.01212.pdf). Adds in seperate edge network to allow messages to flow along scalar coupling edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeNetwork(nn.Module):\n",
    "    def __init__(self, n_h, n_e, n_sc_e, stride=5, net_args={}):\n",
    "        super().__init__()\n",
    "        stride = n_h\n",
    "        self.n_h, self.stride = n_h, stride\n",
    "        self.adj_net = FullyConnectedNet(n_e, n_h*stride, **net_args)\n",
    "        self.sc_adj_net = FullyConnectedNet(n_sc_e, n_h*stride, **net_args)\n",
    "        self.b = nn.Parameter(torch.Tensor(n_h)) # bias for the message function\n",
    "        nn.init.zeros_(self.b)\n",
    "    \n",
    "    def forward(self, h, e, sc_e, pairs_idx, sc_pairs_idx, t=0):\n",
    "        \"\"\"\n",
    "        Compute message vector m_t given the previuos hidden state\n",
    "        h_t-1 and edge features e.\n",
    "        - h: tensor of hidden states of shape (batch_size * n_nodes, n_h)\n",
    "        - e: tensor of edge features of shape (batch_size * n_edges, n_e).\n",
    "        - sc_e: tensor of scalar coupling edge features of shape \n",
    "            (batch_size * n_sc, n_sc_e).\n",
    "        - pairs_idx: tensor of shape (batch_size * n_edges, 2) mapping atom \n",
    "            indexes (first column) to the other atom indexes they form a \n",
    "            bond with (second column). Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_pairs_idx: tensor of shape (batch_size * n_sc, 2) containing atom \n",
    "            indices of the atoms for which the scalar coupling constant\n",
    "            need to be predicted. Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - t: update iteration. \n",
    "        \"\"\"\n",
    "        # compute 'A(e)'\n",
    "        if t==0: \n",
    "            self.a_mat = self.get_a_mat(self.adj_net(e))\n",
    "            self.a_sc_mat = self.get_a_mat(self.sc_adj_net(sc_e))\n",
    "            \n",
    "        # compute 'm_{i} = sum_{j in N(i)}(A_{ij}h_{j})' for all nodes 'i'\n",
    "        m = self.add_message(torch.zeros_like(h), self.a_mat, h, pairs_idx)\n",
    "        m = self.add_message(m, self.a_sc_mat, h, sc_pairs_idx)\n",
    "        return m + self.b # add message bias\n",
    "    \n",
    "    def get_a_mat(self, a_vect):\n",
    "        return a_vect.view(-1, self.n_h, self.stride) / (self.stride ** .5)\n",
    "    \n",
    "    def add_message(self, m, a, h, pairs_idx):\n",
    "        # transform 'pairs_idx' and 'a' to make messages go both in to and out of all nodes\n",
    "        in_out_idx = torch.cat((pairs_idx, pairs_idx[:, [1, 0]]))\n",
    "        a_ = torch.cat((a, a)) \n",
    "        \n",
    "        # select the 'h_{j}' feeding into the 'm_{i}'\n",
    "        h_in = h.index_select(0, in_out_idx[:,1])\n",
    "        \n",
    "        # do the matrix multiplication 'A_{ij}h_{j}'\n",
    "        # h_unfolded = F.pad(h_in, 2*(self.stride//2, )).unfold(1, self.stride, 1)\n",
    "        # ah = (h_unfolded * a_).sum(-1) \n",
    "        ah = (h_in.unsqueeze(1) @ a_).squeeze(1)\n",
    "        \n",
    "        # Sum up all 'A_{ij}h_{j}' per node 'i'\n",
    "        return m.scatter_add(0, in_out_idx[:,0,None].repeat(1, self.n_h), ah)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GRU update function as described in the MPNN paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUUpdate(nn.Module):\n",
    "    def __init__(self, n_h):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRUCell(n_h, n_h)\n",
    "        \n",
    "    def forward(self, m, h_prev):\n",
    "        \"\"\"\n",
    "        Update hidden state h.\n",
    "        - h_prev is vector of hidden states of shape (batch_size * n_nodes, n_h)\n",
    "        - m is vector of messages of shape (batch_size * n_nodes, n_h)\n",
    "        \"\"\"\n",
    "        return self.gru(m, h_prev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom readout network following th set2set processing stage. Allows some final specialization/fine-tuning for each scalar coupling type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomHead(nn.Module):\n",
    "    def __init__(self, n_input, n_output, pre_layers=[], post_layers=[], act=nn.ReLU(True), dropout=[], \n",
    "                 batch_norm=False):\n",
    "        super().__init__()\n",
    "        n_pre_layers = len(pre_layers)\n",
    "        self.preproc = FullyConnectedNet(n_input, None, pre_layers, act, dropout[:n_pre_layers], batch_norm)\n",
    "        self.postproc = nn.ModuleList([\n",
    "            FullyConnectedNet(pre_layers[-1], n_output, post_layers, act, dropout[n_pre_layers:], batch_norm=False)\n",
    "            for _ in range(N_TYPES)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x, sc_types):\n",
    "        x_ = self.preproc(x)\n",
    "        y = torch.zeros(sc_types.size(0), device=x.device)\n",
    "        for i in range(N_TYPES):\n",
    "            if torch.any(sc_types == i): \n",
    "                y[sc_types == i] = self.postproc[i](x_[sc_types == i]).view(-1)\n",
    "        return y        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines all the the components of the readout function described in the MPNN network using set2set processing and the scalar coupling type customized head. Also adds in some skip connections to final node states and scalar coupling input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Set2SetOutput(nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_sc_m, proc_steps, net_args):\n",
    "        super().__init__()\n",
    "        self.R_proj = nn.Linear(n_h + n_x, n_h)\n",
    "        self.R_proc = Set2Set(n_h, proc_steps)\n",
    "        self.R_write = MyCustomHead((4 * n_h) + n_sc_m, 1, **net_args)\n",
    "    \n",
    "    def forward(self, h, x, sc_m, node_idx, sc_idx, sc_pairs_idx, sc_types):\n",
    "        \"\"\"\n",
    "        Make prediction.\n",
    "        - h is vector of hidden states of shape (batch_size * n_nodes, n_h).\n",
    "        - x is vector of input features of shape (batch_size * n_nodes, n_x).\n",
    "        - sc_m: tensor of scalar coupling molecule level features of shape \n",
    "            (batch_size * n_sc, n_sc_m).\n",
    "        - node_idx: tensor of shape (batch_size * n_nodes) mapping each\n",
    "            node to its corresponding index in the batch.\n",
    "        - sc_idx: tensor of shape (batch_size * n_sc) mapping each\n",
    "            scalar coupling constant to its corresponding index in the batch.\n",
    "        - sc_pairs_idx: tensor of shape (batch_size * n_sc, 2) containing atom \n",
    "            indices of the atoms for which the scalar coupling constant\n",
    "            need to be predicted. Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_types: tensor of shape (batch_size * n_sc) containing the scalar \n",
    "            coupling type of each observation. \n",
    "        \"\"\"\n",
    "        m = self.R_proj(torch.cat([h, x], dim=1))\n",
    "        q = self.R_proc(m, node_idx)\n",
    "        \n",
    "        # introduce skip connection to final node states of scalar coupling atoms\n",
    "        inp = torch.cat([\n",
    "            q.index_select(0, sc_idx),\n",
    "            h.index_select(0, sc_pairs_idx[:,0]),\n",
    "            h.index_select(0, sc_pairs_idx[:,1]),\n",
    "            sc_m\n",
    "        ], dim=-1)\n",
    "        y = self.R_write(inp, sc_types)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines the edge-network message (M), GRU update (U) and set2set readout (R) functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNN(nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_e, n_sc_e, n_sc_m, stride=5, update_steps=3, proc_steps=10, \n",
    "                 preproc_net_args={}, enn_args={}, R_net_args={}):\n",
    "        super().__init__()\n",
    "        self.preproc_net = FullyConnectedNet(n_x, n_h, **preproc_net_args)\n",
    "        self.M = EdgeNetwork(n_h, n_e, n_sc_e, stride, enn_args)\n",
    "        self.U = GRUUpdate(n_h)\n",
    "        self.R = Set2SetOutput(n_x, n_h, n_sc_m, proc_steps, R_net_args)\n",
    "        self.update_steps = update_steps\n",
    "        \n",
    "    def forward(self, x, e, sc_e, sc_m, node_idx, pairs_idx, sc_idx, sc_pairs_idx, sc_types):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: tensor of node features of shape (batch_size * n_nodes, n_x).\n",
    "        - e: tensor of edge features of shape (batch_size * n_edges, n_e).\n",
    "        - sc_e: tensor of scalar coupling edge features of shape \n",
    "            (batch_size * n_sc, n_sc_e).\n",
    "        - sc_m: tensor of scalar coupling molecule level features of shape \n",
    "            (batch_size * n_sc, n_sc_m).\n",
    "        - node_idx: tensor of shape (batch_size * n_nodes) mapping each\n",
    "            node to its corresponding index in the batch.\n",
    "        - pairs_idx: tensor of shape (batch_size * n_edges, 2) mapping atom \n",
    "            indexes (first column) to the other atom indexes they form a \n",
    "            bond with (second column). Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_idx: tensor of shape (batch_size * n_sc) mapping each\n",
    "            scalar coupling constant to its corresponding index in the batch.\n",
    "        - sc_pairs_idx: tensor of shape (batch_size * n_sc, 2) containing atom \n",
    "            indices of the atoms for which the scalar coupling constant\n",
    "            need to be predicted. Atom indices are unique to the entire\n",
    "            batch.\n",
    "        - sc_types: tensor of shape (batch_size * n_sc) containing the scalar \n",
    "            coupling type of each observation. \n",
    "        \"\"\"\n",
    "        h = self.preproc_net(x)\n",
    "        for t in range(self.update_steps):\n",
    "            m = self.M(h, e, sc_e, pairs_idx, sc_pairs_idx, t)\n",
    "            h = self.U(m, h)\n",
    "        y = self.R(h, x, sc_m, node_idx, sc_idx, sc_pairs_idx, sc_types)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=100):\n",
    "    # python RNG\n",
    "    random.seed(seed)\n",
    "\n",
    "    # pytorch RNGs\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # numpy RNG\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_ids = train_df['molecule_id'].unique()\n",
    "n_obs = len(mol_ids)\n",
    "split = int(n_obs*0.75)\n",
    "set_seed(100)\n",
    "mol_ids_ = np.random.choice(mol_ids, size=n_obs, replace=False)\n",
    "train_mol_ids, val_mol_ids = pd.Series(mol_ids_[:split]), pd.Series(mol_ids_[split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_mol_sc = train_df.groupby('molecule_id')\n",
    "test_gb_mol_sc = test_df.groupby('molecule_id')\n",
    "gb_mol_atom = atom_df.groupby('molecule_id')\n",
    "gb_mol_edge = edge_df.groupby('molecule_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the pytorch dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_np(x):\n",
    "    sz = len(x), len(np.unique(x))\n",
    "    x_one_hot = np.zeros(sz, dtype=np.long)\n",
    "    x_one_hot[np.arange(sz[0]), x] = 1\n",
    "    return x_one_hot\n",
    "\n",
    "class MoleculeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, mol_ids, gb_mol_sc, gb_mol_atom, gb_mol_edge):\n",
    "        self.n = len(mol_ids)\n",
    "        self.mol_ids = mol_ids\n",
    "        self.gb_mol_sc = gb_mol_sc\n",
    "        self.gb_mol_atom = gb_mol_atom\n",
    "        self.gb_mol_edge = gb_mol_edge\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.gb_mol_sc.get_group(self.mol_ids[idx]), \n",
    "                self.gb_mol_atom.get_group(self.mol_ids[idx]), \n",
    "                self.gb_mol_edge.get_group(self.mol_ids[idx]))\n",
    "\n",
    "def np_lst_to_torch(arr_lst, dtype=torch.float):\n",
    "    return torch.from_numpy(np.ascontiguousarray(np.concatenate(arr_lst))).type(dtype)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch_size, n_atom_sum = len(batch), 0\n",
    "    x, e, sc_e, sc_m, sc_types, sc_vals = [], [], [], [], [], []\n",
    "    node_idx, pairs_idx, sc_pairs_idx, sc_idx = [], [], [], []\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        sc_df, atom_df, edge_df = batch[b]\n",
    "        n_atoms, n_sc = len(atom_df), len(sc_df)\n",
    "        \n",
    "        x.append(atom_df.drop(columns='molecule_id').values)\n",
    "        e.append(edge_df.drop(columns=['idx_0', 'idx_1', 'molecule_id']).values)\n",
    "        sc_e.append(sc_df[SC_EDGE_FEATS].values)\n",
    "        sc_m.append(sc_df[SC_MOL_FEATS].values)\n",
    "        sc_types.append(sc_df['type'].values)\n",
    "        sc_vals.append(sc_df['scalar_coupling_constant'].values)\n",
    "        \n",
    "        node_idx.append(np.repeat(b, n_atoms))\n",
    "        sc_idx.append(np.repeat(b, n_sc))\n",
    "        pairs_idx.append(edge_df[['idx_0', 'idx_1']].values + n_atom_sum)\n",
    "        sc_pairs_idx.append(sc_df[['atom_index_0', 'atom_index_1']].values + n_atom_sum)\n",
    "        \n",
    "        n_atom_sum += n_atoms\n",
    "    \n",
    "    x, e = np_lst_to_torch(x), np_lst_to_torch(e), \n",
    "    sc_e, sc_m = np_lst_to_torch(sc_e), np_lst_to_torch(sc_m)\n",
    "    sc_vals, sc_types = np_lst_to_torch(sc_vals), np_lst_to_torch(sc_types, torch.long)\n",
    "    node_idx = np_lst_to_torch(node_idx, torch.long)\n",
    "    sc_idx = np_lst_to_torch(sc_idx, torch.long)\n",
    "    pairs_idx = np_lst_to_torch(pairs_idx, torch.long)\n",
    "    sc_pairs_idx = np_lst_to_torch(sc_pairs_idx, torch.long)\n",
    "    \n",
    "    return (x, e, sc_e, sc_m, node_idx, pairs_idx, sc_idx, sc_pairs_idx, sc_types), sc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MoleculeDataset(train_mol_ids, gb_mol_sc, gb_mol_atom, gb_mol_edge)\n",
    "val_ds   = MoleculeDataset(val_mol_ids, gb_mol_sc, gb_mol_atom, gb_mol_edge)\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "val_dl   = DataLoader(val_ds, batch_size, num_workers=8, drop_last=True)\n",
    "db = DataBunch(train_dl, val_dl, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([375, 20])\n",
      "torch.Size([387, 8])\n",
      "torch.Size([1144, 16])\n",
      "torch.Size([1144, 22])\n",
      "torch.Size([375])\n",
      "torch.Size([387, 2])\n",
      "torch.Size([1144])\n",
      "torch.Size([1144, 2])\n",
      "torch.Size([1144])\n",
      "torch.Size([1144])\n"
     ]
    }
   ],
   "source": [
    "for el in batch[0]: print(el.size())\n",
    "print(batch[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " tensor([[0.0000, 1.0000, 0.0000,  ..., 1.2037, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 1.3965, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 1.2018, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 1.0617, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 1.0785, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 1.0802, 0.0000, 0.0000]])\n",
      "e:\n",
      " tensor([[ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  1.5316,  1.3957],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0947, -0.7402],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0948, -0.7397],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.3961,  0.9587],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.3049,  0.2646],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0802, -1.4458]])\n",
      "sc_e:\n",
      " tensor([[ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.3127],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.3438,  0.7481, -0.7354],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.4088, -0.8878],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.9860, -0.9776],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.4963,  0.8363,  0.8911],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.4963]])\n",
      "sc_m:\n",
      " tensor([[1.0000, 0.0000, 0.0000,  ..., 1.6000, 0.0000, 0.1000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.6000, 0.0000, 0.1000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.6000, 0.0000, 0.1000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3000, 0.1000, 0.1000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3000, 0.1000, 0.1000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 0.3000, 0.1000, 0.1000]])\n",
      "node_idx:\n",
      " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "        12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "        15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "        17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "        18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])\n",
      "pairs_idx:\n",
      " tensor([[  0,   1],\n",
      "        [  0,   9],\n",
      "        [  0,  10],\n",
      "        [  0,  11],\n",
      "        [  1,   2],\n",
      "        [  1,   3],\n",
      "        [  1,  12],\n",
      "        [  2,  13],\n",
      "        [  2,  14],\n",
      "        [  2,  15],\n",
      "        [  3,   4],\n",
      "        [  4,  16],\n",
      "        [  4,   7],\n",
      "        [  4,   5],\n",
      "        [  5,   6],\n",
      "        [  5,  17],\n",
      "        [  5,  18],\n",
      "        [  6,   7],\n",
      "        [  6,  19],\n",
      "        [  6,  20],\n",
      "        [  7,   8],\n",
      "        [  7,  21],\n",
      "        [  8,  22],\n",
      "        [  8,  23],\n",
      "        [  8,  24],\n",
      "        [ 25,  26],\n",
      "        [ 25,  34],\n",
      "        [ 25,  35],\n",
      "        [ 25,  36],\n",
      "        [ 26,  27],\n",
      "        [ 26,  31],\n",
      "        [ 27,  28],\n",
      "        [ 28,  29],\n",
      "        [ 28,  32],\n",
      "        [ 29,  30],\n",
      "        [ 29,  37],\n",
      "        [ 30,  31],\n",
      "        [ 30,  38],\n",
      "        [ 32,  33],\n",
      "        [ 39,  40],\n",
      "        [ 39,  47],\n",
      "        [ 39,  48],\n",
      "        [ 39,  49],\n",
      "        [ 40,  41],\n",
      "        [ 40,  42],\n",
      "        [ 41,  42],\n",
      "        [ 41,  50],\n",
      "        [ 41,  51],\n",
      "        [ 42,  46],\n",
      "        [ 42,  43],\n",
      "        [ 43,  44],\n",
      "        [ 43,  52],\n",
      "        [ 43,  53],\n",
      "        [ 44,  45],\n",
      "        [ 44,  54],\n",
      "        [ 44,  55],\n",
      "        [ 45,  46],\n",
      "        [ 46,  56],\n",
      "        [ 46,  57],\n",
      "        [ 58,  59],\n",
      "        [ 58,  67],\n",
      "        [ 58,  68],\n",
      "        [ 58,  69],\n",
      "        [ 59,  60],\n",
      "        [ 59,  65],\n",
      "        [ 60,  61],\n",
      "        [ 61,  62],\n",
      "        [ 61,  63],\n",
      "        [ 62,  70],\n",
      "        [ 63,  64],\n",
      "        [ 63,  71],\n",
      "        [ 64,  65],\n",
      "        [ 64,  72],\n",
      "        [ 65,  66],\n",
      "        [ 73,  74],\n",
      "        [ 73,  82],\n",
      "        [ 73,  83],\n",
      "        [ 73,  84],\n",
      "        [ 74,  75],\n",
      "        [ 74,  85],\n",
      "        [ 74,  86],\n",
      "        [ 75,  76],\n",
      "        [ 75,  78],\n",
      "        [ 75,  81],\n",
      "        [ 76,  87],\n",
      "        [ 76,  88],\n",
      "        [ 76,  77],\n",
      "        [ 77,  89],\n",
      "        [ 77,  90],\n",
      "        [ 77,  91],\n",
      "        [ 78,  79],\n",
      "        [ 78,  92],\n",
      "        [ 78,  93],\n",
      "        [ 79,  80],\n",
      "        [ 79,  81],\n",
      "        [ 79,  94],\n",
      "        [ 80,  96],\n",
      "        [ 80,  81],\n",
      "        [ 80,  95],\n",
      "        [ 81,  97],\n",
      "        [ 98,  99],\n",
      "        [ 98, 107],\n",
      "        [ 98, 108],\n",
      "        [ 98, 109],\n",
      "        [ 99, 100],\n",
      "        [ 99, 102],\n",
      "        [ 99, 110],\n",
      "        [100, 101],\n",
      "        [100, 102],\n",
      "        [100, 111],\n",
      "        [101, 112],\n",
      "        [102, 103],\n",
      "        [102, 106],\n",
      "        [103, 104],\n",
      "        [103, 113],\n",
      "        [103, 114],\n",
      "        [104, 105],\n",
      "        [104, 106],\n",
      "        [104, 115],\n",
      "        [105, 106],\n",
      "        [106, 116],\n",
      "        [117, 118],\n",
      "        [117, 126],\n",
      "        [117, 127],\n",
      "        [117, 128],\n",
      "        [118, 119],\n",
      "        [118, 124],\n",
      "        [119, 120],\n",
      "        [119, 129],\n",
      "        [120, 121],\n",
      "        [120, 123],\n",
      "        [121, 122],\n",
      "        [121, 130],\n",
      "        [121, 131],\n",
      "        [122, 132],\n",
      "        [123, 124],\n",
      "        [124, 125],\n",
      "        [133, 134],\n",
      "        [133, 142],\n",
      "        [133, 143],\n",
      "        [133, 144],\n",
      "        [134, 135],\n",
      "        [134, 145],\n",
      "        [134, 146],\n",
      "        [135, 136],\n",
      "        [135, 147],\n",
      "        [135, 148],\n",
      "        [136, 137],\n",
      "        [137, 141],\n",
      "        [137, 140],\n",
      "        [137, 138],\n",
      "        [138, 139],\n",
      "        [138, 149],\n",
      "        [138, 150],\n",
      "        [139, 151],\n",
      "        [139, 152],\n",
      "        [139, 153],\n",
      "        [140, 141],\n",
      "        [140, 154],\n",
      "        [140, 155],\n",
      "        [141, 156],\n",
      "        [141, 157],\n",
      "        [158, 159],\n",
      "        [158, 167],\n",
      "        [158, 168],\n",
      "        [158, 169],\n",
      "        [159, 160],\n",
      "        [159, 161],\n",
      "        [159, 170],\n",
      "        [160, 171],\n",
      "        [160, 161],\n",
      "        [161, 162],\n",
      "        [161, 165],\n",
      "        [162, 163],\n",
      "        [162, 172],\n",
      "        [162, 173],\n",
      "        [163, 164],\n",
      "        [164, 174],\n",
      "        [165, 166],\n",
      "        [165, 175],\n",
      "        [176, 177],\n",
      "        [176, 184],\n",
      "        [176, 185],\n",
      "        [176, 186],\n",
      "        [177, 178],\n",
      "        [177, 187],\n",
      "        [177, 188],\n",
      "        [178, 189],\n",
      "        [178, 182],\n",
      "        [178, 179],\n",
      "        [179, 180],\n",
      "        [179, 190],\n",
      "        [179, 191],\n",
      "        [180, 181],\n",
      "        [181, 192],\n",
      "        [181, 193],\n",
      "        [181, 194],\n",
      "        [182, 183],\n",
      "        [195, 196],\n",
      "        [195, 204],\n",
      "        [195, 205],\n",
      "        [195, 206],\n",
      "        [196, 197],\n",
      "        [196, 203],\n",
      "        [197, 198],\n",
      "        [197, 203],\n",
      "        [197, 207],\n",
      "        [198, 208],\n",
      "        [198, 199],\n",
      "        [198, 200],\n",
      "        [199, 200],\n",
      "        [199, 209],\n",
      "        [200, 201],\n",
      "        [200, 203],\n",
      "        [201, 210],\n",
      "        [201, 202],\n",
      "        [203, 211],\n",
      "        [212, 213],\n",
      "        [212, 221],\n",
      "        [212, 222],\n",
      "        [212, 223],\n",
      "        [213, 214],\n",
      "        [213, 215],\n",
      "        [213, 224],\n",
      "        [214, 225],\n",
      "        [214, 226],\n",
      "        [214, 227],\n",
      "        [215, 228],\n",
      "        [215, 219],\n",
      "        [215, 216],\n",
      "        [216, 217],\n",
      "        [216, 229],\n",
      "        [216, 230],\n",
      "        [217, 218],\n",
      "        [217, 219],\n",
      "        [217, 231],\n",
      "        [218, 219],\n",
      "        [219, 220],\n",
      "        [220, 232],\n",
      "        [220, 233],\n",
      "        [220, 234],\n",
      "        [235, 236],\n",
      "        [235, 244],\n",
      "        [235, 245],\n",
      "        [235, 246],\n",
      "        [236, 237],\n",
      "        [236, 240],\n",
      "        [236, 242],\n",
      "        [237, 248],\n",
      "        [237, 247],\n",
      "        [237, 238],\n",
      "        [238, 239],\n",
      "        [238, 249],\n",
      "        [238, 250],\n",
      "        [239, 240],\n",
      "        [240, 241],\n",
      "        [241, 251],\n",
      "        [242, 243],\n",
      "        [243, 252],\n",
      "        [253, 254],\n",
      "        [253, 262],\n",
      "        [254, 255],\n",
      "        [254, 263],\n",
      "        [255, 256],\n",
      "        [256, 257],\n",
      "        [256, 260],\n",
      "        [256, 261],\n",
      "        [257, 264],\n",
      "        [257, 259],\n",
      "        [257, 258],\n",
      "        [258, 259],\n",
      "        [258, 261],\n",
      "        [258, 265],\n",
      "        [259, 260],\n",
      "        [259, 266],\n",
      "        [260, 261],\n",
      "        [260, 267],\n",
      "        [261, 268],\n",
      "        [269, 270],\n",
      "        [269, 278],\n",
      "        [269, 279],\n",
      "        [269, 280],\n",
      "        [270, 271],\n",
      "        [270, 276],\n",
      "        [270, 281],\n",
      "        [271, 272],\n",
      "        [272, 282],\n",
      "        [272, 283],\n",
      "        [272, 273],\n",
      "        [273, 274],\n",
      "        [274, 275],\n",
      "        [274, 277],\n",
      "        [274, 284],\n",
      "        [275, 276],\n",
      "        [275, 285],\n",
      "        [275, 286],\n",
      "        [276, 277],\n",
      "        [276, 287],\n",
      "        [277, 288],\n",
      "        [277, 289],\n",
      "        [290, 291],\n",
      "        [290, 299],\n",
      "        [291, 292],\n",
      "        [291, 295],\n",
      "        [292, 293],\n",
      "        [292, 300],\n",
      "        [292, 301],\n",
      "        [293, 296],\n",
      "        [293, 302],\n",
      "        [293, 294],\n",
      "        [294, 295],\n",
      "        [294, 303],\n",
      "        [294, 304],\n",
      "        [296, 297],\n",
      "        [296, 298],\n",
      "        [296, 305],\n",
      "        [297, 307],\n",
      "        [297, 298],\n",
      "        [297, 306],\n",
      "        [298, 308],\n",
      "        [309, 310],\n",
      "        [309, 318],\n",
      "        [309, 319],\n",
      "        [309, 320],\n",
      "        [310, 311],\n",
      "        [310, 313],\n",
      "        [310, 321],\n",
      "        [311, 315],\n",
      "        [311, 322],\n",
      "        [311, 312],\n",
      "        [312, 313],\n",
      "        [312, 323],\n",
      "        [313, 314],\n",
      "        [315, 316],\n",
      "        [315, 317],\n",
      "        [315, 324],\n",
      "        [316, 326],\n",
      "        [316, 317],\n",
      "        [316, 325],\n",
      "        [317, 327],\n",
      "        [328, 329],\n",
      "        [329, 330],\n",
      "        [329, 337],\n",
      "        [330, 331],\n",
      "        [330, 338],\n",
      "        [331, 332],\n",
      "        [331, 339],\n",
      "        [331, 340],\n",
      "        [332, 333],\n",
      "        [332, 334],\n",
      "        [334, 335],\n",
      "        [334, 341],\n",
      "        [334, 342],\n",
      "        [335, 336],\n",
      "        [336, 343],\n",
      "        [344, 345],\n",
      "        [344, 353],\n",
      "        [345, 346],\n",
      "        [345, 354],\n",
      "        [345, 355],\n",
      "        [346, 347],\n",
      "        [346, 352],\n",
      "        [347, 348],\n",
      "        [347, 356],\n",
      "        [348, 351],\n",
      "        [348, 349],\n",
      "        [348, 350],\n",
      "        [349, 350],\n",
      "        [349, 357],\n",
      "        [349, 358],\n",
      "        [350, 359],\n",
      "        [350, 360],\n",
      "        [351, 352],\n",
      "        [352, 361],\n",
      "        [352, 362],\n",
      "        [363, 364],\n",
      "        [363, 372],\n",
      "        [364, 365],\n",
      "        [365, 366],\n",
      "        [366, 367],\n",
      "        [367, 368],\n",
      "        [367, 371],\n",
      "        [368, 369],\n",
      "        [368, 373],\n",
      "        [369, 370],\n",
      "        [370, 371],\n",
      "        [371, 374]])\n",
      "sc_idx:\n",
      " tensor([ 0,  0,  0,  ..., 19, 19, 19])\n",
      "sc_pairs_idx:\n",
      " tensor([[  9,   0],\n",
      "        [  9,   1],\n",
      "        [  9,   2],\n",
      "        ...,\n",
      "        [374, 368],\n",
      "        [374, 370],\n",
      "        [374, 371]])\n",
      "sc_types:\n",
      " tensor([0, 4, 6,  ..., 6, 3, 0])\n",
      "sc_vals:\n",
      " tensor([ 1.9866, -0.5538, -0.3553,  ..., -0.3705, -0.1089,  3.4257])\n"
     ]
    }
   ],
   "source": [
    "b_dict = dict(x=batch[0][0], \n",
    "              e=batch[0][1], \n",
    "              sc_e=batch[0][2], \n",
    "              sc_m=batch[0][3], \n",
    "              node_idx=batch[0][4], \n",
    "              pairs_idx=batch[0][5], \n",
    "              sc_idx=batch[0][6], \n",
    "              sc_pairs_idx=batch[0][7], \n",
    "              sc_types=batch[0][8], \n",
    "              sc_vals=batch[1])\n",
    "for k,v in b_dict.items(): print(f'{k}:\\n {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the metric used for this competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_mean_log_mae(y_true, y_pred, types):\n",
    "    proc = lambda x: x.cpu().numpy().ravel() \n",
    "    y_true, y_pred, types = proc(y_true), proc(y_pred), proc(types)\n",
    "    y_true = SC_MEAN + y_true * SC_STD\n",
    "    y_pred = SC_MEAN + y_pred * SC_STD\n",
    "    maes = pd.Series(y_true - y_pred).abs().groupby(types).mean()\n",
    "    return np.log(maes).mean()\n",
    "\n",
    "class GroupMeanLogMAE(Callback):\n",
    "    _order = -20 #Needs to run before the recorder\n",
    "\n",
    "    def __init__(self, learn, **kwargs): self.learn = learn\n",
    "    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['group_mean_log_mae'])\n",
    "    def on_epoch_begin(self, **kwargs): self.input, self.output, self.target = [], [], []\n",
    "    \n",
    "    def on_batch_end(self, last_target, last_output, last_input, train, **kwargs):\n",
    "        if not train:\n",
    "            self.input.append(last_input[-1])\n",
    "            self.output.append(last_output)\n",
    "            self.target.append(last_target)\n",
    "                \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        if (len(self.input) > 0) and (len(self.output) > 0):\n",
    "            inputs = torch.cat(self.input)\n",
    "            preds = torch.cat(self.output)\n",
    "            target = torch.cat(self.target)\n",
    "            metric = group_mean_log_mae(preds, target, inputs)\n",
    "            return add_metrics(last_metrics, [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd, batch_norm, act = 0, True, nn.ReLU(True)\n",
    "stride, update_steps, proc_steps = 15, 5, 10\n",
    "n_x, n_h, n_e, n_sc_e, n_sc_m = N_ATOM_FEATURES, 150, N_EDGE_FEATURES, N_SC_EDGE_FEATURES, N_SC_MOL_FEATURES\n",
    "preproc_net_args = dict(layers=[], act=act, dropout=[], batch_norm=batch_norm, out_act=nn.Tanh())\n",
    "enn_args = dict(layers=3*[n_h], act=act, dropout=3*[0.0], batch_norm=batch_norm)\n",
    "R_net_args = dict(pre_layers=[1000], post_layers=[500], act=act, dropout=[0.0, 0.0], batch_norm=batch_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(100)\n",
    "model = MPNN(n_x, n_h, n_e, n_sc_e, n_sc_m, stride, update_steps, proc_steps, preproc_net_args, enn_args, R_net_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNN(\n",
      "  (preproc_net): FullyConnectedNet(\n",
      "    (layers): Sequential(\n",
      "      (0): Linear(in_features=20, out_features=150, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (M): EdgeNetwork(\n",
      "    (adj_net): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=8, out_features=150, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): Linear(in_features=150, out_features=150, bias=True)\n",
      "        (4): ReLU(inplace)\n",
      "        (5): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): Linear(in_features=150, out_features=150, bias=True)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (9): Linear(in_features=150, out_features=22500, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (sc_adj_net): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=150, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): Linear(in_features=150, out_features=150, bias=True)\n",
      "        (4): ReLU(inplace)\n",
      "        (5): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): Linear(in_features=150, out_features=150, bias=True)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (9): Linear(in_features=150, out_features=22500, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (U): GRUUpdate(\n",
      "    (gru): GRUCell(150, 150)\n",
      "  )\n",
      "  (R): Set2SetOutput(\n",
      "    (R_proj): Linear(in_features=170, out_features=150, bias=True)\n",
      "    (R_proc): Set2Set(\n",
      "      (lstm): LSTM(300, 150, num_layers=3)\n",
      "    )\n",
      "    (R_write): MyCustomHead(\n",
      "      (preproc): FullyConnectedNet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=622, out_features=1000, bias=True)\n",
      "          (1): ReLU(inplace)\n",
      "          (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (postproc): ModuleList(\n",
      "        (0): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (1): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (2): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (3): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (4): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (5): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (6): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (7): FullyConnectedNet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "            (1): ReLU(inplace)\n",
      "            (2): Linear(in_features=500, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "tensor([-0.3355, -0.0560, -0.0692,  ..., -0.0690,  0.0105, -0.4574],\n",
      "       grad_fn=<IndexPutBackward>)\n",
      "torch.Size([1144])\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(model(*batch[0]))\n",
    "print(model(*batch[0]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(db, model, metrics=[mean_absolute_error], callback_fns=GroupMeanLogMAE, \n",
    "                wd=wd, loss_func=root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(start_lr=1e-6, end_lr=1.0, num_it=100, stop_div=True)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      40.00% [4/10 42:10<1:03:15]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>group_mean_log_mae</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.036652</td>\n",
       "      <td>0.035907</td>\n",
       "      <td>0.023091</td>\n",
       "      <td>-0.206450</td>\n",
       "      <td>10:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.030917</td>\n",
       "      <td>0.029770</td>\n",
       "      <td>0.020593</td>\n",
       "      <td>-0.362751</td>\n",
       "      <td>10:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.026214</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>0.015775</td>\n",
       "      <td>-0.637797</td>\n",
       "      <td>10:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.022205</td>\n",
       "      <td>0.020040</td>\n",
       "      <td>0.013836</td>\n",
       "      <td>-0.797247</td>\n",
       "      <td>10:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1899' class='' max='3187', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      59.59% [1899/3187 05:05<03:27 0.0194]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with group_mean_log_mae value: -0.20645031332969666.\n",
      "Better model found at epoch 1 with group_mean_log_mae value: -0.3627508878707886.\n",
      "Better model found at epoch 2 with group_mean_log_mae value: -0.6377966403961182.\n",
      "Better model found at epoch 3 with group_mean_log_mae value: -0.7972471117973328.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, max_lr=1e-3, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='group_mean_log_mae',  name='mpnn1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses(skip_start=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(20, max_lr=3e-4, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='group_mean_log_mae',  name='mpnn2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(20, max_lr=1e-4, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='group_mean_log_mae',  name='mpnn3')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses(500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
