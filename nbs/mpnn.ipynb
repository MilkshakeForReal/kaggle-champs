{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import deepchem as dc\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.spatial.distance import norm\n",
    "\n",
    "from fastai.tabular import *\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "from fastai.basic_data import DataBunch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "PATH = '../tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scalar_coupling_contributions.csv',\n",
       " 'mulliken_charges.csv',\n",
       " 'structures.csv',\n",
       " 'test.csv',\n",
       " 'train.csv',\n",
       " 'magnetic_shielding_tensors.csv',\n",
       " 'dipole_moments.csv',\n",
       " 'sample_submission.csv',\n",
       " 'potential_energy.csv']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(DATA_PATH)\n",
    "files = [f for f in files if f.find('.csv') != -1]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH+'train.csv')\n",
    "test_df = pd.read_csv(DATA_PATH+'test.csv')\n",
    "structures_df = pd.read_csv(DATA_PATH+'structures.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Written by Jan H. Jensen based on this paper Yeonjoon Kim and Woo Youn Kim \n",
    "# \"Universal Structure Conversion Method for Organic Molecules: From Atomic Connectivity\n",
    "# to Three-Dimensional Geometry\" Bull. Korean Chem. Soc. 2015, Vol. 36, 1769-1777 DOI: 10.1002/bkcs.10334\n",
    "#\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import itertools\n",
    "from rdkit.Chem import rdmolops\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import networkx as nx #uncomment if you don't want to use \"quick\"/install networkx\n",
    "\n",
    "\n",
    "global __ATOM_LIST__\n",
    "__ATOM_LIST__ = [ x.strip() for x in ['h ','he', \\\n",
    "      'li','be','b ','c ','n ','o ','f ','ne', \\\n",
    "      'na','mg','al','si','p ','s ','cl','ar', \\\n",
    "      'k ','ca','sc','ti','v ','cr','mn','fe','co','ni','cu', \\\n",
    "      'zn','ga','ge','as','se','br','kr', \\\n",
    "      'rb','sr','y ','zr','nb','mo','tc','ru','rh','pd','ag', \\\n",
    "      'cd','in','sn','sb','te','i ','xe', \\\n",
    "      'cs','ba','la','ce','pr','nd','pm','sm','eu','gd','tb','dy', \\\n",
    "      'ho','er','tm','yb','lu','hf','ta','w ','re','os','ir','pt', \\\n",
    "      'au','hg','tl','pb','bi','po','at','rn', \\\n",
    "      'fr','ra','ac','th','pa','u ','np','pu'] ]\n",
    "\n",
    "\n",
    "def get_atom(atom):\n",
    "    global __ATOM_LIST__\n",
    "    atom = atom.lower()\n",
    "    return __ATOM_LIST__.index(atom) + 1\n",
    "\n",
    "\n",
    "def getUA(maxValence_list, valence_list):\n",
    "    UA = []\n",
    "    DU = []\n",
    "    for i, (maxValence,valence) in enumerate(zip(maxValence_list, valence_list)):\n",
    "        if maxValence - valence > 0:\n",
    "            UA.append(i)\n",
    "            DU.append(maxValence - valence)\n",
    "    return UA,DU\n",
    "\n",
    "\n",
    "def get_BO(AC,UA,DU,valences,UA_pairs,quick):\n",
    "    BO = AC.copy()\n",
    "    DU_save = []\n",
    "\n",
    "    while DU_save != DU:\n",
    "        for i,j in UA_pairs:\n",
    "            BO[i,j] += 1\n",
    "            BO[j,i] += 1 \n",
    "        \n",
    "        BO_valence = list(BO.sum(axis=1))\n",
    "        DU_save = copy.copy(DU)\n",
    "        UA, DU = getUA(valences, BO_valence)\n",
    "        UA_pairs = get_UA_pairs(UA,AC,quick)[0]\n",
    "\n",
    "    return BO\n",
    "\n",
    "\n",
    "def valences_not_too_large(BO,valences):\n",
    "    number_of_bonds_list = BO.sum(axis=1)\n",
    "    for valence, number_of_bonds in zip(valences,number_of_bonds_list):\n",
    "        if number_of_bonds > valence:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def BO_is_OK(BO,AC,charge,DU,atomic_valence_electrons,atomicNumList,charged_fragments):\n",
    "    Q = 0 # total charge\n",
    "    q_list = []\n",
    "    if charged_fragments:\n",
    "        BO_valences = list(BO.sum(axis=1))\n",
    "        for i,atom in enumerate(atomicNumList):\n",
    "            q = get_atomic_charge(atom,atomic_valence_electrons[atom],BO_valences[i])\n",
    "            Q += q\n",
    "            if atom == 6:\n",
    "                number_of_single_bonds_to_C = list(BO[i,:]).count(1)\n",
    "                if number_of_single_bonds_to_C == 2 and BO_valences[i] == 2:\n",
    "                    Q += 1\n",
    "                    q = 2\n",
    "                if number_of_single_bonds_to_C == 3 and Q + 1 < charge:\n",
    "                    Q += 2\n",
    "                    q = 1\n",
    "            \n",
    "            if q != 0:\n",
    "                q_list.append(q)\n",
    "\n",
    "    if (BO-AC).sum() == sum(DU) and charge == Q and len(q_list) <= abs(charge):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_atomic_charge(atom,atomic_valence_electrons,BO_valence):\n",
    "    if atom == 1:\n",
    "        charge = 1 - BO_valence\n",
    "    elif atom == 5:\n",
    "        charge = 3 - BO_valence\n",
    "    elif atom == 15 and BO_valence == 5:\n",
    "        charge = 0\n",
    "    elif atom == 16 and BO_valence == 6:\n",
    "        charge = 0\n",
    "    else:\n",
    "        charge = atomic_valence_electrons - 8 + BO_valence\n",
    "\n",
    "    return charge\n",
    "\n",
    "def clean_charges(mol):\n",
    "    # this hack should not be needed any more but is kept just in case\n",
    "\n",
    "    rxn_smarts = ['[N+:1]=[*:2]-[C-:3]>>[N+0:1]-[*:2]=[C-0:3]',\n",
    "                  '[N+:1]=[*:2]-[O-:3]>>[N+0:1]-[*:2]=[O-0:3]',\n",
    "                  '[N+:1]=[*:2]-[*:3]=[*:4]-[O-:5]>>[N+0:1]-[*:2]=[*:3]-[*:4]=[O-0:5]',\n",
    "                  '[#8:1]=[#6:2]([!-:6])[*:3]=[*:4][#6-:5]>>[*-:1][*:2]([*:6])=[*:3][*:4]=[*+0:5]',\n",
    "                  '[O:1]=[c:2][c-:3]>>[*-:1][*:2][*+0:3]',\n",
    "                  '[O:1]=[C:2][C-:3]>>[*-:1][*:2]=[*+0:3]']\n",
    "\n",
    "    fragments = Chem.GetMolFrags(mol,asMols=True,sanitizeFrags=False)\n",
    "\n",
    "    for i,fragment in enumerate(fragments):\n",
    "        for smarts in rxn_smarts:\n",
    "            patt = Chem.MolFromSmarts(smarts.split(\">>\")[0])\n",
    "            while fragment.HasSubstructMatch(patt):\n",
    "                rxn = AllChem.ReactionFromSmarts(smarts)\n",
    "                ps = rxn.RunReactants((fragment,))\n",
    "                fragment = ps[0][0]\n",
    "        if i == 0:\n",
    "            mol = fragment\n",
    "        else:\n",
    "            mol = Chem.CombineMols(mol,fragment)\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "def BO2mol(mol,BO_matrix, atomicNumList,atomic_valence_electrons,mol_charge,charged_fragments):\n",
    "    # based on code written by Paolo Toscani\n",
    "\n",
    "    l = len(BO_matrix)\n",
    "    l2 = len(atomicNumList)\n",
    "    BO_valences = list(BO_matrix.sum(axis=1))\n",
    "\n",
    "    if (l != l2):\n",
    "        raise RuntimeError('sizes of adjMat ({0:d}) and atomicNumList '\n",
    "            '{1:d} differ'.format(l, l2))\n",
    "\n",
    "    rwMol = Chem.RWMol(mol)\n",
    "\n",
    "    bondTypeDict = {\n",
    "        1: Chem.BondType.SINGLE,\n",
    "        2: Chem.BondType.DOUBLE,\n",
    "        3: Chem.BondType.TRIPLE\n",
    "    }\n",
    "\n",
    "    for i in range(l):\n",
    "        for j in range(i + 1, l):\n",
    "            bo = int(round(BO_matrix[i, j]))\n",
    "            if (bo == 0):\n",
    "                continue\n",
    "            bt = bondTypeDict.get(bo, Chem.BondType.SINGLE)\n",
    "            rwMol.AddBond(i, j, bt)\n",
    "    mol = rwMol.GetMol()\n",
    "\n",
    "    if charged_fragments:\n",
    "        mol = set_atomic_charges(mol,atomicNumList,atomic_valence_electrons,BO_valences,BO_matrix,mol_charge)\n",
    "    else:\n",
    "        mol = set_atomic_radicals(mol,atomicNumList,atomic_valence_electrons,BO_valences)\n",
    "\n",
    "    return mol\n",
    "\n",
    "def set_atomic_charges(mol,atomicNumList,atomic_valence_electrons,BO_valences,BO_matrix,mol_charge):\n",
    "    q = 0\n",
    "    for i,atom in enumerate(atomicNumList):\n",
    "        a = mol.GetAtomWithIdx(i)\n",
    "        charge = get_atomic_charge(atom,atomic_valence_electrons[atom],BO_valences[i])\n",
    "        q += charge\n",
    "        if atom == 6:\n",
    "            number_of_single_bonds_to_C = list(BO_matrix[i,:]).count(1)\n",
    "            if number_of_single_bonds_to_C == 2 and BO_valences[i] == 2:\n",
    "                    q += 1\n",
    "                    charge = 0\n",
    "            if number_of_single_bonds_to_C == 3 and q + 1 < mol_charge:\n",
    "                    q += 2\n",
    "                    charge = 1\n",
    "\n",
    "        if (abs(charge) > 0):\n",
    "            a.SetFormalCharge(int(charge))\n",
    "\n",
    "    # shouldn't be needed anymore bit is kept just in case\n",
    "    #mol = clean_charges(mol)\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "def set_atomic_radicals(mol,atomicNumList,atomic_valence_electrons,BO_valences):\n",
    "    # The number of radical electrons = absolute atomic charge\n",
    "    for i,atom in enumerate(atomicNumList):\n",
    "        a = mol.GetAtomWithIdx(i)\n",
    "        charge = get_atomic_charge(atom,atomic_valence_electrons[atom],BO_valences[i])\n",
    "\n",
    "        if (abs(charge) > 0):\n",
    "            a.SetNumRadicalElectrons(abs(int(charge)))\n",
    "\n",
    "    return mol\n",
    "\n",
    "def get_bonds(UA,AC):\n",
    "    bonds = []\n",
    "\n",
    "    for k,i in enumerate(UA):\n",
    "        for j in UA[k+1:]:\n",
    "            if AC[i,j] == 1:\n",
    "                bonds.append(tuple(sorted([i,j])))\n",
    "\n",
    "    return bonds\n",
    "\n",
    "def get_UA_pairs(UA,AC,quick):\n",
    "    bonds = get_bonds(UA,AC)\n",
    "    if len(bonds) == 0:\n",
    "        return [()]\n",
    "\n",
    "    if quick:\n",
    "        G=nx.Graph()\n",
    "        G.add_edges_from(bonds)\n",
    "        UA_pairs = [list(nx.max_weight_matching(G))]\n",
    "        return UA_pairs\n",
    "\n",
    "    max_atoms_in_combo = 0\n",
    "    UA_pairs = [()]\n",
    "    for combo in list(itertools.combinations(bonds, int(len(UA)/2))):\n",
    "        flat_list = [item for sublist in combo for item in sublist]\n",
    "        atoms_in_combo = len(set(flat_list))\n",
    "        if atoms_in_combo > max_atoms_in_combo:\n",
    "            max_atoms_in_combo = atoms_in_combo\n",
    "            UA_pairs = [combo]\n",
    " #           if quick and max_atoms_in_combo == 2*int(len(UA)/2):\n",
    " #               return UA_pairs\n",
    "        elif atoms_in_combo == max_atoms_in_combo:\n",
    "            UA_pairs.append(combo)\n",
    "\n",
    "    return UA_pairs\n",
    "\n",
    "def AC2BO(AC,atomicNumList,charge,charged_fragments,quick):\n",
    "    # TODO\n",
    "    atomic_valence = defaultdict(list)\n",
    "    atomic_valence[1] = [1]\n",
    "    atomic_valence[6] = [4]\n",
    "    atomic_valence[7] = [4,3]\n",
    "    atomic_valence[8] = [2,1]\n",
    "    atomic_valence[9] = [1]\n",
    "    atomic_valence[14] = [4]\n",
    "    atomic_valence[15] = [5,4,3]\n",
    "    atomic_valence[16] = [6,4,2]\n",
    "    atomic_valence[17] = [1]\n",
    "    atomic_valence[32] = [4]\n",
    "    atomic_valence[35] = [1]\n",
    "    atomic_valence[53] = [1]\n",
    "\n",
    "\n",
    "    atomic_valence_electrons = {}\n",
    "    atomic_valence_electrons[1] = 1\n",
    "    atomic_valence_electrons[6] = 4\n",
    "    atomic_valence_electrons[7] = 5\n",
    "    atomic_valence_electrons[8] = 6\n",
    "    atomic_valence_electrons[9] = 7\n",
    "    atomic_valence_electrons[14] = 4\n",
    "    atomic_valence_electrons[15] = 5\n",
    "    atomic_valence_electrons[16] = 6\n",
    "    atomic_valence_electrons[17] = 7\n",
    "    atomic_valence_electrons[32] = 4\n",
    "    atomic_valence_electrons[35] = 7\n",
    "    atomic_valence_electrons[53] = 7\n",
    "\n",
    "    # make a list of valences, e.g. for CO: [[4],[2,1]]\n",
    "    valences_list_of_lists = []\n",
    "    for atomicNum in atomicNumList:\n",
    "        valences_list_of_lists.append(atomic_valence[atomicNum])\n",
    "\n",
    "    # convert [[4],[2,1]] to [[4,2],[4,1]]\n",
    "    valences_list = list(itertools.product(*valences_list_of_lists))\n",
    "\n",
    "    best_BO = AC.copy()\n",
    "\n",
    "    # implemenation of algorithm shown in Figure 2\n",
    "    # UA: unsaturated atoms\n",
    "    # DU: degree of unsaturation (u matrix in Figure)\n",
    "    # best_BO: Bcurr in Figure \n",
    "    #\n",
    "\n",
    "    for valences in valences_list:\n",
    "        AC_valence = list(AC.sum(axis=1))\n",
    "        UA,DU_from_AC = getUA(valences, AC_valence)\n",
    "\n",
    "        if len(UA) == 0 and BO_is_OK(AC,AC,charge,DU_from_AC,atomic_valence_electrons,atomicNumList,charged_fragments):\n",
    "            return AC,atomic_valence_electrons\n",
    "        \n",
    "        UA_pairs_list = get_UA_pairs(UA,AC,quick) \n",
    "        for UA_pairs in UA_pairs_list:\n",
    "            BO = get_BO(AC,UA,DU_from_AC,valences,UA_pairs,quick)\n",
    "            if BO_is_OK(BO,AC,charge,DU_from_AC,atomic_valence_electrons,atomicNumList,charged_fragments):\n",
    "                return BO,atomic_valence_electrons\n",
    "\n",
    "            elif BO.sum() >= best_BO.sum() and valences_not_too_large(BO,valences):\n",
    "                best_BO = BO.copy()\n",
    "\n",
    "    return best_BO,atomic_valence_electrons\n",
    "\n",
    "\n",
    "def AC2mol(mol,AC,atomicNumList,charge,charged_fragments,quick):\n",
    "    # convert AC matrix to bond order (BO) matrix\n",
    "    BO,atomic_valence_electrons = AC2BO(AC,atomicNumList,charge,charged_fragments,quick)\n",
    "\n",
    "    # add BO connectivity and charge info to mol object\n",
    "    mol = BO2mol(mol,BO, atomicNumList,atomic_valence_electrons,charge,charged_fragments)\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "def get_proto_mol(atomicNumList):\n",
    "    mol = Chem.MolFromSmarts(\"[#\"+str(atomicNumList[0])+\"]\")\n",
    "    rwMol = Chem.RWMol(mol)\n",
    "    for i in range(1,len(atomicNumList)):\n",
    "        a = Chem.Atom(atomicNumList[i])\n",
    "        rwMol.AddAtom(a)\n",
    "    \n",
    "    mol = rwMol.GetMol()\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "def get_atomicNumList(atomic_symbols):\n",
    "    atomicNumList = []\n",
    "    for symbol in atomic_symbols:\n",
    "        atomicNumList.append(get_atom(symbol))\n",
    "    return atomicNumList\n",
    "\n",
    "\n",
    "def read_xyz_file(filename):\n",
    "\n",
    "    atomic_symbols = []\n",
    "    xyz_coordinates = []\n",
    "\n",
    "    with open(filename, \"r\") as file:\n",
    "        for line_number,line in enumerate(file):\n",
    "            if line_number == 0:\n",
    "                num_atoms = int(line)\n",
    "            elif line_number == 1:\n",
    "                if \"charge=\" in line:\n",
    "                    charge = int(line.split(\"=\")[1])\n",
    "                else:\n",
    "                    charge = 0\n",
    "            else:\n",
    "                atomic_symbol, x, y, z = line.split()\n",
    "                atomic_symbols.append(atomic_symbol)\n",
    "                xyz_coordinates.append([float(x),float(y),float(z)])\n",
    "\n",
    "    atomicNumList = get_atomicNumList(atomic_symbols)\n",
    "    \n",
    "    return atomicNumList,charge,xyz_coordinates\n",
    "\n",
    "def xyz2AC(atomicNumList,xyz):\n",
    "    import numpy as np\n",
    "    mol = get_proto_mol(atomicNumList)\n",
    "\n",
    "    conf = Chem.Conformer(mol.GetNumAtoms())\n",
    "    for i in range(mol.GetNumAtoms()):\n",
    "        conf.SetAtomPosition(i,(xyz[i][0],xyz[i][1],xyz[i][2]))\n",
    "    mol.AddConformer(conf)\n",
    "\n",
    "    dMat = Chem.Get3DDistanceMatrix(mol)\n",
    "    pt = Chem.GetPeriodicTable()\n",
    "\n",
    "    num_atoms = len(atomicNumList)\n",
    "    AC = np.zeros((num_atoms,num_atoms)).astype(int)\n",
    "\n",
    "    for i in range(num_atoms):\n",
    "        a_i = mol.GetAtomWithIdx(i)\n",
    "        Rcov_i = pt.GetRcovalent(a_i.GetAtomicNum())*1.30\n",
    "        for j in range(i+1,num_atoms):\n",
    "            a_j = mol.GetAtomWithIdx(j)\n",
    "            Rcov_j = pt.GetRcovalent(a_j.GetAtomicNum())*1.30\n",
    "            if dMat[i,j] <= Rcov_i + Rcov_j:\n",
    "                AC[i,j] = 1\n",
    "                AC[j,i] = 1\n",
    "\n",
    "    return AC,mol,dMat\n",
    "\n",
    "def chiral_stereo_check(mol):\n",
    "    Chem.SanitizeMol(mol)\n",
    "    Chem.DetectBondStereochemistry(mol,-1)\n",
    "    Chem.AssignStereochemistry(mol, flagPossibleStereoCenters=True, force=True)\n",
    "    Chem.AssignAtomChiralTagsFromStructure(mol,-1)\n",
    "\n",
    "    return mol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def xyz2mol(atomicNumList, charge, xyz_coordinates, charged_fragments, quick):\n",
    "\n",
    "    # Get atom connectivity (AC) matrix, list of atomic numbers, molecular charge, \n",
    "    # and mol object with no connectivity information\n",
    "    AC,mol,dMat = xyz2AC(atomicNumList, xyz_coordinates)\n",
    "\n",
    "    # Convert AC to bond order matrix and add connectivity and charge info to mol object\n",
    "    new_mol = AC2mol(mol, AC, atomicNumList, charge, charged_fragments, quick)\n",
    "\n",
    "    # Check for stereocenters and chiral centers\n",
    "    new_mol = chiral_stereo_check(new_mol)\n",
    "\n",
    "    return new_mol,dMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def mol_from_xyz(filepath, add_hs=True):\n",
    "    charged_fragments = True  # alternatively radicals are made\n",
    "\n",
    "    # quick is faster for large systems but requires networkx\n",
    "    # if you don't want to install networkx set quick=False and\n",
    "    # uncomment 'import networkx as nx' at the top of the file\n",
    "    quick = True\n",
    "\n",
    "    atomicNumList, charge, xyz_coordinates = read_xyz_file(filepath)\n",
    "    mol, dMat = xyz2mol(atomicNumList, charge, xyz_coordinates, charged_fragments, quick)\n",
    "    \n",
    "    # Compute distance from centroid\n",
    "    xyz_coord_array = np.array(xyz_coordinates)\n",
    "    centroid = xyz_coord_array.mean(axis=0)\n",
    "    dFromCentroid = norm(xyz_coord_array - centroid, axis=1).shape\n",
    "\n",
    "    # Canonical hack\n",
    "#     smiles = Chem.MolToSmiles(mol, isomericSmiles=True)\n",
    "#     mol = Chem.MolFromSmiles(smiles)\n",
    "#     if add_hs: mol = Chem.AddHs(mol)\n",
    "    return mol, dMat, dFromCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total xyz filepath #  130775\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "xyz_filepath_list = list(glob(DATA_PATH+'structures/*.xyz'))\n",
    "xyz_filepath_list.sort()\n",
    "n_mols = len(xyz_filepath_list)\n",
    "print('total xyz filepath # ', n_mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638d4a3dbce24790beefe5a8e3162f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=130775), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsgdb9nsd_017732 Sanitization error: Explicit valence for atom # 4 C greater than permitted\n",
      "dsgdb9nsd_037494 Sanitization error: Explicit valence for atom # 4 C greater than permitted\n",
      "dsgdb9nsd_037900 Sanitization error: Explicit valence for atom # 5 C greater than permitted\n",
      "dsgdb9nsd_042676 Sanitization error: Explicit valence for atom # 3 C greater than permitted\n",
      "dsgdb9nsd_042681 Sanitization error: Explicit valence for atom # 3 C greater than permitted\n",
      "dsgdb9nsd_044308 Sanitization error: Explicit valence for atom # 5 C greater than permitted\n",
      "dsgdb9nsd_044322 Sanitization error: Explicit valence for atom # 5 C greater than permitted\n",
      "dsgdb9nsd_048903 Sanitization error: Explicit valence for atom # 2 C greater than permitted\n",
      "dsgdb9nsd_066495 Sanitization error: Explicit valence for atom # 7 C greater than permitted\n",
      "dsgdb9nsd_067109 Sanitization error: Explicit valence for atom # 2 C greater than permitted\n",
      "dsgdb9nsd_073323 Sanitization error: Explicit valence for atom # 4 C greater than permitted\n",
      "dsgdb9nsd_090191 Sanitization error: Explicit valence for atom # 3 C greater than permitted\n",
      "dsgdb9nsd_090838 Sanitization error: Explicit valence for atom # 5 C greater than permitted\n",
      "dsgdb9nsd_107870 Sanitization error: Explicit valence for atom # 2 C greater than permitted\n",
      "dsgdb9nsd_133831 Sanitization error: Explicit valence for atom # 2 C greater than permitted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dist_matrices = {}\n",
    "mols = {}\n",
    "dist_from_centroids = {}\n",
    "for i in tqdm_notebook(range(n_mols)):\n",
    "    filepath = xyz_filepath_list[i]\n",
    "    mol_name = filepath.split('/')[-1][:-4]\n",
    "    try: \n",
    "        mol, dist_matrix, dist_from_centroid = mol_from_xyz(filepath)\n",
    "        mols[mol_name] = mol\n",
    "        dist_matrices[mol_name] = dist_matrix\n",
    "        dist_from_centroids[mol_name] = dist_from_centroid\n",
    "    except ValueError as e: \n",
    "        print(mol_name, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EDGE_FEATURES = 16\n",
    "N_ATOM_FEATURES = 26\n",
    "MAX_N_ATOMS     = 29\n",
    "MAX_N_BONDS     = 58\n",
    "TYPES           = train_df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def get_edge_features(mol, eucl_dist):\n",
    "#     \"\"\"\n",
    "#     Compute the following features for each entry in the adjacency matrix pf 'mol':\n",
    "#         - bond type one-hot: categorical {1: single, 2: double, 3: triple, 4: aromatic}\n",
    "#         - is conjugated: bool {0, 1}\n",
    "#         - is in ring: bool {0, 1}\n",
    "#         - graph distance: int\n",
    "#         - euclidean distance: float\n",
    "#     \"\"\"\n",
    "#     n_atoms = mol.GetNumAtoms()\n",
    "#     features = np.zeros((n_atoms, n_atoms, N_EDGE_FEATURES-8))\n",
    "\n",
    "#     # compute distance features\n",
    "#     graph_dist = Chem.AllChem.GetDistanceMatrix(mol)\n",
    "\n",
    "#     features[:,:,-1] = eucl_dist\n",
    "#     features[:,:,-2] = graph_dist\n",
    "#     for e in mol.GetBonds():\n",
    "#         i = e.GetBeginAtomIdx()\n",
    "#         j = e.GetEndAtomIdx()\n",
    "#         dc_e_feats = dc.feat.graph_features.bond_features(e).astype(int)\n",
    "#         features[i,j,:6], features[j,i,:6] = dc_e_feats, dc_e_feats\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_features(mol, eucl_dist, row):\n",
    "    \"\"\"\n",
    "    Compute the following features for each entry in the adjacency matrix pf 'mol':\n",
    "        - bond type one-hot: categorical {1: single, 2: double, 3: triple, 4: aromatic}\n",
    "        - is conjugated: bool {0, 1}\n",
    "        - is in ring: bool {0, 1}\n",
    "        - graph distance: int\n",
    "        - euclidean distance: float\n",
    "    \"\"\"\n",
    "    n_atoms, n_bonds = mol.GetNumAtoms(), mol.GetNumBonds()\n",
    "    n_edge_features = (n_bonds + 1) * 2\n",
    "    features = np.zeros((n_edge_features, N_EDGE_FEATURES))\n",
    "    pairs_idx = np.zeros((n_edge_features, 2)) - 1\n",
    "    \n",
    "    graph_dist = Chem.AllChem.GetDistanceMatrix(mol)\n",
    "    scalar_coupling_has_bond = False\n",
    "    for n, e in enumerate(mol.GetBonds()):\n",
    "        ix1 = 2 * n\n",
    "        ix2 = (2 * n) + 1\n",
    "        i = e.GetBeginAtomIdx()\n",
    "        j = e.GetEndAtomIdx()\n",
    "        dc_e_feats = dc.feat.graph_features.bond_features(e).astype(int)\n",
    "        for ix in [ix1, ix2]:\n",
    "            features[ix, :6] = dc_e_feats\n",
    "            features[ix, 6] = graph_dist[i, j]\n",
    "            features[ix, 7] = eucl_dist[i, j]\n",
    "            if (row['atom_index_0'], row['atom_index_1']) in [(i, j), (j, i)]:\n",
    "                features[ix, 8:] = (TYPES == row['type']).astype(float)\n",
    "                scalar_coupling_has_bond = True\n",
    "        pairs_idx[ix1] = i, j\n",
    "        pairs_idx[ix2] = j, i\n",
    "    if not scalar_coupling_has_bond:\n",
    "        for ix in [-2, -1]:\n",
    "            features[ix, 6] = graph_dist[row['atom_index_0'], row['atom_index_1']]\n",
    "            features[ix, 7] = eucl_dist[row['atom_index_0'], row['atom_index_1']]\n",
    "            features[ix, 8:] = (TYPES == row['type']).astype(float)\n",
    "        pairs_idx[-2] = row['atom_index_0'], row['atom_index_1']\n",
    "        pairs_idx[-1] = row['atom_index_1'], row['atom_index_0']\n",
    "    return features[pairs_idx[:,0].argsort()], pairs_idx[pairs_idx[:,0].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "code_folding": [
     0,
     5,
     11
    ]
   },
   "outputs": [],
   "source": [
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(f\"input {x} not in allowable set{allowable_set}:\")\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def get_atom_features(mol):\n",
    "    \"\"\"\n",
    "    Compute the following features for each atom in 'mol':\n",
    "        - atom type: H, C, N, O, F (one-hot)\n",
    "        - degree: 0, 1, 2, 3, 4 (one-hot)\n",
    "        - implicit valence: 0, 1, 2, 3, 4, 5 (one-hot)\n",
    "        - Hybridization: SP, SP2, SP3, SP3D, SP3D2 (one-hot)\n",
    "        - is aromatic: bool {0, 1}\n",
    "        - formal charge: int\n",
    "        - num radical electrons: int\n",
    "        - atomic number: int\n",
    "    \"\"\"\n",
    "    n_atoms = mol.GetNumAtoms()\n",
    "    features = np.zeros((n_atoms, N_ATOM_FEATURES-1))\n",
    "    for a in mol.GetAtoms():\n",
    "        a_feats = one_of_k_encoding(a.GetSymbol(), ['H', 'C', 'N', 'O', 'F']) \\\n",
    "            + one_of_k_encoding(a.GetDegree(), [0, 1, 2, 3, 4]) \\\n",
    "            + one_of_k_encoding(a.GetImplicitValence(), [0, 1, 2, 3, 4]) \\\n",
    "            + one_of_k_encoding_unk(a.GetHybridization(), [\n",
    "                Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
    "                Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.SP3D, \n",
    "                Chem.rdchem.HybridizationType.SP3D2, Chem.rdchem.HybridizationType.UNSPECIFIED]) \\\n",
    "            + [a.GetIsAromatic(), a.GetFormalCharge(), a.GetNumRadicalElectrons(), a.GetAtomicNum()]\n",
    "        features[a.GetIdx(),:] = np.array(a_feats).astype(int)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# n_obs = 50000 # len(mols)\n",
    "# atomic_features = np.zeros((n_obs, MAX_N_ATOMS, N_ATOM_FEATURES))\n",
    "# edge_features = np.zeros((n_obs, MAX_N_ATOMS, MAX_N_ATOMS, N_EDGE_FEATURES))\n",
    "# mask = np.zeros((n_mols, MAX_N_ATOMS))\n",
    "# target = np.zeros(n_obs)\n",
    "# keep = []\n",
    "# mol_name = ''\n",
    "# succesful_mols = list(mols.keys())\n",
    "# types = train_df['type'].unique()\n",
    "# for i in tqdm_notebook(range(n_obs)):\n",
    "#     row = train_df.iloc[i,:]\n",
    "#     new_mol_name = row['molecule_name']\n",
    "#     if mol_name!=new_mol_name:\n",
    "#         if new_mol_name in succesful_mols:\n",
    "#             mol_name = new_mol_name\n",
    "#             mol, dist_matrix = mols[mol_name], dist_matrices[mol_name]\n",
    "#             n_atoms = mol.GetNumAtoms()\n",
    "#         else:\n",
    "#             continue\n",
    "#     atomic_features[i, :n_atoms, :-1] = get_atom_features(mol)\n",
    "#     atomic_features[i, row['atom_index_0'], -1] = 1.\n",
    "#     atomic_features[i, row['atom_index_1'], -1] = 1.\n",
    "#     edge_features[i, :n_atoms, :n_atoms, :-8] = get_edge_features(mol, dist_matrix)\n",
    "#     edge_features[i, row['atom_index_0'], row['atom_index_1'], -8:] = (types == row['type']).astype(float)\n",
    "#     mask[i,:n_atoms] = 1.\n",
    "#     target[i] = row['scalar_coupling_constant']\n",
    "#     keep.append(i)\n",
    "# keep = np.array(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025ad7f11eac46319f77a9916e5dedb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_obs = 50000 # len(mols)\n",
    "atomic_features = np.zeros((n_obs, MAX_N_ATOMS, N_ATOM_FEATURES))\n",
    "edge_features = np.zeros((n_obs, MAX_N_BONDS, N_EDGE_FEATURES))\n",
    "pairs_idx = np.zeros((n_obs, MAX_N_BONDS, 2)) - 1\n",
    "mask = np.zeros((n_obs, MAX_N_ATOMS))\n",
    "edge_mask = np.zeros((n_obs, MAX_N_BONDS))\n",
    "target = np.zeros(n_obs)\n",
    "keep = []\n",
    "mol_name = ''\n",
    "succesful_mols = list(mols.keys())\n",
    "for i in tqdm_notebook(range(n_obs)):\n",
    "    row = train_df.iloc[i,:]\n",
    "    new_mol_name = row['molecule_name']\n",
    "    if mol_name!=new_mol_name:\n",
    "        if new_mol_name in succesful_mols:\n",
    "            mol_name = new_mol_name\n",
    "            mol, dist_matrix = mols[mol_name], dist_matrices[mol_name]\n",
    "            n_atoms = mol.GetNumAtoms()\n",
    "            n_bonds = mol.GetNumBonds()\n",
    "            n_edge_features = (n_bonds + 1) * 2\n",
    "        else:\n",
    "            continue\n",
    "    atomic_features[i, :n_atoms, :-1] = get_atom_features(mol)\n",
    "    atomic_features[i, row['atom_index_0'], -1] = 1.\n",
    "    atomic_features[i, row['atom_index_1'], -1] = 1.\n",
    "    edge_features[i, :n_edge_features, :], pairs_idx[i, :n_edge_features, :] = \\\n",
    "        get_edge_features(mol, dist_matrix, row)\n",
    "    mask[i, :n_atoms], edge_mask[i, pairs_idx[i,:,0] != -1] = 1., 1.\n",
    "    target[i] = row['scalar_coupling_constant']\n",
    "    keep.append(i)\n",
    "keep = np.array(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_idx_tmp_torch = torch.tensor(pairs_idx[-2,:,1], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([58, 26]), torch.Size([40, 26]))"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(atomic_features[-2])[pairs_idx_tmp_torch].size(), \\\n",
    "torch.tensor(atomic_features[-2])[pairs_idx_tmp_torch][torch.tensor(edge_mask[-2], dtype=torch.uint8)==True].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 0.,  ..., 0., 6., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 1., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64),\n",
       " tensor([[0., 1., 0.,  ..., 0., 6., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 1., 0.],\n",
       "         ...,\n",
       "         [0., 1., 0.,  ..., 0., 6., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 6., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 6., 0.]], dtype=torch.float64))"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(atomic_features[-2])[pairs_idx_tmp_torch], \\\n",
    "torch.tensor(atomic_features[-2])[pairs_idx_tmp_torch][torch.tensor(edge_mask[-2], dtype=torch.uint8)==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_features = atomic_features[keep]\n",
    "edge_features   = edge_features[keep]\n",
    "pairs_idx       = pairs_idx[keep]\n",
    "mask            = mask[keep]\n",
    "edge_mask       = edge_mask[keep]\n",
    "target          = target[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atomic_features.shape\t: (50000, 29, 26)\n",
      "edge_features.shape\t: (50000, 58, 16)\n"
     ]
    }
   ],
   "source": [
    "print(f'atomic_features.shape\\t: {atomic_features.shape}\\nedge_features.shape\\t: {edge_features.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MPNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [],
   "source": [
    "enn_args = dict(layers=[50, 50, 50, 50], act=nn.ReLU(True), dropout=[0.0, 0.0, 0.0, 0.0], batch_norm=False)\n",
    "R_net_args = dict(layers=[200, 100], act=nn.ReLU(True), dropout=[0.0, 0.0], batch_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "def hidden_layer(n_in, n_out, batch_norm, dropout, act=None):\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(n_in, n_out))\n",
    "    if act: layers.append(act)\n",
    "    if batch_norm: layers.append(nn.BatchNorm1d(n_out))\n",
    "    if dropout != 0: layers.append(nn.Dropout(dropout))\n",
    "    return layers\n",
    "\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input, n_output, layers=[], act=nn.ReLU(True), dropout=[], batch_norm=False):\n",
    "        super().__init__()\n",
    "        sizes = [n_input] + layers + [n_output]\n",
    "        layers_ = []\n",
    "        for i, (n_in, n_out, dr) in enumerate(zip(sizes[:-1], sizes[1:], dropout+[0.0])):\n",
    "            act_ = act if i < len(layers) else None\n",
    "            batch_norm_ = batch_norm if i < len(layers) else False\n",
    "            layers_ += hidden_layer(n_in, n_out, batch_norm_, dr, act_)      \n",
    "        self.layers = nn.Sequential(*layers_)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class HiddenLSTMCell(nn.Module):\n",
    "    \"\"\"Implements the LSTM cell update described in the sec 4.2 of https://arxiv.org/pdf/1511.06391.pdf.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_h_out):\n",
    "        \"\"\"This LSTM cell takes no external 'x' inputs, but has a hidden state appended with the \n",
    "        readout from a content based attention mechanism. Therefore the hidden state is of a dimension\n",
    "        that is two times the number of nodes in the set.\"\"\"\n",
    "        super().__init__()\n",
    "        self.n_h_out, self.n_h = n_h_out, n_h_out * 2 \n",
    "        self.w_h = nn.Parameter(torch.Tensor(self.n_h, n_h_out * 4))\n",
    "        self.b = nn.Parameter(torch.Tensor(n_h_out * 4))\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2: \n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            else: \n",
    "                nn.init.zeros_(p.data)\n",
    "                # initialize the forget gate bias to 1\n",
    "                p.data[self.n_h_out:self.n_h_out*2] = torch.ones(self.n_h_out)\n",
    "        \n",
    "    def forward(self, h_prev, c_prev):\n",
    "        \"\"\"Takes previuos hidden and cell states as arguments and performs a single LSTM step using \n",
    "        no external input.\n",
    "        \"\"\"\n",
    "        n_h_ = self.n_h_out # number of output hidden states\n",
    "        # batch the computations into a single matrix multiplication\n",
    "        gates = h_prev @ self.w_h + self.b\n",
    "        i_g, f_g, g, o_g = (\n",
    "            torch.sigmoid(gates[:, :n_h_]), # input\n",
    "            torch.sigmoid(gates[:, n_h_:n_h_*2]), # forget\n",
    "            torch.tanh(gates[:, n_h_*2:n_h_*3]),\n",
    "            torch.sigmoid(gates[:, n_h_*3:]), # output\n",
    "        )\n",
    "        c = f_g * c_prev + i_g * g\n",
    "        h = o_g * torch.tanh(c)\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Set2Set(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted from: https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric\\\n",
    "        /nn/glob/set2set.html#Set2Set\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, proc_steps):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = 2 * in_channels\n",
    "        self.proc_steps = proc_steps\n",
    "        self.lstm = HiddenLSTMCell(self.in_channels)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        x - input tensor of shape (batch_size, n_nodes, in_channels)\n",
    "        mask - integer tensor used to zero out nodes missing in a particualr graph \n",
    "            (not all graphs have 'n_nodes'). Is of shape (batch_size, n_nodes)\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = mask.size(0), mask.size(1)\n",
    "        batch_idx = torch.arange(0, batch_size).expand(n_nodes, batch_size).transpose(0, 1)\n",
    "        h = torch.zeros(batch_size, self.in_channels)\n",
    "        q_star = torch.zeros(batch_size, self.out_channels)\n",
    "        mask = (mask.float() - 1) * 1e6\n",
    "        for i in range(self.proc_steps):\n",
    "            q, h = self.lstm(q_star, h)\n",
    "            e = (x * q[batch_idx]).sum(dim=-1)\n",
    "            # set masked nodes not to large negative energy (attention mask will convert this to 0)\n",
    "            e += mask \n",
    "            a = F.softmax(e, dim=-1)\n",
    "            # sum a*x over node dimension \n",
    "            r = torch.sum(a.unsqueeze(-1) * x, dim=1)\n",
    "            q_star = torch.cat([q, r], dim=-1)\n",
    "            \n",
    "        return q_star\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels, self.out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def segment_sum(data, segment_ids):\n",
    "    \"\"\"\n",
    "    Computes the sum along segments of a tensor. Analogous to tf.unsorted_segment_sum.\n",
    "\n",
    "    :param data: A tensor whose segments are to be summed.\n",
    "    :param segment_ids: The segment indices tensor.\n",
    "    :return: A tensor of same data type as the data argument.\n",
    "    \"\"\"\n",
    "    assert all([i in data.shape for i in segment_ids.shape]), \"segment_ids.shape should be a prefix of data.shape\"\n",
    "    \n",
    "    # segment_ids is a 1-D tensor repeat it to have the same shape as data\n",
    "    if len(segment_ids.shape) == 1:\n",
    "        s = torch.prod(torch.tensor(data.shape[1:])).long()\n",
    "        segment_ids = segment_ids.repeat_interleave(s).view(segment_ids.shape[0], *data.shape[1:])\n",
    "\n",
    "    assert data.shape == segment_ids.shape, \"data.shape and segment_ids.shape should be equal\"\n",
    "\n",
    "    num_segments = len(torch.unique(segment_ids))\n",
    "    shape = [num_segments] + list(data.shape[1:])\n",
    "    tensor = torch.zeros(*shape).scatter_add(0, segment_ids, data.float())\n",
    "    tensor = tensor.type(data.dtype)\n",
    "    return tensor\n",
    "\n",
    "class EdgeNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_h, n_e, fully_connected_graph=False, use_master_node=True, net_args={}):\n",
    "        super().__init__()\n",
    "        self.n_e, self.n_h = n_e, n_h\n",
    "        self.fully_connected_graph = fully_connected_graph\n",
    "        self.use_master_node = use_master_node\n",
    "        self.adjacency_net = FullyConnectedNet(n_e, n_h ** 2, **net_args)\n",
    "        self.b_m = nn.Parameter(torch.Tensor(n_h)) # bias for the message function\n",
    "        nn.init.zeros_(self.b_m)\n",
    "    \n",
    "    def forward(self, h, e, pairs_idx=None, edge_mask=None):\n",
    "        \"\"\"\n",
    "        Compute message vector m_t given the previuos hidden state\n",
    "        h_t-1 and edge features e. e_out represents the same edge \n",
    "        features as e_in with adjacency matrix transposed.\n",
    "        - h is a collection of  hidden states of shape (batch_size, n_nodes, n_h)\n",
    "        - e is a collection of edge features of shape \n",
    "            (batch_size, n_nodes, n_nodes, n_e) if fully_connected_graph\n",
    "            else shape is (batch_size, n_edges, n_e).\n",
    "        - pairs_idx: if self.fully_connected_graph = False this is a tensor\n",
    "            of shape (batch_size, n_edges, 2) mapping atom indexes \n",
    "            (first column) to the other atom indexes they form a bond with\n",
    "            (second column. \n",
    "        - edge_mask: if self.fully_connected_graph = False this is a tensor\n",
    "            of shape (batch_size, n_edges) masking non present edges.\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = h.size(0), h.size(1)\n",
    "        \n",
    "        # compute a\n",
    "        e_reshaped = e.view(-1, self.n_e)\n",
    "        a_vect = self.adjacency_net(e_reshaped) # dim(a_vect) = (batch_size * n_edges, n_h^2)\n",
    "        if self.fully_connected_graph:\n",
    "            a_tmp = a_vect.view(-1, n_nodes, n_nodes, self.n_h, self.n_h).transpose(2, 3)\n",
    "            a = a_tmp.contiguous().view(-1, n_nodes * self.n_h, n_nodes * self.n_h)\n",
    "            h_flat = h.view(batch_size, n_nodes * self.n_h, 1)\n",
    "            m = torch.matmul(a, h_flat).view(batch_size * n_nodes, self.n_h)\n",
    "        else:\n",
    "            n_edges = e.size(1)\n",
    "            edge_mask_ = edge_mask.type(torch.uint8)==True\n",
    "            edge_mask_flat = edge_mask.view(-1).type(torch.uint8)==True\n",
    "            \n",
    "            a_mat = a_vect[edge_mask_flat].view(-1, self.n_h, self.n_h)\n",
    "            h_flat = torch.cat([h[b,ix,:] for b, ix in enumerate(torch.unbind(pairs_idx[:,:,1]))])\n",
    "            h_flat = h_flat[edge_mask_flat]\n",
    "            ah = torch.einsum('bij,bjk->bik', h_flat.unsqueeze(1), a_mat).squeeze(1)\n",
    "            \n",
    "            n_nodes_per_g = pairs_idx[:,:,0].max(dim=1).values + 1\n",
    "            unique_idx = pairs_idx[:,:,0] + (torch.cat([\n",
    "                                                 torch.zeros(1, dtype=torch.long), \n",
    "                                                 n_nodes_per_g[:-1].cumsum(dim=0)\n",
    "                                             ])).unsqueeze(-1).expand(-1, n_edges)\n",
    "            m_stacked = segment_sum(ah, unique_idx[edge_mask_])\n",
    "            \n",
    "            m_per_g_lst = torch.split(m_stacked, n_nodes_per_g.tolist())\n",
    "            m = torch.cat([F.pad(m_, pad=(0, 0, 0, n_nodes - n_nodes_)) \n",
    "                           for m_, n_nodes_ in zip(m_per_g_lst, n_nodes_per_g)]) \n",
    "            \n",
    "        m += self.b_m\n",
    "\n",
    "        return m.view(batch_size, n_nodes, self.n_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8.2846e-01,  1.3722e+00,  1.3755e+00,  ...,  7.7376e-01,\n",
       "           4.9090e-01, -7.3929e-01],\n",
       "         [-7.6818e-02,  1.9346e-03,  3.5754e-01,  ..., -6.7729e-01,\n",
       "           2.0827e-01,  4.1821e-02],\n",
       "         [-6.7860e-02,  2.5336e-02,  3.3534e-01,  ..., -6.8375e-01,\n",
       "           2.1888e-01, -3.5143e-03],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-2.9843e-01,  3.0289e+00,  1.3437e+00,  ...,  5.8446e-01,\n",
       "           9.8487e-01,  6.6117e-01],\n",
       "         [ 1.5796e+00,  7.4156e-01,  1.0957e+00,  ...,  2.1461e-01,\n",
       "           2.9847e-01, -3.5351e-01],\n",
       "         [ 5.0861e-02,  9.0457e-01,  9.1477e-01,  ...,  1.7157e+00,\n",
       "           1.3507e+00, -1.0601e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-8.2879e-02,  1.0099e-01,  6.5203e-01,  ..., -1.2885e+00,\n",
       "          -5.8079e-01,  4.2729e-01],\n",
       "         [ 5.9582e-01, -8.3338e-01,  5.0628e-01,  ..., -7.3829e-01,\n",
       "          -6.3928e-01,  5.6644e-02],\n",
       "         [ 7.9909e-01, -6.7010e-01,  1.2540e-01,  ..., -3.6373e-01,\n",
       "           1.1843e-01,  6.3828e-01],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-9.4024e-01,  1.6655e+00,  6.3799e-01,  ..., -4.5905e-01,\n",
       "           2.4546e-02, -1.0432e+00],\n",
       "         [-8.2811e-01,  5.5770e-01,  7.7269e-01,  ..., -8.5517e-01,\n",
       "           3.3772e-01, -1.0440e+00],\n",
       "         [-7.4458e-01,  5.8631e-01,  8.2344e-01,  ..., -8.8566e-01,\n",
       "           3.3416e-01, -1.1071e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.0218e+00, -8.1584e-01, -2.9842e-01,  ..., -1.4530e+00,\n",
       "          -4.1298e-01,  1.0363e+00],\n",
       "         [ 8.4040e-01,  4.2149e-02,  7.7811e-01,  ..., -1.3442e+00,\n",
       "          -2.0759e-02,  2.8037e-01],\n",
       "         [ 7.8959e-02, -1.6006e-01, -1.3636e-01,  ...,  3.1801e-01,\n",
       "          -6.2686e-01,  6.7492e-03],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-2.0369e-01,  1.4095e-01,  7.9550e-01,  ...,  3.6619e-01,\n",
       "          -1.2339e+00, -1.7782e-01],\n",
       "         [ 3.4313e-01, -8.8785e-01,  3.7964e-01,  ..., -2.6477e-01,\n",
       "          -2.3279e-01, -6.6723e-01],\n",
       "         [ 2.3796e-01,  3.6180e-01, -2.1749e-01,  ..., -6.4567e-01,\n",
       "          -2.6066e-01, -8.0101e-01],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 964,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, n_nodes, n_h, n_e, n_edges = 20, MAX_N_ATOMS, 50, N_EDGE_FEATURES, MAX_N_BONDS\n",
    "h = torch.randn(batch_size, n_nodes, n_h, dtype=torch.float)\n",
    "e = torch.tensor(edge_features[:20,:,:], dtype=torch.float)\n",
    "p_idx = torch.tensor(pairs_idx[:20,:,:], dtype=torch.long)\n",
    "msk = torch.tensor(edge_mask[:20,:])\n",
    "enn = EdgeNetwork(n_h, n_e, fully_connected_graph=False, use_master_node=True, net_args=enn_args)\n",
    "enn(h, e, p_idx, msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 16])\n",
      "torch.Size([1160, 2500])\n",
      "torch.Size([20, 58]) torch.Size([1160])\n",
      "torch.Size([164, 50, 50])\n",
      "torch.Size([1160, 50])\n",
      "torch.Size([164, 50])\n",
      "torch.Size([164, 50])\n",
      "torch.Size([91, 50])\n",
      "torch.Size([5, 50])\n",
      "torch.Size([580, 50])\n",
      "torch.Size([580, 50])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 29, 50])"
      ]
     },
     "execution_count": 965,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_reshaped = e.view(-1, n_e)\n",
    "print(e_reshaped.size())\n",
    "a_vect = enn.adjacency_net(e_reshaped)\n",
    "print(a_vect.size())\n",
    "edge_mask_ = msk.type(torch.uint8)==True\n",
    "edge_mask_flat = msk.view(-1).type(torch.uint8)==True\n",
    "print(edge_mask_.size(), edge_mask_flat.size())\n",
    "a_mat = a_vect[edge_mask_flat].view(-1, n_h, n_h)\n",
    "print(a_mat.size())\n",
    "h_flat = torch.cat([h[batch,ix,:] for batch, ix in enumerate(torch.unbind(p_idx[:,:,1]))])\n",
    "print(h_flat.size())\n",
    "h_flat = h_flat[edge_mask_flat]\n",
    "print(h_flat.size())\n",
    "ah = torch.einsum('bij,bjk->bik', h_flat.unsqueeze(1), a_mat).squeeze(1)\n",
    "print(ah.size())\n",
    "n_nodes_per_g = p_idx[:,:,0].max(dim=1).values + 1\n",
    "unique_idx = p_idx[:,:,0] + (torch.cat([\n",
    "                                torch.zeros(1, dtype=torch.long), \n",
    "                                n_nodes_per_g[:-1].cumsum(dim=0)\n",
    "                            ])).unsqueeze(-1).expand(-1, n_edges)\n",
    "m_stacked = segment_sum(ah, unique_idx[edge_mask_])\n",
    "print(m_stacked.size())\n",
    "\n",
    "m_per_g_lst = torch.split(m_stacked, n_nodes_per_g.tolist())\n",
    "print(m_per_g_lst[0].size())\n",
    "m = torch.cat([F.pad(m_, pad=(0, 0, 0, n_nodes - n_nodes_)) for m_, n_nodes_ in zip(m_per_g_lst, n_nodes_per_g)]) \n",
    "print(m.size())\n",
    "m += enn.b_m\n",
    "print(m.size())\n",
    "m.view(batch_size, n_nodes, n_h).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class GRUUpdate(nn.Module):\n",
    "    def __init__(self, n_h):\n",
    "        super().__init__()\n",
    "        self.n_h = n_h\n",
    "        self.gru = nn.GRUCell(n_h, n_h)\n",
    "        \n",
    "    def forward(self, m, h_prev, mask):\n",
    "        \"\"\"\n",
    "        Update hidden state h.\n",
    "        - h_prev is vector of hidden states of shape (batch_size, n_nodes, n_h)\n",
    "        - m is vector of messages of shape (batch_size, n_nodes, n_h)\n",
    "        - mask is used to  zero out nodes missing in a particualr graph (not all graphs \n",
    "            have 'n_nodes'). Is of shape (batch_size, n_nodes)\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = h_prev.size(0), h_prev.size(1)\n",
    "        h = self.gru(m.view(-1, self.n_h), h_prev.view(-1, self.n_h))\n",
    "        return h.view(batch_size, n_nodes, self.n_h) * mask.unsqueeze(-1).expand(batch_size, n_nodes, self.n_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Set2SetOutput(nn.Module):\n",
    "    def __init__(self, n_x, n_h, proc_steps, net_args):\n",
    "        super().__init__()\n",
    "        self.n_h, self.n_x = n_h, n_x\n",
    "        self.R_proj = nn.Linear(n_h + n_x, n_h)\n",
    "        self.R_proc = Set2Set(n_h, proc_steps)\n",
    "        self.R_write = FullyConnectedNet(2 * n_h, 1, **net_args)\n",
    "    \n",
    "    def forward(self, h, x, mask):\n",
    "        \"\"\"\n",
    "        Update hidden state h.\n",
    "        - h is vector of hidden states of shape (batch_size, n_nodes, n_h)\n",
    "        - x is vector of input features of shape (batch_size, n_nodes, n_x)\n",
    "        - mask is used to  zero out nodes missing in a particualr graph (not all graphs \n",
    "            have 'n_nodes'). Is of shape (batch_size, n_nodes)\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = h.size(0), h.size(1)\n",
    "        m = self.R_proj(torch.cat((h.view(-1, self.n_h), x.view(-1, self.n_x)), dim=1))\n",
    "        q = self.R_proc(m.view(batch_size, n_nodes, self.n_h), mask) \n",
    "        y = self.R_write(q) # dim(q) = (batch_size, n_h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNN(nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_e, update_steps=3, proc_steps=10, enn_args={}, R_net_args={}):\n",
    "        super().__init__()\n",
    "        self.n_h, self.n_x = n_h, n_x\n",
    "        self.M = EdgeNetwork(n_h, n_e, net_args=enn_args)\n",
    "        self.U = GRUUpdate(n_h)\n",
    "        self.R = Set2SetOutput(n_x, n_h, proc_steps, R_net_args)\n",
    "        self.update_steps = update_steps\n",
    "        \n",
    "    def forward(self, x, e, mask, pairs_idx=None, edge_mask=None):\n",
    "        h = F.pad(x, pad=(0, self.n_h - self.n_x))\n",
    "        for t in range(self.update_steps):\n",
    "            m = self.M(h, e, pairs_idx, edge_mask)\n",
    "            h = self.U(m, h, mask)\n",
    "        y = self.R(h, x, mask)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNN(\n",
      "  (M): EdgeNetwork(\n",
      "    (adjacency_net): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=50, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (5): ReLU(inplace)\n",
      "        (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): Linear(in_features=50, out_features=2500, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (U): GRUUpdate(\n",
      "    (gru): GRUCell(50, 50)\n",
      "  )\n",
      "  (R): Set2SetOutput(\n",
      "    (R_proj): Linear(in_features=76, out_features=50, bias=True)\n",
      "    (R_proc): Set2Set(50, 100)\n",
      "    (R_write): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=100, out_features=200, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Linear(in_features=100, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "tensor([[-0.0884],\n",
      "        [-0.0891],\n",
      "        [-0.0891],\n",
      "        [-0.0891],\n",
      "        [-0.0884],\n",
      "        [-0.0891],\n",
      "        [-0.0891],\n",
      "        [-0.0884],\n",
      "        [-0.0891],\n",
      "        [-0.0884],\n",
      "        [-0.0899],\n",
      "        [-0.0911],\n",
      "        [-0.0911],\n",
      "        [-0.0899],\n",
      "        [-0.0911],\n",
      "        [-0.0899],\n",
      "        [-0.0889],\n",
      "        [-0.0822],\n",
      "        [-0.0799],\n",
      "        [-0.0873]], grad_fn=<AddmmBackward>)\n",
      "torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "batch_size, n_nodes, n_h, n_e, n_x, n_edges = 20, MAX_N_ATOMS, 50, N_EDGE_FEATURES, N_ATOM_FEATURES, MAX_N_BONDS\n",
    "x     = torch.tensor(atomic_features[:batch_size,:,:], dtype=torch.float)\n",
    "e     = torch.tensor(edge_features[:batch_size,:,:], dtype=torch.float)\n",
    "msk   = torch.tensor(mask[:batch_size,:], dtype=torch.float)\n",
    "p_idx = torch.tensor(pairs_idx[:batch_size,:,:], dtype=torch.long)\n",
    "e_msk = torch.tensor(edge_mask[:batch_size,:], dtype=torch.float)\n",
    "\n",
    "mpnn = MPNN(n_x, n_h, n_e, update_steps=3, proc_steps=10, enn_args=enn_args, R_net_args=R_net_args)\n",
    "print(mpnn)\n",
    "print(mpnn(x, e, msk, p_idx, e_msk))\n",
    "print(mpnn(x, e, msk, p_idx, e_msk).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Fit MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = train_test_split(np.arange(n_obs), test_size=0.25, shuffle=True, random_state=100)\n",
    "x_train, x_val = atomic_features[train_idx], atomic_features[val_idx]\n",
    "e_train, e_val = edge_features[train_idx], edge_features[val_idx]\n",
    "y_train, y_val = target[train_idx], target[val_idx]\n",
    "mask_train, mask_val = mask[train_idx], mask[val_idx]\n",
    "edge_mask_train, edge_mask_val = edge_mask[train_idx], edge_mask[val_idx]\n",
    "pairs_idx_train, pairs_idx_val = pairs_idx[train_idx], pairs_idx[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_target = StandardScaler()\n",
    "y_train = ss_target.fit_transform(y_train.reshape(-1,1))\n",
    "y_val = ss_target.transform(y_val.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, y, x, e, mask, pairs_idx=None, edge_mask=None):\n",
    "        self.n = len(y)\n",
    "        self.y = y.astype(np.float32)\n",
    "        self.x = x.astype(np.float32)\n",
    "        self.e = e.astype(np.float32)\n",
    "        self.mask = mask.astype(np.float32)\n",
    "        self.fully_connected_graphs = edge_mask is None\n",
    "        if not self.fully_connected_graphs:\n",
    "            self.pairs_idx = pairs_idx.astype(np.long)\n",
    "            self.edge_mask = edge_mask.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.fully_connected_graphs:\n",
    "            return (self.x[idx], self.e[idx], self.mask[idx]), self.y[idx]\n",
    "        else:\n",
    "            return (self.x[idx], self.e[idx], self.mask[idx], self.pairs_idx[idx], self.edge_mask[idx]), self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MoleculeDataset(y_train, x_train, e_train, mask_train, pairs_idx_train, edge_mask_train)\n",
    "val_ds   = MoleculeDataset(y_val, x_val, e_val, mask_val, pairs_idx_val, edge_mask_val)\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=8)\n",
    "val_dl   = DataLoader(val_ds, batch_size, num_workers=8)\n",
    "db = DataBunch(train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_mean_log_mae(y_true, y_pred, types):\n",
    "    y_true, y_pred, types = y_true.cpu().numpy().ravel(), y_pred.cpu().numpy().ravel(), types.cpu().numpy().ravel()\n",
    "    y_true = ss_target.mean_ + y_true * ss_target.scale_\n",
    "    y_pred = ss_target.mean_ + y_pred * ss_target.scale_\n",
    "    maes = pd.Series(y_true-y_pred).abs().groupby(types).mean()\n",
    "    return np.log(maes).mean()\n",
    "\n",
    "class GroupMeanLogMAE(Callback):\n",
    "    _order = -20 #Needs to run before the recorder\n",
    "    types_cidx = 2\n",
    "\n",
    "    def __init__(self, learn, **kwargs): self.learn = learn\n",
    "    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['GroupMeanLogMAE'])\n",
    "    def on_epoch_begin(self, **kwargs): self.input, self.output, self.target = [], [], []\n",
    "    \n",
    "    def on_batch_end(self, last_target, last_output, last_input, train, **kwargs):\n",
    "        if not train:\n",
    "            last_e = last_input[1]\n",
    "            if len(last_e.size()) == 4: types = torch.nonzero(last_e[:,:,:,-8:])[:,-1]\n",
    "            else: types = torch.nonzero(last_e[:,:,-8:])[::2,-1]\n",
    "            self.input.append(types)\n",
    "            self.output.append(last_output)\n",
    "            self.target.append(last_target)\n",
    "                \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        if (len(self.input) > 0) and (len(self.output) > 0):\n",
    "            inputs = torch.cat(self.input)\n",
    "            preds = torch.cat(self.output)\n",
    "            target = torch.cat(self.target)\n",
    "            metric = group_mean_log_mae(preds, target, inputs)\n",
    "            return add_metrics(last_metrics, [metric])\n",
    "\n",
    "def set_seed(seed=100):\n",
    "    # python RNG\n",
    "    random.seed(seed)\n",
    "\n",
    "    # pytorch RNGs\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # numpy RNG\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-6\n",
    "n_hidden = 50\n",
    "enn_args = dict(layers=[50, 50, 50, 50], act=nn.ReLU(True), dropout=[0.0, 0.0, 0.0, 0.0], batch_norm=False)\n",
    "R_net_args = dict(layers=[200, 100], act=nn.ReLU(True), dropout=[0.0, 0.0], batch_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(100)\n",
    "model = MPNN(N_ATOM_FEATURES, n_hidden, N_EDGE_FEATURES, update_steps=1, proc_steps=5, \n",
    "             enn_args=enn_args, R_net_args=R_net_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(db, model, metrics=[mean_absolute_error, root_mean_squared_error], \n",
    "                callback_fns=GroupMeanLogMAE, wd=wd, loss_func=root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.lr_find(start_lr=1e-8, end_lr=1, num_it=100, stop_div=True)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>GroupMeanLogMAE</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.159601</td>\n",
       "      <td>0.156184</td>\n",
       "      <td>0.105536</td>\n",
       "      <td>0.156184</td>\n",
       "      <td>1.354229</td>\n",
       "      <td>03:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.127612</td>\n",
       "      <td>0.118614</td>\n",
       "      <td>0.089700</td>\n",
       "      <td>0.118614</td>\n",
       "      <td>1.153358</td>\n",
       "      <td>03:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.106659</td>\n",
       "      <td>0.100454</td>\n",
       "      <td>0.069477</td>\n",
       "      <td>0.100454</td>\n",
       "      <td>0.842295</td>\n",
       "      <td>03:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.100778</td>\n",
       "      <td>0.121220</td>\n",
       "      <td>0.082152</td>\n",
       "      <td>0.121220</td>\n",
       "      <td>0.880352</td>\n",
       "      <td>03:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.095718</td>\n",
       "      <td>0.092992</td>\n",
       "      <td>0.065019</td>\n",
       "      <td>0.092992</td>\n",
       "      <td>0.757166</td>\n",
       "      <td>03:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.082667</td>\n",
       "      <td>0.081624</td>\n",
       "      <td>0.056402</td>\n",
       "      <td>0.081624</td>\n",
       "      <td>0.651035</td>\n",
       "      <td>03:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075210</td>\n",
       "      <td>0.073650</td>\n",
       "      <td>0.050919</td>\n",
       "      <td>0.073650</td>\n",
       "      <td>0.523686</td>\n",
       "      <td>03:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.066438</td>\n",
       "      <td>0.045899</td>\n",
       "      <td>0.066438</td>\n",
       "      <td>0.371690</td>\n",
       "      <td>03:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.054816</td>\n",
       "      <td>0.059368</td>\n",
       "      <td>0.041857</td>\n",
       "      <td>0.059368</td>\n",
       "      <td>0.311036</td>\n",
       "      <td>03:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.053513</td>\n",
       "      <td>0.057250</td>\n",
       "      <td>0.040247</td>\n",
       "      <td>0.057250</td>\n",
       "      <td>0.267407</td>\n",
       "      <td>03:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with GroupMeanLogMAE value: 1.354228859685035.\n",
      "Better model found at epoch 1 with GroupMeanLogMAE value: 1.1533581682915712.\n",
      "Better model found at epoch 2 with GroupMeanLogMAE value: 0.8422953966309138.\n",
      "Better model found at epoch 4 with GroupMeanLogMAE value: 0.7571660086835312.\n",
      "Better model found at epoch 5 with GroupMeanLogMAE value: 0.6510346373432624.\n",
      "Better model found at epoch 6 with GroupMeanLogMAE value: 0.5236864444576811.\n",
      "Better model found at epoch 7 with GroupMeanLogMAE value: 0.3716901914886019.\n",
      "Better model found at epoch 8 with GroupMeanLogMAE value: 0.31103578241766366.\n",
      "Better model found at epoch 9 with GroupMeanLogMAE value: 0.26740657729393014.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, max_lr=1e-3, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='GroupMeanLogMAE',  name='mpnn')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>GroupMeanLogMAE</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.057422</td>\n",
       "      <td>0.057541</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>0.057541</td>\n",
       "      <td>0.286319</td>\n",
       "      <td>02:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.055529</td>\n",
       "      <td>0.059438</td>\n",
       "      <td>0.041918</td>\n",
       "      <td>0.059438</td>\n",
       "      <td>0.320873</td>\n",
       "      <td>03:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.059378</td>\n",
       "      <td>0.059227</td>\n",
       "      <td>0.042514</td>\n",
       "      <td>0.059227</td>\n",
       "      <td>0.336825</td>\n",
       "      <td>03:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.057274</td>\n",
       "      <td>0.055405</td>\n",
       "      <td>0.039596</td>\n",
       "      <td>0.055405</td>\n",
       "      <td>0.281443</td>\n",
       "      <td>03:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.053913</td>\n",
       "      <td>0.057279</td>\n",
       "      <td>0.039944</td>\n",
       "      <td>0.057279</td>\n",
       "      <td>0.303203</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.052195</td>\n",
       "      <td>0.056035</td>\n",
       "      <td>0.039194</td>\n",
       "      <td>0.056035</td>\n",
       "      <td>0.222439</td>\n",
       "      <td>03:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.048742</td>\n",
       "      <td>0.052346</td>\n",
       "      <td>0.036425</td>\n",
       "      <td>0.052346</td>\n",
       "      <td>0.167444</td>\n",
       "      <td>03:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.046596</td>\n",
       "      <td>0.050768</td>\n",
       "      <td>0.035409</td>\n",
       "      <td>0.050768</td>\n",
       "      <td>0.150190</td>\n",
       "      <td>03:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.048443</td>\n",
       "      <td>0.049717</td>\n",
       "      <td>0.034626</td>\n",
       "      <td>0.049717</td>\n",
       "      <td>0.131897</td>\n",
       "      <td>03:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.047076</td>\n",
       "      <td>0.049524</td>\n",
       "      <td>0.034494</td>\n",
       "      <td>0.049524</td>\n",
       "      <td>0.124534</td>\n",
       "      <td>03:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with GroupMeanLogMAE value: 0.28631927272693414.\n",
      "Better model found at epoch 3 with GroupMeanLogMAE value: 0.28144344014824785.\n",
      "Better model found at epoch 5 with GroupMeanLogMAE value: 0.22243898377855462.\n",
      "Better model found at epoch 6 with GroupMeanLogMAE value: 0.1674443047489782.\n",
      "Better model found at epoch 7 with GroupMeanLogMAE value: 0.1501904718669072.\n",
      "Better model found at epoch 8 with GroupMeanLogMAE value: 0.1318967869551606.\n",
      "Better model found at epoch 9 with GroupMeanLogMAE value: 0.1245335506225918.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, max_lr=2e-4, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='GroupMeanLogMAE',  name='mpnn')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>GroupMeanLogMAE</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.048812</td>\n",
       "      <td>0.049702</td>\n",
       "      <td>0.034633</td>\n",
       "      <td>0.049702</td>\n",
       "      <td>0.127906</td>\n",
       "      <td>03:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.046267</td>\n",
       "      <td>0.049696</td>\n",
       "      <td>0.034670</td>\n",
       "      <td>0.049696</td>\n",
       "      <td>0.131523</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.045230</td>\n",
       "      <td>0.050078</td>\n",
       "      <td>0.035130</td>\n",
       "      <td>0.050078</td>\n",
       "      <td>0.150454</td>\n",
       "      <td>03:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.048768</td>\n",
       "      <td>0.049210</td>\n",
       "      <td>0.034214</td>\n",
       "      <td>0.049210</td>\n",
       "      <td>0.121127</td>\n",
       "      <td>03:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.046830</td>\n",
       "      <td>0.049385</td>\n",
       "      <td>0.034457</td>\n",
       "      <td>0.049385</td>\n",
       "      <td>0.127631</td>\n",
       "      <td>03:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.047618</td>\n",
       "      <td>0.049113</td>\n",
       "      <td>0.034081</td>\n",
       "      <td>0.049113</td>\n",
       "      <td>0.117352</td>\n",
       "      <td>03:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.044582</td>\n",
       "      <td>0.048713</td>\n",
       "      <td>0.033777</td>\n",
       "      <td>0.048713</td>\n",
       "      <td>0.102756</td>\n",
       "      <td>03:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.045670</td>\n",
       "      <td>0.048842</td>\n",
       "      <td>0.033876</td>\n",
       "      <td>0.048842</td>\n",
       "      <td>0.107339</td>\n",
       "      <td>03:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.048197</td>\n",
       "      <td>0.048487</td>\n",
       "      <td>0.033572</td>\n",
       "      <td>0.048487</td>\n",
       "      <td>0.096942</td>\n",
       "      <td>03:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.045038</td>\n",
       "      <td>0.048442</td>\n",
       "      <td>0.033557</td>\n",
       "      <td>0.048442</td>\n",
       "      <td>0.096955</td>\n",
       "      <td>03:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with GroupMeanLogMAE value: 0.12790607972417514.\n",
      "Better model found at epoch 3 with GroupMeanLogMAE value: 0.12112732865715103.\n",
      "Better model found at epoch 5 with GroupMeanLogMAE value: 0.11735198926441456.\n",
      "Better model found at epoch 6 with GroupMeanLogMAE value: 0.10275615135438726.\n",
      "Better model found at epoch 8 with GroupMeanLogMAE value: 0.09694183179473853.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, max_lr=4e-5, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='GroupMeanLogMAE',  name='mpnn')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>GroupMeanLogMAE</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.048459</td>\n",
       "      <td>0.033606</td>\n",
       "      <td>0.048459</td>\n",
       "      <td>0.098804</td>\n",
       "      <td>03:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.045910</td>\n",
       "      <td>0.048540</td>\n",
       "      <td>0.033550</td>\n",
       "      <td>0.048540</td>\n",
       "      <td>0.096201</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.046046</td>\n",
       "      <td>0.048621</td>\n",
       "      <td>0.033625</td>\n",
       "      <td>0.048621</td>\n",
       "      <td>0.095609</td>\n",
       "      <td>03:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.047394</td>\n",
       "      <td>0.048486</td>\n",
       "      <td>0.033614</td>\n",
       "      <td>0.048486</td>\n",
       "      <td>0.103721</td>\n",
       "      <td>03:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.048073</td>\n",
       "      <td>0.048659</td>\n",
       "      <td>0.033661</td>\n",
       "      <td>0.048659</td>\n",
       "      <td>0.096728</td>\n",
       "      <td>03:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.046877</td>\n",
       "      <td>0.048345</td>\n",
       "      <td>0.033501</td>\n",
       "      <td>0.048345</td>\n",
       "      <td>0.094218</td>\n",
       "      <td>03:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.046217</td>\n",
       "      <td>0.048304</td>\n",
       "      <td>0.033401</td>\n",
       "      <td>0.048304</td>\n",
       "      <td>0.092690</td>\n",
       "      <td>03:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.046137</td>\n",
       "      <td>0.048236</td>\n",
       "      <td>0.033399</td>\n",
       "      <td>0.048236</td>\n",
       "      <td>0.093047</td>\n",
       "      <td>03:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.047683</td>\n",
       "      <td>0.048207</td>\n",
       "      <td>0.033332</td>\n",
       "      <td>0.048207</td>\n",
       "      <td>0.090394</td>\n",
       "      <td>03:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.046603</td>\n",
       "      <td>0.048204</td>\n",
       "      <td>0.033339</td>\n",
       "      <td>0.048204</td>\n",
       "      <td>0.090764</td>\n",
       "      <td>03:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with GroupMeanLogMAE value: 0.09880390561805735.\n",
      "Better model found at epoch 1 with GroupMeanLogMAE value: 0.09620074511375563.\n",
      "Better model found at epoch 2 with GroupMeanLogMAE value: 0.09560922042310946.\n",
      "Better model found at epoch 5 with GroupMeanLogMAE value: 0.09421753289340161.\n",
      "Better model found at epoch 6 with GroupMeanLogMAE value: 0.09268977237219678.\n",
      "Better model found at epoch 8 with GroupMeanLogMAE value: 0.09039376142404532.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, max_lr=1e-5, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='GroupMeanLogMAE',  name='mpnn')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, _ = learn.get_preds()\n",
    "pred_test, _ = learn.get_preds(DatasetType.Test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
