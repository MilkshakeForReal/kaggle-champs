{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import deepchem as dc\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.spatial.distance import norm\n",
    "\n",
    "from fastai.tabular import *\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "from fastai.basic_data import DataBunch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "# DATA_PATH = '../storage/CHAMPS/'\n",
    "PATH = '../tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scalar_coupling_contributions.csv',\n",
       " 'mulliken_charges.csv',\n",
       " 'structures.csv',\n",
       " 'test.csv',\n",
       " 'train.csv',\n",
       " 'magnetic_shielding_tensors.csv',\n",
       " 'dipole_moments.csv',\n",
       " 'sample_submission.csv',\n",
       " 'potential_energy.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(DATA_PATH)\n",
    "files = [f for f in files if f.find('.csv') != -1]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH+'train.csv')\n",
    "test_df = pd.read_csv(DATA_PATH+'test.csv')\n",
    "structures_df = pd.read_csv(DATA_PATH+'structures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.24 s, sys: 127 ms, total: 2.37 s\n",
      "Wall time: 692 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "atoms_per_molecule_df = structures_df.groupby(['molecule_name', 'atom']).count()\n",
    "atoms_per_molecule_map = atoms_per_molecule_df['atom_index'].unstack().fillna(0).astype(int).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 900 ms, total: 16.1 s\n",
      "Wall time: 5.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pd.options.mode.chained_assignment = None\n",
    "atoms = structures_df['atom'].unique()\n",
    "train_df['num_atoms'] = 0\n",
    "test_df['num_atoms'] = 0\n",
    "for atom in atoms:\n",
    "    train_df[f'num_{atom}_atoms'] = train_df['molecule_name'].map(atoms_per_molecule_map[atom])\n",
    "    train_df['num_atoms'] += train_df[f'num_{atom}_atoms']\n",
    "    test_df[f'num_{atom}_atoms'] = test_df['molecule_name'].map(atoms_per_molecule_map[atom])\n",
    "    test_df['num_atoms'] += test_df[f'num_{atom}_atoms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'molecule_name', 'atom_index_0', 'atom_index_1', 'type',\n",
       "       'scalar_coupling_constant', 'num_atoms', 'num_C_atoms', 'num_H_atoms',\n",
       "       'num_N_atoms', 'num_O_atoms', 'num_F_atoms'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Written by Jan H. Jensen based on this paper Yeonjoon Kim and Woo Youn Kim \n",
    "# \"Universal Structure Conversion Method for Organic Molecules: From Atomic Connectivity\n",
    "# to Three-Dimensional Geometry\" Bull. Korean Chem. Soc. 2015, Vol. 36, 1769-1777 DOI: 10.1002/bkcs.10334\n",
    "#\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import itertools\n",
    "from rdkit.Chem import rdmolops\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import networkx as nx #uncomment if you don't want to use \"quick\"/install networkx\n",
    "\n",
    "\n",
    "global __ATOM_LIST__\n",
    "__ATOM_LIST__ = [ x.strip() for x in ['h ','he', \\\n",
    "      'li','be','b ','c ','n ','o ','f ','ne', \\\n",
    "      'na','mg','al','si','p ','s ','cl','ar', \\\n",
    "      'k ','ca','sc','ti','v ','cr','mn','fe','co','ni','cu', \\\n",
    "      'zn','ga','ge','as','se','br','kr', \\\n",
    "      'rb','sr','y ','zr','nb','mo','tc','ru','rh','pd','ag', \\\n",
    "      'cd','in','sn','sb','te','i ','xe', \\\n",
    "      'cs','ba','la','ce','pr','nd','pm','sm','eu','gd','tb','dy', \\\n",
    "      'ho','er','tm','yb','lu','hf','ta','w ','re','os','ir','pt', \\\n",
    "      'au','hg','tl','pb','bi','po','at','rn', \\\n",
    "      'fr','ra','ac','th','pa','u ','np','pu'] ]\n",
    "\n",
    "\n",
    "def get_atom(atom):\n",
    "    global __ATOM_LIST__\n",
    "    atom = atom.lower()\n",
    "    return __ATOM_LIST__.index(atom) + 1\n",
    "\n",
    "\n",
    "def getUA(maxValence_list, valence_list):\n",
    "    UA = []\n",
    "    DU = []\n",
    "    for i, (maxValence,valence) in enumerate(zip(maxValence_list, valence_list)):\n",
    "        if maxValence - valence > 0:\n",
    "            UA.append(i)\n",
    "            DU.append(maxValence - valence)\n",
    "    return UA,DU\n",
    "\n",
    "\n",
    "def get_BO(AC,UA,DU,valences,UA_pairs,quick):\n",
    "    BO = AC.copy()\n",
    "    DU_save = []\n",
    "\n",
    "    while DU_save != DU:\n",
    "        for i,j in UA_pairs:\n",
    "            BO[i,j] += 1\n",
    "            BO[j,i] += 1 \n",
    "        \n",
    "        BO_valence = list(BO.sum(axis=1))\n",
    "        DU_save = copy.copy(DU)\n",
    "        UA, DU = getUA(valences, BO_valence)\n",
    "        UA_pairs = get_UA_pairs(UA,AC,quick)[0]\n",
    "\n",
    "    return BO\n",
    "\n",
    "\n",
    "def valences_not_too_large(BO,valences):\n",
    "    number_of_bonds_list = BO.sum(axis=1)\n",
    "    for valence, number_of_bonds in zip(valences,number_of_bonds_list):\n",
    "        if number_of_bonds > valence:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def BO_is_OK(BO,AC,charge,DU,atomic_valence_electrons,atomicNumList,charged_fragments):\n",
    "    Q = 0 # total charge\n",
    "    q_list = []\n",
    "    if charged_fragments:\n",
    "        BO_valences = list(BO.sum(axis=1))\n",
    "        for i,atom in enumerate(atomicNumList):\n",
    "            q = get_atomic_charge(atom,atomic_valence_electrons[atom],BO_valences[i])\n",
    "            Q += q\n",
    "            if atom == 6:\n",
    "                number_of_single_bonds_to_C = list(BO[i,:]).count(1)\n",
    "                if number_of_single_bonds_to_C == 2 and BO_valences[i] == 2:\n",
    "                    Q += 1\n",
    "                    q = 2\n",
    "                if number_of_single_bonds_to_C == 3 and Q + 1 < charge:\n",
    "                    Q += 2\n",
    "                    q = 1\n",
    "            \n",
    "            if q != 0:\n",
    "                q_list.append(q)\n",
    "\n",
    "    if (BO-AC).sum() == sum(DU) and charge == Q and len(q_list) <= abs(charge):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_atomic_charge(atom,atomic_valence_electrons,BO_valence):\n",
    "    if atom == 1:\n",
    "        charge = 1 - BO_valence\n",
    "    elif atom == 5:\n",
    "        charge = 3 - BO_valence\n",
    "    elif atom == 15 and BO_valence == 5:\n",
    "        charge = 0\n",
    "    elif atom == 16 and BO_valence == 6:\n",
    "        charge = 0\n",
    "    else:\n",
    "        charge = atomic_valence_electrons - 8 + BO_valence\n",
    "\n",
    "    return charge\n",
    "\n",
    "def clean_charges(mol):\n",
    "    # this hack should not be needed any more but is kept just in case\n",
    "\n",
    "    rxn_smarts = ['[N+:1]=[*:2]-[C-:3]>>[N+0:1]-[*:2]=[C-0:3]',\n",
    "                  '[N+:1]=[*:2]-[O-:3]>>[N+0:1]-[*:2]=[O-0:3]',\n",
    "                  '[N+:1]=[*:2]-[*:3]=[*:4]-[O-:5]>>[N+0:1]-[*:2]=[*:3]-[*:4]=[O-0:5]',\n",
    "                  '[#8:1]=[#6:2]([!-:6])[*:3]=[*:4][#6-:5]>>[*-:1][*:2]([*:6])=[*:3][*:4]=[*+0:5]',\n",
    "                  '[O:1]=[c:2][c-:3]>>[*-:1][*:2][*+0:3]',\n",
    "                  '[O:1]=[C:2][C-:3]>>[*-:1][*:2]=[*+0:3]']\n",
    "\n",
    "    fragments = Chem.GetMolFrags(mol,asMols=True,sanitizeFrags=False)\n",
    "\n",
    "    for i,fragment in enumerate(fragments):\n",
    "        for smarts in rxn_smarts:\n",
    "            patt = Chem.MolFromSmarts(smarts.split(\">>\")[0])\n",
    "            while fragment.HasSubstructMatch(patt):\n",
    "                rxn = AllChem.ReactionFromSmarts(smarts)\n",
    "                ps = rxn.RunReactants((fragment,))\n",
    "                fragment = ps[0][0]\n",
    "        if i == 0:\n",
    "            mol = fragment\n",
    "        else:\n",
    "            mol = Chem.CombineMols(mol,fragment)\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "def BO2mol(mol,BO_matrix, atomicNumList,atomic_valence_electrons,mol_charge,charged_fragments):\n",
    "    # based on code written by Paolo Toscani\n",
    "\n",
    "    l = len(BO_matrix)\n",
    "    l2 = len(atomicNumList)\n",
    "    BO_valences = list(BO_matrix.sum(axis=1))\n",
    "\n",
    "    if (l != l2):\n",
    "        raise RuntimeError('sizes of adjMat ({0:d}) and atomicNumList '\n",
    "            '{1:d} differ'.format(l, l2))\n",
    "\n",
    "    rwMol = Chem.RWMol(mol)\n",
    "\n",
    "    bondTypeDict = {\n",
    "        1: Chem.BondType.SINGLE,\n",
    "        2: Chem.BondType.DOUBLE,\n",
    "        3: Chem.BondType.TRIPLE\n",
    "    }\n",
    "\n",
    "    for i in range(l):\n",
    "        for j in range(i + 1, l):\n",
    "            bo = int(round(BO_matrix[i, j]))\n",
    "            if (bo == 0):\n",
    "                continue\n",
    "            bt = bondTypeDict.get(bo, Chem.BondType.SINGLE)\n",
    "            rwMol.AddBond(i, j, bt)\n",
    "    mol = rwMol.GetMol()\n",
    "\n",
    "    if charged_fragments:\n",
    "        mol = set_atomic_charges(mol,atomicNumList,atomic_valence_electrons,BO_valences,BO_matrix,mol_charge)\n",
    "    else:\n",
    "        mol = set_atomic_radicals(mol,atomicNumList,atomic_valence_electrons,BO_valences)\n",
    "\n",
    "    return mol\n",
    "\n",
    "def set_atomic_charges(mol,atomicNumList,atomic_valence_electrons,BO_valences,BO_matrix,mol_charge):\n",
    "    q = 0\n",
    "    for i,atom in enumerate(atomicNumList):\n",
    "        a = mol.GetAtomWithIdx(i)\n",
    "        charge = get_atomic_charge(atom,atomic_valence_electrons[atom],BO_valences[i])\n",
    "        q += charge\n",
    "        if atom == 6:\n",
    "            number_of_single_bonds_to_C = list(BO_matrix[i,:]).count(1)\n",
    "            if number_of_single_bonds_to_C == 2 and BO_valences[i] == 2:\n",
    "                    q += 1\n",
    "                    charge = 0\n",
    "            if number_of_single_bonds_to_C == 3 and q + 1 < mol_charge:\n",
    "                    q += 2\n",
    "                    charge = 1\n",
    "\n",
    "        if (abs(charge) > 0):\n",
    "            a.SetFormalCharge(int(charge))\n",
    "\n",
    "    # shouldn't be needed anymore bit is kept just in case\n",
    "    #mol = clean_charges(mol)\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "def set_atomic_radicals(mol,atomicNumList,atomic_valence_electrons,BO_valences):\n",
    "    # The number of radical electrons = absolute atomic charge\n",
    "    for i,atom in enumerate(atomicNumList):\n",
    "        a = mol.GetAtomWithIdx(i)\n",
    "        charge = get_atomic_charge(atom,atomic_valence_electrons[atom],BO_valences[i])\n",
    "\n",
    "        if (abs(charge) > 0):\n",
    "            a.SetNumRadicalElectrons(abs(int(charge)))\n",
    "\n",
    "    return mol\n",
    "\n",
    "def get_bonds(UA,AC):\n",
    "    bonds = []\n",
    "\n",
    "    for k,i in enumerate(UA):\n",
    "        for j in UA[k+1:]:\n",
    "            if AC[i,j] == 1:\n",
    "                bonds.append(tuple(sorted([i,j])))\n",
    "\n",
    "    return bonds\n",
    "\n",
    "def get_UA_pairs(UA,AC,quick):\n",
    "    bonds = get_bonds(UA,AC)\n",
    "    if len(bonds) == 0:\n",
    "        return [()]\n",
    "\n",
    "    if quick:\n",
    "        G=nx.Graph()\n",
    "        G.add_edges_from(bonds)\n",
    "        UA_pairs = [list(nx.max_weight_matching(G))]\n",
    "        return UA_pairs\n",
    "\n",
    "    max_atoms_in_combo = 0\n",
    "    UA_pairs = [()]\n",
    "    for combo in list(itertools.combinations(bonds, int(len(UA)/2))):\n",
    "        flat_list = [item for sublist in combo for item in sublist]\n",
    "        atoms_in_combo = len(set(flat_list))\n",
    "        if atoms_in_combo > max_atoms_in_combo:\n",
    "            max_atoms_in_combo = atoms_in_combo\n",
    "            UA_pairs = [combo]\n",
    " #           if quick and max_atoms_in_combo == 2*int(len(UA)/2):\n",
    " #               return UA_pairs\n",
    "        elif atoms_in_combo == max_atoms_in_combo:\n",
    "            UA_pairs.append(combo)\n",
    "\n",
    "    return UA_pairs\n",
    "\n",
    "def AC2BO(AC,atomicNumList,charge,charged_fragments,quick):\n",
    "    # TODO\n",
    "    atomic_valence = defaultdict(list)\n",
    "    atomic_valence[1] = [1]\n",
    "    atomic_valence[6] = [4]\n",
    "    atomic_valence[7] = [4,3]\n",
    "    atomic_valence[8] = [2,1]\n",
    "    atomic_valence[9] = [1]\n",
    "    atomic_valence[14] = [4]\n",
    "    atomic_valence[15] = [5,4,3]\n",
    "    atomic_valence[16] = [6,4,2]\n",
    "    atomic_valence[17] = [1]\n",
    "    atomic_valence[32] = [4]\n",
    "    atomic_valence[35] = [1]\n",
    "    atomic_valence[53] = [1]\n",
    "\n",
    "\n",
    "    atomic_valence_electrons = {}\n",
    "    atomic_valence_electrons[1] = 1\n",
    "    atomic_valence_electrons[6] = 4\n",
    "    atomic_valence_electrons[7] = 5\n",
    "    atomic_valence_electrons[8] = 6\n",
    "    atomic_valence_electrons[9] = 7\n",
    "    atomic_valence_electrons[14] = 4\n",
    "    atomic_valence_electrons[15] = 5\n",
    "    atomic_valence_electrons[16] = 6\n",
    "    atomic_valence_electrons[17] = 7\n",
    "    atomic_valence_electrons[32] = 4\n",
    "    atomic_valence_electrons[35] = 7\n",
    "    atomic_valence_electrons[53] = 7\n",
    "\n",
    "    # make a list of valences, e.g. for CO: [[4],[2,1]]\n",
    "    valences_list_of_lists = []\n",
    "    for atomicNum in atomicNumList:\n",
    "        valences_list_of_lists.append(atomic_valence[atomicNum])\n",
    "\n",
    "    # convert [[4],[2,1]] to [[4,2],[4,1]]\n",
    "    valences_list = list(itertools.product(*valences_list_of_lists))\n",
    "\n",
    "    best_BO = AC.copy()\n",
    "\n",
    "    # implemenation of algorithm shown in Figure 2\n",
    "    # UA: unsaturated atoms\n",
    "    # DU: degree of unsaturation (u matrix in Figure)\n",
    "    # best_BO: Bcurr in Figure \n",
    "    #\n",
    "\n",
    "    for valences in valences_list:\n",
    "        AC_valence = list(AC.sum(axis=1))\n",
    "        UA,DU_from_AC = getUA(valences, AC_valence)\n",
    "\n",
    "        if len(UA) == 0 and BO_is_OK(AC,AC,charge,DU_from_AC,atomic_valence_electrons,atomicNumList,charged_fragments):\n",
    "            return AC,atomic_valence_electrons\n",
    "        \n",
    "        UA_pairs_list = get_UA_pairs(UA,AC,quick) \n",
    "        for UA_pairs in UA_pairs_list:\n",
    "            BO = get_BO(AC,UA,DU_from_AC,valences,UA_pairs,quick)\n",
    "            if BO_is_OK(BO,AC,charge,DU_from_AC,atomic_valence_electrons,atomicNumList,charged_fragments):\n",
    "                return BO,atomic_valence_electrons\n",
    "\n",
    "            elif BO.sum() >= best_BO.sum() and valences_not_too_large(BO,valences):\n",
    "                best_BO = BO.copy()\n",
    "\n",
    "    return best_BO,atomic_valence_electrons\n",
    "\n",
    "\n",
    "def AC2mol(mol,AC,atomicNumList,charge,charged_fragments,quick):\n",
    "    # convert AC matrix to bond order (BO) matrix\n",
    "    BO,atomic_valence_electrons = AC2BO(AC,atomicNumList,charge,charged_fragments,quick)\n",
    "\n",
    "    # add BO connectivity and charge info to mol object\n",
    "    mol = BO2mol(mol,BO, atomicNumList,atomic_valence_electrons,charge,charged_fragments)\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "def get_proto_mol(atomicNumList):\n",
    "    mol = Chem.MolFromSmarts(\"[#\"+str(atomicNumList[0])+\"]\")\n",
    "    rwMol = Chem.RWMol(mol)\n",
    "    for i in range(1,len(atomicNumList)):\n",
    "        a = Chem.Atom(atomicNumList[i])\n",
    "        rwMol.AddAtom(a)\n",
    "    \n",
    "    mol = rwMol.GetMol()\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "def get_atomicNumList(atomic_symbols):\n",
    "    atomicNumList = []\n",
    "    for symbol in atomic_symbols:\n",
    "        atomicNumList.append(get_atom(symbol))\n",
    "    return atomicNumList\n",
    "\n",
    "\n",
    "def read_xyz_file(filename):\n",
    "\n",
    "    atomic_symbols = []\n",
    "    xyz_coordinates = []\n",
    "\n",
    "    with open(filename, \"r\") as file:\n",
    "        for line_number,line in enumerate(file):\n",
    "            if line_number == 0:\n",
    "                num_atoms = int(line)\n",
    "            elif line_number == 1:\n",
    "                if \"charge=\" in line:\n",
    "                    charge = int(line.split(\"=\")[1])\n",
    "                else:\n",
    "                    charge = 0\n",
    "            else:\n",
    "                atomic_symbol, x, y, z = line.split()\n",
    "                atomic_symbols.append(atomic_symbol)\n",
    "                xyz_coordinates.append([float(x),float(y),float(z)])\n",
    "\n",
    "    atomicNumList = get_atomicNumList(atomic_symbols)\n",
    "    \n",
    "    return atomicNumList,charge,xyz_coordinates\n",
    "\n",
    "def xyz2AC(atomicNumList,xyz):\n",
    "    import numpy as np\n",
    "    mol = get_proto_mol(atomicNumList)\n",
    "\n",
    "    conf = Chem.Conformer(mol.GetNumAtoms())\n",
    "    for i in range(mol.GetNumAtoms()):\n",
    "        conf.SetAtomPosition(i,(xyz[i][0],xyz[i][1],xyz[i][2]))\n",
    "    mol.AddConformer(conf)\n",
    "\n",
    "    dMat = Chem.Get3DDistanceMatrix(mol)\n",
    "    pt = Chem.GetPeriodicTable()\n",
    "\n",
    "    num_atoms = len(atomicNumList)\n",
    "    AC = np.zeros((num_atoms,num_atoms)).astype(int)\n",
    "\n",
    "    for i in range(num_atoms):\n",
    "        a_i = mol.GetAtomWithIdx(i)\n",
    "        Rcov_i = pt.GetRcovalent(a_i.GetAtomicNum())*1.30\n",
    "        for j in range(i+1,num_atoms):\n",
    "            a_j = mol.GetAtomWithIdx(j)\n",
    "            Rcov_j = pt.GetRcovalent(a_j.GetAtomicNum())*1.30\n",
    "            if dMat[i,j] <= Rcov_i + Rcov_j:\n",
    "                AC[i,j] = 1\n",
    "                AC[j,i] = 1\n",
    "\n",
    "    return AC,mol,dMat\n",
    "\n",
    "def chiral_stereo_check(mol):\n",
    "    Chem.SanitizeMol(mol)\n",
    "    Chem.DetectBondStereochemistry(mol,-1)\n",
    "    Chem.AssignStereochemistry(mol, flagPossibleStereoCenters=True, force=True)\n",
    "    Chem.AssignAtomChiralTagsFromStructure(mol,-1)\n",
    "\n",
    "    return mol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def xyz2mol(atomicNumList, charge, xyz_coordinates, charged_fragments, quick):\n",
    "\n",
    "    # Get atom connectivity (AC) matrix, list of atomic numbers, molecular charge, \n",
    "    # and mol object with no connectivity information\n",
    "    AC,mol,dMat = xyz2AC(atomicNumList, xyz_coordinates)\n",
    "\n",
    "    # Convert AC to bond order matrix and add connectivity and charge info to mol object\n",
    "    new_mol = AC2mol(mol, AC, atomicNumList, charge, charged_fragments, quick)\n",
    "\n",
    "    # Check for stereocenters and chiral centers\n",
    "    new_mol = chiral_stereo_check(new_mol)\n",
    "\n",
    "    return new_mol,dMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def mol_from_xyz(filepath, add_hs=True):\n",
    "    charged_fragments = True  # alternatively radicals are made\n",
    "\n",
    "    # quick is faster for large systems but requires networkx\n",
    "    # if you don't want to install networkx set quick=False and\n",
    "    # uncomment 'import networkx as nx' at the top of the file\n",
    "    quick = True\n",
    "\n",
    "    atomicNumList, charge, xyz_coordinates = read_xyz_file(filepath)\n",
    "    mol, dMat = xyz2mol(atomicNumList, charge, xyz_coordinates, charged_fragments, quick)\n",
    "    \n",
    "    # Compute distance from centroid\n",
    "    xyz_coord_array = np.array(xyz_coordinates)\n",
    "    centroid = xyz_coord_array.mean(axis=0)\n",
    "    dFromCentroid = norm(xyz_coord_array - centroid, axis=1)\n",
    "\n",
    "    # Canonical hack\n",
    "#     smiles = Chem.MolToSmiles(mol, isomericSmiles=True)\n",
    "#     mol = Chem.MolFromSmiles(smiles)\n",
    "#     if add_hs: mol = Chem.AddHs(mol)\n",
    "    return mol, dMat, dFromCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total xyz filepath #  130775\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "xyz_filepath_list = list(glob(DATA_PATH+'structures/*.xyz'))\n",
    "xyz_filepath_list.sort()\n",
    "n_mols = len(xyz_filepath_list)\n",
    "print('total xyz filepath # ', n_mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902cbd0493b14ca1869e0fa30ccb0045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=130775), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsgdb9nsd_017732 Sanitization error: Explicit valence for atom # 4 C greater than permitted\n",
      "dsgdb9nsd_037494 Sanitization error: Explicit valence for atom # 4 C greater than permitted\n",
      "dsgdb9nsd_037900 Sanitization error: Explicit valence for atom # 5 C greater than permitted\n",
      "dsgdb9nsd_042676 Sanitization error: Explicit valence for atom # 3 C greater than permitted\n",
      "dsgdb9nsd_042681 Sanitization error: Explicit valence for atom # 3 C greater than permitted\n",
      "dsgdb9nsd_044308 Sanitization error: Explicit valence for atom # 5 C greater than permitted\n",
      "dsgdb9nsd_044322 Sanitization error: Explicit valence for atom # 5 C greater than permitted\n",
      "dsgdb9nsd_048903 Sanitization error: Explicit valence for atom # 2 C greater than permitted\n",
      "dsgdb9nsd_066495 Sanitization error: Explicit valence for atom # 7 C greater than permitted\n",
      "dsgdb9nsd_067109 Sanitization error: Explicit valence for atom # 2 C greater than permitted\n",
      "dsgdb9nsd_073323 Sanitization error: Explicit valence for atom # 4 C greater than permitted\n",
      "dsgdb9nsd_090191 Sanitization error: Explicit valence for atom # 3 C greater than permitted\n",
      "dsgdb9nsd_090838 Sanitization error: Explicit valence for atom # 5 C greater than permitted\n",
      "dsgdb9nsd_107870 Sanitization error: Explicit valence for atom # 2 C greater than permitted\n",
      "dsgdb9nsd_133831 Sanitization error: Explicit valence for atom # 2 C greater than permitted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dist_matrices = {}\n",
    "mols = {}\n",
    "dist_from_centroids = {}\n",
    "for i in tqdm_notebook(range(n_mols)):\n",
    "    filepath = xyz_filepath_list[i]\n",
    "    mol_name = filepath.split('/')[-1][:-4]\n",
    "    try: \n",
    "        mol, dist_matrix, dist_from_centroid = mol_from_xyz(filepath)\n",
    "        mols[mol_name] = mol\n",
    "        dist_matrices[mol_name] = dist_matrix\n",
    "        dist_from_centroids[mol_name] = dist_from_centroid\n",
    "    except ValueError as e: \n",
    "        print(mol_name, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EDGE_FEATURES        = 16\n",
    "N_ATOM_FEATURES        = 27\n",
    "N_MASTER_EDGE_FEATURES = 9\n",
    "N_MASTER_FEATURES      = 9\n",
    "MAX_N_ATOMS            = 29\n",
    "MAX_N_BONDS            = 58\n",
    "TYPES                  = train_df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def get_edge_features(mol, eucl_dist):\n",
    "#     \"\"\"\n",
    "#     Compute the following features for each entry in the adjacency matrix pf 'mol':\n",
    "#         - bond type one-hot: categorical {1: single, 2: double, 3: triple, 4: aromatic}\n",
    "#         - is conjugated: bool {0, 1}\n",
    "#         - is in ring: bool {0, 1}\n",
    "#         - graph distance: int\n",
    "#         - euclidean distance: float\n",
    "#     \"\"\"\n",
    "#     n_atoms = mol.GetNumAtoms()\n",
    "#     features = np.zeros((n_atoms, n_atoms, N_EDGE_FEATURES-8))\n",
    "\n",
    "#     # compute distance features\n",
    "#     graph_dist = Chem.AllChem.GetDistanceMatrix(mol)\n",
    "\n",
    "#     features[:,:,-1] = eucl_dist\n",
    "#     features[:,:,-2] = graph_dist\n",
    "#     for e in mol.GetBonds():\n",
    "#         i = e.GetBeginAtomIdx()\n",
    "#         j = e.GetEndAtomIdx()\n",
    "#         dc_e_feats = dc.feat.graph_features.bond_features(e).astype(int)\n",
    "#         features[i,j,:6], features[j,i,:6] = dc_e_feats, dc_e_feats\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_edge_features(mol, eucl_dist, row):\n",
    "    \"\"\"\n",
    "    Compute the following features for each entry in the adjacency matrix pf 'mol':\n",
    "        - bond type one-hot: categorical {1: single, 2: double, 3: triple, 4: aromatic}\n",
    "        - is conjugated: bool {0, 1}\n",
    "        - is in ring: bool {0, 1}\n",
    "        - graph distance: int\n",
    "        - euclidean distance: float\n",
    "        - type of scalar couplig type: categorical {1:8}\n",
    "    \"\"\"\n",
    "    n_atoms, n_bonds = mol.GetNumAtoms(), mol.GetNumBonds()\n",
    "    n_edge_features = (n_bonds + 1) * 2\n",
    "    features = np.zeros((n_edge_features, N_EDGE_FEATURES))\n",
    "    pairs_idx = np.zeros((n_edge_features, 2)) - 1\n",
    "    \n",
    "    graph_dist = Chem.AllChem.GetDistanceMatrix(mol)\n",
    "    scalar_coupling_has_bond = False\n",
    "    for n, e in enumerate(mol.GetBonds()):\n",
    "        ix1 = 2 * n\n",
    "        ix2 = (2 * n) + 1\n",
    "        i = e.GetBeginAtomIdx()\n",
    "        j = e.GetEndAtomIdx()\n",
    "        dc_e_feats = dc.feat.graph_features.bond_features(e).astype(int)\n",
    "        for ix in [ix1, ix2]:\n",
    "            features[ix, :6] = dc_e_feats\n",
    "            features[ix, 6] = graph_dist[i, j]\n",
    "            features[ix, 7] = eucl_dist[i, j]\n",
    "            if (row['atom_index_0'], row['atom_index_1']) in [(i, j), (j, i)]:\n",
    "                features[ix, 8:] = (TYPES == row['type']).astype(float)\n",
    "                scalar_coupling_has_bond = True\n",
    "        pairs_idx[ix1] = i, j\n",
    "        pairs_idx[ix2] = j, i\n",
    "    if not scalar_coupling_has_bond:\n",
    "        for ix in [-2, -1]:\n",
    "            features[ix, 6] = graph_dist[row['atom_index_0'], row['atom_index_1']]\n",
    "            features[ix, 7] = eucl_dist[row['atom_index_0'], row['atom_index_1']]\n",
    "            features[ix, 8:] = (TYPES == row['type']).astype(float)\n",
    "        pairs_idx[-2] = row['atom_index_0'], row['atom_index_1']\n",
    "        pairs_idx[-1] = row['atom_index_1'], row['atom_index_0']\n",
    "    return features[pairs_idx[:,0].argsort()], pairs_idx[pairs_idx[:,0].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [],
   "source": [
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(f\"input {x} not in allowable set{allowable_set}:\")\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def get_atom_features(mol):\n",
    "    \"\"\"\n",
    "    Compute the following features for each atom in 'mol':\n",
    "        - atom type: H, C, N, O, F (one-hot)\n",
    "        - degree: 0, 1, 2, 3, 4 (one-hot)\n",
    "        - implicit valence: 0, 1, 2, 3, 4, 5 (one-hot)\n",
    "        - Hybridization: SP, SP2, SP3, SP3D, SP3D2 (one-hot)\n",
    "        - is aromatic: bool {0, 1}\n",
    "        - formal charge: int\n",
    "        - num radical electrons: int\n",
    "        - atomic number: int\n",
    "    \"\"\"\n",
    "    n_atoms = mol.GetNumAtoms()\n",
    "    features = np.zeros((n_atoms, N_ATOM_FEATURES-1))\n",
    "    for a in mol.GetAtoms():\n",
    "        a_feats = one_of_k_encoding(a.GetSymbol(), ['H', 'C', 'N', 'O', 'F']) \\\n",
    "            + one_of_k_encoding(a.GetDegree(), [0, 1, 2, 3, 4]) \\\n",
    "            + one_of_k_encoding(a.GetImplicitValence(), [0, 1, 2, 3, 4]) \\\n",
    "            + one_of_k_encoding_unk(a.GetHybridization(), [\n",
    "                Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
    "                Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.SP3D, \n",
    "                Chem.rdchem.HybridizationType.SP3D2, Chem.rdchem.HybridizationType.UNSPECIFIED]) \\\n",
    "            + [a.GetIsAromatic(), a.GetFormalCharge(), a.GetNumRadicalElectrons(), a.GetAtomicNum(),\n",
    "               a.IsInRing()]\n",
    "        features[a.GetIdx(),:] = np.array(a_feats).astype(int)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# n_obs = 50000 # len(mols)\n",
    "# atomic_features = np.zeros((n_obs, MAX_N_ATOMS, N_ATOM_FEATURES))\n",
    "# edge_features = np.zeros((n_obs, MAX_N_ATOMS, MAX_N_ATOMS, N_EDGE_FEATURES))\n",
    "# mask = np.zeros((n_mols, MAX_N_ATOMS))\n",
    "# target = np.zeros(n_obs)\n",
    "# keep = []\n",
    "# mol_name = ''\n",
    "# succesful_mols = list(mols.keys())\n",
    "# types = train_df['type'].unique()\n",
    "# for i in tqdm_notebook(range(n_obs)):\n",
    "#     row = train_df.iloc[i,:]\n",
    "#     new_mol_name = row['molecule_name']\n",
    "#     if mol_name!=new_mol_name:\n",
    "#         if new_mol_name in succesful_mols:\n",
    "#             mol_name = new_mol_name\n",
    "#             mol, dist_matrix = mols[mol_name], dist_matrices[mol_name]\n",
    "#             n_atoms = mol.GetNumAtoms()\n",
    "#         else:\n",
    "#             continue\n",
    "#     atomic_features[i, :n_atoms, :-1] = get_atom_features(mol)\n",
    "#     atomic_features[i, row['atom_index_0'], -1] = 1.\n",
    "#     atomic_features[i, row['atom_index_1'], -1] = 1.\n",
    "#     edge_features[i, :n_atoms, :n_atoms, :-8] = get_edge_features(mol, dist_matrix)\n",
    "#     edge_features[i, row['atom_index_0'], row['atom_index_1'], -8:] = (types == row['type']).astype(float)\n",
    "#     mask[i,:n_atoms] = 1.\n",
    "#     target[i] = row['scalar_coupling_constant']\n",
    "#     keep.append(i)\n",
    "# keep = np.array(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# n_obs = 50000 # len(mols)\n",
    "# atomic_features = np.zeros((n_obs, MAX_N_ATOMS, N_ATOM_FEATURES))\n",
    "# edge_features = np.zeros((n_obs, MAX_N_BONDS, N_EDGE_FEATURES))\n",
    "# pairs_idx = np.zeros((n_obs, MAX_N_BONDS, 2)) - 1\n",
    "# mask = np.zeros((n_obs, MAX_N_ATOMS))\n",
    "# edge_mask = np.zeros((n_obs, MAX_N_BONDS))\n",
    "# target = np.zeros(n_obs)\n",
    "# keep = []\n",
    "# mol_name = ''\n",
    "# succesful_mols = list(mols.keys())\n",
    "# for i in tqdm_notebook(range(n_obs)):\n",
    "#     row = train_df.iloc[i,:]\n",
    "#     new_mol_name = row['molecule_name']\n",
    "#     if mol_name!=new_mol_name:\n",
    "#         if new_mol_name in succesful_mols:\n",
    "#             mol_name = new_mol_name\n",
    "#             mol, dist_matrix = mols[mol_name], dist_matrices[mol_name]\n",
    "#             n_atoms = mol.GetNumAtoms()\n",
    "#             n_bonds = mol.GetNumBonds()\n",
    "#             n_edge_features = (n_bonds + 1) * 2\n",
    "#         else:\n",
    "#             continue\n",
    "#     atomic_features[i, :n_atoms, :-1] = get_atom_features(mol)\n",
    "#     atomic_features[i, row['atom_index_0'], -1] = 1.\n",
    "#     atomic_features[i, row['atom_index_1'], -1] = 1.\n",
    "#     edge_features[i, :n_edge_features, :], pairs_idx[i, :n_edge_features, :] = \\\n",
    "#         get_edge_features(mol, dist_matrix, row)\n",
    "#     mask[i, :n_atoms], edge_mask[i, pairs_idx[i,:,0] != -1] = 1., 1.\n",
    "#     target[i] = row['scalar_coupling_constant']\n",
    "#     keep.append(i)\n",
    "# keep = np.array(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e98aef7f5944f6a4e7fe713bd07d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_obs = 50000 # len(mols)\n",
    "atomic_features = np.zeros((n_obs, MAX_N_ATOMS, N_ATOM_FEATURES))\n",
    "master_features = np.zeros((n_obs, N_MASTER_FEATURES))\n",
    "edge_features = np.zeros((n_obs, MAX_N_BONDS, N_EDGE_FEATURES))\n",
    "master_edge_features = np.zeros((n_obs, MAX_N_ATOMS, N_MASTER_EDGE_FEATURES))\n",
    "pairs_idx = np.zeros((n_obs, MAX_N_BONDS, 2)) - 1\n",
    "mask = np.zeros((n_obs, MAX_N_ATOMS))\n",
    "edge_mask = np.zeros((n_obs, MAX_N_BONDS))\n",
    "target = np.zeros(n_obs)\n",
    "keep = []\n",
    "mol_name = ''\n",
    "succesful_mols = list(mols.keys())\n",
    "for i in tqdm_notebook(range(n_obs)):\n",
    "    row = train_df.iloc[i,:]\n",
    "    new_mol_name = row['molecule_name']\n",
    "    if mol_name!=new_mol_name:\n",
    "        if new_mol_name in succesful_mols:\n",
    "            mol_name = new_mol_name\n",
    "            mol, dist_matrix = mols[mol_name], dist_matrices[mol_name]\n",
    "            dist_from_centroid = dist_from_centroids[mol_name]\n",
    "            n_atoms = mol.GetNumAtoms()\n",
    "            n_bonds = mol.GetNumBonds()\n",
    "            n_edge_features = (n_bonds + 1) * 2\n",
    "        else:\n",
    "            continue\n",
    "    atomic_features[i, :n_atoms, :-1] = get_atom_features(mol)\n",
    "    atomic_features[i, row['atom_index_0'], -1] = 1.\n",
    "    atomic_features[i, row['atom_index_1'], -1] = 1.\n",
    "    master_features[i, :6] = row[['num_atoms', 'num_C_atoms', 'num_H_atoms', \n",
    "                                  'num_N_atoms', 'num_O_atoms', 'num_F_atoms']]\n",
    "    master_features[i, 6:] = mol.GetNumHeavyAtoms(), n_bonds, mol.GetRingInfo().NumRings()\n",
    "    edge_features[i, :n_edge_features, :], pairs_idx[i, :n_edge_features, :] = \\\n",
    "        get_edge_features(mol, dist_matrix, row)\n",
    "    master_edge_features[i, :n_atoms, 0] = dist_from_centroid\n",
    "    master_edge_features[i, row['atom_index_0'], 1:] = (TYPES == row['type']).astype(float)\n",
    "    master_edge_features[i, row['atom_index_1'], 1:] = (TYPES == row['type']).astype(float)\n",
    "    mask[i, :n_atoms], edge_mask[i, pairs_idx[i,:,0] != -1] = 1., 1.\n",
    "    target[i] = row['scalar_coupling_constant']\n",
    "    keep.append(i)\n",
    "keep = np.array(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_features      = atomic_features[keep]\n",
    "master_features      = master_features[keep]\n",
    "edge_features        = edge_features[keep]\n",
    "master_edge_features = master_edge_features[keep]\n",
    "pairs_idx            = pairs_idx[keep]\n",
    "mask                 = mask[keep]\n",
    "edge_mask            = edge_mask[keep]\n",
    "target               = target[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.505295, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       [1.006628, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       [1.302268, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       [1.808148, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       ...,\n",
       "       [2.682558, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       [2.001112, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       [2.187803, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_features,master_edge_features\n",
    "master_edge_features[i,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atomic_features.shape\t\t: (50000, 29, 27)\n",
      "edge_features.shape\t\t: (50000, 58, 16)\n",
      "master_features.shape\t\t: (50000, 9)\n",
      "master_edge_features.shape\t: (50000, 29, 9)\n"
     ]
    }
   ],
   "source": [
    "print(f'atomic_features.shape\\t\\t: {atomic_features.shape}\\nedge_features.shape\\t\\t: {edge_features.shape}'\n",
    "      f'\\nmaster_features.shape\\t\\t: {master_features.shape}\\nmaster_edge_features.shape\\t: {master_edge_features.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MPNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "enn_args = dict(layers=[50, 50, 50, 50], act=nn.ReLU(True), dropout=[0.0, 0.0, 0.0, 0.0], batch_norm=False)\n",
    "master_enn_args = dict(layers=[50, 50, 50, 50], act=nn.ReLU(True), dropout=[0.0, 0.0, 0.0, 0.0], batch_norm=False)\n",
    "R_net_args = dict(layers=[200, 100], act=nn.ReLU(True), dropout=[0.0, 0.0], batch_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "def hidden_layer(n_in, n_out, batch_norm, dropout, act=None):\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(n_in, n_out))\n",
    "    if act: layers.append(act)\n",
    "    if batch_norm: layers.append(nn.BatchNorm1d(n_out))\n",
    "    if dropout != 0: layers.append(nn.Dropout(dropout))\n",
    "    return layers\n",
    "\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input, n_output, layers=[], act=nn.ReLU(True), dropout=[], batch_norm=False):\n",
    "        super().__init__()\n",
    "        sizes = [n_input] + layers + [n_output]\n",
    "        layers_ = []\n",
    "        for i, (n_in, n_out, dr) in enumerate(zip(sizes[:-1], sizes[1:], dropout+[0.0])):\n",
    "            act_ = act if i < len(layers) else None\n",
    "            batch_norm_ = batch_norm if i < len(layers) else False\n",
    "            layers_ += hidden_layer(n_in, n_out, batch_norm_, dr, act_)      \n",
    "        self.layers = nn.Sequential(*layers_)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class HiddenLSTMCell(nn.Module):\n",
    "    \"\"\"Implements the LSTM cell update described in the sec 4.2 of https://arxiv.org/pdf/1511.06391.pdf.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_h_out):\n",
    "        \"\"\"This LSTM cell takes no external 'x' inputs, but has a hidden state appended with the \n",
    "        readout from a content based attention mechanism. Therefore the hidden state is of a dimension\n",
    "        that is two times the number of nodes in the set.\"\"\"\n",
    "        super().__init__()\n",
    "        self.n_h_out, self.n_h = n_h_out, n_h_out * 2 \n",
    "        self.w_h = nn.Parameter(torch.Tensor(self.n_h, n_h_out * 4))\n",
    "        self.b = nn.Parameter(torch.Tensor(n_h_out * 4))\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2: \n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            else: \n",
    "                nn.init.zeros_(p.data)\n",
    "                # initialize the forget gate bias to 1\n",
    "                p.data[self.n_h_out:self.n_h_out*2] = torch.ones(self.n_h_out)\n",
    "        \n",
    "    def forward(self, h_prev, c_prev):\n",
    "        \"\"\"Takes previuos hidden and cell states as arguments and performs a single LSTM step using \n",
    "        no external input.\n",
    "        \"\"\"\n",
    "        n_h_ = self.n_h_out # number of output hidden states\n",
    "        # batch the computations into a single matrix multiplication\n",
    "        gates = h_prev @ self.w_h + self.b\n",
    "        i_g, f_g, g, o_g = (\n",
    "            torch.sigmoid(gates[:, :n_h_]), # input\n",
    "            torch.sigmoid(gates[:, n_h_:n_h_*2]), # forget\n",
    "            torch.tanh(gates[:, n_h_*2:n_h_*3]),\n",
    "            torch.sigmoid(gates[:, n_h_*3:]), # output\n",
    "        )\n",
    "        c = f_g * c_prev + i_g * g\n",
    "        h = o_g * torch.tanh(c)\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Set2Set(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted from: https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric\\\n",
    "        /nn/glob/set2set.html#Set2Set\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, proc_steps):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = 2 * in_channels\n",
    "        self.proc_steps = proc_steps\n",
    "        self.lstm = HiddenLSTMCell(self.in_channels)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        x - input tensor of shape (batch_size, n_nodes, in_channels)\n",
    "        mask - integer tensor used to zero out nodes missing in a particualr graph \n",
    "            (not all graphs have 'n_nodes'). Is of shape (batch_size, n_nodes)\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = mask.size(0), mask.size(1)\n",
    "        batch_idx = torch.arange(0, batch_size).expand(n_nodes, batch_size).transpose(0, 1)\n",
    "        h = torch.zeros(batch_size, self.in_channels, device=x.device)\n",
    "        q_star = torch.zeros(batch_size, self.out_channels, device=x.device\n",
    "                            )\n",
    "        mask = (mask.float() - 1) * 1e6\n",
    "        for i in range(self.proc_steps):\n",
    "            q, h = self.lstm(q_star, h)\n",
    "            e = (x * q[batch_idx]).sum(dim=-1)\n",
    "            # set masked nodes not to large negative energy (attention mask will convert this to 0)\n",
    "            e += mask \n",
    "            a = F.softmax(e, dim=-1)\n",
    "            # sum a*x over node dimension \n",
    "            r = torch.sum(a.unsqueeze(-1) * x, dim=1)\n",
    "            q_star = torch.cat([q, r], dim=-1)\n",
    "            \n",
    "        return q_star\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels, self.out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "code_folding": [
     0,
     23,
     113
    ]
   },
   "outputs": [],
   "source": [
    "def segment_sum(data, segment_ids):\n",
    "    \"\"\"\n",
    "    Computes the sum along segments of a tensor. Analogous to tf.unsorted_segment_sum.\n",
    "\n",
    "    :param data: A tensor whose segments are to be summed.\n",
    "    :param segment_ids: The segment indices tensor.\n",
    "    :return: A tensor of same data type as the data argument.\n",
    "    \"\"\"\n",
    "    assert all([i in data.shape for i in segment_ids.shape]), \"segment_ids.shape should be a prefix of data.shape\"\n",
    "        \n",
    "    # segment_ids is a 1-D tensor repeat it to have the same shape as data\n",
    "    if len(segment_ids.shape) == 1:\n",
    "        s = torch.prod(torch.tensor(data.shape[1:], device=data.device)).long()\n",
    "        segment_ids = segment_ids.repeat_interleave(s).view(segment_ids.shape[0], *data.shape[1:])\n",
    "\n",
    "    assert data.shape == segment_ids.shape, \"data.shape and segment_ids.shape should be equal\"\n",
    "\n",
    "    num_segments = len(torch.unique(segment_ids))\n",
    "    shape = [num_segments] + list(data.shape[1:])\n",
    "    tensor = torch.zeros(*shape, device=data.device).scatter_add(0, segment_ids, data.float())\n",
    "    tensor = tensor.type(data.dtype)\n",
    "    return tensor\n",
    "\n",
    "class EdgeNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_h, n_e, fully_connected_graph=False, use_master_node=False, \n",
    "                 n_h_m=0, n_e_m=0, net_args={}, master_net_args={}):\n",
    "        super().__init__()\n",
    "        self.n_e, self.n_h, self.n_e_m, self.n_h_m = n_e, n_h, n_e_m, n_h_m\n",
    "        self.fully_connected_graph = fully_connected_graph\n",
    "        self.use_master_node = use_master_node\n",
    "        self.adj_net = FullyConnectedNet(n_e, n_h ** 2, **net_args)\n",
    "        self.b = nn.Parameter(torch.Tensor(n_h)) # bias for the message function\n",
    "        nn.init.zeros_(self.b)\n",
    "        if use_master_node:\n",
    "            self.master_adj_net_in = FullyConnectedNet(n_e_m, n_h * n_h_m, **master_net_args)\n",
    "            self.master_adj_net_out = FullyConnectedNet(n_e_m, n_h_m * n_h, **master_net_args)\n",
    "            self.b_m = nn.Parameter(torch.Tensor(n_h_m)) # bias for the master message function\n",
    "            nn.init.zeros_(self.b_m)\n",
    "    \n",
    "    def forward(self, h, e, mask=None, pairs_idx=None, edge_mask=None, h_m=None, e_m=None):\n",
    "        \"\"\"\n",
    "        Compute message vector m_t given the previuos hidden state\n",
    "        h_t-1 and edge features e. e_out represents the same edge \n",
    "        features as e_in with adj matrix transposed.\n",
    "        - h is a collection of hidden states of shape (batch_size, n_nodes, n_h)\n",
    "        - e is a collection of edge features of shape \n",
    "            (batch_size, n_nodes, n_nodes, n_e) if fully_connected_graph\n",
    "            else shape is (batch_size, n_edges, n_e).\n",
    "        - mask is a tensor used to  zero out nodes missing in a particualr \n",
    "            graph (not all graphs have 'n_nodes'). Is of shape \n",
    "            (batch_size, n_nodes)\n",
    "        - pairs_idx: if self.fully_connected_graph = False this is a tensor\n",
    "            of shape (batch_size, n_edges, 2) mapping atom indexes \n",
    "            (first column) to the other atom indexes they form a bond with\n",
    "            (second column. \n",
    "        - edge_mask: if self.fully_connected_graph = False this is a tensor\n",
    "            of shape (batch_size, n_edges) masking non present edges.\n",
    "        - h_m: if not None, tensor of shape (batch_size, n_h_m) containing \n",
    "            hidden states for master node.\n",
    "        - e_m: if not None, tensor of shape (batch_size, n_nodes, n_e_m) containing \n",
    "            edge features for edges connected to the master node.\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = h.size(0), h.size(1)\n",
    "        \n",
    "        # compute a\n",
    "        a_vect = self.adj_net(e.view(-1, self.n_e))\n",
    "        if self.fully_connected_graph:\n",
    "            a_tmp = a_vect.view(-1, n_nodes, n_nodes, self.n_h, self.n_h).transpose(2, 3)\n",
    "            a = a_tmp.contiguous().view(-1, n_nodes * self.n_h, n_nodes * self.n_h)\n",
    "            h_flat = h.view(batch_size, n_nodes * self.n_h, 1)\n",
    "            m = torch.matmul(a, h_flat).view(batch_size * n_nodes, self.n_h)\n",
    "        else:\n",
    "            n_edges = e.size(1)\n",
    "            edge_mask_ = edge_mask.type(torch.uint8)==True\n",
    "            edge_mask_flat = edge_mask.view(-1).type(torch.uint8)==True\n",
    "            \n",
    "            a_mat = a_vect[edge_mask_flat].view(-1, self.n_h, self.n_h)\n",
    "            h_stacked = torch.cat([h[b,ix,:] for b, ix in enumerate(torch.unbind(pairs_idx[:,:,1]))])\n",
    "            h_stacked = h_stacked[edge_mask_flat]\n",
    "            ah = torch.einsum('bij,bjk->bik', h_stacked.unsqueeze(1), a_mat).squeeze(1)\n",
    "            \n",
    "            n_nodes_per_graph = pairs_idx[:,:,0].max(dim=1).values + 1\n",
    "            unique_idx = pairs_idx[:,:,0] + (torch.cat([\n",
    "                                                 torch.zeros(1, dtype=torch.long, device=h.device), \n",
    "                                                 n_nodes_per_graph[:-1].cumsum(dim=0)\n",
    "                                             ])).unsqueeze(-1).expand(-1, n_edges)\n",
    "            m_stacked = segment_sum(ah, unique_idx[edge_mask_])\n",
    "            \n",
    "            m_per_graph_lst = torch.split(m_stacked, n_nodes_per_graph.tolist())\n",
    "            m = torch.cat([F.pad(m_, pad=(0, 0, 0, n_nodes - n_nodes_)) \n",
    "                           for m_, n_nodes_ in zip(m_per_graph_lst, n_nodes_per_graph)]) \n",
    "            \n",
    "            if self.use_master_node:\n",
    "                a_mo_vect = self.master_adj_net_out(e_m.view(-1, self.n_e_m)) # dim(a_mo_vect) = (batch_size * n_nodes, n_h_m * n_h)\n",
    "                a_mo_mat = a_mo_vect.view(-1, self.n_h_m, self.n_h)\n",
    "                h_m_expanded = h_m.repeat_interleave(n_nodes, 0).unsqueeze(1)\n",
    "                ah_mo = torch.einsum('bij,bjk->bik', h_m_expanded, a_mo_mat).squeeze(1) # dim(ah_mo) = (batch_size * n_nodes, n_h)\n",
    "                m += ah_mo * mask.view(-1, 1)\n",
    "                \n",
    "                a_mi_vect = self.master_adj_net_in(e_m.view(-1, self.n_e_m)) # dim(a_mi_vect) = (batch_size * n_nodes, n_h * n_h_m)\n",
    "                a_mi_mat = a_mi_vect.view(-1, self.n_h, self.n_h_m)\n",
    "                ah_mi = torch.einsum('bij,bjk->bik', h.view(-1, self.n_h).unsqueeze(1), a_mi_mat).squeeze(1) # dim(ah_mi) = (batch_size, 1, n_h_m)\n",
    "                m_m = (ah_mi.view(-1, n_nodes, self.n_h_m) * mask.unsqueeze(-1)).sum(dim=1)\n",
    "            \n",
    "        m += self.b\n",
    "        \n",
    "        if self.use_master_node:\n",
    "            m_m += self.b_m\n",
    "            return m.view(batch_size, n_nodes, self.n_h), m_m\n",
    "        else:\n",
    "            return m.view(batch_size, n_nodes, self.n_h)\n",
    "\n",
    "class EdgeNetworkV2(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_h, n_e, fully_connected_graph=False, use_master_node=False, \n",
    "                 n_h_m=0, n_e_m=0, net_args={}, master_net_args={}):\n",
    "        super().__init__()\n",
    "        self.n_e, self.n_h, self.n_e_m, self.n_h_m = n_e, n_h, n_e_m, n_h_m\n",
    "        self.fully_connected_graph = fully_connected_graph\n",
    "        self.use_master_node = use_master_node\n",
    "        self.adj_net = FullyConnectedNet(n_e + n_h, n_h, **net_args)\n",
    "        if use_master_node:\n",
    "            self.master_adj_net_in = FullyConnectedNet(n_e_m + n_h, n_h_m, **master_net_args)\n",
    "            self.master_adj_net_out = FullyConnectedNet(n_e_m + n_h_m, n_h, **master_net_args)\n",
    "    \n",
    "    def forward(self, h, e, mask=None, pairs_idx=None, edge_mask=None, h_m=None, e_m=None):\n",
    "        \"\"\"\n",
    "        Compute message vector m_t given the previuos hidden state\n",
    "        h_t-1 and edge features e. e_out represents the same edge \n",
    "        features as e_in with adj matrix transposed.\n",
    "        - h is a collection of hidden states of shape (batch_size, n_nodes, n_h)\n",
    "        - e is a collection of edge features of shape \n",
    "            (batch_size, n_nodes, n_nodes, n_e) if fully_connected_graph\n",
    "            else shape is (batch_size, n_edges, n_e).\n",
    "        - mask is a tensor used to  zero out nodes missing in a particualr \n",
    "            graph (not all graphs have 'n_nodes'). Is of shape \n",
    "            (batch_size, n_nodes)\n",
    "        - pairs_idx: if self.fully_connected_graph = False this is a tensor\n",
    "            of shape (batch_size, n_edges, 2) mapping atom indexes \n",
    "            (first column) to the other atom indexes they form a bond with\n",
    "            (second column. \n",
    "        - edge_mask: if self.fully_connected_graph = False this is a tensor\n",
    "            of shape (batch_size, n_edges) masking non present edges.\n",
    "        - h_m: if not None, tensor of shape (batch_size, n_h_m) containing \n",
    "            hidden states for master node.\n",
    "        - e_m: if not None, tensor of shape (batch_size, n_nodes, n_e_m) containing \n",
    "            edge features for edges connected to the master node.\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = h.size(0), h.size(1)\n",
    "        \n",
    "        # compute a\n",
    "        if self.fully_connected_graph:\n",
    "            h_stacked =  h.repeat(1, n_nodes, 1) # dim(h_resized) = (batch_size, n_nodes ** 2, n_h)\n",
    "            net_out = self.adj_net(torch.cat([e.view(-1, self.n_e), h_stacked], dim=1)) # (batch_size, n_nodes ** 2, n_h)\n",
    "            net_out_reshaped = net_out.view(-1, n_nodes, n_nodes, self.n_h)\n",
    "            net_out_masked = net_out_reshaped * mask[..., None, None].transpose(1, 2)\n",
    "            m = net_out_masked.sum(dim=2)\n",
    "        else:\n",
    "            n_edges = e.size(1)\n",
    "            edge_mask_ = edge_mask.type(torch.uint8)==True\n",
    "            edge_mask_flat = edge_mask.view(-1).type(torch.uint8)==True\n",
    "            \n",
    "            h_stacked = torch.cat([h[b,ix,:] for b, ix in enumerate(torch.unbind(pairs_idx[:,:,1]))])\n",
    "            masked_inp = torch.cat([e.view(-1, self.n_e), h_stacked], dim=1)[edge_mask_flat]\n",
    "            net_out = self.adj_net(masked_inp)\n",
    "            \n",
    "            n_nodes_per_graph = pairs_idx[:,:,0].max(dim=1).values + 1\n",
    "            unique_idx = pairs_idx[:,:,0] + (torch.cat([\n",
    "                                                 torch.zeros(1, dtype=torch.long, device=h.device), \n",
    "                                                 n_nodes_per_graph[:-1].cumsum(dim=0)\n",
    "                                             ])).unsqueeze(-1).expand(-1, n_edges)\n",
    "            m_stacked = segment_sum(net_out, unique_idx[edge_mask_])\n",
    "            \n",
    "            m_per_graph_lst = torch.split(m_stacked, n_nodes_per_graph.tolist())\n",
    "            m = torch.cat([F.pad(m_, pad=(0, 0, 0, n_nodes - n_nodes_)) \n",
    "                           for m_, n_nodes_ in zip(m_per_graph_lst, n_nodes_per_graph)]) \n",
    "            \n",
    "            if self.use_master_node:\n",
    "                mo_inp = torch.cat([e_m.view(-1, self.n_e_m), h_m.repeat_interleave(n_nodes, 0)], dim=1)\n",
    "                net_out_mo = self.master_adj_net_out(mo_inp) # dim(a_mo_vect) = (batch_size * n_nodes, n_h)\n",
    "                m += net_out_mo\n",
    "                \n",
    "                mi_inp = torch.cat([e_m.view(-1, self.n_e_m), h.view(-1, self.n_h)], dim=1)\n",
    "                net_out_mi = self.master_adj_net_in(mi_inp) # dim(a_mo_vect) = (batch_size * n_nodes, n_h)\n",
    "                net_out_mi_masked = net_out_mi.view(-1, n_nodes, self.n_h_m) * mask.unsqueeze(-1)\n",
    "                m_m = net_out_mi_masked.sum(dim=1)\n",
    "        \n",
    "        if self.use_master_node:\n",
    "            return m.view(batch_size, n_nodes, self.n_h), m_m\n",
    "        else:\n",
    "            return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class GRUUpdate(nn.Module):\n",
    "    def __init__(self, n_h):\n",
    "        super().__init__()\n",
    "        self.n_h = n_h\n",
    "        self.gru = nn.GRUCell(n_h, n_h)\n",
    "        \n",
    "    def forward(self, m, h_prev, mask):\n",
    "        \"\"\"\n",
    "        Update hidden state h.\n",
    "        - h_prev is vector of hidden states of shape (batch_size, n_nodes, n_h)\n",
    "        - m is vector of messages of shape (batch_size, n_nodes, n_h)\n",
    "        - mask is used to  zero out nodes missing in a particualr graph (not all graphs \n",
    "            have 'n_nodes'). Is of shape (batch_size, n_nodes)\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = h_prev.size(0), h_prev.size(1)\n",
    "        h = self.gru(m.view(-1, self.n_h), h_prev.view(-1, self.n_h))\n",
    "        return h.view(batch_size, n_nodes, self.n_h) * mask.unsqueeze(-1).expand(batch_size, n_nodes, self.n_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Set2SetOutput(nn.Module):\n",
    "    def __init__(self, n_x, n_h, proc_steps, net_args, use_master_node=False, n_x_m=0, n_h_m=0):\n",
    "        super().__init__()\n",
    "        self.n_h, self.n_x = n_h, n_x\n",
    "        self.use_master_node = use_master_node\n",
    "        self.R_proj = nn.Linear(n_h + n_x, n_h)\n",
    "        if use_master_node: self.R_proj_m = nn.Linear(n_h_m + n_x_m, n_h)\n",
    "        self.R_proc = Set2Set(n_h, proc_steps)\n",
    "        self.R_write = FullyConnectedNet(2 * n_h, 1, **net_args)\n",
    "    \n",
    "    def forward(self, h, x, mask, h_m=None, x_m=None):\n",
    "        \"\"\"\n",
    "        Update hidden state h.\n",
    "        - h is vector of hidden states of shape (batch_size, n_nodes, n_h)\n",
    "        - x is vector of input features of shape (batch_size, n_nodes, n_x)\n",
    "        - mask is used to  zero out nodes missing in a particualr graph (not all graphs \n",
    "            have 'n_nodes'). Is of shape (batch_size, n_nodes)\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = h.size(0), h.size(1)\n",
    "        m = self.R_proj(torch.cat([h.view(-1, self.n_h), x.view(-1, self.n_x)], dim=1))\n",
    "        m_reshaped = m.view(batch_size, n_nodes, self.n_h)\n",
    "        if self.use_master_node: \n",
    "            m_m = self.R_proj_m(torch.cat([h_m, x_m], dim=1))\n",
    "            m_reshaped = torch.cat([m_reshaped, m_m.unsqueeze(1)], dim=1)\n",
    "            mask_ = torch.cat([mask.clone(), torch.ones(batch_size, 1, device=x.device)], dim=1)\n",
    "        else:\n",
    "            mask_ = mask.clone()\n",
    "        q = self.R_proc(m_reshaped, mask_) \n",
    "        y = self.R_write(q) # dim(q) = (batch_size, n_h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNN(nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_e, update_steps=3, proc_steps=10, enn_args={}, R_net_args={}, \n",
    "                 fully_connected_graph=False, use_master_node=False, n_x_m=0, n_h_m=0, n_e_m=0,\n",
    "                 master_enn_args={}):\n",
    "        super().__init__()\n",
    "        self.n_h, self.n_x, self.n_h_m, self.n_x_m = n_h, n_x, n_h_m, n_x_m\n",
    "        self.use_master_node = use_master_node\n",
    "        self.M = EdgeNetwork(n_h, n_e, fully_connected_graph, use_master_node, n_h_m, n_e_m,\n",
    "                             enn_args, master_enn_args)\n",
    "        self.U = GRUUpdate(n_h)\n",
    "        if use_master_node: self.U_m = GRUUpdate(n_h_m)\n",
    "        self.R = Set2SetOutput(n_x, n_h, proc_steps, R_net_args, use_master_node, n_x_m, n_h_m)\n",
    "        self.update_steps = update_steps\n",
    "        \n",
    "    def forward(self, x, e, mask, pairs_idx=None, edge_mask=None, x_m=None, e_m=None):\n",
    "        h = F.pad(x, pad=(0, self.n_h - self.n_x))\n",
    "        h_m = F.pad(x_m, pad=(0, self.n_h_m - self.n_x_m)) if self.use_master_node else None\n",
    "        for t in range(self.update_steps):\n",
    "            if self.use_master_node: \n",
    "                m, m_m = self.M(h, e, mask, pairs_idx, edge_mask, h_m, e_m)\n",
    "                h = self.U(m, h, mask)\n",
    "                h_m = self.U_m(m_m.unsqueeze(1), h_m.unsqueeze(1), \n",
    "                               torch.ones(1, 1, device=x.device)).squeeze(1)\n",
    "            else:\n",
    "                m = self.M(h, e, mask, pairs_idx, edge_mask, h_m, e_m)\n",
    "                h = self.U(m, h, mask)\n",
    "        y = self.R(h, x, mask, h_m, x_m)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_master_node = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNN(\n",
      "  (M): EdgeNetworkV2(\n",
      "    (adj_net): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=66, out_features=50, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (5): ReLU(inplace)\n",
      "        (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (U): GRUUpdate(\n",
      "    (gru): GRUCell(50, 50)\n",
      "  )\n",
      "  (R): Set2SetOutput(\n",
      "    (R_proj): Linear(in_features=77, out_features=50, bias=True)\n",
      "    (R_proc): Set2Set(50, 100)\n",
      "    (R_write): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=100, out_features=200, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Linear(in_features=100, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "tensor([[0.0328],\n",
      "        [0.0323],\n",
      "        [0.0323],\n",
      "        [0.0323],\n",
      "        [0.0328],\n",
      "        [0.0323],\n",
      "        [0.0323],\n",
      "        [0.0328],\n",
      "        [0.0323],\n",
      "        [0.0328],\n",
      "        [0.0326],\n",
      "        [0.0320],\n",
      "        [0.0320],\n",
      "        [0.0326],\n",
      "        [0.0320],\n",
      "        [0.0326],\n",
      "        [0.0320],\n",
      "        [0.0299],\n",
      "        [0.0299],\n",
      "        [0.0344]], grad_fn=<AddmmBackward>)\n",
      "torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "batch_size, n_nodes, n_h, n_e, n_x, n_edges = 20, MAX_N_ATOMS, 50, N_EDGE_FEATURES, N_ATOM_FEATURES, MAX_N_BONDS\n",
    "n_h_m, n_e_m, n_x_m = 100, N_MASTER_EDGE_FEATURES, N_MASTER_FEATURES\n",
    "x     = torch.tensor(atomic_features[:batch_size,:,:], dtype=torch.float)\n",
    "e     = torch.tensor(edge_features[:batch_size,:,:], dtype=torch.float)\n",
    "msk   = torch.tensor(mask[:batch_size,:], dtype=torch.float)\n",
    "p_idx = torch.tensor(pairs_idx[:batch_size,:,:], dtype=torch.long)\n",
    "e_msk = torch.tensor(edge_mask[:batch_size,:], dtype=torch.float)\n",
    "x_m   = torch.tensor(master_features[:batch_size,:], dtype=torch.float)\n",
    "e_m   = torch.tensor(master_edge_features[:batch_size,:,:], dtype=torch.float)\n",
    "\n",
    "if use_master_node:\n",
    "    mpnn = MPNN(n_x, n_h, n_e, update_steps=5, proc_steps=10, enn_args=enn_args, R_net_args=R_net_args,\n",
    "                fully_connected_graph=False, use_master_node=use_master_node, n_x_m=n_x_m, n_h_m=n_h_m, \n",
    "                n_e_m=n_e_m, master_enn_args=master_enn_args)\n",
    "else:\n",
    "    mpnn = MPNN(n_x, n_h, n_e, update_steps=5, proc_steps=10, enn_args=enn_args, R_net_args=R_net_args,\n",
    "                fully_connected_graph=False, use_master_node=use_master_node)\n",
    "    \n",
    "print(mpnn)\n",
    "\n",
    "xs = (x, e, msk, p_idx, e_msk, x_m, e_m) if use_master_node else (x, e, msk, p_idx, e_msk)\n",
    "print(mpnn(*xs))\n",
    "print(mpnn(*xs).size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Fit MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = train_test_split(np.arange(n_obs), test_size=0.25, shuffle=True, random_state=100)\n",
    "x_train, x_val     = atomic_features[train_idx], atomic_features[val_idx]\n",
    "e_train, e_val     = edge_features[train_idx], edge_features[val_idx]\n",
    "x_m_train, x_m_val = master_features[train_idx], master_features[val_idx]\n",
    "e_m_train, e_m_val = master_edge_features[train_idx], master_edge_features[val_idx]\n",
    "y_train, y_val     = target[train_idx], target[val_idx]\n",
    "mask_train, mask_val = mask[train_idx], mask[val_idx]\n",
    "edge_mask_train, edge_mask_val = edge_mask[train_idx], edge_mask[val_idx]\n",
    "pairs_idx_train, pairs_idx_val = pairs_idx[train_idx], pairs_idx[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_target = StandardScaler()\n",
    "y_train = ss_target.fit_transform(y_train.reshape(-1,1))\n",
    "y_val = ss_target.transform(y_val.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MoleculeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, y, x, e, mask, pairs_idx=None, use_master_node=True, \n",
    "                 edge_mask=None, x_m=None, e_m=None):\n",
    "        self.n = len(y)\n",
    "        self.y = y.astype(np.float32)\n",
    "        self.x = x.astype(np.float32)\n",
    "        self.e = e.astype(np.float32)\n",
    "        self.mask = mask.astype(np.float32)\n",
    "        self.fully_connected_graphs = edge_mask is None\n",
    "        if not self.fully_connected_graphs:\n",
    "            self.pairs_idx = pairs_idx.astype(np.long)\n",
    "            self.edge_mask = edge_mask.astype(np.float32)\n",
    "            self.use_master_node = use_master_node\n",
    "            if self.use_master_node:\n",
    "                self.x_m = x_m.astype(np.float32)\n",
    "                self.e_m = e_m.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.fully_connected_graphs:\n",
    "            xs = (self.x[idx], self.e[idx], self.mask[idx])\n",
    "        else:\n",
    "            if self.use_master_node:\n",
    "                xs = (self.x[idx], self.e[idx], self.mask[idx], self.pairs_idx[idx], \n",
    "                      self.edge_mask[idx], self.x_m[idx], self.e_m[idx])\n",
    "            else: \n",
    "                xs = (self.x[idx], self.e[idx], self.mask[idx], self.pairs_idx[idx], \n",
    "                      self.edge_mask[idx])\n",
    "        return xs, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "use_master_node = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MoleculeDataset(y_train, x_train, e_train, mask_train, pairs_idx_train, \n",
    "                           use_master_node, edge_mask_train, x_m_train, e_m_train)\n",
    "val_ds   = MoleculeDataset(y_val, x_val, e_val, mask_val, pairs_idx_val, \n",
    "                           use_master_node, edge_mask_val, x_m_val, e_m_val)\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=8)\n",
    "val_dl   = DataLoader(val_ds, batch_size, num_workers=8)\n",
    "db = DataBunch(train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "code_folding": [
     0,
     7,
     32
    ]
   },
   "outputs": [],
   "source": [
    "def group_mean_log_mae(y_true, y_pred, types):\n",
    "    y_true, y_pred, types = y_true.cpu().numpy().ravel(), y_pred.cpu().numpy().ravel(), types.cpu().numpy().ravel()\n",
    "    y_true = ss_target.mean_ + y_true * ss_target.scale_\n",
    "    y_pred = ss_target.mean_ + y_pred * ss_target.scale_\n",
    "    maes = pd.Series(y_true-y_pred).abs().groupby(types).mean()\n",
    "    return np.log(maes).mean()\n",
    "\n",
    "class GroupMeanLogMAE(Callback):\n",
    "    _order = -20 #Needs to run before the recorder\n",
    "    types_cidx = 2\n",
    "\n",
    "    def __init__(self, learn, **kwargs): self.learn = learn\n",
    "    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['GroupMeanLogMAE'])\n",
    "    def on_epoch_begin(self, **kwargs): self.input, self.output, self.target = [], [], []\n",
    "    \n",
    "    def on_batch_end(self, last_target, last_output, last_input, train, **kwargs):\n",
    "        if not train:\n",
    "            last_e = last_input[1]\n",
    "            if len(last_e.size()) == 4: types = torch.nonzero(last_e[:,:,:,-8:])[:,-1]\n",
    "            else: types = torch.nonzero(last_e[:,:,-8:])[::2,-1]\n",
    "            self.input.append(types)\n",
    "            self.output.append(last_output)\n",
    "            self.target.append(last_target)\n",
    "                \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        if (len(self.input) > 0) and (len(self.output) > 0):\n",
    "            inputs = torch.cat(self.input)\n",
    "            preds = torch.cat(self.output)\n",
    "            target = torch.cat(self.target)\n",
    "            metric = group_mean_log_mae(preds, target, inputs)\n",
    "            return add_metrics(last_metrics, [metric])\n",
    "\n",
    "def set_seed(seed=100):\n",
    "    # python RNG\n",
    "    random.seed(seed)\n",
    "\n",
    "    # pytorch RNGs\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # numpy RNG\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-6\n",
    "update_steps, proc_steps = 5, 10\n",
    "n_x, n_h, n_e = N_ATOM_FEATURES, 50, N_EDGE_FEATURES\n",
    "n_x_m, n_h_m, n_e_m = N_MASTER_FEATURES, 100, N_MASTER_EDGE_FEATURES\n",
    "enn_args = dict(layers=[50, 50, 50, 50], act=nn.ReLU(True), dropout=[0.0, 0.0, 0.0, 0.0], batch_norm=False)\n",
    "master_enn_args = dict(layers=[50, 50, 50, 50], act=nn.ReLU(True), dropout=[0.0, 0.0, 0.0, 0.0], batch_norm=False)\n",
    "R_net_args = dict(layers=[200, 100], act=nn.ReLU(True), dropout=[0.0, 0.0], batch_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(100)\n",
    "if use_master_node:\n",
    "    model = MPNN(n_x, n_h, n_e, update_steps, proc_steps, enn_args, R_net_args, False, use_master_node, \n",
    "                 n_x_m, n_h_m, n_e_m, master_enn_args)\n",
    "else:\n",
    "    model = MPNN(n_x, n_h, n_e, update_steps, proc_steps, enn_args, R_net_args, False, use_master_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(db, model, metrics=[mean_absolute_error], callback_fns=GroupMeanLogMAE, \n",
    "                wd=wd, loss_func=root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd3zV9fX48dfJTsgmg5BBGGEEkBWWCmJRC9pqHfUr6s86+rXWWrW2trbWfq1ttdXuuqqt4qra1q0ouMABCEE2BAiQkEAW2Xvd9++Pe5PchIQEuJ/c3HvP8/G4D+79jHvP/XBzz31vMcaglFLKd/m5OwCllFLupYlAKaV8nCYCpZTycZoIlFLKx2kiUEopHxfg7gBOVFxcnElPT3d3GEop5VE2bdp01BgT39s+j0sE6enpZGdnuzsMpZTyKCKS39c+rRpSSikfp4lAKaV8nCYCpZTycZoIlFLKx2kiUEopH6eJQCmlfJwmAqWU8nGaCJRSygP8+YO9fLqvzJLn1kSglFIe4NGP97N2f7klz62JQCmlPIDNGPzEmufWRKCUUh7AZgyCNZlAE4FSSnkAA1oiUEopX2WMwRgQ8bASgYg8JSKlIrKjj/0TRWSdiDSLyI+sikMppTydMfZ/LcoDlpYIlgNLjrO/ArgV+L2FMSillMdz5AH8PK1EYIz5BPuXfV/7S40xG4FWq2JQSilvYHMUCXy6jUBEbhSRbBHJLiuzZkCFUkoNVR2JwOPaCFzJGPOEMSbLGJMVH9/rSmtKKeW1PLmNQCmllAt0JAKPayNQSinlGp1VQxY9v2WL14vIi8AiIE5ECoH/AwIBjDGPi8gIIBuIBGwicjuQaYypsSompZTyRFb3GrIsERhjlvWzvxhIser1lVLKW3Q1Flvz/Fo1pJRSQ5yx2f/16V5DSinlyww6jkAppXyaTXsNKaWUb9M2AqWU8nFdA8q0RKCUUj7J6FxDSinl2zraCHSFMqWU8lHaa0gppXyc9hpSSikfZ+uqG7KEJgKllPIQWiJQSikfZfXso5oIlFJqiOtcj8Cib2xNBEopNcR1rVmsVUNKKeWTOtqKraKJQHmV2qZWPtlb5u4wlHIxDy0RiMhTIlIqIjv62C8i8lcRyRWRbSIy06pYBkN9cxsFFQ3uDsMrNLW2853nssm4ewVvbztyQude+eQXXPPUBg4erbcoOqUGnyePI1gOLDnO/qVAhuN2I/CYhbG4XFNrO8XVTdhshpY2Gw+t3MOCBz9m86FKd4fm8R79OJeVO0tobTfc8q/NNLW209jS3u9572wrYvvhagD+vma/1WEqNWisnn3UyqUqPxGR9OMcchHwrLHPprReRKJFJMkYU2RVTK70k1e28cYW+6/V5OhQQoP8AfjiYAUz0mLcGZrHe3Nr91LA+gPlXPv0Rn7xtUyuP3P0MccbY9hwsIKHVuYAMCkpkpc2FnD+1CQWjo8flJiVslJnryEvHFCWDBQ4PS50bDuGiNwoItkikl1WNjTqfz/YVdJ5/3BVI7mldQDsLak9qeeraWrlhS/yu0YQ+qjaplbyyhuICw/mnEmJAPzuvT0A3Pf2LrYVVh1zzuaCKv7nifXklTfwm4un8JcrpgPw7Lq8wQp7wDpmkVTqRHSVCDyvaqg/vb2jXv9KjDFPGGOyjDFZ8fFD4xdeYlQIAA9ddhpj44d1bt9XUndSz/f7lXu4+7UdTL9vFQDtPpQQjDGs3lPK29uOsLXAXrXzu0un8uQ1sxgTP4zdRTWdx171jy+OOX/VTntSXjYnlWWz0xifGMHiiQkUVjYOzhsYoLZ2G+f+6RN++dZOd4eiPIyxdoYJ66qGBqAQSHV6nAKcWMvgIFqxvYhXvyzkyWuyaGhpJ7+8gVvOHsc3s1JZkBFPfnk97+4o5uWNBdhsBr8TLMOV17cAUNPURvpd7yACj101kyVTkqx4O0PK818c4p7Xu/cpmDAiAhFhVloMB8rsDb+z02PYmFdJQ0sbYUH2j25bu43HHe0B9188tfMXU3JMKBvyKjqfzxiDzYC/VWXrAXj441xyS+vILa3jngsyT/gzonyX8eDG4v68CVzj6D00D6gequ0Dre02bn7hSz7YXco9b+zg9pe30G4zzB0TC8CIqBDmjhnOxBERNLa2n9Av0eLqJl7bXHhMlYcx9i8OX/DcurxjtiVHhwJw51cnMGd0LD+/YBLXzE8H4JBT76yS2mYAbjhzdLdic2pMGLVNbZTWNAHw2Jr9jP3ZCppa+290tsq6/eWd9zsatZUaiM4BZZ42slhEXgTWARNEpFBEbhCRm0TkJschK4ADQC7wJHCzVbGcqgsf/rzz/vPrD/H+rhJOHzuceWOGdzsuIzECgD0n0E4w74EP+cHLWymoaOSquWm88t3T2X//+fzw3PHsOFzDq18WuuZNnISdR6qpcJRUrPLfTYXsLanjnq9lsv/+87lsVgp3fnVC55d6QmQI//7OfL69YAxpsWEA5B3tSgSHHUn3rB6Nwh2NxB/mlALwoKOdYVN+7726fvHGDsvHH+SV17N4YgIi8JEjLqUGomuuIQ8rERhjlhljkowxgcaYFGPMP40xjxtjHnfsN8aY7xljxhpjphpjsq2K5VT84o0d3eqoO/x06SQC/btfvvGJ4QDk9HL8QKTFhjFrVAz+ftLZO+aOf2/l0dXuKRlc8NfPmPmr99mUX9H/wSfho5wSfvSfrQBcOG0k/n7C7785je+dPa7X4zMSwwny9+vsomuzmc769pSY0G7Hjk8MJy48iE35ldhshiDH/9Un+7p/2b+3o5jrl2/k2XX5XPPUBssac2ubWimpaWbmqBhmpEazcmexNhyrAev4pOji9W7QbjM8uy6/133jR4Qfsy0iJJCJIyJYd6D8mH2Hyhv45Vs7qW5sZWtBFW9sOUxbuw1/P+Ga+aP4wTnjuXRWSufxw4IDSI21f7k9+N4eznroY/aXnVxD9ECU1Tbz+Jr9nVUnDS1tnfsufWwdGw5WuPz1f/zfbQBcOTeN+Ijgfo8PCwpg5qhoPtl3FIANeRXsPFLDsjmpjI4b1u1YEWFaSjRbC6rYXFBFS7sNsFfPdHwBf7K3jJue39Tt1/nqPa4rFTS2tPPbd3Moq23ubASfmhzFN7NSySmu5VPH++hNa7uN0tomt1ZlqaHD6FxD7nPYqa7/qrlprP7RIt743hmsuXMRwQH+vZ6zICOO7LzKYwZA3fvWTp7+PI/n1+dz0SOfc9tLW7jnjR202wxTRkZx2zkZxIV3/zL8702nc+tX7L+O88sbWPyHNXznuWz2ltS6pJtpeV0zr20upLXdxs9e285v381h+n2rKKhooLzOXiU0My0agMv/vo7Ff1jjsi+m+uY2jta1cG5mIj9dOnHA5y3IiGd3UQ1X/+MLnlmbR4CfcPcFmb12qzstJZp9pXVc+thaAM7NTGRbYTVn/u5jSmubuOapDcec86P/bD3lX+pr9pZRVN3I+7tLeHzNfi58+DM+2F2CCExPi+aSmckkRARzzVMbuPfN3nsQ3fbSZub85kPO/dOaU4pFeYfOdWm0RDD4dhyx/4r76dKJ3H3BJNLjhjEtNZpRw4f1ec6ZGfG0tNv44mBXqeDpzw92/upctbO4c/uLGwpIHx7G0qkjen2uxMgQ7jhvAtvuPY+LZ9iHWKzcWcJ5f/qEZ9blneK7g2fW5fODl7fy7Lr8zqTX1GrjkY9zWfjQxwDcvGgc6cPDOs959cvD/T7v65sP86f39/b6hdrabmNPcS3vbLP3C7hidioRIYEDjnl6qj0xfZZ7lHd3FJOVHkN4cO+d3zoa8zt87TR7D6zDVY185vg1fsa44fzw3PGcPnY4wQF+lNe38MIXhwYcT4fS2iYefC+HN7Yc5ltPbWD+Ax9x64ubASiqbmL52jyMgciQQIID/Fk6xf5/vnxtHofKG3hnWxEtbTa2Ftg7DazYbv+cFFQMrS6wyj2s7jXkzu6jQ97HOaVEhwVyw5mjCfAfWM6ck27/8rn26Y3suu+r5BTX8su3dnXu31rYvbfIG987s98vwsiQQB64ZCqXZ6USFODHpY+t5bn1+Sybk0ZIoL1k0tjSzl8+3EdMWCDl9S0crmzk7IkJXDhtJEEBvcde6Oh9s3pPKUeqG7l6Xhr55Q28tLFrnN/w8CAeuWomD63cw+o9Zdz71k4umj6SsCB/nl+fz6IJCaTGdiUKYwy3v7wFgPljhzN3dCzvbC/i89yjnJc5gqc+P9hZJZISE3rCI39HOSUlgPlj4vo8dt6Y4Xz0w7MormmiprGVczNHsPlQFcvX5nU2DP/u0tNIiQnj+4sz2FZYxYUPf87PX9/BWePju72v47HZDD/6z7ZeG5t/d+lUVu4s4aOcUu786oTO7d9fnEFQgB9PfnqQu1/f3q2a6F/fntvtOT7bd5QzM+zv0xjDloIq/vXFIR64ZOqAP5fKs3nsFBOeqqm1ndzSOqYkR1FY2ci4+PAT+mMLDfJnUlIku4tq2HKoiit7GQAF8MAlUzlrfDxRYQP7NRwS6M/8sfZeSk9fN5vrnt7I9174knMyE/ls31HiI4JZvjav2znvbC/irle28cp3T+fLQ5VcNXdUZ1LYX1bHq5vtv+47voRGRocyYURk5+MpyZGMTQgnMiSQ5dfNYfnnB7n3rV3MuO993r9jIfe8sZPJIwt459YFna+5paCrG+wVT6zngqlJvLPd/uv/xQ3OA8nh6nmjjmlw709SVPdG4YzEY9tqnI2JD2dMfNcxNy4cw/K1eby+5QhB/n7dnm9qchSZSZHsKqphwYMfc+/XM7lmfnqf/f035lXws1e3s88xqvz8qSOYOCKSK2an0tJu48UNh7hkZgoXz0ihpd3WreQSFx7MT5ZM5MlPDx7TVtDxmblkZjKvfnmYq//5BU/8v1lMT4vm6n98wV7HoMUr5qQxa5ROZ+ILrO41pImgh+Vr8/jtuzk8fe1sjtY1Mya+72qgvvzzW1mc/tuPOv+ggwP8aG6z8f/mjeK59fbG5+mp0YyMDj3e0/Tp7AkJfHfRWB5bvb+ze2Rf2myGix6xd3+ta2rj+4szKK5uYvEf7HXPydGhHK6yVz9cMDWJxMgQDpbVs3B8HIsmJHR7rsyRUQC0tNu4fvlGAPKcZvn8T3YBdzoagDt0JAFnP14ygXX7y7lybtqJvG3APiDszVvO4IX1h3g5u+CYEkJ/RkaHdibqhePjug0wExFW3LaAx1bv53fv5XDvW7sorGzk51/L7PW5fv3O7s4kAHD3BZmd4x8A7vxqV9tHb6WyAH8//rpsBk9+coDMpEhezu6eKL939rjOqrgbn9t0zPlPfX6QhIhg7n59BwF+wqjhYUwZGdWt04HyEhbPNaSJoIcjji/F6xxfdHNGxx7v8F4lOaaf6PD8t+cyOz2Wo3XNPLc+n0lJkUwcEXFKcd7mqMr4PLerLWJaSlRn1dPt52TQ2NrO5vyqzhG2H+SU8v3FGfzto30AfGViAv/8VhbZ+ZWkxYaRGGmP+xdf7/2Lb87oWF66cR63/OtL9jtG+9a3tFNZ30JBZQN3O0YH/+obU7DZDP/naAgdHTeM28/J4LaX7FVG35yVys2Leu8iOhCnpUQz6eJILstKYbIjOZ2Ivy2bzid7j7J4UkKv+286awy/e88+gd3KXcWdiWDVzmIMMG/0cKLCAvF3/FHGhAUyMjqUkT3+3wfiwmkjuXDaSMA+mvq+t3cxangYf1s2g7Hx4dx/8VR+9tr2Xs99Z1tRZ1uLs3MnJxJ5Au0uaujrnIbaokygicDhj6v2sKWw+pgGzuY22wk/V88eLB2//OPCg3nv9gWMiQs/5cmjQgL9eeHb83h0dS7jEyKYlhpNfEQwRdWN/H3NAf5ndipJUaGszT3Klf/4gvDgAHYdqaagooFXvzzMJTOT+ePl9snZZqcPPNnNGzOcr502kuVr87hqbhovfHGIGb96H4DQQH82/fwchjt6Py2dOoIv86vISo8hJiyoMxEMpKtofwL9/U4obmfjEiIYl9B3Inb+vymoaOTD3SV8ZWJC56/yUcPDWHn7QvaV1HH1vDR+ddGUY847GdefOZoLTksiOiyws1falXPT+CinlA92l5AcHcofL59GUIAf0WFB3PfWTj52dHc9NzOR9x0TIW45VKWzrnoZqxev10Tg8NePugZthQcH8IuvZfLEpwc6f62dqL8tm8GHu0uYmBTZ7ZfixBGRpxyrs56/rJOiQrn3wsmdj08fF8fHP1pEdl4Fd/53Gwse/JiQQD9uW5xx0q95z9cy+d+FY0iMCCa/vIHPcu113KmxoZ1JACAhIoQlU7p6RJ0xbjghfXS7HWqevX5OZ/fSG57J5oufLe7cl1/ewPPr86ltbmN2eqxLZ4TsKJU5+83FU5iRFs1ls1K67f/nt2bz7Lo8apvauP7M0TyzLo8H39vDl4cqNRF4ma4BZVoiGDSLJyVw+exULp+d2v/Bffj6tJF8/SSTiKuNjhvWbVzDrFExx+0C2x9/P+msC19+3Wxue3kL7+8q4e4Leq9S6vDCt+ed9GsOtoXj41lz5yIu//s6SmqamXv/hwD86X+m8YOXt/Lrd3YDXd1ZrZQYGdLraGs/P+HaM7rWZ7h50Tje3HKkz2k0lOfqWrzemuf3mb5nB8rq+OdnB6lqOHbuHGNMt0bDnqNUvUHmyEjuu2gyM9Oiuc9RleEKAf5+PHLlTPb+eukx8/14ulHDh/HRDxd1fjbOzUzkwmndl8xIPskGf6vMHBXDlkNVPr+uhbcxXrwewaDKKa7lV2/votgxG6Wz+pZ22m2m84tsQUbffdM92TXz03n15jMYG3/8Lpeqy7DgAFbevpAbzhzNby6egr+fcKtTtdpQ68c/Ky2G2ua2zsGQyjtYvUKZz1QNhToNvHJW39zG844unUunjODxq2d1LjupFMC4hHDucepCese545k7Opb65rbjnOUeiyclEBTgxyubCjktxfpqKzU4PHnx+iElOND+Vptau/cCenvbEX77rr2rYFRooCYBNSBnjIvjvMm9Tw3iTtFhQSyZPILXtxzxqVXuvJ3N4plqfSYRdJQIek6aVu40374uOq+8wZkZcVQ3tpJXXt//wcojePMKZYOq45d+RyJoabOx4WAFtU1tiEDOr5Yw4iQGBCk11ExxDLLboaugeQ3jqSuUAYjIEhHZIyK5InJXL/tjROQ1EdkmIhtExHXdWXrobCNwJIKHVuZw+d/X8djq/RhD5+RtSnm6jgV8dh45uQWS1NDTOQ21p61QJiL+wCPAUiATWCYiPTua/wzYYow5DbgG+ItV8YT0SASbD1Ud73ClPFagvx8TkyLYqT2HvIbBc8cRzAFyjTEHjDEtwEvART2OyQQ+BDDG5ADpIpJoRTAhnW0EJz5lhFKeZvLISHYcrtHlML1E18I0HlYiAJIB5+kUCx3bnG0FLgEQkTnAKOCYqRNF5EYRyRaR7LKyk1tKsGdjcX2LLgGovNfkkVFUN7ZSWKkL23i63NI6/vz+XsAz1yPoLeSeP09+C/xFRLYA24HNwDGds40xTwBPAGRlZZ3UT5xAf8FP4KWNh0iODqW+uY056bEEBghLpiSdzFMqNWRNSrLPaZVTXDvgBXbU0PPyxkP85JWu2Wc9cYWyQsB5sp4U4IjzAcaYGuA6ALGXeQ46bi4nIoQG+lNQ0cjtL28hdlgQ40eE8+tvTLXi5ZRyqwmOac73FNdwbqYlta3KYgfK6rolAbAv9WoFK6uGNgIZIjJaRIKAK4A3nQ8QkWjHPoBvA584koMlwkO68l5FfQvhwTpnu/JO4cEBjIgMIa+8wd2hqBNQWNnAt5/JpqSmiYsfXQvArV8Zx4c/PItrT09njEXzoFlWIjDGtInILcBKwB94yhizU0Rucux/HJgEPCsi7cAu4Aar4gEI6NEJNzxYu4wq75UUHUJRtbYReJLHVu/ng90lHDhaR3VjK985awy3Ls4gwN+v2/TyrmbpXEPGmBXAih7bHne6vw44+YnxT1Bdj7lhnNeQVcrbjIwKZXeRjiXwBLVNrQT4+VHV2ArAgbJ6xsQN464lEy3rKeTMp74Jj0kEupyf8mIpsaG8v6uE2qZWIvSzPmRVN7Sy+I+rabMZgp3Wto4MDRyUJAA+NMUEcMwkXAkuWDJRqaHqvMwRtLTb+Cin1N2hqOP4aE8JR+taqGpopaSmmfMyExkW5M9t5wxaZYlvJYKO1aSWOpZPPJmF6ZXyFNNSoggO8GN7oY4wHso25lUSERJAnGOZ1ynJUey8bwlnT0gYtBh8qmromevnUFzdRFpsGPde2KrzCymvFuDvx8SkSLYW6nQqQ9nWgipOS4kiPDiAlTtLOC0latBj8KlEEBUaSFSova5U1x1QvmBhRhyPfJxLUXUjSVFDa1lNBXlH69l5pIYfL5nAxTOSOX9qEosGsSTQwaeqhpTyNZdnpeLvJzz1mSXjNNUpaGpt5x+fHcBP4JIZKSRFhXLR9J6z8AwOnyoRKOVrUmPDmJocxdYCbScYSprb2rngr5+yv6yeMfHD3L4WipYIlPJyk0dGsatIZyIdCprb2qmob+HNLUfYX2ZfQW7aEFhbWksESnm50XHDqGtuo7y+pbNninKPn7+2g/9sKgQgMTKYP10+nSluaBzuSUsESnm5UcPts48eqtB5h9yprd3GG1u75t382fmTOH1cHJFDYLCflgiU8nLpjonK9pfWMTMtxs3R+K7S2mZa2mw8cMlUls1Jc3c43WiJQCkvlz58GKGB/rqGsZsVVTcBuL1huDeaCJTycv5+wsSkCHKKNRG4U7EjESRpIlBKucOo2DBdttLNdhVV4+8npMQMvRXjNBEo5QNSYsIoqm6izaIVrtTx1Te38caWI8xKixmS099rIlDKB6TGhtJuM9pzyE3+vmY/h6saueO88e4OpVeWJgIRWSIie0QkV0Tu6mV/lIi8JSJbRWSniFxnZTxK+apZo+wz7a7dX+7mSHxTdn4lU5OjmDdmuLtD6ZVliUBE/IFHgKVAJrBMRDJ7HPY9YJcxZhqwCPiD0xrGSikXGRs/jDFxw3j1y0J3h+KT9pbUMSExwt1h9MnKEsEcINcYc8AY0wK8BFzU4xgDRIh9GZ5woAJoQynlUiLCJTOT+fJQFeV1ze4Ox6eU1zVztK6ZCSN8MxEkAwVOjwsd25w9jH0B+yPAduA2Y8wxrVkicqOIZItIdllZmVXxKuXV5o+1V0tk51e6ORLfsqekFoDxPloi6G2xzZ6zXn0V2AKMBKYDD4tI5DEnGfOEMSbLGJMVHx/v+kiV8gETR9j/tPY5vpjU4Hhj8xEC/ITMkcd8tQ0ZViaCQiDV6XEK9l/+zq4DXjV2ucBBYKKFMSnls4YFB5AcHcq+0jp3h+JT1h44ynmTE4f0hH9WJoKNQIaIjHY0AF8BvNnjmEPAYgARSQQmAAcsjEkpnzYuIZxcTQSDpqXNxuHKRsYlDN1qIbBw0jljTJuI3AKsBPyBp4wxO0XkJsf+x4FfActFZDv2qqSfGGOOWhWTUr4uIyGc9QfKabcZ/P16q71VrnTgaB02A6Pjht5oYmeWDnEzxqwAVvTY9rjT/SPAeVbGoJTqMjEpkuY2G3tLapmUNHTrrL3Fh7tLAYbs+IEOOrJYKR+ycHwcIvD+rhJ3h+L1Ps4p5aGVe5ieGk1SVKi7wzkuTQRK+ZCEiBBmpsWwalexu0Pxeg+u3APANfNHuTmS/g0oEYjIWBEJdtxfJCK3ioj7F9pUSp2w08cOZ3dRLU2t7e4OxWsZY8gvr+e6M9K5ZGaKu8Pp10BLBK8A7SIyDvgnMBr4l2VRKaUsM3FEJO02o72HLFRc00RDSzvpw4e5O5QBGWgisBlj2oCLgT8bY34AJFkXllLKKpOS7F0ZdxfpQjVW+ffGQkS6RnMPdQNNBK0isgz4FvC2Y5v7V1xWSp2wUY6lK3cX6Qhjq3yWW8a0lOghPa2Es4EmguuA+cBvjDEHRWQ08Lx1YSmlrOLvJ0weGUl2foW7Q/FKTa3tbC2oZs7oWHeHMmADSgTGmF3GmFuNMS+KSAwQYYz5rcWxKaUscvbEBLYVVlNS0+TuULzOtsJqWtptzE73skQgIqtFJFJEYoGtwNMi8kdrQ1NKWeW8zESga8CTcp2NefaS1uz0GDdHMnADrRqKMsbUAJcATxtjZgHnWBeWUspK4xLCiQgOYK/OROpy2XkVjE8MJzrMc9bYGmgiCBCRJOByuhqLlVIeSkRIjQ3TNYwtkFfeQIaHNBJ3GGgiuA/75HH7jTEbRWQMsM+6sJRSVkuNDSXvaL27w/Aq7TZDYWUDabFDe5K5ngbaWPwfY8xpxpjvOh4fMMZcam1oSikrnZYSzYGj9ZTWaoOxqxyubKS13ZAa44WJQERSROQ1ESkVkRIReUVEhv64aaVUn84YFwfAl/lVbo7Ee6zZZ19K15O6jsLAq4aexr6ozEjs6w6/5dimlPJQGQnhAOwv06kmXGXDwQpGRoUwNt4zppboMNBEEG+MedoY0+a4LQd08WClPNiw4ABGRoXonEMutKWgkulp0Yh41qI/A00ER0XkahHxd9yuBsr7O0lElojIHhHJFZG7etl/p4hscdx2iEi7Y6yCUmoQjNWlK12mvK6ZgopGpqV43sTMA00E12PvOloMFAGXYZ92ok8i4g88AiwFMoFlIpLpfIwx5iFjzHRjzHTgp8AaY4yOe1dqkIyND2d/WR02m3F3KB5v2+FqAKalemkiMMYcMsZcaIyJN8YkGGO+gX1w2fHMAXIdPYxagJeAi45z/DLgxQFFrZRyiXEJ4TS0tFOsU02csnxHV9xxjrYXT3IqK5Td0c/+ZKDA6XGhY9sxRCQMWIJ93YPe9t8oItkikl1WVnYysSqletHxpaXVQ6eusLKRkEA/hg/znBHFHU4lEfTXGtLb/r7Kn18HPu+rWsgY84QxJssYkxUfr23USrlKRyLQqSZO3aGKBpKjQz2uoRhOLRH0V6lYCKQ6PU4BjvRx7BVotZBSgy4uPJikqBC2FVa7OxSP1m4zbMyr4DQPbCgGCDjeThGppfcvfAFC+3nujUCGY+2Cw9i/7K/s5TWigLOAqwcSsFLKtWakRbO5oH6l3/4AABb7SURBVNLdYXi0LQWVVDa08pWJCe4O5aQcNxEYY0565iRjTJuI3IJ9jiJ/4CljzE4Rucmx/3HHoRcDq4wxOumJUm4wIzWGFduLKattJj4i2N3heKQ1e4/iJ7BwvGdWXR83EZwqY8wKYEWPbY/3eLwcWG5lHEqpvs1Is1dnbCmo4lzHOgXqxOw6UsPY+HCiQj1zBd9TaSNQSnmBKclRBPgJmw9p9dDJ2l1Uw8SkSHeHcdI0ESjl40IC/ckcGcnmQzr53MmoaWrlcFUjk5I8aw0CZ5oIlFLMTItha2EVbe02d4ficXKK7F1vJ43QEoFSyoPNSIumoaWdvSU6sOxE7S6qAWCSVg0ppTzZjFT7QutbCrR66ETlFNcQHRZIYqTn9rjSRKCUIjU2lGFB/jrC+CTsKqpl0ohIjxxR3EETgVIKEWFcYgT7SjURnIh2m2Fvca1HVwuBJgKllENGQjj7tI3ghOSX19PY2s5ED+4xBJoIlFIO4xLCKa1t5qnPDro7FI+RU2wvQWVqiUAp5Q3GJ9pnIr3v7V1ujsRzbDhYQZC/n0euQeBME4FSCoCzJyRwwWlJABRUNLg5Gs/w7o4iFk9KICTQ392hnBJNBEopwN5gfMe54wFYvVcXgOpPWW0zJTXNzBoV4+5QTpkmAqVUpzFxw0iICGbjQV06vD8dA8kyR3p2+wBoIlBKORERZo+OJTtPE0F/OhOBhzcUgyYCpVQPs0fFcKS6icNVje4OZUjbcaSGkVEhRId53hrFPWkiUEp1k5UeC6ClguNotxk+zz3K3DHD3R2KS1iaCERkiYjsEZFcEbmrj2MWicgWEdkpImusjEcp1b9JSZGEBwewURNBn/LK66mob2H+WO9IBJatUCYi/sAjwLnYF7LfKCJvGmN2OR0TDTwKLDHGHBIRz1zwUykv4u8nnJYSxdYCXdC+L3uLPX/qaWdWlgjmALnGmAPGmBbgJeCiHsdcCbxqjDkEYIwptTAepdQAzUiLZndRDWW1ze4OZUjaU1KLCB4/kKyDlYkgGShwelzo2OZsPBAjIqtFZJOIXNPbE4nIjSKSLSLZZWXav1kpq10yM4U2m+GtrUfcHcqQtK+kjlGxYYQGefZAsg5WJoLe5mQ1PR4HALOAC4CvAveIyPhjTjLmCWNMljEmKz4+3vWRKqW6GRsfTnJ0KNn52k7Qmz0ltWQkevZEc86sTASFQKrT4xSg58+LQuA9Y0y9MeYo8AkwzcKYlFIDlJUeQ3ZeJcb0/P3m25rb2sk7Wt85N5M3sDIRbAQyRGS0iAQBVwBv9jjmDWCBiASISBgwF9htYUxKqQHKGhVDaW0zhZU6nsDZwaP1tNkM472oRGBZryFjTJuI3AKsBPyBp4wxO0XkJsf+x40xu0XkPWAbYAP+YYzZYVVMSqmB6xxPkF9BamyYm6MZOjrWddZEMEDGmBXAih7bHu/x+CHgISvjUEqduPGJEUQEB5CdV8nFM1LcHc6Qsbe4Fn8/YUz8MHeH4jI6slgp1St/P2HGqBg25Ve6O5QhJae4lvThYQQHeEePIdBEoJQ6jrmjY8kprqWkpsndoQwZOw5XMzU5yt1huJQmAqVUn87LTARg1a4SN0cyNJTWNlFc08QUTQRKKV8xLiGcMfHDWLmj2N2hDAk7Dtun3TgtJdrNkbiWJgKlVJ9EhCWTR7DuQDn3vrmTv6/Z7+6Q3KpjsfpJSd7TYwg0ESil+vHNrFTabYbla/N44N0cKutb3B2S2xRXNxEZEkBESKC7Q3EpTQRKqeMaHTeM4ICur4ovfHgZy+LqJpKiQt0dhstpIlBK9eupa2dz9bw0gvz9+PKQ73YnLa5pIjEqxN1huJylA8qUUt7hjHFxnDEujt1FtT67cllbu419JXX8z+zU/g/2MFoiUEoNWNaoGL48VMUPXt5CU2u7u8MZVO9sL6KxtZ1pqd7VdRQ0ESilTsDMUTEAvLb5MB/u9q11pN7ccoTQQH/OzRzh7lBcThOBUmrAnNfofW59nk9NUX2oooEFGXGEB3tfjbomAqXUgEWGBPLe7Qu49vR01h+oYN3+cneHNCiMMRRUNpDmpbOwaiJQSp2QiSMiuWvpRIIC/Pgwxzeqh8rqmmlqtZE2XBOBUkoBEBLoz5z0WD7bd9TdoQyKgooGAK9dl0ETgVLqpJyZEceeEt+YmfRQRyKI0URwwkRkiYjsEZFcEbmrl/2LRKRaRLY4br+wMh6llOssyIgD8IlSwe6iWoL8/UiN9b5RxWBhIhARf+ARYCmQCSwTkcxeDv3UGDPdcbvPqniUUq41aUQkw4cF8em+MneHYrlN+ZVkjoz0qsVonFlZIpgD5BpjDhhjWoCXgIssfD2l1CDy8xPOzIjj031HaWu3uTscyxRUNLApv5LFExPcHYplrEwEyUCB0+NCx7ae5ovIVhF5V0Qm9/ZEInKjiGSLSHZZmff/+lDKUyyZPILy+hY2ePFEdHnl9QDMHTO8nyM9l5WJQHrZ1nP0yZfAKGPMNOBvwOu9PZEx5gljTJYxJis+Pt7FYSqlTtaiCQmEBvrz9vYid4dimcqGVgBih3nX1NPOrEwEhYDz7EwpwBHnA4wxNcaYOsf9FUCgiMRZGJNSyoVCg/xZPCmB93YUe+3cQx3rL8SEBbk5EutYmQg2AhkiMlpEgoArgDedDxCRESIijvtzHPH4xlBFpbzElXPSqKhv4bfv5gzoeGMMv3lnF4+uzrU4MteocCSCqFDvLRFYNmmGMaZNRG4BVgL+wFPGmJ0icpNj/+PAZcB3RaQNaASuML40eYlSXuD0cXFcf8Zonvr8IGdNiCczKZLEyN7n7DfG8FFOKU9+ehCAS2akMGKIz+9f1dBCVGggAf7eO+zK0ndmjFlhjBlvjBlrjPmNY9vjjiSAMeZhY8xkY8w0Y8w8Y8xaK+NRSlnjR18dT1iQP9c9vZG593/Y2YvoaF0zNlvXb7vH1uznhmeyOx8/vz5/0GM9UYermkiMDHZ3GJby3hSnlBo0YUEBXHdGeufjcXe/S/pd75D16w/4x2cHAHtpYPnneQDMHR3Lgow43tx6ZMjPYJpXXs/ouGHuDsNSmgiUUi5x2+LxXJ6Vcsz2+1fksGpnMV8crKC0tpk/fHMaL39nPl+fNpJDFQ1szBu6S1+22wyHyhsYHRfu7lAs5X0Tayul3CIowI8HL5vGRdOTCQ8OoKSmiZLaZu55fQc3PrcJsDe4Lp1qX9hl6ZQR/GHVHn766jbevW0hNmNoam0negj1zjlS1UhLu43Rcd45x1AHLREopVzqjHFxTEuN5rzJI/h/80Z123fDmaMJC7L//owICeTer09mf1k9a/cf5dYXNzP9vvdpHUKjlA8ctQ8m8/YSgSYCpZSlzhrfNQh0Xo/RuWdPtA9I+3B3Kat2lQDwz88ODmp8x5NbWgfg9W0EWjWklLLU41fPorCygeY2G1OSuy/8HhLoz8LxcTzn1HvoLx/s45IZyST00QV1MO08Uk1CRDDxEdprSCmlTlpokD8ZiRHHJIEOX3GazO1XF02mtd3Gnz/cN1jh9ckYw4aDFZyW0nvc3kQTgVLKrZZOTSIsyB9/P+EbM5L5ZlYqr2wqpK65za1x7SqqobCykfMmj3BrHINBE4FSyq0iQwLZdd8S9t9/PhEhgVw2K4XmNhv/3ljQ/8kW2l5YDdjHPHg7TQRKqSFl1qgYpqVG8+/sAqobW90Wx+6iGoYF+Xvt8pTONBEopYacszLiyCmuZdovV7lt5HFhZSNpw4fh59fbjPreRROBUmrIucpp/EFHX/7BdriqkeRo9/dcGgyaCJRSQ05iZAif/vhsAN7e6p5Fb4qqm0iK8s7F6nvSRKCUGpJSY8OYkhzJo6tzOxeHGSx1zW1UN7YyMloTgVJKudUvvjaZ5jYbn+wb3LXKi6oaARipVUNKKeVes0bFEBMWyJo9g5sIDjsSQbKWCE6diCwRkT0ikisidx3nuNki0i4il1kZj1LKs/j7CQvHx/PJvrJuC9xYrai6CYAkTQSnRkT8gUeApUAmsExEMvs47nfYl7RUSqluFmbEc7SuhbX7B2858yNVjfgJJHr5HEMdrCwRzAFyjTEHjDEtwEvARb0c933gFaDUwliUUh5q6dQRpMaGcutLm6kfpGknDlc1MiIyxKvXKXZm5btMBpzHiBc6tnUSkWTgYuDx4z2RiNwoItkikl1WNrh1hUop9woLCuD3l02jor6Fd7YNTlfSI1WNPlMtBNYmgt6G4/Ws5Psz8BNjTPvxnsgY84QxJssYkxUfH3+8Q5VSXmjO6FjGxA/jhS/yB2WkcX55A6NivX9qiQ5WJoJCINXpcQpwpMcxWcBLIpIHXAY8KiLfsDAmpZQHEhFuOHM0WwureXFDAe02w6Orcxl/97tc9MjnnQvIuEJjSztF1U1evxiNMysTwUYgQ0RGi0gQcAXwpvMBxpjRxph0Y0w68F/gZmPM6xbGpJTyUBdOGwnAz17bzq0vbubB9/bQ0m5ja0EVP3llm8te51BFAwCjNBGcOmNMG3AL9t5Au4F/G2N2ishNInKTVa+rlPJOESGBPHrVTCJCAnhnu72t4OZFY7k8K4VN+ZUsePAj3ttRdMrrGBytawYgwUd6DIHFS1UaY1YAK3ps67Vh2BhzrZWxKKU83/lTk1g4Pp4p/2fvbX7z2ePwE1i1q4SCikZuev5L5o8ZzhPXzCIiJPCkXqMjEcSFB7ks7qHON/pGKaW8RnhwAP+9aT63nD2O8OAAwoICWHX7QpbNsTdJrjtQzrRfrmJTfsUJPe+qncVc/vd1/OzV7QAMH+Y7JQJx11zfJysrK8tkZ2e7Owyl1BDUbjO8vvkwP/zPVgDeufVMJo/sf83hgooGFv1+Ne1Oo5cP3H++V61FICKbjDFZve3TEoFSymv4+wmXzkrhyWuyCA7w44K/fsaTnxw47jmHyhtY8ODH3ZLAvDGxXpUE+mNpG4FSSrnDuZmJ/Pem07n6n1/w4Moczj8tqc8J5JY9ub7z/qc/PptUHxo/0EFLBEoprzQ1JYp3b1sAwM9e3d7rpHVHqho7Zxrd+cuv+mQSAE0ESikvNjI6lNvPGc+avWW8sOFQ5/aSmia2FlTxUY59irP3f7CQYcG+W0Hiu+9cKeUT/nfBGD7YXcI9r+/gra1HmJYSRU5xLZ/uOwpAWmwY4xLC3Ryle2mJQCnl1YIC/Hj2+jkAbDhYwZOfHuxMAgDTUqMR8Z2G4d5oIlBKeb2IkED+9e25XD0vrXPbX5fNYNmcVG4/J8ONkQ0NWjWklPIJp4+L4/RxcUxLiSa3rI6vTU3qnL/I12kiUEr5lG9mpfZ/kI/RqiGllPJxmgiUUsrHaSJQSikfp4lAKaV8nCYCpZTycZoIlFLKx2kiUEopH6eJQCmlfJzHrVAmImVAFVDttDnK6bHz/TjgKK7j/NyuOP54+3vb13Pb8R7rdTj2vqdeh4Fu1+vQ/2Nfvg4Zxpjel2szxnjcDXiir8c97mdb+bqnevzx9ve273jvW6+D916HgW7X66DX4UQeO988tWroreM87rnPytc91eOPt7+3fcd73z0f63UY2GufisG6DgPdrteh/8d6HXrhcVVDJ0JEsk0fizX7Er0Odnod7PQ62Ol16OKpJYKBesLdAQwReh3s9DrY6XWw0+vg4NUlAqWUUv3z9hKBUkqpfmgiUEopH+cxiUBEnhKRUhHZcRLnzhKR7SKSKyJ/FacFSkXkchHZJSI7ReRfro3a9ay4DiJyrYiUicgWx+3bro/ctaz6PDj2XyYiRkSGfEOiRZ+Hmxzbt4jIZyKS6frIXcui63CH47thm4h8KCKjXB/5EOHKfrRW3oCFwExgx0mcuwGYDwjwLrDUsT0D2AzEOB4nuPt9uuk6XAs87O735u7r4NgXAXwCrAey3P0+3fR5iHQ65kLgPXe/Tzddh7OBMMf97wIvu/t9WnXzmBKBMeYToMJ5m4iMFZH3RGSTiHwqIhN7niciSdg/2OuM/X/0WeAbjt3/CzxijKl0vEapte/i1Fl0HTyOhdfhV8CDQJOF4buMFdfBGFPjdOgwYMj3KLHoOnxsjGlwHLoeSLH2XbiPxySCPjwBfN8YMwv4EfBoL8ckA4VOjwsd2wDGA+NF5HMRWS8iSyyN1jqneh0ALnUUgf8rIp66qOspXQcRmQGkGmPetjpQi53y50FEvici+7EnxVstjNVKrvi76HAD9tKCV/LYxetFJBw4HfiPUxVvcG+H9rKt4xdOAPbqoUXYs/2nIjLFGFPl2mit46Lr8BbwojGmWURuAp4BvuLqWK10qtdBRPyAP2GvJvNYLvo8YIx5BHhERK4Efg58y8WhWspV18HxXFcDWcBZroxxKPHYRIC9NFNljJnuvFFE/IFNjodvAo/RvUiXAhxx3C8E1htjWoGDIrIHe2LYaGXgLnbK18EYU+60/Ungd5ZFa51TvQ4RwBRgteOLYwTwpohcaIzJtjh2V3LF34WzlxzHehqXXAcROQe4GzjLGNNsacTu5O5GihO5Aek4NQYBa4FvOu4LMK2P8zYC8+hqDDrfsX0J8IzjfhxQAAx39/t0w3VIcjrmYuzJ0e3vc7CvQ49jVuMBjcUWfR4ynI75Oi6enM2DrsMMYL/z9fDWm9sDOIH/5BeBIqAV+y/5G4DRwHvAVmAX8Is+zs0Cdjj+Ux+ma0S1AH90nLsduMLd79NN1+EBYKfj/I+Bie5+n+64Dj2O8YhEYNHn4S+Oz8MWx+dhsrvfp5uuwwdAieM6bAHedPf7tOqmU0wopZSP8/ReQ0oppU6RJgKllPJxmgiUUsrHaSJQSikfp4lAKaV8nCYC5RVEpG6QX+8frpqVU0TaHTN97hCRt0Qkup/jo0XkZle8tlKgK5QpLyEidcaYcBc+X4Axps1Vz9fPa3XGLiLPAHuNMb85zvHpwNvGmCmDEZ/yfloiUF5LROJF5BUR2ei4neHYPkdE1orIZse/ExzbrxWR/4jIW8AqEVkkIqsdE/HliMgLTnPVr+5Yr0BE6kTkNyKy1TF5YaJj+1jH440ict8ASy3r6JoEL9wxD/6XjvnyL3Ic81tgrKMU8ZDj2Dsdr7NNRH7pwsuofIAmAuXN/gL8yRgzG7gU+Idjew6w0BgzA/gFcL/TOfOBbxljOibdmwHcDmQCY4AzenmdYdin5ZiGfS2D/3V6/b84Xr+3eXy6ccyDsxj7HDhgnwr7YmPMTOxz4//BkYjuAvYbY6YbY+4UkfOwz5E1B5gOzBKRhf29nlIdPHnSOaX6cw6Q6TT7ZKSIRABRwDMikoF9pslAp3PeN8Y4z2u/wRhTCCAiW7DPZ/NZj9dpATqmrt4EnOu4P5+utQ7+Bfy+jzhDnZ57E/C+Y7sA9zu+1G3YSwqJvZx/nuO22fE4HHti+KSP11OqG00Eypv5AfONMY3OG0Xkb8DHxpiLHfXtq5121/d4DucZJ9vp/W+m1XQ1tvV1zPE0GmOmi0gU9oTyPeCvwFVAPDDLGNMqInlASC/nC/CAMebvJ/i6SgFaNaS82yrglo4HItIxJXEUcNhx/1oLX3899iopgCv6O9gYU419EZgfiUgg9jhLHUngbKBjzdxa7NNmd1gJXO+Ygx8RSRaRBBe9B+UDNBEobxEmIoVOtzuwf6lmORpQdwE3OY59EHhARD4H/C2M6XbgDhHZACQB1f2dYIzZjH22zCuAF7DHn429dJDjOKYc+NzR3fQhY8wq7FVP60RkO/BfuicKpY5Lu48qZRERCcNe7WNE5ApgmTHmov7OU2qwaRuBUtaZBTzs6OlTBVzv5niU6pWWCJRSysdpG4FSSvk4TQRKKeXjNBEopZSP00SglFI+ThOBUkr5uP8Pp8sCJNB0wW4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(start_lr=1e-6, end_lr=1.0, num_it=1000, stop_div=True)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      80.00% [8/10 31:00<07:45]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>GroupMeanLogMAE</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.228849</td>\n",
       "      <td>0.163110</td>\n",
       "      <td>1.624078</td>\n",
       "      <td>03:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.135939</td>\n",
       "      <td>0.118371</td>\n",
       "      <td>0.084278</td>\n",
       "      <td>1.039467</td>\n",
       "      <td>04:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.114867</td>\n",
       "      <td>0.145403</td>\n",
       "      <td>0.108337</td>\n",
       "      <td>1.283537</td>\n",
       "      <td>04:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.113504</td>\n",
       "      <td>0.104530</td>\n",
       "      <td>0.073917</td>\n",
       "      <td>0.901964</td>\n",
       "      <td>04:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>0.099154</td>\n",
       "      <td>0.065776</td>\n",
       "      <td>0.687658</td>\n",
       "      <td>03:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.083872</td>\n",
       "      <td>0.089922</td>\n",
       "      <td>0.062209</td>\n",
       "      <td>0.690730</td>\n",
       "      <td>03:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.079388</td>\n",
       "      <td>0.076065</td>\n",
       "      <td>0.052551</td>\n",
       "      <td>0.527754</td>\n",
       "      <td>03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.066542</td>\n",
       "      <td>0.069098</td>\n",
       "      <td>0.047191</td>\n",
       "      <td>0.429257</td>\n",
       "      <td>03:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='1875', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with GroupMeanLogMAE value: 1.6240777666680835.\n",
      "Better model found at epoch 1 with GroupMeanLogMAE value: 1.039467475394045.\n",
      "Better model found at epoch 3 with GroupMeanLogMAE value: 0.9019635363920293.\n",
      "Better model found at epoch 4 with GroupMeanLogMAE value: 0.6876582130594661.\n",
      "Better model found at epoch 6 with GroupMeanLogMAE value: 0.5277539878127282.\n",
      "Better model found at epoch 7 with GroupMeanLogMAE value: 0.42925728693158755.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-f1178911c1dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m learn.fit_one_cycle(10, max_lr=1e-3, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n\u001b[0;32m----> 2\u001b[0;31m                                                                   monitor='GroupMeanLogMAE',  name='mpnn1')])\n\u001b[0m",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, max_lr=1e-3, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='GroupMeanLogMAE',  name='mpnn1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='9' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      90.00% [9/10 28:40<03:11]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>GroupMeanLogMAE</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.055546</td>\n",
       "      <td>0.054493</td>\n",
       "      <td>0.038904</td>\n",
       "      <td>0.281104</td>\n",
       "      <td>02:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.054953</td>\n",
       "      <td>0.059799</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.328403</td>\n",
       "      <td>03:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.055076</td>\n",
       "      <td>0.058598</td>\n",
       "      <td>0.042745</td>\n",
       "      <td>0.370567</td>\n",
       "      <td>03:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.053045</td>\n",
       "      <td>0.056321</td>\n",
       "      <td>0.040117</td>\n",
       "      <td>0.311218</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.050672</td>\n",
       "      <td>0.052822</td>\n",
       "      <td>0.037468</td>\n",
       "      <td>0.251799</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.050407</td>\n",
       "      <td>0.052468</td>\n",
       "      <td>0.037248</td>\n",
       "      <td>0.218212</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.046689</td>\n",
       "      <td>0.050405</td>\n",
       "      <td>0.035437</td>\n",
       "      <td>0.184689</td>\n",
       "      <td>03:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.048847</td>\n",
       "      <td>0.049699</td>\n",
       "      <td>0.034902</td>\n",
       "      <td>0.171461</td>\n",
       "      <td>03:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.047377</td>\n",
       "      <td>0.048352</td>\n",
       "      <td>0.033803</td>\n",
       "      <td>0.129196</td>\n",
       "      <td>03:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='1875', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with GroupMeanLogMAE value: 0.2811039045571447.\n",
      "Better model found at epoch 4 with GroupMeanLogMAE value: 0.2517991800089508.\n",
      "Better model found at epoch 5 with GroupMeanLogMAE value: 0.21821212933133607.\n",
      "Better model found at epoch 6 with GroupMeanLogMAE value: 0.1846890714580683.\n",
      "Better model found at epoch 7 with GroupMeanLogMAE value: 0.17146089142034124.\n",
      "Better model found at epoch 8 with GroupMeanLogMAE value: 0.1291960322756513.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-4e8373c068fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m learn.fit_one_cycle(10, max_lr=2e-4, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n\u001b[0;32m----> 2\u001b[0;31m                                                                   monitor='GroupMeanLogMAE',  name='mpnn2')])\n\u001b[0m",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_dl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_update\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_interrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcur_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_update\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_iter_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36mupdate_bar\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Your generator is empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'100% [0/0]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{100 * val/self.total:.2f}% [{val}/{self.total} {elapsed_t}<{remaining_t}{end}]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36mon_update\u001b[0;34m(self, val, text, interrupted)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml_progress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterrupted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNBMasterBar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMasterBar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mto_show\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_show\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, obj, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0madditional\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mupdate_display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \"\"\"\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mupdate_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mupdate_display\u001b[0;34m(obj, display_id, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \"\"\"\n\u001b[1;32m    326\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'update'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0;31m# kwarg-specified metadata gets precedence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0m_merge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdisplay_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDisplayHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mpublish_display_data\u001b[0;34m(data, metadata, source, transient, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     )\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36mpublish\u001b[0;34m(self, data, metadata, source, transient, update)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         self.session.send(\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         )\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, stream, msg_or_type, content, parent, ident, buffers, track, header, metadata)\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt_version\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mto_send\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m         \u001b[0mto_send\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0mlongest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_send\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(self, msg, ident)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;31m# content is already packed, as in a relayed message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m# disallow nan, because it's not actually valid JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m json_packer = lambda obj: jsonapi.dumps(obj, default=date_default,\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m )\n\u001b[1;32m    105\u001b[0m \u001b[0mjson_unpacker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjsonapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/zmq/utils/jsonapi.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(o, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'separators'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsonmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/simplejson/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, encoding, default, use_decimal, namedtuple_as_object, tuple_as_array, bigint_as_string, sort_keys, item_sort_key, for_json, ignore_nan, int_as_string_bitcount, iterable_as_array, **kw)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mignore_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_nan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mint_as_string_bitcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint_as_string_bitcount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/simplejson/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/simplejson/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    371\u001b[0m                 self.iterable_as_array, Decimal=decimal.Decimal)\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mkey_memo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/simplejson/encoder.py\u001b[0m in \u001b[0;36mencode_basestring\u001b[0;34m(s, _PY3, _q)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mESCAPE_DCT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_q\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mESCAPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/simplejson/encoder.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(match)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getnewargs__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mESCAPE_DCT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_q\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mESCAPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, max_lr=2e-4, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='GroupMeanLogMAE',  name='mpnn2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=4e-5, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='GroupMeanLogMAE',  name='mpnn3')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=8e-6, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='GroupMeanLogMAE',  name='mpnn4')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CUDA but got backend CPU for argument #3 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-dece9e0ff5d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mget_preds\u001b[0;34m(self, ds_type, with_loss, n_batch, pbar)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mlf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwith_loss\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         return get_preds(self.model, self.dl(ds_type), cb_handler=CallbackHandler(self.callbacks),\n\u001b[0;32m--> 327\u001b[0;31m                          activ=_loss_func2activ(self.loss_func), loss_func=lf, n_batch=n_batch, pbar=pbar)\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpred_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruct\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mget_preds\u001b[0;34m(model, dl, pbar, cb_handler, activ, loss_func, n_batch)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;34m\"Tuple of predictions and targets, and optional losses (if `loss_func`) using `dl`, max batches `n_batch`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     res = [torch.cat(o).cpu() for o in\n\u001b[0;32m---> 43\u001b[0;31m            zip(*validate(model, dl, cb_handler=cb_handler, pbar=pbar, average=False, n_batch=n_batch))]\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mNoneReduceOnCPU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dl, loss_func, cb_handler, pbar, average, n_batch)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-a1d0aa2c73ac>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, e, mask, pairs_idx, edge_mask, x_m, e_m)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_master_node\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mh_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-24023d0184b1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, h, e, mask, pairs_idx, edge_mask, h_m, e_m)\u001b[0m\n\u001b[1;32m     85\u001b[0m                                                  \u001b[0mn_nodes_per_graph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                                              ])).unsqueeze(-1).expand(-1, n_edges)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mm_stacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mah\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_mask_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mm_per_graph_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_stacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nodes_per_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-24023d0184b1>\u001b[0m in \u001b[0;36msegment_sum\u001b[0;34m(data, segment_ids)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msegment_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data.shape and segment_ids.shape should be equal\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CUDA but got backend CPU for argument #3 'index'"
     ]
    }
   ],
   "source": [
    "pred, _ = learn.get_preds()\n",
    "pred_test, _ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
