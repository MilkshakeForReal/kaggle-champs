{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import deepchem as dc\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.spatial.distance import norm\n",
    "\n",
    "from fastai.tabular import *\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "from fastai.basic_data import DataBunch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "PATH = '../tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scalar_coupling_contributions.csv',\n",
       " 'mulliken_charges.csv',\n",
       " 'structures.csv',\n",
       " 'test.csv',\n",
       " 'train.csv',\n",
       " 'magnetic_shielding_tensors.csv',\n",
       " 'dipole_moments.csv',\n",
       " 'sample_submission.csv',\n",
       " 'potential_energy.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(DATA_PATH)\n",
    "files = [f for f in files if f.find('.csv') != -1]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH+'train.csv')\n",
    "test_df = pd.read_csv(DATA_PATH+'test.csv')\n",
    "structures_df = pd.read_csv(DATA_PATH+'structures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.91 s, sys: 102 ms, total: 2.01 s\n",
      "Wall time: 582 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "atoms_per_molecule_df = structures_df.groupby(['molecule_name', 'atom']).count()\n",
    "atoms_per_molecule_map = atoms_per_molecule_df['atom_index'].unstack().fillna(0).astype(int).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.4 s, sys: 827 ms, total: 15.2 s\n",
      "Wall time: 4.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pd.options.mode.chained_assignment = None\n",
    "atoms = structures_df['atom'].unique()\n",
    "train_df['num_atoms'] = 0\n",
    "test_df['num_atoms'] = 0\n",
    "for atom in atoms:\n",
    "    train_df[f'num_{atom}_atoms'] = train_df['molecule_name'].map(atoms_per_molecule_map[atom])\n",
    "    train_df['num_atoms'] += train_df[f'num_{atom}_atoms']\n",
    "    test_df[f'num_{atom}_atoms'] = test_df['molecule_name'].map(atoms_per_molecule_map[atom])\n",
    "    test_df['num_atoms'] += test_df[f'num_{atom}_atoms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'molecule_name', 'atom_index_0', 'atom_index_1', 'type',\n",
       "       'scalar_coupling_constant', 'num_atoms', 'num_C_atoms', 'num_H_atoms',\n",
       "       'num_N_atoms', 'num_O_atoms', 'num_F_atoms'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Written by Jan H. Jensen based on this paper Yeonjoon Kim and Woo Youn Kim \n",
    "# \"Universal Structure Conversion Method for Organic Molecules: From Atomic Connectivity\n",
    "# to Three-Dimensional Geometry\" Bull. Korean Chem. Soc. 2015, Vol. 36, 1769-1777 DOI: 10.1002/bkcs.10334\n",
    "#\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import itertools\n",
    "from rdkit.Chem import rdmolops\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import networkx as nx #uncomment if you don't want to use \"quick\"/install networkx\n",
    "\n",
    "\n",
    "global __ATOM_LIST__\n",
    "__ATOM_LIST__ = [ x.strip() for x in ['h ','he', \\\n",
    "      'li','be','b ','c ','n ','o ','f ','ne', \\\n",
    "      'na','mg','al','si','p ','s ','cl','ar', \\\n",
    "      'k ','ca','sc','ti','v ','cr','mn','fe','co','ni','cu', \\\n",
    "      'zn','ga','ge','as','se','br','kr', \\\n",
    "      'rb','sr','y ','zr','nb','mo','tc','ru','rh','pd','ag', \\\n",
    "      'cd','in','sn','sb','te','i ','xe', \\\n",
    "      'cs','ba','la','ce','pr','nd','pm','sm','eu','gd','tb','dy', \\\n",
    "      'ho','er','tm','yb','lu','hf','ta','w ','re','os','ir','pt', \\\n",
    "      'au','hg','tl','pb','bi','po','at','rn', \\\n",
    "      'fr','ra','ac','th','pa','u ','np','pu'] ]\n",
    "\n",
    "\n",
    "def get_atom(atom):\n",
    "    global __ATOM_LIST__\n",
    "    atom = atom.lower()\n",
    "    return __ATOM_LIST__.index(atom) + 1\n",
    "\n",
    "\n",
    "def getUA(maxValence_list, valence_list):\n",
    "    UA = []\n",
    "    DU = []\n",
    "    for i, (maxValence,valence) in enumerate(zip(maxValence_list, valence_list)):\n",
    "        if maxValence - valence > 0:\n",
    "            UA.append(i)\n",
    "            DU.append(maxValence - valence)\n",
    "    return UA,DU\n",
    "\n",
    "\n",
    "def get_BO(AC,UA,DU,valences,UA_pairs,quick):\n",
    "    BO = AC.copy()\n",
    "    DU_save = []\n",
    "\n",
    "    while DU_save != DU:\n",
    "        for i,j in UA_pairs:\n",
    "            BO[i,j] += 1\n",
    "            BO[j,i] += 1 \n",
    "        \n",
    "        BO_valence = list(BO.sum(axis=1))\n",
    "        DU_save = copy.copy(DU)\n",
    "        UA, DU = getUA(valences, BO_valence)\n",
    "        UA_pairs = get_UA_pairs(UA,AC,quick)[0]\n",
    "\n",
    "    return BO\n",
    "\n",
    "\n",
    "def valences_not_too_large(BO,valences):\n",
    "    number_of_bonds_list = BO.sum(axis=1)\n",
    "    for valence, number_of_bonds in zip(valences,number_of_bonds_list):\n",
    "        if number_of_bonds > valence:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def BO_is_OK(BO,AC,charge,DU,atomic_valence_electrons,atomicNumList,charged_fragments):\n",
    "    Q = 0 # total charge\n",
    "    q_list = []\n",
    "    if charged_fragments:\n",
    "        BO_valences = list(BO.sum(axis=1))\n",
    "        for i,atom in enumerate(atomicNumList):\n",
    "            q = get_atomic_charge(atom,atomic_valence_electrons[atom],BO_valences[i])\n",
    "            Q += q\n",
    "            if atom == 6:\n",
    "                number_of_single_bonds_to_C = list(BO[i,:]).count(1)\n",
    "                if number_of_single_bonds_to_C == 2 and BO_valences[i] == 2:\n",
    "                    Q += 1\n",
    "                    q = 2\n",
    "                if number_of_single_bonds_to_C == 3 and Q + 1 < charge:\n",
    "                    Q += 2\n",
    "                    q = 1\n",
    "            \n",
    "            if q != 0:\n",
    "                q_list.append(q)\n",
    "\n",
    "    if (BO-AC).sum() == sum(DU) and charge == Q and len(q_list) <= abs(charge):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_atomic_charge(atom,atomic_valence_electrons,BO_valence):\n",
    "    if atom == 1:\n",
    "        charge = 1 - BO_valence\n",
    "    elif atom == 5:\n",
    "        charge = 3 - BO_valence\n",
    "    elif atom == 15 and BO_valence == 5:\n",
    "        charge = 0\n",
    "    elif atom == 16 and BO_valence == 6:\n",
    "        charge = 0\n",
    "    else:\n",
    "        charge = atomic_valence_electrons - 8 + BO_valence\n",
    "\n",
    "    return charge\n",
    "\n",
    "def clean_charges(mol):\n",
    "    # this hack should not be needed any more but is kept just in case\n",
    "\n",
    "    rxn_smarts = ['[N+:1]=[*:2]-[C-:3]>>[N+0:1]-[*:2]=[C-0:3]',\n",
    "                  '[N+:1]=[*:2]-[O-:3]>>[N+0:1]-[*:2]=[O-0:3]',\n",
    "                  '[N+:1]=[*:2]-[*:3]=[*:4]-[O-:5]>>[N+0:1]-[*:2]=[*:3]-[*:4]=[O-0:5]',\n",
    "                  '[#8:1]=[#6:2]([!-:6])[*:3]=[*:4][#6-:5]>>[*-:1][*:2]([*:6])=[*:3][*:4]=[*+0:5]',\n",
    "                  '[O:1]=[c:2][c-:3]>>[*-:1][*:2][*+0:3]',\n",
    "                  '[O:1]=[C:2][C-:3]>>[*-:1][*:2]=[*+0:3]']\n",
    "\n",
    "    fragments = Chem.GetMolFrags(mol,asMols=True,sanitizeFrags=False)\n",
    "\n",
    "    for i,fragment in enumerate(fragments):\n",
    "        for smarts in rxn_smarts:\n",
    "            patt = Chem.MolFromSmarts(smarts.split(\">>\")[0])\n",
    "            while fragment.HasSubstructMatch(patt):\n",
    "                rxn = AllChem.ReactionFromSmarts(smarts)\n",
    "                ps = rxn.RunReactants((fragment,))\n",
    "                fragment = ps[0][0]\n",
    "        if i == 0:\n",
    "            mol = fragment\n",
    "        else:\n",
    "            mol = Chem.CombineMols(mol,fragment)\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "def BO2mol(mol,BO_matrix, atomicNumList,atomic_valence_electrons,mol_charge,charged_fragments):\n",
    "    # based on code written by Paolo Toscani\n",
    "\n",
    "    l = len(BO_matrix)\n",
    "    l2 = len(atomicNumList)\n",
    "    BO_valences = list(BO_matrix.sum(axis=1))\n",
    "\n",
    "    if (l != l2):\n",
    "        raise RuntimeError('sizes of adjMat ({0:d}) and atomicNumList '\n",
    "            '{1:d} differ'.format(l, l2))\n",
    "\n",
    "    rwMol = Chem.RWMol(mol)\n",
    "\n",
    "    bondTypeDict = {\n",
    "        1: Chem.BondType.SINGLE,\n",
    "        2: Chem.BondType.DOUBLE,\n",
    "        3: Chem.BondType.TRIPLE\n",
    "    }\n",
    "\n",
    "    for i in range(l):\n",
    "        for j in range(i + 1, l):\n",
    "            bo = int(round(BO_matrix[i, j]))\n",
    "            if (bo == 0):\n",
    "                continue\n",
    "            bt = bondTypeDict.get(bo, Chem.BondType.SINGLE)\n",
    "            rwMol.AddBond(i, j, bt)\n",
    "    mol = rwMol.GetMol()\n",
    "\n",
    "    if charged_fragments:\n",
    "        mol = set_atomic_charges(mol,atomicNumList,atomic_valence_electrons,BO_valences,BO_matrix,mol_charge)\n",
    "    else:\n",
    "        mol = set_atomic_radicals(mol,atomicNumList,atomic_valence_electrons,BO_valences)\n",
    "\n",
    "    return mol\n",
    "\n",
    "def set_atomic_charges(mol,atomicNumList,atomic_valence_electrons,BO_valences,BO_matrix,mol_charge):\n",
    "    q = 0\n",
    "    for i,atom in enumerate(atomicNumList):\n",
    "        a = mol.GetAtomWithIdx(i)\n",
    "        charge = get_atomic_charge(atom,atomic_valence_electrons[atom],BO_valences[i])\n",
    "        q += charge\n",
    "        if atom == 6:\n",
    "            number_of_single_bonds_to_C = list(BO_matrix[i,:]).count(1)\n",
    "            if number_of_single_bonds_to_C == 2 and BO_valences[i] == 2:\n",
    "                    q += 1\n",
    "                    charge = 0\n",
    "            if number_of_single_bonds_to_C == 3 and q + 1 < mol_charge:\n",
    "                    q += 2\n",
    "                    charge = 1\n",
    "\n",
    "        if (abs(charge) > 0):\n",
    "            a.SetFormalCharge(int(charge))\n",
    "\n",
    "    # shouldn't be needed anymore bit is kept just in case\n",
    "    #mol = clean_charges(mol)\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "def set_atomic_radicals(mol,atomicNumList,atomic_valence_electrons,BO_valences):\n",
    "    # The number of radical electrons = absolute atomic charge\n",
    "    for i,atom in enumerate(atomicNumList):\n",
    "        a = mol.GetAtomWithIdx(i)\n",
    "        charge = get_atomic_charge(atom,atomic_valence_electrons[atom],BO_valences[i])\n",
    "\n",
    "        if (abs(charge) > 0):\n",
    "            a.SetNumRadicalElectrons(abs(int(charge)))\n",
    "\n",
    "    return mol\n",
    "\n",
    "def get_bonds(UA,AC):\n",
    "    bonds = []\n",
    "\n",
    "    for k,i in enumerate(UA):\n",
    "        for j in UA[k+1:]:\n",
    "            if AC[i,j] == 1:\n",
    "                bonds.append(tuple(sorted([i,j])))\n",
    "\n",
    "    return bonds\n",
    "\n",
    "def get_UA_pairs(UA,AC,quick):\n",
    "    bonds = get_bonds(UA,AC)\n",
    "    if len(bonds) == 0:\n",
    "        return [()]\n",
    "\n",
    "    if quick:\n",
    "        G=nx.Graph()\n",
    "        G.add_edges_from(bonds)\n",
    "        UA_pairs = [list(nx.max_weight_matching(G))]\n",
    "        return UA_pairs\n",
    "\n",
    "    max_atoms_in_combo = 0\n",
    "    UA_pairs = [()]\n",
    "    for combo in list(itertools.combinations(bonds, int(len(UA)/2))):\n",
    "        flat_list = [item for sublist in combo for item in sublist]\n",
    "        atoms_in_combo = len(set(flat_list))\n",
    "        if atoms_in_combo > max_atoms_in_combo:\n",
    "            max_atoms_in_combo = atoms_in_combo\n",
    "            UA_pairs = [combo]\n",
    " #           if quick and max_atoms_in_combo == 2*int(len(UA)/2):\n",
    " #               return UA_pairs\n",
    "        elif atoms_in_combo == max_atoms_in_combo:\n",
    "            UA_pairs.append(combo)\n",
    "\n",
    "    return UA_pairs\n",
    "\n",
    "def AC2BO(AC,atomicNumList,charge,charged_fragments,quick):\n",
    "    # TODO\n",
    "    atomic_valence = defaultdict(list)\n",
    "    atomic_valence[1] = [1]\n",
    "    atomic_valence[6] = [4]\n",
    "    atomic_valence[7] = [4,3]\n",
    "    atomic_valence[8] = [2,1]\n",
    "    atomic_valence[9] = [1]\n",
    "    atomic_valence[14] = [4]\n",
    "    atomic_valence[15] = [5,4,3]\n",
    "    atomic_valence[16] = [6,4,2]\n",
    "    atomic_valence[17] = [1]\n",
    "    atomic_valence[32] = [4]\n",
    "    atomic_valence[35] = [1]\n",
    "    atomic_valence[53] = [1]\n",
    "\n",
    "\n",
    "    atomic_valence_electrons = {}\n",
    "    atomic_valence_electrons[1] = 1\n",
    "    atomic_valence_electrons[6] = 4\n",
    "    atomic_valence_electrons[7] = 5\n",
    "    atomic_valence_electrons[8] = 6\n",
    "    atomic_valence_electrons[9] = 7\n",
    "    atomic_valence_electrons[14] = 4\n",
    "    atomic_valence_electrons[15] = 5\n",
    "    atomic_valence_electrons[16] = 6\n",
    "    atomic_valence_electrons[17] = 7\n",
    "    atomic_valence_electrons[32] = 4\n",
    "    atomic_valence_electrons[35] = 7\n",
    "    atomic_valence_electrons[53] = 7\n",
    "\n",
    "    # make a list of valences, e.g. for CO: [[4],[2,1]]\n",
    "    valences_list_of_lists = []\n",
    "    for atomicNum in atomicNumList:\n",
    "        valences_list_of_lists.append(atomic_valence[atomicNum])\n",
    "\n",
    "    # convert [[4],[2,1]] to [[4,2],[4,1]]\n",
    "    valences_list = list(itertools.product(*valences_list_of_lists))\n",
    "\n",
    "    best_BO = AC.copy()\n",
    "\n",
    "    # implemenation of algorithm shown in Figure 2\n",
    "    # UA: unsaturated atoms\n",
    "    # DU: degree of unsaturation (u matrix in Figure)\n",
    "    # best_BO: Bcurr in Figure \n",
    "    #\n",
    "\n",
    "    for valences in valences_list:\n",
    "        AC_valence = list(AC.sum(axis=1))\n",
    "        UA,DU_from_AC = getUA(valences, AC_valence)\n",
    "\n",
    "        if len(UA) == 0 and BO_is_OK(AC,AC,charge,DU_from_AC,atomic_valence_electrons,atomicNumList,charged_fragments):\n",
    "            return AC,atomic_valence_electrons\n",
    "        \n",
    "        UA_pairs_list = get_UA_pairs(UA,AC,quick) \n",
    "        for UA_pairs in UA_pairs_list:\n",
    "            BO = get_BO(AC,UA,DU_from_AC,valences,UA_pairs,quick)\n",
    "            if BO_is_OK(BO,AC,charge,DU_from_AC,atomic_valence_electrons,atomicNumList,charged_fragments):\n",
    "                return BO,atomic_valence_electrons\n",
    "\n",
    "            elif BO.sum() >= best_BO.sum() and valences_not_too_large(BO,valences):\n",
    "                best_BO = BO.copy()\n",
    "\n",
    "    return best_BO,atomic_valence_electrons\n",
    "\n",
    "\n",
    "def AC2mol(mol,AC,atomicNumList,charge,charged_fragments,quick):\n",
    "    # convert AC matrix to bond order (BO) matrix\n",
    "    BO,atomic_valence_electrons = AC2BO(AC,atomicNumList,charge,charged_fragments,quick)\n",
    "\n",
    "    # add BO connectivity and charge info to mol object\n",
    "    mol = BO2mol(mol,BO, atomicNumList,atomic_valence_electrons,charge,charged_fragments)\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "def get_proto_mol(atomicNumList):\n",
    "    mol = Chem.MolFromSmarts(\"[#\"+str(atomicNumList[0])+\"]\")\n",
    "    rwMol = Chem.RWMol(mol)\n",
    "    for i in range(1,len(atomicNumList)):\n",
    "        a = Chem.Atom(atomicNumList[i])\n",
    "        rwMol.AddAtom(a)\n",
    "    \n",
    "    mol = rwMol.GetMol()\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "def get_atomicNumList(atomic_symbols):\n",
    "    atomicNumList = []\n",
    "    for symbol in atomic_symbols:\n",
    "        atomicNumList.append(get_atom(symbol))\n",
    "    return atomicNumList\n",
    "\n",
    "\n",
    "def read_xyz_file(filename):\n",
    "\n",
    "    atomic_symbols = []\n",
    "    xyz_coordinates = []\n",
    "\n",
    "    with open(filename, \"r\") as file:\n",
    "        for line_number,line in enumerate(file):\n",
    "            if line_number == 0:\n",
    "                num_atoms = int(line)\n",
    "            elif line_number == 1:\n",
    "                if \"charge=\" in line:\n",
    "                    charge = int(line.split(\"=\")[1])\n",
    "                else:\n",
    "                    charge = 0\n",
    "            else:\n",
    "                atomic_symbol, x, y, z = line.split()\n",
    "                atomic_symbols.append(atomic_symbol)\n",
    "                xyz_coordinates.append([float(x),float(y),float(z)])\n",
    "\n",
    "    atomicNumList = get_atomicNumList(atomic_symbols)\n",
    "    \n",
    "    return atomicNumList,charge,xyz_coordinates\n",
    "\n",
    "def xyz2AC(atomicNumList,xyz):\n",
    "    import numpy as np\n",
    "    mol = get_proto_mol(atomicNumList)\n",
    "\n",
    "    conf = Chem.Conformer(mol.GetNumAtoms())\n",
    "    for i in range(mol.GetNumAtoms()):\n",
    "        conf.SetAtomPosition(i,(xyz[i][0],xyz[i][1],xyz[i][2]))\n",
    "    mol.AddConformer(conf)\n",
    "\n",
    "    dMat = Chem.Get3DDistanceMatrix(mol)\n",
    "    pt = Chem.GetPeriodicTable()\n",
    "\n",
    "    num_atoms = len(atomicNumList)\n",
    "    AC = np.zeros((num_atoms,num_atoms)).astype(int)\n",
    "\n",
    "    for i in range(num_atoms):\n",
    "        a_i = mol.GetAtomWithIdx(i)\n",
    "        Rcov_i = pt.GetRcovalent(a_i.GetAtomicNum())*1.30\n",
    "        for j in range(i+1,num_atoms):\n",
    "            a_j = mol.GetAtomWithIdx(j)\n",
    "            Rcov_j = pt.GetRcovalent(a_j.GetAtomicNum())*1.30\n",
    "            if dMat[i,j] <= Rcov_i + Rcov_j:\n",
    "                AC[i,j] = 1\n",
    "                AC[j,i] = 1\n",
    "\n",
    "    return AC,mol,dMat\n",
    "\n",
    "def chiral_stereo_check(mol):\n",
    "    Chem.SanitizeMol(mol)\n",
    "    Chem.DetectBondStereochemistry(mol,-1)\n",
    "    Chem.AssignStereochemistry(mol, flagPossibleStereoCenters=True, force=True)\n",
    "    Chem.AssignAtomChiralTagsFromStructure(mol,-1)\n",
    "\n",
    "    return mol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def xyz2mol(atomicNumList, charge, xyz_coordinates, charged_fragments, quick):\n",
    "\n",
    "    # Get atom connectivity (AC) matrix, list of atomic numbers, molecular charge, \n",
    "    # and mol object with no connectivity information\n",
    "    AC,mol,dMat = xyz2AC(atomicNumList, xyz_coordinates)\n",
    "\n",
    "    # Convert AC to bond order matrix and add connectivity and charge info to mol object\n",
    "    new_mol = AC2mol(mol, AC, atomicNumList, charge, charged_fragments, quick)\n",
    "\n",
    "    # Check for stereocenters and chiral centers\n",
    "    new_mol = chiral_stereo_check(new_mol)\n",
    "\n",
    "    return new_mol,dMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def mol_from_xyz(filepath, add_hs=True):\n",
    "    charged_fragments = True  # alternatively radicals are made\n",
    "\n",
    "    # quick is faster for large systems but requires networkx\n",
    "    # if you don't want to install networkx set quick=False and\n",
    "    # uncomment 'import networkx as nx' at the top of the file\n",
    "    quick = True\n",
    "\n",
    "    atomicNumList, charge, xyz_coordinates = read_xyz_file(filepath)\n",
    "    mol, dMat = xyz2mol(atomicNumList, charge, xyz_coordinates, charged_fragments, quick)\n",
    "    \n",
    "    # Compute distance from centroid\n",
    "    xyz_coord_array = np.array(xyz_coordinates)\n",
    "    centroid = xyz_coord_array.mean(axis=0)\n",
    "    dFromCentroid = norm(xyz_coord_array - centroid, axis=1)\n",
    "\n",
    "    # Canonical hack\n",
    "#     smiles = Chem.MolToSmiles(mol, isomericSmiles=True)\n",
    "#     mol = Chem.MolFromSmiles(smiles)\n",
    "#     if add_hs: mol = Chem.AddHs(mol)\n",
    "    return mol, dMat, dFromCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total xyz filepath #  130775\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "xyz_filepath_list = list(glob(DATA_PATH+'structures/*.xyz'))\n",
    "xyz_filepath_list.sort()\n",
    "n_mols = len(xyz_filepath_list)\n",
    "print('total xyz filepath # ', n_mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81eab1d36e44229bd6701f9e8b93551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=130775), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsgdb9nsd_017732 Sanitization error: Explicit valence for atom # 4 C greater than permitted\n",
      "dsgdb9nsd_037494 Sanitization error: Explicit valence for atom # 4 C greater than permitted\n",
      "dsgdb9nsd_037900 Sanitization error: Explicit valence for atom # 5 C greater than permitted\n",
      "dsgdb9nsd_042676 Sanitization error: Explicit valence for atom # 3 C greater than permitted\n",
      "dsgdb9nsd_042681 Sanitization error: Explicit valence for atom # 3 C greater than permitted\n",
      "dsgdb9nsd_044308 Sanitization error: Explicit valence for atom # 5 C greater than permitted\n",
      "dsgdb9nsd_044322 Sanitization error: Explicit valence for atom # 5 C greater than permitted\n",
      "dsgdb9nsd_048903 Sanitization error: Explicit valence for atom # 2 C greater than permitted\n",
      "dsgdb9nsd_066495 Sanitization error: Explicit valence for atom # 7 C greater than permitted\n",
      "dsgdb9nsd_067109 Sanitization error: Explicit valence for atom # 2 C greater than permitted\n",
      "dsgdb9nsd_073323 Sanitization error: Explicit valence for atom # 4 C greater than permitted\n",
      "dsgdb9nsd_090191 Sanitization error: Explicit valence for atom # 3 C greater than permitted\n",
      "dsgdb9nsd_090838 Sanitization error: Explicit valence for atom # 5 C greater than permitted\n",
      "dsgdb9nsd_107870 Sanitization error: Explicit valence for atom # 2 C greater than permitted\n",
      "dsgdb9nsd_133831 Sanitization error: Explicit valence for atom # 2 C greater than permitted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dist_matrices = {}\n",
    "mols = {}\n",
    "dist_from_centroids = {}\n",
    "for i in tqdm_notebook(range(n_mols)):\n",
    "    filepath = xyz_filepath_list[i]\n",
    "    mol_name = filepath.split('/')[-1][:-4]\n",
    "    try: \n",
    "        mol, dist_matrix, dist_from_centroid = mol_from_xyz(filepath)\n",
    "        mols[mol_name] = mol\n",
    "        dist_matrices[mol_name] = dist_matrix\n",
    "        dist_from_centroids[mol_name] = dist_from_centroid\n",
    "    except ValueError as e: \n",
    "        print(mol_name, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EDGE_FEATURES        = 16\n",
    "N_ATOM_FEATURES        = 27\n",
    "N_MASTER_EDGE_FEATURES = 9\n",
    "N_MASTER_FEATURES      = 9\n",
    "MAX_N_ATOMS            = 29\n",
    "MAX_N_BONDS            = 58\n",
    "TYPES                  = train_df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def get_edge_features(mol, eucl_dist):\n",
    "#     \"\"\"\n",
    "#     Compute the following features for each entry in the adjacency matrix pf 'mol':\n",
    "#         - bond type one-hot: categorical {1: single, 2: double, 3: triple, 4: aromatic}\n",
    "#         - is conjugated: bool {0, 1}\n",
    "#         - is in ring: bool {0, 1}\n",
    "#         - graph distance: int\n",
    "#         - euclidean distance: float\n",
    "#     \"\"\"\n",
    "#     n_atoms = mol.GetNumAtoms()\n",
    "#     features = np.zeros((n_atoms, n_atoms, N_EDGE_FEATURES-8))\n",
    "\n",
    "#     # compute distance features\n",
    "#     graph_dist = Chem.AllChem.GetDistanceMatrix(mol)\n",
    "\n",
    "#     features[:,:,-1] = eucl_dist\n",
    "#     features[:,:,-2] = graph_dist\n",
    "#     for e in mol.GetBonds():\n",
    "#         i = e.GetBeginAtomIdx()\n",
    "#         j = e.GetEndAtomIdx()\n",
    "#         dc_e_feats = dc.feat.graph_features.bond_features(e).astype(int)\n",
    "#         features[i,j,:6], features[j,i,:6] = dc_e_feats, dc_e_feats\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_edge_features(mol, eucl_dist, row):\n",
    "    \"\"\"\n",
    "    Compute the following features for each entry in the adjacency matrix pf 'mol':\n",
    "        - bond type one-hot: categorical {1: single, 2: double, 3: triple, 4: aromatic}\n",
    "        - is conjugated: bool {0, 1}\n",
    "        - is in ring: bool {0, 1}\n",
    "        - graph distance: int\n",
    "        - euclidean distance: float\n",
    "        - type of scalar couplig type: categorical {1:8}\n",
    "    \"\"\"\n",
    "    n_atoms, n_bonds = mol.GetNumAtoms(), mol.GetNumBonds()\n",
    "    n_edge_features = (n_bonds + 1) * 2\n",
    "    features = np.zeros((n_edge_features, N_EDGE_FEATURES))\n",
    "    pairs_idx = np.zeros((n_edge_features, 2)) - 1\n",
    "    \n",
    "    graph_dist = Chem.AllChem.GetDistanceMatrix(mol)\n",
    "    scalar_coupling_has_bond = False\n",
    "    for n, e in enumerate(mol.GetBonds()):\n",
    "        ix1 = 2 * n\n",
    "        ix2 = (2 * n) + 1\n",
    "        i = e.GetBeginAtomIdx()\n",
    "        j = e.GetEndAtomIdx()\n",
    "        dc_e_feats = dc.feat.graph_features.bond_features(e).astype(int)\n",
    "        for ix in [ix1, ix2]:\n",
    "            features[ix, :6] = dc_e_feats\n",
    "            features[ix, 6] = graph_dist[i, j]\n",
    "            features[ix, 7] = eucl_dist[i, j]\n",
    "            if (row['atom_index_0'], row['atom_index_1']) in [(i, j), (j, i)]:\n",
    "                features[ix, 8:] = (TYPES == row['type']).astype(float)\n",
    "                scalar_coupling_has_bond = True\n",
    "        pairs_idx[ix1] = i, j\n",
    "        pairs_idx[ix2] = j, i\n",
    "    if not scalar_coupling_has_bond:\n",
    "        for ix in [-2, -1]:\n",
    "            features[ix, 6] = graph_dist[row['atom_index_0'], row['atom_index_1']]\n",
    "            features[ix, 7] = eucl_dist[row['atom_index_0'], row['atom_index_1']]\n",
    "            features[ix, 8:] = (TYPES == row['type']).astype(float)\n",
    "        pairs_idx[-2] = row['atom_index_0'], row['atom_index_1']\n",
    "        pairs_idx[-1] = row['atom_index_1'], row['atom_index_0']\n",
    "    return features[pairs_idx[:,0].argsort()], pairs_idx[pairs_idx[:,0].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [],
   "source": [
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(f\"input {x} not in allowable set{allowable_set}:\")\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def get_atom_features(mol):\n",
    "    \"\"\"\n",
    "    Compute the following features for each atom in 'mol':\n",
    "        - atom type: H, C, N, O, F (one-hot)\n",
    "        - degree: 0, 1, 2, 3, 4 (one-hot)\n",
    "        - implicit valence: 0, 1, 2, 3, 4, 5 (one-hot)\n",
    "        - Hybridization: SP, SP2, SP3, SP3D, SP3D2 (one-hot)\n",
    "        - is aromatic: bool {0, 1}\n",
    "        - formal charge: int\n",
    "        - num radical electrons: int\n",
    "        - atomic number: int\n",
    "    \"\"\"\n",
    "    n_atoms = mol.GetNumAtoms()\n",
    "    features = np.zeros((n_atoms, N_ATOM_FEATURES-1))\n",
    "    for a in mol.GetAtoms():\n",
    "        a_feats = one_of_k_encoding(a.GetSymbol(), ['H', 'C', 'N', 'O', 'F']) \\\n",
    "            + one_of_k_encoding(a.GetDegree(), [0, 1, 2, 3, 4]) \\\n",
    "            + one_of_k_encoding(a.GetImplicitValence(), [0, 1, 2, 3, 4]) \\\n",
    "            + one_of_k_encoding_unk(a.GetHybridization(), [\n",
    "                Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
    "                Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.SP3D, \n",
    "                Chem.rdchem.HybridizationType.SP3D2, Chem.rdchem.HybridizationType.UNSPECIFIED]) \\\n",
    "            + [a.GetIsAromatic(), a.GetFormalCharge(), a.GetNumRadicalElectrons(), a.GetAtomicNum(),\n",
    "               a.IsInRing()]\n",
    "        features[a.GetIdx(),:] = np.array(a_feats).astype(int)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# n_obs = 50000 # len(mols)\n",
    "# atomic_features = np.zeros((n_obs, MAX_N_ATOMS, N_ATOM_FEATURES))\n",
    "# edge_features = np.zeros((n_obs, MAX_N_ATOMS, MAX_N_ATOMS, N_EDGE_FEATURES))\n",
    "# mask = np.zeros((n_mols, MAX_N_ATOMS))\n",
    "# target = np.zeros(n_obs)\n",
    "# keep = []\n",
    "# mol_name = ''\n",
    "# succesful_mols = list(mols.keys())\n",
    "# types = train_df['type'].unique()\n",
    "# for i in tqdm_notebook(range(n_obs)):\n",
    "#     row = train_df.iloc[i,:]\n",
    "#     new_mol_name = row['molecule_name']\n",
    "#     if mol_name!=new_mol_name:\n",
    "#         if new_mol_name in succesful_mols:\n",
    "#             mol_name = new_mol_name\n",
    "#             mol, dist_matrix = mols[mol_name], dist_matrices[mol_name]\n",
    "#             n_atoms = mol.GetNumAtoms()\n",
    "#         else:\n",
    "#             continue\n",
    "#     atomic_features[i, :n_atoms, :-1] = get_atom_features(mol)\n",
    "#     atomic_features[i, row['atom_index_0'], -1] = 1.\n",
    "#     atomic_features[i, row['atom_index_1'], -1] = 1.\n",
    "#     edge_features[i, :n_atoms, :n_atoms, :-8] = get_edge_features(mol, dist_matrix)\n",
    "#     edge_features[i, row['atom_index_0'], row['atom_index_1'], -8:] = (types == row['type']).astype(float)\n",
    "#     mask[i,:n_atoms] = 1.\n",
    "#     target[i] = row['scalar_coupling_constant']\n",
    "#     keep.append(i)\n",
    "# keep = np.array(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# n_obs = 50000 # len(mols)\n",
    "# atomic_features = np.zeros((n_obs, MAX_N_ATOMS, N_ATOM_FEATURES))\n",
    "# edge_features = np.zeros((n_obs, MAX_N_BONDS, N_EDGE_FEATURES))\n",
    "# pairs_idx = np.zeros((n_obs, MAX_N_BONDS, 2)) - 1\n",
    "# mask = np.zeros((n_obs, MAX_N_ATOMS))\n",
    "# edge_mask = np.zeros((n_obs, MAX_N_BONDS))\n",
    "# target = np.zeros(n_obs)\n",
    "# keep = []\n",
    "# mol_name = ''\n",
    "# succesful_mols = list(mols.keys())\n",
    "# for i in tqdm_notebook(range(n_obs)):\n",
    "#     row = train_df.iloc[i,:]\n",
    "#     new_mol_name = row['molecule_name']\n",
    "#     if mol_name!=new_mol_name:\n",
    "#         if new_mol_name in succesful_mols:\n",
    "#             mol_name = new_mol_name\n",
    "#             mol, dist_matrix = mols[mol_name], dist_matrices[mol_name]\n",
    "#             n_atoms = mol.GetNumAtoms()\n",
    "#             n_bonds = mol.GetNumBonds()\n",
    "#             n_edge_features = (n_bonds + 1) * 2\n",
    "#         else:\n",
    "#             continue\n",
    "#     atomic_features[i, :n_atoms, :-1] = get_atom_features(mol)\n",
    "#     atomic_features[i, row['atom_index_0'], -1] = 1.\n",
    "#     atomic_features[i, row['atom_index_1'], -1] = 1.\n",
    "#     edge_features[i, :n_edge_features, :], pairs_idx[i, :n_edge_features, :] = \\\n",
    "#         get_edge_features(mol, dist_matrix, row)\n",
    "#     mask[i, :n_atoms], edge_mask[i, pairs_idx[i,:,0] != -1] = 1., 1.\n",
    "#     target[i] = row['scalar_coupling_constant']\n",
    "#     keep.append(i)\n",
    "# keep = np.array(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae6fd3fc5594095a7f2d24650111b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_obs = 50000 # len(mols)\n",
    "atomic_features = np.zeros((n_obs, MAX_N_ATOMS, N_ATOM_FEATURES))\n",
    "master_features = np.zeros((n_obs, N_MASTER_FEATURES))\n",
    "edge_features = np.zeros((n_obs, MAX_N_BONDS, N_EDGE_FEATURES))\n",
    "master_edge_features = np.zeros((n_obs, MAX_N_ATOMS, N_MASTER_EDGE_FEATURES))\n",
    "pairs_idx = np.zeros((n_obs, MAX_N_BONDS, 2)) - 1\n",
    "mask = np.zeros((n_obs, MAX_N_ATOMS))\n",
    "edge_mask = np.zeros((n_obs, MAX_N_BONDS))\n",
    "target = np.zeros(n_obs)\n",
    "keep = []\n",
    "mol_name = ''\n",
    "succesful_mols = list(mols.keys())\n",
    "for i in tqdm_notebook(range(n_obs)):\n",
    "    row = train_df.iloc[i,:]\n",
    "    new_mol_name = row['molecule_name']\n",
    "    if mol_name!=new_mol_name:\n",
    "        if new_mol_name in succesful_mols:\n",
    "            mol_name = new_mol_name\n",
    "            mol, dist_matrix = mols[mol_name], dist_matrices[mol_name]\n",
    "            dist_from_centroid = dist_from_centroids[mol_name]\n",
    "            n_atoms = mol.GetNumAtoms()\n",
    "            n_bonds = mol.GetNumBonds()\n",
    "            n_edge_features = (n_bonds + 1) * 2\n",
    "        else:\n",
    "            continue\n",
    "    atomic_features[i, :n_atoms, :-1] = get_atom_features(mol)\n",
    "    atomic_features[i, row['atom_index_0'], -1] = 1.\n",
    "    atomic_features[i, row['atom_index_1'], -1] = 1.\n",
    "    master_features[i, :6] = row[['num_atoms', 'num_C_atoms', 'num_H_atoms', \n",
    "                                  'num_N_atoms', 'num_O_atoms', 'num_F_atoms']]\n",
    "    master_features[i, 6:] = mol.GetNumHeavyAtoms(), n_bonds, mol.GetRingInfo().NumRings()\n",
    "    edge_features[i, :n_edge_features, :], pairs_idx[i, :n_edge_features, :] = \\\n",
    "        get_edge_features(mol, dist_matrix, row)\n",
    "    master_edge_features[i, :n_atoms, 0] = dist_from_centroid\n",
    "    master_edge_features[i, row['atom_index_0'], 1:] = (TYPES == row['type']).astype(float)\n",
    "    master_edge_features[i, row['atom_index_1'], 1:] = (TYPES == row['type']).astype(float)\n",
    "    mask[i, :n_atoms], edge_mask[i, pairs_idx[i,:,0] != -1] = 1., 1.\n",
    "    target[i] = row['scalar_coupling_constant']\n",
    "    keep.append(i)\n",
    "keep = np.array(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_features      = atomic_features[keep]\n",
    "master_features      = master_features[keep]\n",
    "edge_features        = edge_features[keep]\n",
    "master_edge_features = master_edge_features[keep]\n",
    "pairs_idx            = pairs_idx[keep]\n",
    "mask                 = mask[keep]\n",
    "edge_mask            = edge_mask[keep]\n",
    "target               = target[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.505295, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       [1.006628, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       [1.302268, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       [1.808148, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       ...,\n",
       "       [2.682558, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       [2.001112, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       [2.187803, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_features,master_edge_features\n",
    "master_edge_features[i,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atomic_features.shape\t\t: (50000, 29, 27)\n",
      "edge_features.shape\t\t: (50000, 58, 16)\n",
      "master_features.shape\t\t: (50000, 9)\n",
      "master_edge_features.shape\t: (50000, 29, 9)\n"
     ]
    }
   ],
   "source": [
    "print(f'atomic_features.shape\\t\\t: {atomic_features.shape}\\nedge_features.shape\\t\\t: {edge_features.shape}'\n",
    "      f'\\nmaster_features.shape\\t\\t: {master_features.shape}\\nmaster_edge_features.shape\\t: {master_edge_features.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MPNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "enn_args = dict(layers=[50, 50, 50, 50], act=nn.ReLU(True), dropout=[0.0, 0.0, 0.0, 0.0], batch_norm=False)\n",
    "master_enn_args = dict(layers=[50, 50, 50, 50], act=nn.ReLU(True), dropout=[0.0, 0.0, 0.0, 0.0], batch_norm=False)\n",
    "R_net_args = dict(layers=[200, 100], act=nn.ReLU(True), dropout=[0.0, 0.0], batch_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "def hidden_layer(n_in, n_out, batch_norm, dropout, act=None):\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(n_in, n_out))\n",
    "    if act: layers.append(act)\n",
    "    if batch_norm: layers.append(nn.BatchNorm1d(n_out))\n",
    "    if dropout != 0: layers.append(nn.Dropout(dropout))\n",
    "    return layers\n",
    "\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input, n_output, layers=[], act=nn.ReLU(True), dropout=[], batch_norm=False):\n",
    "        super().__init__()\n",
    "        sizes = [n_input] + layers + [n_output]\n",
    "        layers_ = []\n",
    "        for i, (n_in, n_out, dr) in enumerate(zip(sizes[:-1], sizes[1:], dropout+[0.0])):\n",
    "            act_ = act if i < len(layers) else None\n",
    "            batch_norm_ = batch_norm if i < len(layers) else False\n",
    "            layers_ += hidden_layer(n_in, n_out, batch_norm_, dr, act_)      \n",
    "        self.layers = nn.Sequential(*layers_)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class HiddenLSTMCell(nn.Module):\n",
    "    \"\"\"Implements the LSTM cell update described in the sec 4.2 of https://arxiv.org/pdf/1511.06391.pdf.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_h_out):\n",
    "        \"\"\"This LSTM cell takes no external 'x' inputs, but has a hidden state appended with the \n",
    "        readout from a content based attention mechanism. Therefore the hidden state is of a dimension\n",
    "        that is two times the number of nodes in the set.\"\"\"\n",
    "        super().__init__()\n",
    "        self.n_h_out, self.n_h = n_h_out, n_h_out * 2 \n",
    "        self.w_h = nn.Parameter(torch.Tensor(self.n_h, n_h_out * 4))\n",
    "        self.b = nn.Parameter(torch.Tensor(n_h_out * 4))\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2: \n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            else: \n",
    "                nn.init.zeros_(p.data)\n",
    "                # initialize the forget gate bias to 1\n",
    "                p.data[self.n_h_out:self.n_h_out*2] = torch.ones(self.n_h_out)\n",
    "        \n",
    "    def forward(self, h_prev, c_prev):\n",
    "        \"\"\"Takes previuos hidden and cell states as arguments and performs a single LSTM step using \n",
    "        no external input.\n",
    "        \"\"\"\n",
    "        n_h_ = self.n_h_out # number of output hidden states\n",
    "        # batch the computations into a single matrix multiplication\n",
    "        gates = h_prev @ self.w_h + self.b\n",
    "        i_g, f_g, g, o_g = (\n",
    "            torch.sigmoid(gates[:, :n_h_]), # input\n",
    "            torch.sigmoid(gates[:, n_h_:n_h_*2]), # forget\n",
    "            torch.tanh(gates[:, n_h_*2:n_h_*3]),\n",
    "            torch.sigmoid(gates[:, n_h_*3:]), # output\n",
    "        )\n",
    "        c = f_g * c_prev + i_g * g\n",
    "        h = o_g * torch.tanh(c)\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Set2Set(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted from: https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric\\\n",
    "        /nn/glob/set2set.html#Set2Set\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, proc_steps):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = 2 * in_channels\n",
    "        self.proc_steps = proc_steps\n",
    "        self.lstm = HiddenLSTMCell(self.in_channels)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        x - input tensor of shape (batch_size, n_nodes, in_channels)\n",
    "        mask - integer tensor used to zero out nodes missing in a particualr graph \n",
    "            (not all graphs have 'n_nodes'). Is of shape (batch_size, n_nodes)\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = mask.size(0), mask.size(1)\n",
    "        batch_idx = torch.arange(0, batch_size).expand(n_nodes, batch_size).transpose(0, 1)\n",
    "        h = torch.zeros(batch_size, self.in_channels, device=x.device)\n",
    "        q_star = torch.zeros(batch_size, self.out_channels, device=x.device\n",
    "                            )\n",
    "        mask = (mask.float() - 1) * 1e6\n",
    "        for i in range(self.proc_steps):\n",
    "            q, h = self.lstm(q_star, h)\n",
    "            e = (x * q[batch_idx]).sum(dim=-1)\n",
    "            # set masked nodes not to large negative energy (attention mask will convert this to 0)\n",
    "            e += mask \n",
    "            a = F.softmax(e, dim=-1)\n",
    "            # sum a*x over node dimension \n",
    "            r = torch.sum(a.unsqueeze(-1) * x, dim=1)\n",
    "            q_star = torch.cat([q, r], dim=-1)\n",
    "            \n",
    "        return q_star\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels, self.out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def segment_sum(data, segment_ids):\n",
    "    \"\"\"\n",
    "    Computes the sum along segments of a tensor. Analogous to tf.unsorted_segment_sum.\n",
    "\n",
    "    :param data: A tensor whose segments are to be summed.\n",
    "    :param segment_ids: The segment indices tensor.\n",
    "    :return: A tensor of same data type as the data argument.\n",
    "    \"\"\"\n",
    "    assert all([i in data.shape for i in segment_ids.shape]), \"segment_ids.shape should be a prefix of data.shape\"\n",
    "        \n",
    "    # segment_ids is a 1-D tensor repeat it to have the same shape as data\n",
    "    if len(segment_ids.shape) == 1:\n",
    "        s = torch.prod(torch.tensor(data.shape[1:], device=data.device)).long()\n",
    "        segment_ids = segment_ids.repeat_interleave(s).view(segment_ids.shape[0], *data.shape[1:])\n",
    "\n",
    "    assert data.shape == segment_ids.shape, \"data.shape and segment_ids.shape should be equal\"\n",
    "\n",
    "    num_segments = len(torch.unique(segment_ids))\n",
    "    shape = [num_segments] + list(data.shape[1:])\n",
    "    tensor = torch.zeros(*shape, device=data.device).scatter_add(0, segment_ids, data.float())\n",
    "    tensor = tensor.type(data.dtype)\n",
    "    return tensor\n",
    "\n",
    "class EdgeNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_h, n_e, fully_connected_graph=False, use_master_node=False, \n",
    "                 n_h_m=0, n_e_m=0, net_args={}, master_net_args={}):\n",
    "        super().__init__()\n",
    "        self.n_e, self.n_h, self.n_e_m, self.n_h_m = n_e, n_h, n_e_m, n_h_m\n",
    "        self.fully_connected_graph = fully_connected_graph\n",
    "        self.use_master_node = use_master_node\n",
    "        self.adj_net = FullyConnectedNet(n_e, n_h ** 2, **net_args)\n",
    "        self.master_adj_net_in = FullyConnectedNet(n_e_m, n_h * n_h_m, **master_net_args)\n",
    "        self.master_adj_net_out = FullyConnectedNet(n_e_m, n_h_m * n_h, **master_net_args)\n",
    "        self.b = nn.Parameter(torch.Tensor(n_h)) # bias for the message function\n",
    "        self.b_m = nn.Parameter(torch.Tensor(n_h_m)) # bias for the master message function\n",
    "        nn.init.zeros_(self.b)\n",
    "        nn.init.zeros_(self.b_m)\n",
    "    \n",
    "    def forward(self, h, e, mask=None, pairs_idx=None, edge_mask=None, h_m=None, e_m=None):\n",
    "        \"\"\"\n",
    "        Compute message vector m_t given the previuos hidden state\n",
    "        h_t-1 and edge features e. e_out represents the same edge \n",
    "        features as e_in with adj matrix transposed.\n",
    "        - h is a collection of hidden states of shape (batch_size, n_nodes, n_h)\n",
    "        - e is a collection of edge features of shape \n",
    "            (batch_size, n_nodes, n_nodes, n_e) if fully_connected_graph\n",
    "            else shape is (batch_size, n_edges, n_e).\n",
    "        - mask is a tensor used to  zero out nodes missing in a particualr \n",
    "            graph (not all graphs have 'n_nodes'). Is of shape \n",
    "            (batch_size, n_nodes)\n",
    "        - pairs_idx: if self.fully_connected_graph = False this is a tensor\n",
    "            of shape (batch_size, n_edges, 2) mapping atom indexes \n",
    "            (first column) to the other atom indexes they form a bond with\n",
    "            (second column. \n",
    "        - edge_mask: if self.fully_connected_graph = False this is a tensor\n",
    "            of shape (batch_size, n_edges) masking non present edges.\n",
    "        - h_m: if not None, tensor of shape (batch_size, n_h_m) containing \n",
    "            hidden states for master node.\n",
    "        - e_m: if not None, tensor of shape (batch_size, n_nodes, n_e_m) containing \n",
    "            edge features for edges connected to the master node.\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = h.size(0), h.size(1)\n",
    "        \n",
    "        # compute a\n",
    "        a_vect = self.adj_net(e.view(-1, self.n_e)) # dim(a_vect) = (batch_size * n_edges, n_h^2)\n",
    "        if self.fully_connected_graph:\n",
    "            a_tmp = a_vect.view(-1, n_nodes, n_nodes, self.n_h, self.n_h).transpose(2, 3)\n",
    "            a = a_tmp.contiguous().view(-1, n_nodes * self.n_h, n_nodes * self.n_h)\n",
    "            h_flat = h.view(batch_size, n_nodes * self.n_h, 1)\n",
    "            m = torch.matmul(a, h_flat).view(batch_size * n_nodes, self.n_h)\n",
    "        else:\n",
    "            n_edges = e.size(1)\n",
    "            edge_mask_ = edge_mask.type(torch.uint8)==True\n",
    "            edge_mask_flat = edge_mask.view(-1).type(torch.uint8)==True\n",
    "            \n",
    "            a_mat = a_vect[edge_mask_flat].view(-1, self.n_h, self.n_h)\n",
    "            h_stacked = torch.cat([h[b,ix,:] for b, ix in enumerate(torch.unbind(pairs_idx[:,:,1]))])\n",
    "            h_stacked = h_stacked[edge_mask_flat]\n",
    "            ah = torch.einsum('bij,bjk->bik', h_stacked.unsqueeze(1), a_mat).squeeze(1)\n",
    "            \n",
    "            n_nodes_per_graph = pairs_idx[:,:,0].max(dim=1).values + 1\n",
    "            unique_idx = pairs_idx[:,:,0] + (torch.cat([\n",
    "                                                 torch.zeros(1, dtype=torch.long, device=h.device), \n",
    "                                                 n_nodes_per_graph[:-1].cumsum(dim=0)\n",
    "                                             ])).unsqueeze(-1).expand(-1, n_edges)\n",
    "            m_stacked = segment_sum(ah, unique_idx[edge_mask_])\n",
    "            \n",
    "            m_per_graph_lst = torch.split(m_stacked, n_nodes_per_graph.tolist())\n",
    "            m = torch.cat([F.pad(m_, pad=(0, 0, 0, n_nodes - n_nodes_)) \n",
    "                           for m_, n_nodes_ in zip(m_per_graph_lst, n_nodes_per_graph)]) \n",
    "            \n",
    "            if self.use_master_node:\n",
    "                a_mo_vect = self.master_adj_net_out(e_m.view(-1, self.n_e_m)) # dim(a_mo_vect) = (batch_size * n_nodes, n_h_m * n_h)\n",
    "                a_mo_mat = a_mo_vect.view(-1, self.n_h_m, self.n_h)\n",
    "                h_m_expanded = h_m.repeat_interleave(n_nodes, 0).unsqueeze(1)\n",
    "                ah_mo = torch.einsum('bij,bjk->bik', h_m_expanded, a_mo_mat).squeeze(1) # dim(ah_mo) = (batch_size * n_nodes, n_h)\n",
    "                m += ah_mo * mask.view(-1, 1)\n",
    "                \n",
    "                a_mi_vect = self.master_adj_net_in(e_m.view(-1, self.n_e_m)) # dim(a_mi_vect) = (batch_size * n_nodes, n_h * n_h_m)\n",
    "                a_mi_mat = a_mi_vect.view(-1, self.n_h, self.n_h_m)\n",
    "                ah_mi = torch.einsum('bij,bjk->bik', h.view(-1, self.n_h).unsqueeze(1), a_mi_mat).squeeze(1) # dim(ah_mi) = (batch_size, 1, n_h_m)\n",
    "                m_m = ah_mi.view(-1, n_nodes, self.n_h_m).sum(dim=1)\n",
    "            \n",
    "        m += self.b\n",
    "        \n",
    "        if self.use_master_node:\n",
    "            m_m += self.b_m\n",
    "            return m.view(batch_size, n_nodes, self.n_h), m_m\n",
    "        else:\n",
    "            return m.view(batch_size, n_nodes, self.n_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class GRUUpdate(nn.Module):\n",
    "    def __init__(self, n_h):\n",
    "        super().__init__()\n",
    "        self.n_h = n_h\n",
    "        self.gru = nn.GRUCell(n_h, n_h)\n",
    "        \n",
    "    def forward(self, m, h_prev, mask):\n",
    "        \"\"\"\n",
    "        Update hidden state h.\n",
    "        - h_prev is vector of hidden states of shape (batch_size, n_nodes, n_h)\n",
    "        - m is vector of messages of shape (batch_size, n_nodes, n_h)\n",
    "        - mask is used to  zero out nodes missing in a particualr graph (not all graphs \n",
    "            have 'n_nodes'). Is of shape (batch_size, n_nodes)\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = h_prev.size(0), h_prev.size(1)\n",
    "        h = self.gru(m.view(-1, self.n_h), h_prev.view(-1, self.n_h))\n",
    "        return h.view(batch_size, n_nodes, self.n_h) * mask.unsqueeze(-1).expand(batch_size, n_nodes, self.n_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Set2SetOutput(nn.Module):\n",
    "    def __init__(self, n_x, n_h, proc_steps, net_args, use_master_node=False, n_x_m=0, n_h_m=0):\n",
    "        super().__init__()\n",
    "        self.n_h, self.n_x = n_h, n_x\n",
    "        self.use_master_node = use_master_node\n",
    "        self.R_proj = nn.Linear(n_h + n_x, n_h)\n",
    "        if use_master_node: self.R_proj_m = nn.Linear(n_h_m + n_x_m, n_h)\n",
    "        self.R_proc = Set2Set(n_h, proc_steps)\n",
    "        self.R_write = FullyConnectedNet(2 * n_h, 1, **net_args)\n",
    "    \n",
    "    def forward(self, h, x, mask, h_m=None, x_m=None):\n",
    "        \"\"\"\n",
    "        Update hidden state h.\n",
    "        - h is vector of hidden states of shape (batch_size, n_nodes, n_h)\n",
    "        - x is vector of input features of shape (batch_size, n_nodes, n_x)\n",
    "        - mask is used to  zero out nodes missing in a particualr graph (not all graphs \n",
    "            have 'n_nodes'). Is of shape (batch_size, n_nodes)\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = h.size(0), h.size(1)\n",
    "        m = self.R_proj(torch.cat([h.view(-1, self.n_h), x.view(-1, self.n_x)], dim=1))\n",
    "        m_reshaped = m.view(batch_size, n_nodes, self.n_h)\n",
    "        if self.use_master_node: \n",
    "            m_m = self.R_proj_m(torch.cat([h_m, x_m], dim=1))\n",
    "            m_reshaped = torch.cat([m_reshaped, m_m.unsqueeze(1)], dim=1)\n",
    "            mask_ = torch.cat([mask.clone(), torch.ones(batch_size, 1, device=x.device)], dim=1)\n",
    "        else:\n",
    "            mask_ = mask.clome()\n",
    "        q = self.R_proc(m_reshaped, mask_) \n",
    "        y = self.R_write(q) # dim(q) = (batch_size, n_h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNN(nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_e, update_steps=3, proc_steps=10, enn_args={}, R_net_args={}, \n",
    "                 fully_connected_graph=False, use_master_node=False, n_x_m=0, n_h_m=0, n_e_m=0,\n",
    "                 master_enn_args={}):\n",
    "        super().__init__()\n",
    "        self.n_h, self.n_x, self.n_h_m, self.n_x_m = n_h, n_x, n_h_m, n_x_m\n",
    "        self.use_master_node = use_master_node\n",
    "        self.M = EdgeNetwork(n_h, n_e, fully_connected_graph, use_master_node, n_h_m, n_e_m,\n",
    "                             enn_args, master_enn_args)\n",
    "        self.U = GRUUpdate(n_h)\n",
    "        if use_master_node: self.U_m = GRUUpdate(n_h_m)\n",
    "        self.R = Set2SetOutput(n_x, n_h, proc_steps, R_net_args, use_master_node, n_x_m, n_h_m)\n",
    "        self.update_steps = update_steps\n",
    "        \n",
    "    def forward(self, x, e, mask, pairs_idx=None, edge_mask=None, x_m=None, e_m=None):\n",
    "        h = F.pad(x, pad=(0, self.n_h - self.n_x))\n",
    "        h_m = F.pad(x_m, pad=(0, self.n_h_m - self.n_x_m)) if self.use_master_node else None\n",
    "        for t in range(self.update_steps):\n",
    "            if self.use_master_node: \n",
    "                m, m_m = self.M(h, e, mask, pairs_idx, edge_mask, h_m, e_m)\n",
    "                h = self.U(m, h, mask)\n",
    "                h_m = self.U_m(m_m.unsqueeze(1), h_m.unsqueeze(1), \n",
    "                               torch.ones(1, 1, device=x.device)).squeeze(1)\n",
    "            else:\n",
    "                m = self.M(h, e, mask, pairs_idx, edge_mask, h_m, e_m)\n",
    "                h = self.U(m, h, mask)\n",
    "        y = self.R(h, x, mask, h_m, x_m)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNN(\n",
      "  (M): EdgeNetwork(\n",
      "    (adj_net): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=50, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (5): ReLU(inplace)\n",
      "        (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): Linear(in_features=50, out_features=2500, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (master_adj_net_in): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=9, out_features=50, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (5): ReLU(inplace)\n",
      "        (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): Linear(in_features=50, out_features=5000, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (master_adj_net_out): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=9, out_features=50, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (5): ReLU(inplace)\n",
      "        (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): Linear(in_features=50, out_features=5000, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (U): GRUUpdate(\n",
      "    (gru): GRUCell(50, 50)\n",
      "  )\n",
      "  (U_m): GRUUpdate(\n",
      "    (gru): GRUCell(100, 100)\n",
      "  )\n",
      "  (R): Set2SetOutput(\n",
      "    (R_proj): Linear(in_features=77, out_features=50, bias=True)\n",
      "    (R_proj_m): Linear(in_features=109, out_features=50, bias=True)\n",
      "    (R_proc): Set2Set(50, 100)\n",
      "    (R_write): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=100, out_features=200, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Linear(in_features=100, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "tensor([[-0.0372],\n",
      "        [-0.0361],\n",
      "        [-0.0361],\n",
      "        [-0.0361],\n",
      "        [-0.0372],\n",
      "        [-0.0361],\n",
      "        [-0.0361],\n",
      "        [-0.0372],\n",
      "        [-0.0361],\n",
      "        [-0.0372],\n",
      "        [-0.0358],\n",
      "        [-0.0328],\n",
      "        [-0.0328],\n",
      "        [-0.0358],\n",
      "        [-0.0328],\n",
      "        [-0.0358],\n",
      "        [-0.0335],\n",
      "        [-0.0381],\n",
      "        [-0.0340],\n",
      "        [-0.0449]], grad_fn=<AddmmBackward>)\n",
      "torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "batch_size, n_nodes, n_h, n_e, n_x, n_edges = 20, MAX_N_ATOMS, 50, N_EDGE_FEATURES, N_ATOM_FEATURES, MAX_N_BONDS\n",
    "n_h_m, n_e_m, n_x_m = 100, N_MASTER_EDGE_FEATURES, N_MASTER_FEATURES\n",
    "x     = torch.tensor(atomic_features[:batch_size,:,:], dtype=torch.float)\n",
    "e     = torch.tensor(edge_features[:batch_size,:,:], dtype=torch.float)\n",
    "msk   = torch.tensor(mask[:batch_size,:], dtype=torch.float)\n",
    "p_idx = torch.tensor(pairs_idx[:batch_size,:,:], dtype=torch.long)\n",
    "e_msk = torch.tensor(edge_mask[:batch_size,:], dtype=torch.float)\n",
    "x_m   = torch.tensor(master_features[:batch_size,:], dtype=torch.float)\n",
    "e_m   = torch.tensor(master_edge_features[:batch_size,:,:], dtype=torch.float)\n",
    "\n",
    "mpnn = MPNN(n_x, n_h, n_e, update_steps=5, proc_steps=10, enn_args=enn_args, R_net_args=R_net_args,\n",
    "            fully_connected_graph=False, use_master_node=True, n_x_m=n_x_m, n_h_m=n_h_m, n_e_m=n_e_m,\n",
    "            master_enn_args=master_enn_args)\n",
    "print(mpnn)\n",
    "print(mpnn(x, e, msk, p_idx, e_msk, x_m, e_m))\n",
    "print(mpnn(x, e, msk, p_idx, e_msk, x_m, e_m).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Fit MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = train_test_split(np.arange(n_obs), test_size=0.25, shuffle=True, random_state=100)\n",
    "x_train, x_val     = atomic_features[train_idx], atomic_features[val_idx]\n",
    "e_train, e_val     = edge_features[train_idx], edge_features[val_idx]\n",
    "x_m_train, x_m_val = master_features[train_idx], master_features[val_idx]\n",
    "e_m_train, e_m_val = master_edge_features[train_idx], master_edge_features[val_idx]\n",
    "y_train, y_val     = target[train_idx], target[val_idx]\n",
    "mask_train, mask_val = mask[train_idx], mask[val_idx]\n",
    "edge_mask_train, edge_mask_val = edge_mask[train_idx], edge_mask[val_idx]\n",
    "pairs_idx_train, pairs_idx_val = pairs_idx[train_idx], pairs_idx[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_target = StandardScaler()\n",
    "y_train = ss_target.fit_transform(y_train.reshape(-1,1))\n",
    "y_val = ss_target.transform(y_val.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MoleculeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, y, x, e, mask, pairs_idx=None, edge_mask=None, x_m=None, e_m=None):\n",
    "        self.n = len(y)\n",
    "        self.y = y.astype(np.float32)\n",
    "        self.x = x.astype(np.float32)\n",
    "        self.e = e.astype(np.float32)\n",
    "        self.mask = mask.astype(np.float32)\n",
    "        self.fully_connected_graphs = edge_mask is None\n",
    "        if not self.fully_connected_graphs:\n",
    "            self.pairs_idx = pairs_idx.astype(np.long)\n",
    "            self.edge_mask = edge_mask.astype(np.float32)\n",
    "            self.use_master_node = x_m is not None\n",
    "            if self.use_master_node:\n",
    "                self.x_m = x_m.astype(np.float32)\n",
    "                self.e_m = e_m.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.fully_connected_graphs:\n",
    "            xs = (self.x[idx], self.e[idx], self.mask[idx])\n",
    "        else:\n",
    "            if self.use_master_node:\n",
    "                xs = (self.x[idx], self.e[idx], self.mask[idx], self.pairs_idx[idx], \n",
    "                      self.edge_mask[idx], self.x_m[idx], self.e_m[idx])\n",
    "            else: \n",
    "                xs = (self.x[idx], self.e[idx], self.mask[idx], self.pairs_idx[idx], \n",
    "                      self.edge_mask[idx])\n",
    "        return xs, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MoleculeDataset(y_train, x_train, e_train, mask_train, pairs_idx_train, \n",
    "                           edge_mask_train, x_m_train, e_m_train)\n",
    "val_ds   = MoleculeDataset(y_val, x_val, e_val, mask_val, pairs_idx_val, \n",
    "                           edge_mask_val, x_m_val, e_m_val)\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=8)\n",
    "val_dl   = DataLoader(val_ds, batch_size, num_workers=8)\n",
    "db = DataBunch(train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "code_folding": [
     0,
     7,
     32
    ]
   },
   "outputs": [],
   "source": [
    "def group_mean_log_mae(y_true, y_pred, types):\n",
    "    y_true, y_pred, types = y_true.cpu().numpy().ravel(), y_pred.cpu().numpy().ravel(), types.cpu().numpy().ravel()\n",
    "    y_true = ss_target.mean_ + y_true * ss_target.scale_\n",
    "    y_pred = ss_target.mean_ + y_pred * ss_target.scale_\n",
    "    maes = pd.Series(y_true-y_pred).abs().groupby(types).mean()\n",
    "    return np.log(maes).mean()\n",
    "\n",
    "class GroupMeanLogMAE(Callback):\n",
    "    _order = -20 #Needs to run before the recorder\n",
    "    types_cidx = 2\n",
    "\n",
    "    def __init__(self, learn, **kwargs): self.learn = learn\n",
    "    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['GroupMeanLogMAE'])\n",
    "    def on_epoch_begin(self, **kwargs): self.input, self.output, self.target = [], [], []\n",
    "    \n",
    "    def on_batch_end(self, last_target, last_output, last_input, train, **kwargs):\n",
    "        if not train:\n",
    "            last_e = last_input[1]\n",
    "            if len(last_e.size()) == 4: types = torch.nonzero(last_e[:,:,:,-8:])[:,-1]\n",
    "            else: types = torch.nonzero(last_e[:,:,-8:])[::2,-1]\n",
    "            self.input.append(types)\n",
    "            self.output.append(last_output)\n",
    "            self.target.append(last_target)\n",
    "                \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        if (len(self.input) > 0) and (len(self.output) > 0):\n",
    "            inputs = torch.cat(self.input)\n",
    "            preds = torch.cat(self.output)\n",
    "            target = torch.cat(self.target)\n",
    "            metric = group_mean_log_mae(preds, target, inputs)\n",
    "            return add_metrics(last_metrics, [metric])\n",
    "\n",
    "def set_seed(seed=100):\n",
    "    # python RNG\n",
    "    random.seed(seed)\n",
    "\n",
    "    # pytorch RNGs\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # numpy RNG\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-6\n",
    "update_steps, proc_steps = 5, 10\n",
    "n_x, n_h, n_e = N_ATOM_FEATURES, 50, N_EDGE_FEATURES\n",
    "n_x_m, n_h_m, n_e_m = N_MASTER_FEATURES, 100, N_MASTER_EDGE_FEATURES\n",
    "enn_args = dict(layers=[50, 50, 50, 50], act=nn.ReLU(True), dropout=[0.0, 0.0, 0.0, 0.0], batch_norm=False)\n",
    "master_enn_args = dict(layers=[50, 50, 50, 50], act=nn.ReLU(True), dropout=[0.0, 0.0, 0.0, 0.0], batch_norm=False)\n",
    "R_net_args = dict(layers=[200, 100], act=nn.ReLU(True), dropout=[0.0, 0.0], batch_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(100)\n",
    "model = MPNN(n_x, n_h, n_e, update_steps, proc_steps, enn_args, R_net_args, False, True, \n",
    "             n_x_m, n_h_m, n_e_m, master_enn_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(db, model, metrics=[mean_absolute_error], callback_fns=GroupMeanLogMAE, \n",
    "                wd=wd, loss_func=root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(start_lr=1e-8, end_lr=1, num_it=200, stop_div=True)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>GroupMeanLogMAE</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.228968</td>\n",
       "      <td>0.183314</td>\n",
       "      <td>0.140585</td>\n",
       "      <td>1.620372</td>\n",
       "      <td>23:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.115994</td>\n",
       "      <td>0.099356</td>\n",
       "      <td>0.070873</td>\n",
       "      <td>1.001293</td>\n",
       "      <td>25:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.101909</td>\n",
       "      <td>0.110408</td>\n",
       "      <td>0.079734</td>\n",
       "      <td>0.982607</td>\n",
       "      <td>24:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.089327</td>\n",
       "      <td>0.090962</td>\n",
       "      <td>0.062281</td>\n",
       "      <td>0.761852</td>\n",
       "      <td>23:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.078640</td>\n",
       "      <td>0.082553</td>\n",
       "      <td>0.060340</td>\n",
       "      <td>0.731241</td>\n",
       "      <td>25:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.069883</td>\n",
       "      <td>0.063609</td>\n",
       "      <td>0.044363</td>\n",
       "      <td>0.441220</td>\n",
       "      <td>24:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.058718</td>\n",
       "      <td>0.056186</td>\n",
       "      <td>0.040282</td>\n",
       "      <td>0.337238</td>\n",
       "      <td>24:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.051435</td>\n",
       "      <td>0.051260</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>0.217043</td>\n",
       "      <td>23:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.047681</td>\n",
       "      <td>0.048614</td>\n",
       "      <td>0.034125</td>\n",
       "      <td>0.145414</td>\n",
       "      <td>25:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.044695</td>\n",
       "      <td>0.047451</td>\n",
       "      <td>0.033126</td>\n",
       "      <td>0.111140</td>\n",
       "      <td>25:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with GroupMeanLogMAE value: 1.620371968065821.\n",
      "Better model found at epoch 1 with GroupMeanLogMAE value: 1.0012926929590282.\n",
      "Better model found at epoch 2 with GroupMeanLogMAE value: 0.9826073500929338.\n",
      "Better model found at epoch 3 with GroupMeanLogMAE value: 0.7618520874817801.\n",
      "Better model found at epoch 4 with GroupMeanLogMAE value: 0.7312411666302335.\n",
      "Better model found at epoch 5 with GroupMeanLogMAE value: 0.44121998811972046.\n",
      "Better model found at epoch 6 with GroupMeanLogMAE value: 0.3372382530175701.\n",
      "Better model found at epoch 7 with GroupMeanLogMAE value: 0.2170430977770317.\n",
      "Better model found at epoch 8 with GroupMeanLogMAE value: 0.14541395277396463.\n",
      "Better model found at epoch 9 with GroupMeanLogMAE value: 0.11114038742248991.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, max_lr=1e-3, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='GroupMeanLogMAE',  name='mpnn1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      20.00% [2/10 52:37<3:30:30]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>GroupMeanLogMAE</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.043967</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>0.033247</td>\n",
       "      <td>0.117283</td>\n",
       "      <td>25:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.046034</td>\n",
       "      <td>0.047675</td>\n",
       "      <td>0.033409</td>\n",
       "      <td>0.115949</td>\n",
       "      <td>27:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='1875', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with GroupMeanLogMAE value: 0.11728293677794015.\n",
      "Better model found at epoch 1 with GroupMeanLogMAE value: 0.11594874821080375.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "Traceback (most recent call last):\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-9db314fc83ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m learn.fit_one_cycle(10, max_lr=1e-4, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n\u001b[0;32m----> 2\u001b[0;31m                                                                   monitor='GroupMeanLogMAE',  name='mpnn2')])\n\u001b[0m",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, max_lr=1e-4, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='GroupMeanLogMAE',  name='mpnn2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=2e-5, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='GroupMeanLogMAE',  name='mpnn3')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=4e-6, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='GroupMeanLogMAE',  name='mpnn4')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CUDA but got backend CPU for argument #3 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-dece9e0ff5d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mget_preds\u001b[0;34m(self, ds_type, with_loss, n_batch, pbar)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mlf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwith_loss\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         return get_preds(self.model, self.dl(ds_type), cb_handler=CallbackHandler(self.callbacks),\n\u001b[0;32m--> 327\u001b[0;31m                          activ=_loss_func2activ(self.loss_func), loss_func=lf, n_batch=n_batch, pbar=pbar)\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpred_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruct\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mget_preds\u001b[0;34m(model, dl, pbar, cb_handler, activ, loss_func, n_batch)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;34m\"Tuple of predictions and targets, and optional losses (if `loss_func`) using `dl`, max batches `n_batch`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     res = [torch.cat(o).cpu() for o in\n\u001b[0;32m---> 43\u001b[0;31m            zip(*validate(model, dl, cb_handler=cb_handler, pbar=pbar, average=False, n_batch=n_batch))]\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mNoneReduceOnCPU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dl, loss_func, cb_handler, pbar, average, n_batch)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-a1d0aa2c73ac>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, e, mask, pairs_idx, edge_mask, x_m, e_m)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_master_node\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mh_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-24023d0184b1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, h, e, mask, pairs_idx, edge_mask, h_m, e_m)\u001b[0m\n\u001b[1;32m     85\u001b[0m                                                  \u001b[0mn_nodes_per_graph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                                              ])).unsqueeze(-1).expand(-1, n_edges)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mm_stacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mah\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_mask_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mm_per_graph_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_stacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nodes_per_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-24023d0184b1>\u001b[0m in \u001b[0;36msegment_sum\u001b[0;34m(data, segment_ids)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msegment_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data.shape and segment_ids.shape should be equal\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CUDA but got backend CPU for argument #3 'index'"
     ]
    }
   ],
   "source": [
    "pred, _ = learn.get_preds()\n",
    "pred_test, _ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
