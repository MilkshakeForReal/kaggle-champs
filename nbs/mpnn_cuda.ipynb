{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import deepchem as dc\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.spatial.distance import norm\n",
    "\n",
    "from fastai.tabular import *\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "from fastai.basic_data import DataBunch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "PATH = '../tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scalar_coupling_contributions.csv',\n",
       " 'mulliken_charges.csv',\n",
       " 'structures.csv',\n",
       " 'test.csv',\n",
       " 'train.csv',\n",
       " 'magnetic_shielding_tensors.csv',\n",
       " 'dipole_moments.csv',\n",
       " 'sample_submission.csv',\n",
       " 'potential_energy.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(DATA_PATH)\n",
    "files = [f for f in files if f.find('.csv') != -1]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH+'train.csv')\n",
    "test_df = pd.read_csv(DATA_PATH+'test.csv')\n",
    "structures_df = pd.read_csv(DATA_PATH+'structures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.24 s, sys: 127 ms, total: 2.37 s\n",
      "Wall time: 692 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "atoms_per_molecule_df = structures_df.groupby(['molecule_name', 'atom']).count()\n",
    "atoms_per_molecule_map = atoms_per_molecule_df['atom_index'].unstack().fillna(0).astype(int).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 900 ms, total: 16.1 s\n",
      "Wall time: 5.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pd.options.mode.chained_assignment = None\n",
    "atoms = structures_df['atom'].unique()\n",
    "train_df['num_atoms'] = 0\n",
    "test_df['num_atoms'] = 0\n",
    "for atom in atoms:\n",
    "    train_df[f'num_{atom}_atoms'] = train_df['molecule_name'].map(atoms_per_molecule_map[atom])\n",
    "    train_df['num_atoms'] += train_df[f'num_{atom}_atoms']\n",
    "    test_df[f'num_{atom}_atoms'] = test_df['molecule_name'].map(atoms_per_molecule_map[atom])\n",
    "    test_df['num_atoms'] += test_df[f'num_{atom}_atoms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'molecule_name', 'atom_index_0', 'atom_index_1', 'type',\n",
       "       'scalar_coupling_constant', 'num_atoms', 'num_C_atoms', 'num_H_atoms',\n",
       "       'num_N_atoms', 'num_O_atoms', 'num_F_atoms'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Written by Jan H. Jensen based on this paper Yeonjoon Kim and Woo Youn Kim \n",
    "# \"Universal Structure Conversion Method for Organic Molecules: From Atomic Connectivity\n",
    "# to Three-Dimensional Geometry\" Bull. Korean Chem. Soc. 2015, Vol. 36, 1769-1777 DOI: 10.1002/bkcs.10334\n",
    "#\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import itertools\n",
    "from rdkit.Chem import rdmolops\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import networkx as nx #uncomment if you don't want to use \"quick\"/install networkx\n",
    "\n",
    "\n",
    "global __ATOM_LIST__\n",
    "__ATOM_LIST__ = [ x.strip() for x in ['h ','he', \\\n",
    "      'li','be','b ','c ','n ','o ','f ','ne', \\\n",
    "      'na','mg','al','si','p ','s ','cl','ar', \\\n",
    "      'k ','ca','sc','ti','v ','cr','mn','fe','co','ni','cu', \\\n",
    "      'zn','ga','ge','as','se','br','kr', \\\n",
    "      'rb','sr','y ','zr','nb','mo','tc','ru','rh','pd','ag', \\\n",
    "      'cd','in','sn','sb','te','i ','xe', \\\n",
    "      'cs','ba','la','ce','pr','nd','pm','sm','eu','gd','tb','dy', \\\n",
    "      'ho','er','tm','yb','lu','hf','ta','w ','re','os','ir','pt', \\\n",
    "      'au','hg','tl','pb','bi','po','at','rn', \\\n",
    "      'fr','ra','ac','th','pa','u ','np','pu'] ]\n",
    "\n",
    "\n",
    "def get_atom(atom):\n",
    "    global __ATOM_LIST__\n",
    "    atom = atom.lower()\n",
    "    return __ATOM_LIST__.index(atom) + 1\n",
    "\n",
    "\n",
    "def getUA(maxValence_list, valence_list):\n",
    "    UA = []\n",
    "    DU = []\n",
    "    for i, (maxValence,valence) in enumerate(zip(maxValence_list, valence_list)):\n",
    "        if maxValence - valence > 0:\n",
    "            UA.append(i)\n",
    "            DU.append(maxValence - valence)\n",
    "    return UA,DU\n",
    "\n",
    "\n",
    "def get_BO(AC,UA,DU,valences,UA_pairs,quick):\n",
    "    BO = AC.copy()\n",
    "    DU_save = []\n",
    "\n",
    "    while DU_save != DU:\n",
    "        for i,j in UA_pairs:\n",
    "            BO[i,j] += 1\n",
    "            BO[j,i] += 1 \n",
    "        \n",
    "        BO_valence = list(BO.sum(axis=1))\n",
    "        DU_save = copy.copy(DU)\n",
    "        UA, DU = getUA(valences, BO_valence)\n",
    "        UA_pairs = get_UA_pairs(UA,AC,quick)[0]\n",
    "\n",
    "    return BO\n",
    "\n",
    "\n",
    "def valences_not_too_large(BO,valences):\n",
    "    number_of_bonds_list = BO.sum(axis=1)\n",
    "    for valence, number_of_bonds in zip(valences,number_of_bonds_list):\n",
    "        if number_of_bonds > valence:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def BO_is_OK(BO,AC,charge,DU,atomic_valence_electrons,atomicNumList,charged_fragments):\n",
    "    Q = 0 # total charge\n",
    "    q_list = []\n",
    "    if charged_fragments:\n",
    "        BO_valences = list(BO.sum(axis=1))\n",
    "        for i,atom in enumerate(atomicNumList):\n",
    "            q = get_atomic_charge(atom,atomic_valence_electrons[atom],BO_valences[i])\n",
    "            Q += q\n",
    "            if atom == 6:\n",
    "                number_of_single_bonds_to_C = list(BO[i,:]).count(1)\n",
    "                if number_of_single_bonds_to_C == 2 and BO_valences[i] == 2:\n",
    "                    Q += 1\n",
    "                    q = 2\n",
    "                if number_of_single_bonds_to_C == 3 and Q + 1 < charge:\n",
    "                    Q += 2\n",
    "                    q = 1\n",
    "            \n",
    "            if q != 0:\n",
    "                q_list.append(q)\n",
    "\n",
    "    if (BO-AC).sum() == sum(DU) and charge == Q and len(q_list) <= abs(charge):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_atomic_charge(atom,atomic_valence_electrons,BO_valence):\n",
    "    if atom == 1:\n",
    "        charge = 1 - BO_valence\n",
    "    elif atom == 5:\n",
    "        charge = 3 - BO_valence\n",
    "    elif atom == 15 and BO_valence == 5:\n",
    "        charge = 0\n",
    "    elif atom == 16 and BO_valence == 6:\n",
    "        charge = 0\n",
    "    else:\n",
    "        charge = atomic_valence_electrons - 8 + BO_valence\n",
    "\n",
    "    return charge\n",
    "\n",
    "def clean_charges(mol):\n",
    "    # this hack should not be needed any more but is kept just in case\n",
    "\n",
    "    rxn_smarts = ['[N+:1]=[*:2]-[C-:3]>>[N+0:1]-[*:2]=[C-0:3]',\n",
    "                  '[N+:1]=[*:2]-[O-:3]>>[N+0:1]-[*:2]=[O-0:3]',\n",
    "                  '[N+:1]=[*:2]-[*:3]=[*:4]-[O-:5]>>[N+0:1]-[*:2]=[*:3]-[*:4]=[O-0:5]',\n",
    "                  '[#8:1]=[#6:2]([!-:6])[*:3]=[*:4][#6-:5]>>[*-:1][*:2]([*:6])=[*:3][*:4]=[*+0:5]',\n",
    "                  '[O:1]=[c:2][c-:3]>>[*-:1][*:2][*+0:3]',\n",
    "                  '[O:1]=[C:2][C-:3]>>[*-:1][*:2]=[*+0:3]']\n",
    "\n",
    "    fragments = Chem.GetMolFrags(mol,asMols=True,sanitizeFrags=False)\n",
    "\n",
    "    for i,fragment in enumerate(fragments):\n",
    "        for smarts in rxn_smarts:\n",
    "            patt = Chem.MolFromSmarts(smarts.split(\">>\")[0])\n",
    "            while fragment.HasSubstructMatch(patt):\n",
    "                rxn = AllChem.ReactionFromSmarts(smarts)\n",
    "                ps = rxn.RunReactants((fragment,))\n",
    "                fragment = ps[0][0]\n",
    "        if i == 0:\n",
    "            mol = fragment\n",
    "        else:\n",
    "            mol = Chem.CombineMols(mol,fragment)\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "def BO2mol(mol,BO_matrix, atomicNumList,atomic_valence_electrons,mol_charge,charged_fragments):\n",
    "    # based on code written by Paolo Toscani\n",
    "\n",
    "    l = len(BO_matrix)\n",
    "    l2 = len(atomicNumList)\n",
    "    BO_valences = list(BO_matrix.sum(axis=1))\n",
    "\n",
    "    if (l != l2):\n",
    "        raise RuntimeError('sizes of adjMat ({0:d}) and atomicNumList '\n",
    "            '{1:d} differ'.format(l, l2))\n",
    "\n",
    "    rwMol = Chem.RWMol(mol)\n",
    "\n",
    "    bondTypeDict = {\n",
    "        1: Chem.BondType.SINGLE,\n",
    "        2: Chem.BondType.DOUBLE,\n",
    "        3: Chem.BondType.TRIPLE\n",
    "    }\n",
    "\n",
    "    for i in range(l):\n",
    "        for j in range(i + 1, l):\n",
    "            bo = int(round(BO_matrix[i, j]))\n",
    "            if (bo == 0):\n",
    "                continue\n",
    "            bt = bondTypeDict.get(bo, Chem.BondType.SINGLE)\n",
    "            rwMol.AddBond(i, j, bt)\n",
    "    mol = rwMol.GetMol()\n",
    "\n",
    "    if charged_fragments:\n",
    "        mol = set_atomic_charges(mol,atomicNumList,atomic_valence_electrons,BO_valences,BO_matrix,mol_charge)\n",
    "    else:\n",
    "        mol = set_atomic_radicals(mol,atomicNumList,atomic_valence_electrons,BO_valences)\n",
    "\n",
    "    return mol\n",
    "\n",
    "def set_atomic_charges(mol,atomicNumList,atomic_valence_electrons,BO_valences,BO_matrix,mol_charge):\n",
    "    q = 0\n",
    "    for i,atom in enumerate(atomicNumList):\n",
    "        a = mol.GetAtomWithIdx(i)\n",
    "        charge = get_atomic_charge(atom,atomic_valence_electrons[atom],BO_valences[i])\n",
    "        q += charge\n",
    "        if atom == 6:\n",
    "            number_of_single_bonds_to_C = list(BO_matrix[i,:]).count(1)\n",
    "            if number_of_single_bonds_to_C == 2 and BO_valences[i] == 2:\n",
    "                    q += 1\n",
    "                    charge = 0\n",
    "            if number_of_single_bonds_to_C == 3 and q + 1 < mol_charge:\n",
    "                    q += 2\n",
    "                    charge = 1\n",
    "\n",
    "        if (abs(charge) > 0):\n",
    "            a.SetFormalCharge(int(charge))\n",
    "\n",
    "    # shouldn't be needed anymore bit is kept just in case\n",
    "    #mol = clean_charges(mol)\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "def set_atomic_radicals(mol,atomicNumList,atomic_valence_electrons,BO_valences):\n",
    "    # The number of radical electrons = absolute atomic charge\n",
    "    for i,atom in enumerate(atomicNumList):\n",
    "        a = mol.GetAtomWithIdx(i)\n",
    "        charge = get_atomic_charge(atom,atomic_valence_electrons[atom],BO_valences[i])\n",
    "\n",
    "        if (abs(charge) > 0):\n",
    "            a.SetNumRadicalElectrons(abs(int(charge)))\n",
    "\n",
    "    return mol\n",
    "\n",
    "def get_bonds(UA,AC):\n",
    "    bonds = []\n",
    "\n",
    "    for k,i in enumerate(UA):\n",
    "        for j in UA[k+1:]:\n",
    "            if AC[i,j] == 1:\n",
    "                bonds.append(tuple(sorted([i,j])))\n",
    "\n",
    "    return bonds\n",
    "\n",
    "def get_UA_pairs(UA,AC,quick):\n",
    "    bonds = get_bonds(UA,AC)\n",
    "    if len(bonds) == 0:\n",
    "        return [()]\n",
    "\n",
    "    if quick:\n",
    "        G=nx.Graph()\n",
    "        G.add_edges_from(bonds)\n",
    "        UA_pairs = [list(nx.max_weight_matching(G))]\n",
    "        return UA_pairs\n",
    "\n",
    "    max_atoms_in_combo = 0\n",
    "    UA_pairs = [()]\n",
    "    for combo in list(itertools.combinations(bonds, int(len(UA)/2))):\n",
    "        flat_list = [item for sublist in combo for item in sublist]\n",
    "        atoms_in_combo = len(set(flat_list))\n",
    "        if atoms_in_combo > max_atoms_in_combo:\n",
    "            max_atoms_in_combo = atoms_in_combo\n",
    "            UA_pairs = [combo]\n",
    " #           if quick and max_atoms_in_combo == 2*int(len(UA)/2):\n",
    " #               return UA_pairs\n",
    "        elif atoms_in_combo == max_atoms_in_combo:\n",
    "            UA_pairs.append(combo)\n",
    "\n",
    "    return UA_pairs\n",
    "\n",
    "def AC2BO(AC,atomicNumList,charge,charged_fragments,quick):\n",
    "    # TODO\n",
    "    atomic_valence = defaultdict(list)\n",
    "    atomic_valence[1] = [1]\n",
    "    atomic_valence[6] = [4]\n",
    "    atomic_valence[7] = [4,3]\n",
    "    atomic_valence[8] = [2,1]\n",
    "    atomic_valence[9] = [1]\n",
    "    atomic_valence[14] = [4]\n",
    "    atomic_valence[15] = [5,4,3]\n",
    "    atomic_valence[16] = [6,4,2]\n",
    "    atomic_valence[17] = [1]\n",
    "    atomic_valence[32] = [4]\n",
    "    atomic_valence[35] = [1]\n",
    "    atomic_valence[53] = [1]\n",
    "\n",
    "\n",
    "    atomic_valence_electrons = {}\n",
    "    atomic_valence_electrons[1] = 1\n",
    "    atomic_valence_electrons[6] = 4\n",
    "    atomic_valence_electrons[7] = 5\n",
    "    atomic_valence_electrons[8] = 6\n",
    "    atomic_valence_electrons[9] = 7\n",
    "    atomic_valence_electrons[14] = 4\n",
    "    atomic_valence_electrons[15] = 5\n",
    "    atomic_valence_electrons[16] = 6\n",
    "    atomic_valence_electrons[17] = 7\n",
    "    atomic_valence_electrons[32] = 4\n",
    "    atomic_valence_electrons[35] = 7\n",
    "    atomic_valence_electrons[53] = 7\n",
    "\n",
    "    # make a list of valences, e.g. for CO: [[4],[2,1]]\n",
    "    valences_list_of_lists = []\n",
    "    for atomicNum in atomicNumList:\n",
    "        valences_list_of_lists.append(atomic_valence[atomicNum])\n",
    "\n",
    "    # convert [[4],[2,1]] to [[4,2],[4,1]]\n",
    "    valences_list = list(itertools.product(*valences_list_of_lists))\n",
    "\n",
    "    best_BO = AC.copy()\n",
    "\n",
    "    # implemenation of algorithm shown in Figure 2\n",
    "    # UA: unsaturated atoms\n",
    "    # DU: degree of unsaturation (u matrix in Figure)\n",
    "    # best_BO: Bcurr in Figure \n",
    "    #\n",
    "\n",
    "    for valences in valences_list:\n",
    "        AC_valence = list(AC.sum(axis=1))\n",
    "        UA,DU_from_AC = getUA(valences, AC_valence)\n",
    "\n",
    "        if len(UA) == 0 and BO_is_OK(AC,AC,charge,DU_from_AC,atomic_valence_electrons,atomicNumList,charged_fragments):\n",
    "            return AC,atomic_valence_electrons\n",
    "        \n",
    "        UA_pairs_list = get_UA_pairs(UA,AC,quick) \n",
    "        for UA_pairs in UA_pairs_list:\n",
    "            BO = get_BO(AC,UA,DU_from_AC,valences,UA_pairs,quick)\n",
    "            if BO_is_OK(BO,AC,charge,DU_from_AC,atomic_valence_electrons,atomicNumList,charged_fragments):\n",
    "                return BO,atomic_valence_electrons\n",
    "\n",
    "            elif BO.sum() >= best_BO.sum() and valences_not_too_large(BO,valences):\n",
    "                best_BO = BO.copy()\n",
    "\n",
    "    return best_BO,atomic_valence_electrons\n",
    "\n",
    "\n",
    "def AC2mol(mol,AC,atomicNumList,charge,charged_fragments,quick):\n",
    "    # convert AC matrix to bond order (BO) matrix\n",
    "    BO,atomic_valence_electrons = AC2BO(AC,atomicNumList,charge,charged_fragments,quick)\n",
    "\n",
    "    # add BO connectivity and charge info to mol object\n",
    "    mol = BO2mol(mol,BO, atomicNumList,atomic_valence_electrons,charge,charged_fragments)\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "def get_proto_mol(atomicNumList):\n",
    "    mol = Chem.MolFromSmarts(\"[#\"+str(atomicNumList[0])+\"]\")\n",
    "    rwMol = Chem.RWMol(mol)\n",
    "    for i in range(1,len(atomicNumList)):\n",
    "        a = Chem.Atom(atomicNumList[i])\n",
    "        rwMol.AddAtom(a)\n",
    "    \n",
    "    mol = rwMol.GetMol()\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "def get_atomicNumList(atomic_symbols):\n",
    "    atomicNumList = []\n",
    "    for symbol in atomic_symbols:\n",
    "        atomicNumList.append(get_atom(symbol))\n",
    "    return atomicNumList\n",
    "\n",
    "\n",
    "def read_xyz_file(filename):\n",
    "\n",
    "    atomic_symbols = []\n",
    "    xyz_coordinates = []\n",
    "\n",
    "    with open(filename, \"r\") as file:\n",
    "        for line_number,line in enumerate(file):\n",
    "            if line_number == 0:\n",
    "                num_atoms = int(line)\n",
    "            elif line_number == 1:\n",
    "                if \"charge=\" in line:\n",
    "                    charge = int(line.split(\"=\")[1])\n",
    "                else:\n",
    "                    charge = 0\n",
    "            else:\n",
    "                atomic_symbol, x, y, z = line.split()\n",
    "                atomic_symbols.append(atomic_symbol)\n",
    "                xyz_coordinates.append([float(x),float(y),float(z)])\n",
    "\n",
    "    atomicNumList = get_atomicNumList(atomic_symbols)\n",
    "    \n",
    "    return atomicNumList,charge,xyz_coordinates\n",
    "\n",
    "def xyz2AC(atomicNumList,xyz):\n",
    "    import numpy as np\n",
    "    mol = get_proto_mol(atomicNumList)\n",
    "\n",
    "    conf = Chem.Conformer(mol.GetNumAtoms())\n",
    "    for i in range(mol.GetNumAtoms()):\n",
    "        conf.SetAtomPosition(i,(xyz[i][0],xyz[i][1],xyz[i][2]))\n",
    "    mol.AddConformer(conf)\n",
    "\n",
    "    dMat = Chem.Get3DDistanceMatrix(mol)\n",
    "    pt = Chem.GetPeriodicTable()\n",
    "\n",
    "    num_atoms = len(atomicNumList)\n",
    "    AC = np.zeros((num_atoms,num_atoms)).astype(int)\n",
    "\n",
    "    for i in range(num_atoms):\n",
    "        a_i = mol.GetAtomWithIdx(i)\n",
    "        Rcov_i = pt.GetRcovalent(a_i.GetAtomicNum())*1.30\n",
    "        for j in range(i+1,num_atoms):\n",
    "            a_j = mol.GetAtomWithIdx(j)\n",
    "            Rcov_j = pt.GetRcovalent(a_j.GetAtomicNum())*1.30\n",
    "            if dMat[i,j] <= Rcov_i + Rcov_j:\n",
    "                AC[i,j] = 1\n",
    "                AC[j,i] = 1\n",
    "\n",
    "    return AC,mol,dMat\n",
    "\n",
    "def chiral_stereo_check(mol):\n",
    "    Chem.SanitizeMol(mol)\n",
    "    Chem.DetectBondStereochemistry(mol,-1)\n",
    "    Chem.AssignStereochemistry(mol, flagPossibleStereoCenters=True, force=True)\n",
    "    Chem.AssignAtomChiralTagsFromStructure(mol,-1)\n",
    "\n",
    "    return mol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def xyz2mol(atomicNumList, charge, xyz_coordinates, charged_fragments, quick):\n",
    "\n",
    "    # Get atom connectivity (AC) matrix, list of atomic numbers, molecular charge, \n",
    "    # and mol object with no connectivity information\n",
    "    AC,mol,dMat = xyz2AC(atomicNumList, xyz_coordinates)\n",
    "\n",
    "    # Convert AC to bond order matrix and add connectivity and charge info to mol object\n",
    "    new_mol = AC2mol(mol, AC, atomicNumList, charge, charged_fragments, quick)\n",
    "\n",
    "    # Check for stereocenters and chiral centers\n",
    "    new_mol = chiral_stereo_check(new_mol)\n",
    "\n",
    "    return new_mol,dMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def mol_from_xyz(filepath, add_hs=True):\n",
    "    charged_fragments = True  # alternatively radicals are made\n",
    "\n",
    "    # quick is faster for large systems but requires networkx\n",
    "    # if you don't want to install networkx set quick=False and\n",
    "    # uncomment 'import networkx as nx' at the top of the file\n",
    "    quick = True\n",
    "\n",
    "    atomicNumList, charge, xyz_coordinates = read_xyz_file(filepath)\n",
    "    mol, dMat = xyz2mol(atomicNumList, charge, xyz_coordinates, charged_fragments, quick)\n",
    "    \n",
    "    # Compute distance from centroid\n",
    "    xyz_coord_array = np.array(xyz_coordinates)\n",
    "    centroid = xyz_coord_array.mean(axis=0)\n",
    "    dFromCentroid = norm(xyz_coord_array - centroid, axis=1)\n",
    "\n",
    "    # Canonical hack\n",
    "#     smiles = Chem.MolToSmiles(mol, isomericSmiles=True)\n",
    "#     mol = Chem.MolFromSmiles(smiles)\n",
    "#     if add_hs: mol = Chem.AddHs(mol)\n",
    "    return mol, dMat, dFromCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total xyz filepath #  130775\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "xyz_filepath_list = list(glob(DATA_PATH+'structures/*.xyz'))\n",
    "xyz_filepath_list.sort()\n",
    "n_mols = len(xyz_filepath_list)\n",
    "print('total xyz filepath # ', n_mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902cbd0493b14ca1869e0fa30ccb0045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=130775), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsgdb9nsd_017732 Sanitization error: Explicit valence for atom # 4 C greater than permitted\n",
      "dsgdb9nsd_037494 Sanitization error: Explicit valence for atom # 4 C greater than permitted\n",
      "dsgdb9nsd_037900 Sanitization error: Explicit valence for atom # 5 C greater than permitted\n",
      "dsgdb9nsd_042676 Sanitization error: Explicit valence for atom # 3 C greater than permitted\n",
      "dsgdb9nsd_042681 Sanitization error: Explicit valence for atom # 3 C greater than permitted\n",
      "dsgdb9nsd_044308 Sanitization error: Explicit valence for atom # 5 C greater than permitted\n",
      "dsgdb9nsd_044322 Sanitization error: Explicit valence for atom # 5 C greater than permitted\n",
      "dsgdb9nsd_048903 Sanitization error: Explicit valence for atom # 2 C greater than permitted\n",
      "dsgdb9nsd_066495 Sanitization error: Explicit valence for atom # 7 C greater than permitted\n",
      "dsgdb9nsd_067109 Sanitization error: Explicit valence for atom # 2 C greater than permitted\n",
      "dsgdb9nsd_073323 Sanitization error: Explicit valence for atom # 4 C greater than permitted\n",
      "dsgdb9nsd_090191 Sanitization error: Explicit valence for atom # 3 C greater than permitted\n",
      "dsgdb9nsd_090838 Sanitization error: Explicit valence for atom # 5 C greater than permitted\n",
      "dsgdb9nsd_107870 Sanitization error: Explicit valence for atom # 2 C greater than permitted\n",
      "dsgdb9nsd_133831 Sanitization error: Explicit valence for atom # 2 C greater than permitted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dist_matrices = {}\n",
    "mols = {}\n",
    "dist_from_centroids = {}\n",
    "for i in tqdm_notebook(range(n_mols)):\n",
    "    filepath = xyz_filepath_list[i]\n",
    "    mol_name = filepath.split('/')[-1][:-4]\n",
    "    try: \n",
    "        mol, dist_matrix, dist_from_centroid = mol_from_xyz(filepath)\n",
    "        mols[mol_name] = mol\n",
    "        dist_matrices[mol_name] = dist_matrix\n",
    "        dist_from_centroids[mol_name] = dist_from_centroid\n",
    "    except ValueError as e: \n",
    "        print(mol_name, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EDGE_FEATURES        = 16\n",
    "N_ATOM_FEATURES        = 27\n",
    "N_MASTER_EDGE_FEATURES = 9\n",
    "N_MASTER_FEATURES      = 9\n",
    "MAX_N_ATOMS            = 29\n",
    "MAX_N_BONDS            = 58\n",
    "TYPES                  = train_df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def get_edge_features(mol, eucl_dist):\n",
    "#     \"\"\"\n",
    "#     Compute the following features for each entry in the adjacency matrix pf 'mol':\n",
    "#         - bond type one-hot: categorical {1: single, 2: double, 3: triple, 4: aromatic}\n",
    "#         - is conjugated: bool {0, 1}\n",
    "#         - is in ring: bool {0, 1}\n",
    "#         - graph distance: int\n",
    "#         - euclidean distance: float\n",
    "#     \"\"\"\n",
    "#     n_atoms = mol.GetNumAtoms()\n",
    "#     features = np.zeros((n_atoms, n_atoms, N_EDGE_FEATURES-8))\n",
    "\n",
    "#     # compute distance features\n",
    "#     graph_dist = Chem.AllChem.GetDistanceMatrix(mol)\n",
    "\n",
    "#     features[:,:,-1] = eucl_dist\n",
    "#     features[:,:,-2] = graph_dist\n",
    "#     for e in mol.GetBonds():\n",
    "#         i = e.GetBeginAtomIdx()\n",
    "#         j = e.GetEndAtomIdx()\n",
    "#         dc_e_feats = dc.feat.graph_features.bond_features(e).astype(int)\n",
    "#         features[i,j,:6], features[j,i,:6] = dc_e_feats, dc_e_feats\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_edge_features(mol, eucl_dist, row):\n",
    "    \"\"\"\n",
    "    Compute the following features for each entry in the adjacency matrix pf 'mol':\n",
    "        - bond type one-hot: categorical {1: single, 2: double, 3: triple, 4: aromatic}\n",
    "        - is conjugated: bool {0, 1}\n",
    "        - is in ring: bool {0, 1}\n",
    "        - graph distance: int\n",
    "        - euclidean distance: float\n",
    "        - type of scalar couplig type: categorical {1:8}\n",
    "    \"\"\"\n",
    "    n_atoms, n_bonds = mol.GetNumAtoms(), mol.GetNumBonds()\n",
    "    n_edge_features = (n_bonds + 1) * 2\n",
    "    features = np.zeros((n_edge_features, N_EDGE_FEATURES))\n",
    "    pairs_idx = np.zeros((n_edge_features, 2)) - 1\n",
    "    \n",
    "    graph_dist = Chem.AllChem.GetDistanceMatrix(mol)\n",
    "    scalar_coupling_has_bond = False\n",
    "    for n, e in enumerate(mol.GetBonds()):\n",
    "        ix1 = 2 * n\n",
    "        ix2 = (2 * n) + 1\n",
    "        i = e.GetBeginAtomIdx()\n",
    "        j = e.GetEndAtomIdx()\n",
    "        dc_e_feats = dc.feat.graph_features.bond_features(e).astype(int)\n",
    "        for ix in [ix1, ix2]:\n",
    "            features[ix, :6] = dc_e_feats\n",
    "            features[ix, 6] = graph_dist[i, j]\n",
    "            features[ix, 7] = eucl_dist[i, j]\n",
    "            if (row['atom_index_0'], row['atom_index_1']) in [(i, j), (j, i)]:\n",
    "                features[ix, 8:] = (TYPES == row['type']).astype(float)\n",
    "                scalar_coupling_has_bond = True\n",
    "        pairs_idx[ix1] = i, j\n",
    "        pairs_idx[ix2] = j, i\n",
    "    if not scalar_coupling_has_bond:\n",
    "        for ix in [-2, -1]:\n",
    "            features[ix, 6] = graph_dist[row['atom_index_0'], row['atom_index_1']]\n",
    "            features[ix, 7] = eucl_dist[row['atom_index_0'], row['atom_index_1']]\n",
    "            features[ix, 8:] = (TYPES == row['type']).astype(float)\n",
    "        pairs_idx[-2] = row['atom_index_0'], row['atom_index_1']\n",
    "        pairs_idx[-1] = row['atom_index_1'], row['atom_index_0']\n",
    "    return features[pairs_idx[:,0].argsort()], pairs_idx[pairs_idx[:,0].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [],
   "source": [
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(f\"input {x} not in allowable set{allowable_set}:\")\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def get_atom_features(mol):\n",
    "    \"\"\"\n",
    "    Compute the following features for each atom in 'mol':\n",
    "        - atom type: H, C, N, O, F (one-hot)\n",
    "        - degree: 0, 1, 2, 3, 4 (one-hot)\n",
    "        - implicit valence: 0, 1, 2, 3, 4, 5 (one-hot)\n",
    "        - Hybridization: SP, SP2, SP3, SP3D, SP3D2 (one-hot)\n",
    "        - is aromatic: bool {0, 1}\n",
    "        - formal charge: int\n",
    "        - num radical electrons: int\n",
    "        - atomic number: int\n",
    "    \"\"\"\n",
    "    n_atoms = mol.GetNumAtoms()\n",
    "    features = np.zeros((n_atoms, N_ATOM_FEATURES-1))\n",
    "    for a in mol.GetAtoms():\n",
    "        a_feats = one_of_k_encoding(a.GetSymbol(), ['H', 'C', 'N', 'O', 'F']) \\\n",
    "            + one_of_k_encoding(a.GetDegree(), [0, 1, 2, 3, 4]) \\\n",
    "            + one_of_k_encoding(a.GetImplicitValence(), [0, 1, 2, 3, 4]) \\\n",
    "            + one_of_k_encoding_unk(a.GetHybridization(), [\n",
    "                Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
    "                Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.SP3D, \n",
    "                Chem.rdchem.HybridizationType.SP3D2, Chem.rdchem.HybridizationType.UNSPECIFIED]) \\\n",
    "            + [a.GetIsAromatic(), a.GetFormalCharge(), a.GetNumRadicalElectrons(), a.GetAtomicNum(),\n",
    "               a.IsInRing()]\n",
    "        features[a.GetIdx(),:] = np.array(a_feats).astype(int)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# n_obs = 50000 # len(mols)\n",
    "# atomic_features = np.zeros((n_obs, MAX_N_ATOMS, N_ATOM_FEATURES))\n",
    "# edge_features = np.zeros((n_obs, MAX_N_ATOMS, MAX_N_ATOMS, N_EDGE_FEATURES))\n",
    "# mask = np.zeros((n_mols, MAX_N_ATOMS))\n",
    "# target = np.zeros(n_obs)\n",
    "# keep = []\n",
    "# mol_name = ''\n",
    "# succesful_mols = list(mols.keys())\n",
    "# types = train_df['type'].unique()\n",
    "# for i in tqdm_notebook(range(n_obs)):\n",
    "#     row = train_df.iloc[i,:]\n",
    "#     new_mol_name = row['molecule_name']\n",
    "#     if mol_name!=new_mol_name:\n",
    "#         if new_mol_name in succesful_mols:\n",
    "#             mol_name = new_mol_name\n",
    "#             mol, dist_matrix = mols[mol_name], dist_matrices[mol_name]\n",
    "#             n_atoms = mol.GetNumAtoms()\n",
    "#         else:\n",
    "#             continue\n",
    "#     atomic_features[i, :n_atoms, :-1] = get_atom_features(mol)\n",
    "#     atomic_features[i, row['atom_index_0'], -1] = 1.\n",
    "#     atomic_features[i, row['atom_index_1'], -1] = 1.\n",
    "#     edge_features[i, :n_atoms, :n_atoms, :-8] = get_edge_features(mol, dist_matrix)\n",
    "#     edge_features[i, row['atom_index_0'], row['atom_index_1'], -8:] = (types == row['type']).astype(float)\n",
    "#     mask[i,:n_atoms] = 1.\n",
    "#     target[i] = row['scalar_coupling_constant']\n",
    "#     keep.append(i)\n",
    "# keep = np.array(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# n_obs = 50000 # len(mols)\n",
    "# atomic_features = np.zeros((n_obs, MAX_N_ATOMS, N_ATOM_FEATURES))\n",
    "# edge_features = np.zeros((n_obs, MAX_N_BONDS, N_EDGE_FEATURES))\n",
    "# pairs_idx = np.zeros((n_obs, MAX_N_BONDS, 2)) - 1\n",
    "# mask = np.zeros((n_obs, MAX_N_ATOMS))\n",
    "# edge_mask = np.zeros((n_obs, MAX_N_BONDS))\n",
    "# target = np.zeros(n_obs)\n",
    "# keep = []\n",
    "# mol_name = ''\n",
    "# succesful_mols = list(mols.keys())\n",
    "# for i in tqdm_notebook(range(n_obs)):\n",
    "#     row = train_df.iloc[i,:]\n",
    "#     new_mol_name = row['molecule_name']\n",
    "#     if mol_name!=new_mol_name:\n",
    "#         if new_mol_name in succesful_mols:\n",
    "#             mol_name = new_mol_name\n",
    "#             mol, dist_matrix = mols[mol_name], dist_matrices[mol_name]\n",
    "#             n_atoms = mol.GetNumAtoms()\n",
    "#             n_bonds = mol.GetNumBonds()\n",
    "#             n_edge_features = (n_bonds + 1) * 2\n",
    "#         else:\n",
    "#             continue\n",
    "#     atomic_features[i, :n_atoms, :-1] = get_atom_features(mol)\n",
    "#     atomic_features[i, row['atom_index_0'], -1] = 1.\n",
    "#     atomic_features[i, row['atom_index_1'], -1] = 1.\n",
    "#     edge_features[i, :n_edge_features, :], pairs_idx[i, :n_edge_features, :] = \\\n",
    "#         get_edge_features(mol, dist_matrix, row)\n",
    "#     mask[i, :n_atoms], edge_mask[i, pairs_idx[i,:,0] != -1] = 1., 1.\n",
    "#     target[i] = row['scalar_coupling_constant']\n",
    "#     keep.append(i)\n",
    "# keep = np.array(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e98aef7f5944f6a4e7fe713bd07d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_obs = 50000 # len(mols)\n",
    "atomic_features = np.zeros((n_obs, MAX_N_ATOMS, N_ATOM_FEATURES))\n",
    "master_features = np.zeros((n_obs, N_MASTER_FEATURES))\n",
    "edge_features = np.zeros((n_obs, MAX_N_BONDS, N_EDGE_FEATURES))\n",
    "master_edge_features = np.zeros((n_obs, MAX_N_ATOMS, N_MASTER_EDGE_FEATURES))\n",
    "pairs_idx = np.zeros((n_obs, MAX_N_BONDS, 2)) - 1\n",
    "mask = np.zeros((n_obs, MAX_N_ATOMS))\n",
    "edge_mask = np.zeros((n_obs, MAX_N_BONDS))\n",
    "target = np.zeros(n_obs)\n",
    "keep = []\n",
    "mol_name = ''\n",
    "succesful_mols = list(mols.keys())\n",
    "for i in tqdm_notebook(range(n_obs)):\n",
    "    row = train_df.iloc[i,:]\n",
    "    new_mol_name = row['molecule_name']\n",
    "    if mol_name!=new_mol_name:\n",
    "        if new_mol_name in succesful_mols:\n",
    "            mol_name = new_mol_name\n",
    "            mol, dist_matrix = mols[mol_name], dist_matrices[mol_name]\n",
    "            dist_from_centroid = dist_from_centroids[mol_name]\n",
    "            n_atoms = mol.GetNumAtoms()\n",
    "            n_bonds = mol.GetNumBonds()\n",
    "            n_edge_features = (n_bonds + 1) * 2\n",
    "        else:\n",
    "            continue\n",
    "    atomic_features[i, :n_atoms, :-1] = get_atom_features(mol)\n",
    "    atomic_features[i, row['atom_index_0'], -1] = 1.\n",
    "    atomic_features[i, row['atom_index_1'], -1] = 1.\n",
    "    master_features[i, :6] = row[['num_atoms', 'num_C_atoms', 'num_H_atoms', \n",
    "                                  'num_N_atoms', 'num_O_atoms', 'num_F_atoms']]\n",
    "    master_features[i, 6:] = mol.GetNumHeavyAtoms(), n_bonds, mol.GetRingInfo().NumRings()\n",
    "    edge_features[i, :n_edge_features, :], pairs_idx[i, :n_edge_features, :] = \\\n",
    "        get_edge_features(mol, dist_matrix, row)\n",
    "    master_edge_features[i, :n_atoms, 0] = dist_from_centroid\n",
    "    master_edge_features[i, row['atom_index_0'], 1:] = (TYPES == row['type']).astype(float)\n",
    "    master_edge_features[i, row['atom_index_1'], 1:] = (TYPES == row['type']).astype(float)\n",
    "    mask[i, :n_atoms], edge_mask[i, pairs_idx[i,:,0] != -1] = 1., 1.\n",
    "    target[i] = row['scalar_coupling_constant']\n",
    "    keep.append(i)\n",
    "keep = np.array(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_features      = atomic_features[keep]\n",
    "master_features      = master_features[keep]\n",
    "edge_features        = edge_features[keep]\n",
    "master_edge_features = master_edge_features[keep]\n",
    "pairs_idx            = pairs_idx[keep]\n",
    "mask                 = mask[keep]\n",
    "edge_mask            = edge_mask[keep]\n",
    "target               = target[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.505295, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       [1.006628, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       [1.302268, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       [1.808148, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       ...,\n",
       "       [2.682558, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       [2.001112, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       [2.187803, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_features,master_edge_features\n",
    "master_edge_features[i,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atomic_features.shape\t\t: (50000, 29, 27)\n",
      "edge_features.shape\t\t: (50000, 58, 16)\n",
      "master_features.shape\t\t: (50000, 9)\n",
      "master_edge_features.shape\t: (50000, 29, 9)\n"
     ]
    }
   ],
   "source": [
    "print(f'atomic_features.shape\\t\\t: {atomic_features.shape}\\nedge_features.shape\\t\\t: {edge_features.shape}'\n",
    "      f'\\nmaster_features.shape\\t\\t: {master_features.shape}\\nmaster_edge_features.shape\\t: {master_edge_features.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MPNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "enn_args = dict(layers=[50, 50, 50, 50], act=nn.ReLU(True), dropout=[0.0, 0.0, 0.0, 0.0], batch_norm=False)\n",
    "master_enn_args = dict(layers=[50, 50, 50, 50], act=nn.ReLU(True), dropout=[0.0, 0.0, 0.0, 0.0], batch_norm=False)\n",
    "R_net_args = dict(layers=[200, 100], act=nn.ReLU(True), dropout=[0.0, 0.0], batch_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "def hidden_layer(n_in, n_out, batch_norm, dropout, act=None):\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(n_in, n_out))\n",
    "    if act: layers.append(act)\n",
    "    if batch_norm: layers.append(nn.BatchNorm1d(n_out))\n",
    "    if dropout != 0: layers.append(nn.Dropout(dropout))\n",
    "    return layers\n",
    "\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input, n_output, layers=[], act=nn.ReLU(True), dropout=[], batch_norm=False):\n",
    "        super().__init__()\n",
    "        sizes = [n_input] + layers + [n_output]\n",
    "        layers_ = []\n",
    "        for i, (n_in, n_out, dr) in enumerate(zip(sizes[:-1], sizes[1:], dropout+[0.0])):\n",
    "            act_ = act if i < len(layers) else None\n",
    "            batch_norm_ = batch_norm if i < len(layers) else False\n",
    "            layers_ += hidden_layer(n_in, n_out, batch_norm_, dr, act_)      \n",
    "        self.layers = nn.Sequential(*layers_)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class HiddenLSTMCell(nn.Module):\n",
    "    \"\"\"Implements the LSTM cell update described in the sec 4.2 of https://arxiv.org/pdf/1511.06391.pdf.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_h_out):\n",
    "        \"\"\"This LSTM cell takes no external 'x' inputs, but has a hidden state appended with the \n",
    "        readout from a content based attention mechanism. Therefore the hidden state is of a dimension\n",
    "        that is two times the number of nodes in the set.\"\"\"\n",
    "        super().__init__()\n",
    "        self.n_h_out, self.n_h = n_h_out, n_h_out * 2 \n",
    "        self.w_h = nn.Parameter(torch.Tensor(self.n_h, n_h_out * 4))\n",
    "        self.b = nn.Parameter(torch.Tensor(n_h_out * 4))\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2: \n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            else: \n",
    "                nn.init.zeros_(p.data)\n",
    "                # initialize the forget gate bias to 1\n",
    "                p.data[self.n_h_out:self.n_h_out*2] = torch.ones(self.n_h_out)\n",
    "        \n",
    "    def forward(self, h_prev, c_prev):\n",
    "        \"\"\"Takes previuos hidden and cell states as arguments and performs a single LSTM step using \n",
    "        no external input.\n",
    "        \"\"\"\n",
    "        n_h_ = self.n_h_out # number of output hidden states\n",
    "        # batch the computations into a single matrix multiplication\n",
    "        gates = h_prev @ self.w_h + self.b\n",
    "        i_g, f_g, g, o_g = (\n",
    "            torch.sigmoid(gates[:, :n_h_]), # input\n",
    "            torch.sigmoid(gates[:, n_h_:n_h_*2]), # forget\n",
    "            torch.tanh(gates[:, n_h_*2:n_h_*3]),\n",
    "            torch.sigmoid(gates[:, n_h_*3:]), # output\n",
    "        )\n",
    "        c = f_g * c_prev + i_g * g\n",
    "        h = o_g * torch.tanh(c)\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Set2Set(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted from: https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric\\\n",
    "        /nn/glob/set2set.html#Set2Set\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, proc_steps):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = 2 * in_channels\n",
    "        self.proc_steps = proc_steps\n",
    "        self.lstm = HiddenLSTMCell(self.in_channels)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        x - input tensor of shape (batch_size, n_nodes, in_channels)\n",
    "        mask - integer tensor used to zero out nodes missing in a particualr graph \n",
    "            (not all graphs have 'n_nodes'). Is of shape (batch_size, n_nodes)\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = mask.size(0), mask.size(1)\n",
    "        batch_idx = torch.arange(0, batch_size).expand(n_nodes, batch_size).transpose(0, 1)\n",
    "        h = torch.zeros(batch_size, self.in_channels, device=x.device)\n",
    "        q_star = torch.zeros(batch_size, self.out_channels, device=x.device\n",
    "                            )\n",
    "        mask = (mask.float() - 1) * 1e6\n",
    "        for i in range(self.proc_steps):\n",
    "            q, h = self.lstm(q_star, h)\n",
    "            e = (x * q[batch_idx]).sum(dim=-1)\n",
    "            # set masked nodes not to large negative energy (attention mask will convert this to 0)\n",
    "            e += mask \n",
    "            a = F.softmax(e, dim=-1)\n",
    "            # sum a*x over node dimension \n",
    "            r = torch.sum(a.unsqueeze(-1) * x, dim=1)\n",
    "            q_star = torch.cat([q, r], dim=-1)\n",
    "            \n",
    "        return q_star\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels, self.out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def segment_sum(data, segment_ids):\n",
    "    \"\"\"\n",
    "    Computes the sum along segments of a tensor. Analogous to tf.unsorted_segment_sum.\n",
    "\n",
    "    :param data: A tensor whose segments are to be summed.\n",
    "    :param segment_ids: The segment indices tensor.\n",
    "    :return: A tensor of same data type as the data argument.\n",
    "    \"\"\"\n",
    "    assert all([i in data.shape for i in segment_ids.shape]), \"segment_ids.shape should be a prefix of data.shape\"\n",
    "        \n",
    "    # segment_ids is a 1-D tensor repeat it to have the same shape as data\n",
    "    if len(segment_ids.shape) == 1:\n",
    "        s = torch.prod(torch.tensor(data.shape[1:], device=data.device)).long()\n",
    "        segment_ids = segment_ids.repeat_interleave(s).view(segment_ids.shape[0], *data.shape[1:])\n",
    "\n",
    "    assert data.shape == segment_ids.shape, \"data.shape and segment_ids.shape should be equal\"\n",
    "\n",
    "    num_segments = len(torch.unique(segment_ids))\n",
    "    shape = [num_segments] + list(data.shape[1:])\n",
    "    tensor = torch.zeros(*shape, device=data.device).scatter_add(0, segment_ids, data.float())\n",
    "    tensor = tensor.type(data.dtype)\n",
    "    return tensor\n",
    "\n",
    "class EdgeNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_h, n_e, fully_connected_graph=False, use_master_node=False, \n",
    "                 n_h_m=0, n_e_m=0, net_args={}, master_net_args={}):\n",
    "        super().__init__()\n",
    "        self.n_e, self.n_h, self.n_e_m, self.n_h_m = n_e, n_h, n_e_m, n_h_m\n",
    "        self.fully_connected_graph = fully_connected_graph\n",
    "        self.use_master_node = use_master_node\n",
    "        self.adj_net = FullyConnectedNet(n_e, n_h ** 2, **net_args)\n",
    "        self.b = nn.Parameter(torch.Tensor(n_h)) # bias for the message function\n",
    "        nn.init.zeros_(self.b)\n",
    "        if use_master_node:\n",
    "            self.master_adj_net_in = FullyConnectedNet(n_e_m, n_h * n_h_m, **master_net_args)\n",
    "            self.master_adj_net_out = FullyConnectedNet(n_e_m, n_h_m * n_h, **master_net_args)\n",
    "            self.b_m = nn.Parameter(torch.Tensor(n_h_m)) # bias for the master message function\n",
    "            nn.init.zeros_(self.b_m)\n",
    "    \n",
    "    def forward(self, h, e, mask=None, pairs_idx=None, edge_mask=None, h_m=None, e_m=None):\n",
    "        \"\"\"\n",
    "        Compute message vector m_t given the previuos hidden state\n",
    "        h_t-1 and edge features e. e_out represents the same edge \n",
    "        features as e_in with adj matrix transposed.\n",
    "        - h is a collection of hidden states of shape (batch_size, n_nodes, n_h)\n",
    "        - e is a collection of edge features of shape \n",
    "            (batch_size, n_nodes, n_nodes, n_e) if fully_connected_graph\n",
    "            else shape is (batch_size, n_edges, n_e).\n",
    "        - mask is a tensor used to  zero out nodes missing in a particualr \n",
    "            graph (not all graphs have 'n_nodes'). Is of shape \n",
    "            (batch_size, n_nodes)\n",
    "        - pairs_idx: if self.fully_connected_graph = False this is a tensor\n",
    "            of shape (batch_size, n_edges, 2) mapping atom indexes \n",
    "            (first column) to the other atom indexes they form a bond with\n",
    "            (second column. \n",
    "        - edge_mask: if self.fully_connected_graph = False this is a tensor\n",
    "            of shape (batch_size, n_edges) masking non present edges.\n",
    "        - h_m: if not None, tensor of shape (batch_size, n_h_m) containing \n",
    "            hidden states for master node.\n",
    "        - e_m: if not None, tensor of shape (batch_size, n_nodes, n_e_m) containing \n",
    "            edge features for edges connected to the master node.\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = h.size(0), h.size(1)\n",
    "        \n",
    "        # compute a\n",
    "        a_vect = self.adj_net(e.view(-1, self.n_e)) # dim(a_vect) = (batch_size * n_edges, n_h^2)\n",
    "        if self.fully_connected_graph:\n",
    "            a_tmp = a_vect.view(-1, n_nodes, n_nodes, self.n_h, self.n_h).transpose(2, 3)\n",
    "            a = a_tmp.contiguous().view(-1, n_nodes * self.n_h, n_nodes * self.n_h)\n",
    "            h_flat = h.view(batch_size, n_nodes * self.n_h, 1)\n",
    "            m = torch.matmul(a, h_flat).view(batch_size * n_nodes, self.n_h)\n",
    "        else:\n",
    "            n_edges = e.size(1)\n",
    "            edge_mask_ = edge_mask.type(torch.uint8)==True\n",
    "            edge_mask_flat = edge_mask.view(-1).type(torch.uint8)==True\n",
    "            \n",
    "            a_mat = a_vect[edge_mask_flat].view(-1, self.n_h, self.n_h)\n",
    "            h_stacked = torch.cat([h[b,ix,:] for b, ix in enumerate(torch.unbind(pairs_idx[:,:,1]))])\n",
    "            h_stacked = h_stacked[edge_mask_flat]\n",
    "            ah = torch.einsum('bij,bjk->bik', h_stacked.unsqueeze(1), a_mat).squeeze(1)\n",
    "            \n",
    "            n_nodes_per_graph = pairs_idx[:,:,0].max(dim=1).values + 1\n",
    "            unique_idx = pairs_idx[:,:,0] + (torch.cat([\n",
    "                                                 torch.zeros(1, dtype=torch.long, device=h.device), \n",
    "                                                 n_nodes_per_graph[:-1].cumsum(dim=0)\n",
    "                                             ])).unsqueeze(-1).expand(-1, n_edges)\n",
    "            m_stacked = segment_sum(ah, unique_idx[edge_mask_])\n",
    "            \n",
    "            m_per_graph_lst = torch.split(m_stacked, n_nodes_per_graph.tolist())\n",
    "            m = torch.cat([F.pad(m_, pad=(0, 0, 0, n_nodes - n_nodes_)) \n",
    "                           for m_, n_nodes_ in zip(m_per_graph_lst, n_nodes_per_graph)]) \n",
    "            \n",
    "            if self.use_master_node:\n",
    "                a_mo_vect = self.master_adj_net_out(e_m.view(-1, self.n_e_m)) # dim(a_mo_vect) = (batch_size * n_nodes, n_h_m * n_h)\n",
    "                a_mo_mat = a_mo_vect.view(-1, self.n_h_m, self.n_h)\n",
    "                h_m_expanded = h_m.repeat_interleave(n_nodes, 0).unsqueeze(1)\n",
    "                ah_mo = torch.einsum('bij,bjk->bik', h_m_expanded, a_mo_mat).squeeze(1) # dim(ah_mo) = (batch_size * n_nodes, n_h)\n",
    "                m += ah_mo * mask.view(-1, 1)\n",
    "                \n",
    "                a_mi_vect = self.master_adj_net_in(e_m.view(-1, self.n_e_m)) # dim(a_mi_vect) = (batch_size * n_nodes, n_h * n_h_m)\n",
    "                a_mi_mat = a_mi_vect.view(-1, self.n_h, self.n_h_m)\n",
    "                ah_mi = torch.einsum('bij,bjk->bik', h.view(-1, self.n_h).unsqueeze(1), a_mi_mat).squeeze(1) # dim(ah_mi) = (batch_size, 1, n_h_m)\n",
    "                m_m = ah_mi.view(-1, n_nodes, self.n_h_m).sum(dim=1)\n",
    "            \n",
    "        m += self.b\n",
    "        \n",
    "        if self.use_master_node:\n",
    "            m_m += self.b_m\n",
    "            return m.view(batch_size, n_nodes, self.n_h), m_m\n",
    "        else:\n",
    "            return m.view(batch_size, n_nodes, self.n_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class GRUUpdate(nn.Module):\n",
    "    def __init__(self, n_h):\n",
    "        super().__init__()\n",
    "        self.n_h = n_h\n",
    "        self.gru = nn.GRUCell(n_h, n_h)\n",
    "        \n",
    "    def forward(self, m, h_prev, mask):\n",
    "        \"\"\"\n",
    "        Update hidden state h.\n",
    "        - h_prev is vector of hidden states of shape (batch_size, n_nodes, n_h)\n",
    "        - m is vector of messages of shape (batch_size, n_nodes, n_h)\n",
    "        - mask is used to  zero out nodes missing in a particualr graph (not all graphs \n",
    "            have 'n_nodes'). Is of shape (batch_size, n_nodes)\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = h_prev.size(0), h_prev.size(1)\n",
    "        h = self.gru(m.view(-1, self.n_h), h_prev.view(-1, self.n_h))\n",
    "        return h.view(batch_size, n_nodes, self.n_h) * mask.unsqueeze(-1).expand(batch_size, n_nodes, self.n_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Set2SetOutput(nn.Module):\n",
    "    def __init__(self, n_x, n_h, proc_steps, net_args, use_master_node=False, n_x_m=0, n_h_m=0):\n",
    "        super().__init__()\n",
    "        self.n_h, self.n_x = n_h, n_x\n",
    "        self.use_master_node = use_master_node\n",
    "        self.R_proj = nn.Linear(n_h + n_x, n_h)\n",
    "        if use_master_node: self.R_proj_m = nn.Linear(n_h_m + n_x_m, n_h)\n",
    "        self.R_proc = Set2Set(n_h, proc_steps)\n",
    "        self.R_write = FullyConnectedNet(2 * n_h, 1, **net_args)\n",
    "    \n",
    "    def forward(self, h, x, mask, h_m=None, x_m=None):\n",
    "        \"\"\"\n",
    "        Update hidden state h.\n",
    "        - h is vector of hidden states of shape (batch_size, n_nodes, n_h)\n",
    "        - x is vector of input features of shape (batch_size, n_nodes, n_x)\n",
    "        - mask is used to  zero out nodes missing in a particualr graph (not all graphs \n",
    "            have 'n_nodes'). Is of shape (batch_size, n_nodes)\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes = h.size(0), h.size(1)\n",
    "        m = self.R_proj(torch.cat([h.view(-1, self.n_h), x.view(-1, self.n_x)], dim=1))\n",
    "        m_reshaped = m.view(batch_size, n_nodes, self.n_h)\n",
    "        if self.use_master_node: \n",
    "            m_m = self.R_proj_m(torch.cat([h_m, x_m], dim=1))\n",
    "            m_reshaped = torch.cat([m_reshaped, m_m.unsqueeze(1)], dim=1)\n",
    "            mask_ = torch.cat([mask.clone(), torch.ones(batch_size, 1, device=x.device)], dim=1)\n",
    "        else:\n",
    "            mask_ = mask.clone()\n",
    "        q = self.R_proc(m_reshaped, mask_) \n",
    "        y = self.R_write(q) # dim(q) = (batch_size, n_h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNN(nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_e, update_steps=3, proc_steps=10, enn_args={}, R_net_args={}, \n",
    "                 fully_connected_graph=False, use_master_node=False, n_x_m=0, n_h_m=0, n_e_m=0,\n",
    "                 master_enn_args={}):\n",
    "        super().__init__()\n",
    "        self.n_h, self.n_x, self.n_h_m, self.n_x_m = n_h, n_x, n_h_m, n_x_m\n",
    "        self.use_master_node = use_master_node\n",
    "        self.M = EdgeNetwork(n_h, n_e, fully_connected_graph, use_master_node, n_h_m, n_e_m,\n",
    "                             enn_args, master_enn_args)\n",
    "        self.U = GRUUpdate(n_h)\n",
    "        if use_master_node: self.U_m = GRUUpdate(n_h_m)\n",
    "        self.R = Set2SetOutput(n_x, n_h, proc_steps, R_net_args, use_master_node, n_x_m, n_h_m)\n",
    "        self.update_steps = update_steps\n",
    "        \n",
    "    def forward(self, x, e, mask, pairs_idx=None, edge_mask=None, x_m=None, e_m=None):\n",
    "        h = F.pad(x, pad=(0, self.n_h - self.n_x))\n",
    "        h_m = F.pad(x_m, pad=(0, self.n_h_m - self.n_x_m)) if self.use_master_node else None\n",
    "        for t in range(self.update_steps):\n",
    "            if self.use_master_node: \n",
    "                m, m_m = self.M(h, e, mask, pairs_idx, edge_mask, h_m, e_m)\n",
    "                h = self.U(m, h, mask)\n",
    "                h_m = self.U_m(m_m.unsqueeze(1), h_m.unsqueeze(1), \n",
    "                               torch.ones(1, 1, device=x.device)).squeeze(1)\n",
    "            else:\n",
    "                m = self.M(h, e, mask, pairs_idx, edge_mask, h_m, e_m)\n",
    "                h = self.U(m, h, mask)\n",
    "        y = self.R(h, x, mask, h_m, x_m)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_master_node = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNN(\n",
      "  (M): EdgeNetwork(\n",
      "    (adj_net): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=50, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (5): ReLU(inplace)\n",
      "        (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): Linear(in_features=50, out_features=2500, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (U): GRUUpdate(\n",
      "    (gru): GRUCell(50, 50)\n",
      "  )\n",
      "  (R): Set2SetOutput(\n",
      "    (R_proj): Linear(in_features=77, out_features=50, bias=True)\n",
      "    (R_proc): Set2Set(50, 100)\n",
      "    (R_write): FullyConnectedNet(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=100, out_features=200, bias=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Linear(in_features=100, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "tensor([[-0.0833],\n",
      "        [-0.0843],\n",
      "        [-0.0843],\n",
      "        [-0.0843],\n",
      "        [-0.0833],\n",
      "        [-0.0843],\n",
      "        [-0.0843],\n",
      "        [-0.0833],\n",
      "        [-0.0843],\n",
      "        [-0.0833],\n",
      "        [-0.0913],\n",
      "        [-0.0924],\n",
      "        [-0.0924],\n",
      "        [-0.0913],\n",
      "        [-0.0924],\n",
      "        [-0.0913],\n",
      "        [-0.1099],\n",
      "        [-0.1142],\n",
      "        [-0.1136],\n",
      "        [-0.0865]], grad_fn=<AddmmBackward>)\n",
      "torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "batch_size, n_nodes, n_h, n_e, n_x, n_edges = 20, MAX_N_ATOMS, 50, N_EDGE_FEATURES, N_ATOM_FEATURES, MAX_N_BONDS\n",
    "n_h_m, n_e_m, n_x_m = 100, N_MASTER_EDGE_FEATURES, N_MASTER_FEATURES\n",
    "x     = torch.tensor(atomic_features[:batch_size,:,:], dtype=torch.float)\n",
    "e     = torch.tensor(edge_features[:batch_size,:,:], dtype=torch.float)\n",
    "msk   = torch.tensor(mask[:batch_size,:], dtype=torch.float)\n",
    "p_idx = torch.tensor(pairs_idx[:batch_size,:,:], dtype=torch.long)\n",
    "e_msk = torch.tensor(edge_mask[:batch_size,:], dtype=torch.float)\n",
    "x_m   = torch.tensor(master_features[:batch_size,:], dtype=torch.float)\n",
    "e_m   = torch.tensor(master_edge_features[:batch_size,:,:], dtype=torch.float)\n",
    "\n",
    "if use_master_node:\n",
    "    mpnn = MPNN(n_x, n_h, n_e, update_steps=5, proc_steps=10, enn_args=enn_args, R_net_args=R_net_args,\n",
    "                fully_connected_graph=False, use_master_node=use_master_node, n_x_m=n_x_m, n_h_m=n_h_m, \n",
    "                n_e_m=n_e_m, master_enn_args=master_enn_args)\n",
    "else:\n",
    "    mpnn = MPNN(n_x, n_h, n_e, update_steps=5, proc_steps=10, enn_args=enn_args, R_net_args=R_net_args,\n",
    "                fully_connected_graph=False, use_master_node=use_master_node)\n",
    "    \n",
    "print(mpnn)\n",
    "\n",
    "xs = (x, e, msk, p_idx, e_msk, x_m, e_m) if use_master_node else (x, e, msk, p_idx, e_msk)\n",
    "print(mpnn(*xs))\n",
    "print(mpnn(*xs).size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Fit MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = train_test_split(np.arange(n_obs), test_size=0.25, shuffle=True, random_state=100)\n",
    "x_train, x_val     = atomic_features[train_idx], atomic_features[val_idx]\n",
    "e_train, e_val     = edge_features[train_idx], edge_features[val_idx]\n",
    "x_m_train, x_m_val = master_features[train_idx], master_features[val_idx]\n",
    "e_m_train, e_m_val = master_edge_features[train_idx], master_edge_features[val_idx]\n",
    "y_train, y_val     = target[train_idx], target[val_idx]\n",
    "mask_train, mask_val = mask[train_idx], mask[val_idx]\n",
    "edge_mask_train, edge_mask_val = edge_mask[train_idx], edge_mask[val_idx]\n",
    "pairs_idx_train, pairs_idx_val = pairs_idx[train_idx], pairs_idx[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_target = StandardScaler()\n",
    "y_train = ss_target.fit_transform(y_train.reshape(-1,1))\n",
    "y_val = ss_target.transform(y_val.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MoleculeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, y, x, e, mask, pairs_idx=None, use_master_node=True, \n",
    "                 edge_mask=None, x_m=None, e_m=None):\n",
    "        self.n = len(y)\n",
    "        self.y = y.astype(np.float32)\n",
    "        self.x = x.astype(np.float32)\n",
    "        self.e = e.astype(np.float32)\n",
    "        self.mask = mask.astype(np.float32)\n",
    "        self.fully_connected_graphs = edge_mask is None\n",
    "        if not self.fully_connected_graphs:\n",
    "            self.pairs_idx = pairs_idx.astype(np.long)\n",
    "            self.edge_mask = edge_mask.astype(np.float32)\n",
    "            self.use_master_node = use_master_node\n",
    "            if self.use_master_node:\n",
    "                self.x_m = x_m.astype(np.float32)\n",
    "                self.e_m = e_m.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.fully_connected_graphs:\n",
    "            xs = (self.x[idx], self.e[idx], self.mask[idx])\n",
    "        else:\n",
    "            if self.use_master_node:\n",
    "                xs = (self.x[idx], self.e[idx], self.mask[idx], self.pairs_idx[idx], \n",
    "                      self.edge_mask[idx], self.x_m[idx], self.e_m[idx])\n",
    "            else: \n",
    "                xs = (self.x[idx], self.e[idx], self.mask[idx], self.pairs_idx[idx], \n",
    "                      self.edge_mask[idx])\n",
    "        return xs, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "use_master_node = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MoleculeDataset(y_train, x_train, e_train, mask_train, pairs_idx_train, \n",
    "                           use_master_node, edge_mask_train, x_m_train, e_m_train)\n",
    "val_ds   = MoleculeDataset(y_val, x_val, e_val, mask_val, pairs_idx_val, \n",
    "                           use_master_node, edge_mask_val, x_m_val, e_m_val)\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=8)\n",
    "val_dl   = DataLoader(val_ds, batch_size, num_workers=8)\n",
    "db = DataBunch(train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": [
     0,
     7,
     32
    ]
   },
   "outputs": [],
   "source": [
    "def group_mean_log_mae(y_true, y_pred, types):\n",
    "    y_true, y_pred, types = y_true.cpu().numpy().ravel(), y_pred.cpu().numpy().ravel(), types.cpu().numpy().ravel()\n",
    "    y_true = ss_target.mean_ + y_true * ss_target.scale_\n",
    "    y_pred = ss_target.mean_ + y_pred * ss_target.scale_\n",
    "    maes = pd.Series(y_true-y_pred).abs().groupby(types).mean()\n",
    "    return np.log(maes).mean()\n",
    "\n",
    "class GroupMeanLogMAE(Callback):\n",
    "    _order = -20 #Needs to run before the recorder\n",
    "    types_cidx = 2\n",
    "\n",
    "    def __init__(self, learn, **kwargs): self.learn = learn\n",
    "    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['GroupMeanLogMAE'])\n",
    "    def on_epoch_begin(self, **kwargs): self.input, self.output, self.target = [], [], []\n",
    "    \n",
    "    def on_batch_end(self, last_target, last_output, last_input, train, **kwargs):\n",
    "        if not train:\n",
    "            last_e = last_input[1]\n",
    "            if len(last_e.size()) == 4: types = torch.nonzero(last_e[:,:,:,-8:])[:,-1]\n",
    "            else: types = torch.nonzero(last_e[:,:,-8:])[::2,-1]\n",
    "            self.input.append(types)\n",
    "            self.output.append(last_output)\n",
    "            self.target.append(last_target)\n",
    "                \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        if (len(self.input) > 0) and (len(self.output) > 0):\n",
    "            inputs = torch.cat(self.input)\n",
    "            preds = torch.cat(self.output)\n",
    "            target = torch.cat(self.target)\n",
    "            metric = group_mean_log_mae(preds, target, inputs)\n",
    "            return add_metrics(last_metrics, [metric])\n",
    "\n",
    "def set_seed(seed=100):\n",
    "    # python RNG\n",
    "    random.seed(seed)\n",
    "\n",
    "    # pytorch RNGs\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # numpy RNG\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-6\n",
    "update_steps, proc_steps = 5, 10\n",
    "n_x, n_h, n_e = N_ATOM_FEATURES, 50, N_EDGE_FEATURES\n",
    "n_x_m, n_h_m, n_e_m = N_MASTER_FEATURES, 100, N_MASTER_EDGE_FEATURES\n",
    "enn_args = dict(layers=[50, 50, 50, 50], act=nn.ReLU(True), dropout=[0.0, 0.0, 0.0, 0.0], batch_norm=False)\n",
    "master_enn_args = dict(layers=[50, 50, 50, 50], act=nn.ReLU(True), dropout=[0.0, 0.0, 0.0, 0.0], batch_norm=False)\n",
    "R_net_args = dict(layers=[200, 100], act=nn.ReLU(True), dropout=[0.0, 0.0], batch_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(100)\n",
    "if use_master_node:\n",
    "    model = MPNN(n_x, n_h, n_e, update_steps, proc_steps, enn_args, R_net_args, False, use_master_node, \n",
    "                 n_x_m, n_h_m, n_e_m, master_enn_args)\n",
    "else:\n",
    "    model = MPNN(n_x, n_h, n_e, update_steps, proc_steps, enn_args, R_net_args, False, use_master_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(db, model, metrics=[mean_absolute_error], callback_fns=GroupMeanLogMAE, \n",
    "                wd=wd, loss_func=root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(start_lr=1e-8, end_lr=0.1, num_it=200, stop_div=True)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      10.00% [1/10 12:14<1:50:07]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>GroupMeanLogMAE</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.138040</td>\n",
       "      <td>0.134346</td>\n",
       "      <td>0.095290</td>\n",
       "      <td>1.220695</td>\n",
       "      <td>12:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='707' class='' max='1875', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      37.71% [707/1875 04:42<07:46 0.1304]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with GroupMeanLogMAE value: 1.2206945633075212.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, max_lr=1e-3, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='GroupMeanLogMAE',  name='mpnn1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      20.00% [2/10 52:37<3:30:30]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>GroupMeanLogMAE</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.043967</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>0.033247</td>\n",
       "      <td>0.117283</td>\n",
       "      <td>25:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.046034</td>\n",
       "      <td>0.047675</td>\n",
       "      <td>0.033409</td>\n",
       "      <td>0.115949</td>\n",
       "      <td>27:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='1875', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with GroupMeanLogMAE value: 0.11728293677794015.\n",
      "Better model found at epoch 1 with GroupMeanLogMAE value: 0.11594874821080375.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "Traceback (most recent call last):\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda2/envs/python36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-9db314fc83ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m learn.fit_one_cycle(10, max_lr=1e-4, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n\u001b[0;32m----> 2\u001b[0;31m                                                                   monitor='GroupMeanLogMAE',  name='mpnn2')])\n\u001b[0m",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/python36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, max_lr=1e-4, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='GroupMeanLogMAE',  name='mpnn2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=2e-5, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='GroupMeanLogMAE',  name='mpnn3')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=4e-6, callbacks=[SaveModelCallback(learn, every='improvement', mode='min',\n",
    "                                                                  monitor='GroupMeanLogMAE',  name='mpnn4')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CUDA but got backend CPU for argument #3 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-dece9e0ff5d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mget_preds\u001b[0;34m(self, ds_type, with_loss, n_batch, pbar)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mlf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwith_loss\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         return get_preds(self.model, self.dl(ds_type), cb_handler=CallbackHandler(self.callbacks),\n\u001b[0;32m--> 327\u001b[0;31m                          activ=_loss_func2activ(self.loss_func), loss_func=lf, n_batch=n_batch, pbar=pbar)\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpred_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruct\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mget_preds\u001b[0;34m(model, dl, pbar, cb_handler, activ, loss_func, n_batch)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;34m\"Tuple of predictions and targets, and optional losses (if `loss_func`) using `dl`, max batches `n_batch`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     res = [torch.cat(o).cpu() for o in\n\u001b[0;32m---> 43\u001b[0;31m            zip(*validate(model, dl, cb_handler=cb_handler, pbar=pbar, average=False, n_batch=n_batch))]\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mNoneReduceOnCPU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dl, loss_func, cb_handler, pbar, average, n_batch)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-a1d0aa2c73ac>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, e, mask, pairs_idx, edge_mask, x_m, e_m)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_master_node\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mh_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-24023d0184b1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, h, e, mask, pairs_idx, edge_mask, h_m, e_m)\u001b[0m\n\u001b[1;32m     85\u001b[0m                                                  \u001b[0mn_nodes_per_graph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                                              ])).unsqueeze(-1).expand(-1, n_edges)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mm_stacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mah\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_mask_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mm_per_graph_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_stacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nodes_per_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-24023d0184b1>\u001b[0m in \u001b[0;36msegment_sum\u001b[0;34m(data, segment_ids)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msegment_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data.shape and segment_ids.shape should be equal\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CUDA but got backend CPU for argument #3 'index'"
     ]
    }
   ],
   "source": [
    "pred, _ = learn.get_preds()\n",
    "pred_test, _ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
